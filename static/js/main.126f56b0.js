/*! For license information please see main.126f56b0.js.LICENSE.txt */
!function(){var e={463:function(e,t,a){"use strict";var i=a(791),n=a(296);function o(e){for(var t="https://reactjs.org/docs/error-decoder.html?invariant="+e,a=1;a<arguments.length;a++)t+="&args[]="+encodeURIComponent(arguments[a]);return"Minified React error #"+e+"; visit "+t+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}var s=new Set,r={};function c(e,t){l(e,t),l(e+"Capture",t)}function l(e,t){for(r[e]=t,e=0;e<t.length;e++)s.add(t[e])}var d=!("undefined"===typeof window||"undefined"===typeof window.document||"undefined"===typeof window.document.createElement),u=Object.prototype.hasOwnProperty,h=/^[:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD][:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\-.0-9\u00B7\u0300-\u036F\u203F-\u2040]*$/,m={},p={};function f(e,t,a,i,n,o,s){this.acceptsBooleans=2===t||3===t||4===t,this.attributeName=i,this.attributeNamespace=n,this.mustUseProperty=a,this.propertyName=e,this.type=t,this.sanitizeURL=o,this.removeEmptyString=s}var g={};"children dangerouslySetInnerHTML defaultValue defaultChecked innerHTML suppressContentEditableWarning suppressHydrationWarning style".split(" ").forEach((function(e){g[e]=new f(e,0,!1,e,null,!1,!1)})),[["acceptCharset","accept-charset"],["className","class"],["htmlFor","for"],["httpEquiv","http-equiv"]].forEach((function(e){var t=e[0];g[t]=new f(t,1,!1,e[1],null,!1,!1)})),["contentEditable","draggable","spellCheck","value"].forEach((function(e){g[e]=new f(e,2,!1,e.toLowerCase(),null,!1,!1)})),["autoReverse","externalResourcesRequired","focusable","preserveAlpha"].forEach((function(e){g[e]=new f(e,2,!1,e,null,!1,!1)})),"allowFullScreen async autoFocus autoPlay controls default defer disabled disablePictureInPicture disableRemotePlayback formNoValidate hidden loop noModule noValidate open playsInline readOnly required reversed scoped seamless itemScope".split(" ").forEach((function(e){g[e]=new f(e,3,!1,e.toLowerCase(),null,!1,!1)})),["checked","multiple","muted","selected"].forEach((function(e){g[e]=new f(e,3,!0,e,null,!1,!1)})),["capture","download"].forEach((function(e){g[e]=new f(e,4,!1,e,null,!1,!1)})),["cols","rows","size","span"].forEach((function(e){g[e]=new f(e,6,!1,e,null,!1,!1)})),["rowSpan","start"].forEach((function(e){g[e]=new f(e,5,!1,e.toLowerCase(),null,!1,!1)}));var b=/[\-:]([a-z])/g;function v(e){return e[1].toUpperCase()}function y(e,t,a,i){var n=g.hasOwnProperty(t)?g[t]:null;(null!==n?0!==n.type:i||!(2<t.length)||"o"!==t[0]&&"O"!==t[0]||"n"!==t[1]&&"N"!==t[1])&&(function(e,t,a,i){if(null===t||"undefined"===typeof t||function(e,t,a,i){if(null!==a&&0===a.type)return!1;switch(typeof t){case"function":case"symbol":return!0;case"boolean":return!i&&(null!==a?!a.acceptsBooleans:"data-"!==(e=e.toLowerCase().slice(0,5))&&"aria-"!==e);default:return!1}}(e,t,a,i))return!0;if(i)return!1;if(null!==a)switch(a.type){case 3:return!t;case 4:return!1===t;case 5:return isNaN(t);case 6:return isNaN(t)||1>t}return!1}(t,a,n,i)&&(a=null),i||null===n?function(e){return!!u.call(p,e)||!u.call(m,e)&&(h.test(e)?p[e]=!0:(m[e]=!0,!1))}(t)&&(null===a?e.removeAttribute(t):e.setAttribute(t,""+a)):n.mustUseProperty?e[n.propertyName]=null===a?3!==n.type&&"":a:(t=n.attributeName,i=n.attributeNamespace,null===a?e.removeAttribute(t):(a=3===(n=n.type)||4===n&&!0===a?"":""+a,i?e.setAttributeNS(i,t,a):e.setAttribute(t,a))))}"accent-height alignment-baseline arabic-form baseline-shift cap-height clip-path clip-rule color-interpolation color-interpolation-filters color-profile color-rendering dominant-baseline enable-background fill-opacity fill-rule flood-color flood-opacity font-family font-size font-size-adjust font-stretch font-style font-variant font-weight glyph-name glyph-orientation-horizontal glyph-orientation-vertical horiz-adv-x horiz-origin-x image-rendering letter-spacing lighting-color marker-end marker-mid marker-start overline-position overline-thickness paint-order panose-1 pointer-events rendering-intent shape-rendering stop-color stop-opacity strikethrough-position strikethrough-thickness stroke-dasharray stroke-dashoffset stroke-linecap stroke-linejoin stroke-miterlimit stroke-opacity stroke-width text-anchor text-decoration text-rendering underline-position underline-thickness unicode-bidi unicode-range units-per-em v-alphabetic v-hanging v-ideographic v-mathematical vector-effect vert-adv-y vert-origin-x vert-origin-y word-spacing writing-mode xmlns:xlink x-height".split(" ").forEach((function(e){var t=e.replace(b,v);g[t]=new f(t,1,!1,e,null,!1,!1)})),"xlink:actuate xlink:arcrole xlink:role xlink:show xlink:title xlink:type".split(" ").forEach((function(e){var t=e.replace(b,v);g[t]=new f(t,1,!1,e,"http://www.w3.org/1999/xlink",!1,!1)})),["xml:base","xml:lang","xml:space"].forEach((function(e){var t=e.replace(b,v);g[t]=new f(t,1,!1,e,"http://www.w3.org/XML/1998/namespace",!1,!1)})),["tabIndex","crossOrigin"].forEach((function(e){g[e]=new f(e,1,!1,e.toLowerCase(),null,!1,!1)})),g.xlinkHref=new f("xlinkHref",1,!1,"xlink:href","http://www.w3.org/1999/xlink",!0,!1),["src","href","action","formAction"].forEach((function(e){g[e]=new f(e,1,!1,e.toLowerCase(),null,!0,!0)}));var w=i.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED,D=Symbol.for("react.element"),A=Symbol.for("react.portal"),R=Symbol.for("react.fragment"),S=Symbol.for("react.strict_mode"),T=Symbol.for("react.profiler"),C=Symbol.for("react.provider"),E=Symbol.for("react.context"),k=Symbol.for("react.forward_ref"),I=Symbol.for("react.suspense"),M=Symbol.for("react.suspense_list"),O=Symbol.for("react.memo"),L=Symbol.for("react.lazy");Symbol.for("react.scope"),Symbol.for("react.debug_trace_mode");var x=Symbol.for("react.offscreen");Symbol.for("react.legacy_hidden"),Symbol.for("react.cache"),Symbol.for("react.tracing_marker");var P=Symbol.iterator;function B(e){return null===e||"object"!==typeof e?null:"function"===typeof(e=P&&e[P]||e["@@iterator"])?e:null}var N,_=Object.assign;function V(e){if(void 0===N)try{throw Error()}catch(a){var t=a.stack.trim().match(/\n( *(at )?)/);N=t&&t[1]||""}return"\n"+N+e}var W=!1;function F(e,t){if(!e||W)return"";W=!0;var a=Error.prepareStackTrace;Error.prepareStackTrace=void 0;try{if(t)if(t=function(){throw Error()},Object.defineProperty(t.prototype,"props",{set:function(){throw Error()}}),"object"===typeof Reflect&&Reflect.construct){try{Reflect.construct(t,[])}catch(l){var i=l}Reflect.construct(e,[],t)}else{try{t.call()}catch(l){i=l}e.call(t.prototype)}else{try{throw Error()}catch(l){i=l}e()}}catch(l){if(l&&i&&"string"===typeof l.stack){for(var n=l.stack.split("\n"),o=i.stack.split("\n"),s=n.length-1,r=o.length-1;1<=s&&0<=r&&n[s]!==o[r];)r--;for(;1<=s&&0<=r;s--,r--)if(n[s]!==o[r]){if(1!==s||1!==r)do{if(s--,0>--r||n[s]!==o[r]){var c="\n"+n[s].replace(" at new "," at ");return e.displayName&&c.includes("<anonymous>")&&(c=c.replace("<anonymous>",e.displayName)),c}}while(1<=s&&0<=r);break}}}finally{W=!1,Error.prepareStackTrace=a}return(e=e?e.displayName||e.name:"")?V(e):""}function j(e){switch(e.tag){case 5:return V(e.type);case 16:return V("Lazy");case 13:return V("Suspense");case 19:return V("SuspenseList");case 0:case 2:case 15:return e=F(e.type,!1);case 11:return e=F(e.type.render,!1);case 1:return e=F(e.type,!0);default:return""}}function U(e){if(null==e)return null;if("function"===typeof e)return e.displayName||e.name||null;if("string"===typeof e)return e;switch(e){case R:return"Fragment";case A:return"Portal";case T:return"Profiler";case S:return"StrictMode";case I:return"Suspense";case M:return"SuspenseList"}if("object"===typeof e)switch(e.$$typeof){case E:return(e.displayName||"Context")+".Consumer";case C:return(e._context.displayName||"Context")+".Provider";case k:var t=e.render;return(e=e.displayName)||(e=""!==(e=t.displayName||t.name||"")?"ForwardRef("+e+")":"ForwardRef"),e;case O:return null!==(t=e.displayName||null)?t:U(e.type)||"Memo";case L:t=e._payload,e=e._init;try{return U(e(t))}catch(a){}}return null}function z(e){var t=e.type;switch(e.tag){case 24:return"Cache";case 9:return(t.displayName||"Context")+".Consumer";case 10:return(t._context.displayName||"Context")+".Provider";case 18:return"DehydratedFragment";case 11:return e=(e=t.render).displayName||e.name||"",t.displayName||(""!==e?"ForwardRef("+e+")":"ForwardRef");case 7:return"Fragment";case 5:return t;case 4:return"Portal";case 3:return"Root";case 6:return"Text";case 16:return U(t);case 8:return t===S?"StrictMode":"Mode";case 22:return"Offscreen";case 12:return"Profiler";case 21:return"Scope";case 13:return"Suspense";case 19:return"SuspenseList";case 25:return"TracingMarker";case 1:case 0:case 17:case 2:case 14:case 15:if("function"===typeof t)return t.displayName||t.name||null;if("string"===typeof t)return t}return null}function G(e){switch(typeof e){case"boolean":case"number":case"string":case"undefined":case"object":return e;default:return""}}function H(e){var t=e.type;return(e=e.nodeName)&&"input"===e.toLowerCase()&&("checkbox"===t||"radio"===t)}function q(e){e._valueTracker||(e._valueTracker=function(e){var t=H(e)?"checked":"value",a=Object.getOwnPropertyDescriptor(e.constructor.prototype,t),i=""+e[t];if(!e.hasOwnProperty(t)&&"undefined"!==typeof a&&"function"===typeof a.get&&"function"===typeof a.set){var n=a.get,o=a.set;return Object.defineProperty(e,t,{configurable:!0,get:function(){return n.call(this)},set:function(e){i=""+e,o.call(this,e)}}),Object.defineProperty(e,t,{enumerable:a.enumerable}),{getValue:function(){return i},setValue:function(e){i=""+e},stopTracking:function(){e._valueTracker=null,delete e[t]}}}}(e))}function K(e){if(!e)return!1;var t=e._valueTracker;if(!t)return!0;var a=t.getValue(),i="";return e&&(i=H(e)?e.checked?"true":"false":e.value),(e=i)!==a&&(t.setValue(e),!0)}function Q(e){if("undefined"===typeof(e=e||("undefined"!==typeof document?document:void 0)))return null;try{return e.activeElement||e.body}catch(t){return e.body}}function J(e,t){var a=t.checked;return _({},t,{defaultChecked:void 0,defaultValue:void 0,value:void 0,checked:null!=a?a:e._wrapperState.initialChecked})}function Y(e,t){var a=null==t.defaultValue?"":t.defaultValue,i=null!=t.checked?t.checked:t.defaultChecked;a=G(null!=t.value?t.value:a),e._wrapperState={initialChecked:i,initialValue:a,controlled:"checkbox"===t.type||"radio"===t.type?null!=t.checked:null!=t.value}}function X(e,t){null!=(t=t.checked)&&y(e,"checked",t,!1)}function Z(e,t){X(e,t);var a=G(t.value),i=t.type;if(null!=a)"number"===i?(0===a&&""===e.value||e.value!=a)&&(e.value=""+a):e.value!==""+a&&(e.value=""+a);else if("submit"===i||"reset"===i)return void e.removeAttribute("value");t.hasOwnProperty("value")?ee(e,t.type,a):t.hasOwnProperty("defaultValue")&&ee(e,t.type,G(t.defaultValue)),null==t.checked&&null!=t.defaultChecked&&(e.defaultChecked=!!t.defaultChecked)}function $(e,t,a){if(t.hasOwnProperty("value")||t.hasOwnProperty("defaultValue")){var i=t.type;if(!("submit"!==i&&"reset"!==i||void 0!==t.value&&null!==t.value))return;t=""+e._wrapperState.initialValue,a||t===e.value||(e.value=t),e.defaultValue=t}""!==(a=e.name)&&(e.name=""),e.defaultChecked=!!e._wrapperState.initialChecked,""!==a&&(e.name=a)}function ee(e,t,a){"number"===t&&Q(e.ownerDocument)===e||(null==a?e.defaultValue=""+e._wrapperState.initialValue:e.defaultValue!==""+a&&(e.defaultValue=""+a))}var te=Array.isArray;function ae(e,t,a,i){if(e=e.options,t){t={};for(var n=0;n<a.length;n++)t["$"+a[n]]=!0;for(a=0;a<e.length;a++)n=t.hasOwnProperty("$"+e[a].value),e[a].selected!==n&&(e[a].selected=n),n&&i&&(e[a].defaultSelected=!0)}else{for(a=""+G(a),t=null,n=0;n<e.length;n++){if(e[n].value===a)return e[n].selected=!0,void(i&&(e[n].defaultSelected=!0));null!==t||e[n].disabled||(t=e[n])}null!==t&&(t.selected=!0)}}function ie(e,t){if(null!=t.dangerouslySetInnerHTML)throw Error(o(91));return _({},t,{value:void 0,defaultValue:void 0,children:""+e._wrapperState.initialValue})}function ne(e,t){var a=t.value;if(null==a){if(a=t.children,t=t.defaultValue,null!=a){if(null!=t)throw Error(o(92));if(te(a)){if(1<a.length)throw Error(o(93));a=a[0]}t=a}null==t&&(t=""),a=t}e._wrapperState={initialValue:G(a)}}function oe(e,t){var a=G(t.value),i=G(t.defaultValue);null!=a&&((a=""+a)!==e.value&&(e.value=a),null==t.defaultValue&&e.defaultValue!==a&&(e.defaultValue=a)),null!=i&&(e.defaultValue=""+i)}function se(e){var t=e.textContent;t===e._wrapperState.initialValue&&""!==t&&null!==t&&(e.value=t)}function re(e){switch(e){case"svg":return"http://www.w3.org/2000/svg";case"math":return"http://www.w3.org/1998/Math/MathML";default:return"http://www.w3.org/1999/xhtml"}}function ce(e,t){return null==e||"http://www.w3.org/1999/xhtml"===e?re(t):"http://www.w3.org/2000/svg"===e&&"foreignObject"===t?"http://www.w3.org/1999/xhtml":e}var le,de,ue=(de=function(e,t){if("http://www.w3.org/2000/svg"!==e.namespaceURI||"innerHTML"in e)e.innerHTML=t;else{for((le=le||document.createElement("div")).innerHTML="<svg>"+t.valueOf().toString()+"</svg>",t=le.firstChild;e.firstChild;)e.removeChild(e.firstChild);for(;t.firstChild;)e.appendChild(t.firstChild)}},"undefined"!==typeof MSApp&&MSApp.execUnsafeLocalFunction?function(e,t,a,i){MSApp.execUnsafeLocalFunction((function(){return de(e,t)}))}:de);function he(e,t){if(t){var a=e.firstChild;if(a&&a===e.lastChild&&3===a.nodeType)return void(a.nodeValue=t)}e.textContent=t}var me={animationIterationCount:!0,aspectRatio:!0,borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,columns:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridArea:!0,gridRow:!0,gridRowEnd:!0,gridRowSpan:!0,gridRowStart:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnSpan:!0,gridColumnStart:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,zoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},pe=["Webkit","ms","Moz","O"];function fe(e,t,a){return null==t||"boolean"===typeof t||""===t?"":a||"number"!==typeof t||0===t||me.hasOwnProperty(e)&&me[e]?(""+t).trim():t+"px"}function ge(e,t){for(var a in e=e.style,t)if(t.hasOwnProperty(a)){var i=0===a.indexOf("--"),n=fe(a,t[a],i);"float"===a&&(a="cssFloat"),i?e.setProperty(a,n):e[a]=n}}Object.keys(me).forEach((function(e){pe.forEach((function(t){t=t+e.charAt(0).toUpperCase()+e.substring(1),me[t]=me[e]}))}));var be=_({menuitem:!0},{area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0});function ve(e,t){if(t){if(be[e]&&(null!=t.children||null!=t.dangerouslySetInnerHTML))throw Error(o(137,e));if(null!=t.dangerouslySetInnerHTML){if(null!=t.children)throw Error(o(60));if("object"!==typeof t.dangerouslySetInnerHTML||!("__html"in t.dangerouslySetInnerHTML))throw Error(o(61))}if(null!=t.style&&"object"!==typeof t.style)throw Error(o(62))}}function ye(e,t){if(-1===e.indexOf("-"))return"string"===typeof t.is;switch(e){case"annotation-xml":case"color-profile":case"font-face":case"font-face-src":case"font-face-uri":case"font-face-format":case"font-face-name":case"missing-glyph":return!1;default:return!0}}var we=null;function De(e){return(e=e.target||e.srcElement||window).correspondingUseElement&&(e=e.correspondingUseElement),3===e.nodeType?e.parentNode:e}var Ae=null,Re=null,Se=null;function Te(e){if(e=yn(e)){if("function"!==typeof Ae)throw Error(o(280));var t=e.stateNode;t&&(t=Dn(t),Ae(e.stateNode,e.type,t))}}function Ce(e){Re?Se?Se.push(e):Se=[e]:Re=e}function Ee(){if(Re){var e=Re,t=Se;if(Se=Re=null,Te(e),t)for(e=0;e<t.length;e++)Te(t[e])}}function ke(e,t){return e(t)}function Ie(){}var Me=!1;function Oe(e,t,a){if(Me)return e(t,a);Me=!0;try{return ke(e,t,a)}finally{Me=!1,(null!==Re||null!==Se)&&(Ie(),Ee())}}function Le(e,t){var a=e.stateNode;if(null===a)return null;var i=Dn(a);if(null===i)return null;a=i[t];e:switch(t){case"onClick":case"onClickCapture":case"onDoubleClick":case"onDoubleClickCapture":case"onMouseDown":case"onMouseDownCapture":case"onMouseMove":case"onMouseMoveCapture":case"onMouseUp":case"onMouseUpCapture":case"onMouseEnter":(i=!i.disabled)||(i=!("button"===(e=e.type)||"input"===e||"select"===e||"textarea"===e)),e=!i;break e;default:e=!1}if(e)return null;if(a&&"function"!==typeof a)throw Error(o(231,t,typeof a));return a}var xe=!1;if(d)try{var Pe={};Object.defineProperty(Pe,"passive",{get:function(){xe=!0}}),window.addEventListener("test",Pe,Pe),window.removeEventListener("test",Pe,Pe)}catch(de){xe=!1}function Be(e,t,a,i,n,o,s,r,c){var l=Array.prototype.slice.call(arguments,3);try{t.apply(a,l)}catch(d){this.onError(d)}}var Ne=!1,_e=null,Ve=!1,We=null,Fe={onError:function(e){Ne=!0,_e=e}};function je(e,t,a,i,n,o,s,r,c){Ne=!1,_e=null,Be.apply(Fe,arguments)}function Ue(e){var t=e,a=e;if(e.alternate)for(;t.return;)t=t.return;else{e=t;do{0!==(4098&(t=e).flags)&&(a=t.return),e=t.return}while(e)}return 3===t.tag?a:null}function ze(e){if(13===e.tag){var t=e.memoizedState;if(null===t&&(null!==(e=e.alternate)&&(t=e.memoizedState)),null!==t)return t.dehydrated}return null}function Ge(e){if(Ue(e)!==e)throw Error(o(188))}function He(e){return null!==(e=function(e){var t=e.alternate;if(!t){if(null===(t=Ue(e)))throw Error(o(188));return t!==e?null:e}for(var a=e,i=t;;){var n=a.return;if(null===n)break;var s=n.alternate;if(null===s){if(null!==(i=n.return)){a=i;continue}break}if(n.child===s.child){for(s=n.child;s;){if(s===a)return Ge(n),e;if(s===i)return Ge(n),t;s=s.sibling}throw Error(o(188))}if(a.return!==i.return)a=n,i=s;else{for(var r=!1,c=n.child;c;){if(c===a){r=!0,a=n,i=s;break}if(c===i){r=!0,i=n,a=s;break}c=c.sibling}if(!r){for(c=s.child;c;){if(c===a){r=!0,a=s,i=n;break}if(c===i){r=!0,i=s,a=n;break}c=c.sibling}if(!r)throw Error(o(189))}}if(a.alternate!==i)throw Error(o(190))}if(3!==a.tag)throw Error(o(188));return a.stateNode.current===a?e:t}(e))?qe(e):null}function qe(e){if(5===e.tag||6===e.tag)return e;for(e=e.child;null!==e;){var t=qe(e);if(null!==t)return t;e=e.sibling}return null}var Ke=n.unstable_scheduleCallback,Qe=n.unstable_cancelCallback,Je=n.unstable_shouldYield,Ye=n.unstable_requestPaint,Xe=n.unstable_now,Ze=n.unstable_getCurrentPriorityLevel,$e=n.unstable_ImmediatePriority,et=n.unstable_UserBlockingPriority,tt=n.unstable_NormalPriority,at=n.unstable_LowPriority,it=n.unstable_IdlePriority,nt=null,ot=null;var st=Math.clz32?Math.clz32:function(e){return e>>>=0,0===e?32:31-(rt(e)/ct|0)|0},rt=Math.log,ct=Math.LN2;var lt=64,dt=4194304;function ut(e){switch(e&-e){case 1:return 1;case 2:return 2;case 4:return 4;case 8:return 8;case 16:return 16;case 32:return 32;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return 4194240&e;case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:return 130023424&e;case 134217728:return 134217728;case 268435456:return 268435456;case 536870912:return 536870912;case 1073741824:return 1073741824;default:return e}}function ht(e,t){var a=e.pendingLanes;if(0===a)return 0;var i=0,n=e.suspendedLanes,o=e.pingedLanes,s=268435455&a;if(0!==s){var r=s&~n;0!==r?i=ut(r):0!==(o&=s)&&(i=ut(o))}else 0!==(s=a&~n)?i=ut(s):0!==o&&(i=ut(o));if(0===i)return 0;if(0!==t&&t!==i&&0===(t&n)&&((n=i&-i)>=(o=t&-t)||16===n&&0!==(4194240&o)))return t;if(0!==(4&i)&&(i|=16&a),0!==(t=e.entangledLanes))for(e=e.entanglements,t&=i;0<t;)n=1<<(a=31-st(t)),i|=e[a],t&=~n;return i}function mt(e,t){switch(e){case 1:case 2:case 4:return t+250;case 8:case 16:case 32:case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return t+5e3;default:return-1}}function pt(e){return 0!==(e=-1073741825&e.pendingLanes)?e:1073741824&e?1073741824:0}function ft(){var e=lt;return 0===(4194240&(lt<<=1))&&(lt=64),e}function gt(e){for(var t=[],a=0;31>a;a++)t.push(e);return t}function bt(e,t,a){e.pendingLanes|=t,536870912!==t&&(e.suspendedLanes=0,e.pingedLanes=0),(e=e.eventTimes)[t=31-st(t)]=a}function vt(e,t){var a=e.entangledLanes|=t;for(e=e.entanglements;a;){var i=31-st(a),n=1<<i;n&t|e[i]&t&&(e[i]|=t),a&=~n}}var yt=0;function wt(e){return 1<(e&=-e)?4<e?0!==(268435455&e)?16:536870912:4:1}var Dt,At,Rt,St,Tt,Ct=!1,Et=[],kt=null,It=null,Mt=null,Ot=new Map,Lt=new Map,xt=[],Pt="mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput copy cut paste click change contextmenu reset submit".split(" ");function Bt(e,t){switch(e){case"focusin":case"focusout":kt=null;break;case"dragenter":case"dragleave":It=null;break;case"mouseover":case"mouseout":Mt=null;break;case"pointerover":case"pointerout":Ot.delete(t.pointerId);break;case"gotpointercapture":case"lostpointercapture":Lt.delete(t.pointerId)}}function Nt(e,t,a,i,n,o){return null===e||e.nativeEvent!==o?(e={blockedOn:t,domEventName:a,eventSystemFlags:i,nativeEvent:o,targetContainers:[n]},null!==t&&(null!==(t=yn(t))&&At(t)),e):(e.eventSystemFlags|=i,t=e.targetContainers,null!==n&&-1===t.indexOf(n)&&t.push(n),e)}function _t(e){var t=vn(e.target);if(null!==t){var a=Ue(t);if(null!==a)if(13===(t=a.tag)){if(null!==(t=ze(a)))return e.blockedOn=t,void Tt(e.priority,(function(){Rt(a)}))}else if(3===t&&a.stateNode.current.memoizedState.isDehydrated)return void(e.blockedOn=3===a.tag?a.stateNode.containerInfo:null)}e.blockedOn=null}function Vt(e){if(null!==e.blockedOn)return!1;for(var t=e.targetContainers;0<t.length;){var a=Jt(e.domEventName,e.eventSystemFlags,t[0],e.nativeEvent);if(null!==a)return null!==(t=yn(a))&&At(t),e.blockedOn=a,!1;var i=new(a=e.nativeEvent).constructor(a.type,a);we=i,a.target.dispatchEvent(i),we=null,t.shift()}return!0}function Wt(e,t,a){Vt(e)&&a.delete(t)}function Ft(){Ct=!1,null!==kt&&Vt(kt)&&(kt=null),null!==It&&Vt(It)&&(It=null),null!==Mt&&Vt(Mt)&&(Mt=null),Ot.forEach(Wt),Lt.forEach(Wt)}function jt(e,t){e.blockedOn===t&&(e.blockedOn=null,Ct||(Ct=!0,n.unstable_scheduleCallback(n.unstable_NormalPriority,Ft)))}function Ut(e){function t(t){return jt(t,e)}if(0<Et.length){jt(Et[0],e);for(var a=1;a<Et.length;a++){var i=Et[a];i.blockedOn===e&&(i.blockedOn=null)}}for(null!==kt&&jt(kt,e),null!==It&&jt(It,e),null!==Mt&&jt(Mt,e),Ot.forEach(t),Lt.forEach(t),a=0;a<xt.length;a++)(i=xt[a]).blockedOn===e&&(i.blockedOn=null);for(;0<xt.length&&null===(a=xt[0]).blockedOn;)_t(a),null===a.blockedOn&&xt.shift()}var zt=w.ReactCurrentBatchConfig,Gt=!0;function Ht(e,t,a,i){var n=yt,o=zt.transition;zt.transition=null;try{yt=1,Kt(e,t,a,i)}finally{yt=n,zt.transition=o}}function qt(e,t,a,i){var n=yt,o=zt.transition;zt.transition=null;try{yt=4,Kt(e,t,a,i)}finally{yt=n,zt.transition=o}}function Kt(e,t,a,i){if(Gt){var n=Jt(e,t,a,i);if(null===n)zi(e,t,i,Qt,a),Bt(e,i);else if(function(e,t,a,i,n){switch(t){case"focusin":return kt=Nt(kt,e,t,a,i,n),!0;case"dragenter":return It=Nt(It,e,t,a,i,n),!0;case"mouseover":return Mt=Nt(Mt,e,t,a,i,n),!0;case"pointerover":var o=n.pointerId;return Ot.set(o,Nt(Ot.get(o)||null,e,t,a,i,n)),!0;case"gotpointercapture":return o=n.pointerId,Lt.set(o,Nt(Lt.get(o)||null,e,t,a,i,n)),!0}return!1}(n,e,t,a,i))i.stopPropagation();else if(Bt(e,i),4&t&&-1<Pt.indexOf(e)){for(;null!==n;){var o=yn(n);if(null!==o&&Dt(o),null===(o=Jt(e,t,a,i))&&zi(e,t,i,Qt,a),o===n)break;n=o}null!==n&&i.stopPropagation()}else zi(e,t,i,null,a)}}var Qt=null;function Jt(e,t,a,i){if(Qt=null,null!==(e=vn(e=De(i))))if(null===(t=Ue(e)))e=null;else if(13===(a=t.tag)){if(null!==(e=ze(t)))return e;e=null}else if(3===a){if(t.stateNode.current.memoizedState.isDehydrated)return 3===t.tag?t.stateNode.containerInfo:null;e=null}else t!==e&&(e=null);return Qt=e,null}function Yt(e){switch(e){case"cancel":case"click":case"close":case"contextmenu":case"copy":case"cut":case"auxclick":case"dblclick":case"dragend":case"dragstart":case"drop":case"focusin":case"focusout":case"input":case"invalid":case"keydown":case"keypress":case"keyup":case"mousedown":case"mouseup":case"paste":case"pause":case"play":case"pointercancel":case"pointerdown":case"pointerup":case"ratechange":case"reset":case"resize":case"seeked":case"submit":case"touchcancel":case"touchend":case"touchstart":case"volumechange":case"change":case"selectionchange":case"textInput":case"compositionstart":case"compositionend":case"compositionupdate":case"beforeblur":case"afterblur":case"beforeinput":case"blur":case"fullscreenchange":case"focus":case"hashchange":case"popstate":case"select":case"selectstart":return 1;case"drag":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"mousemove":case"mouseout":case"mouseover":case"pointermove":case"pointerout":case"pointerover":case"scroll":case"toggle":case"touchmove":case"wheel":case"mouseenter":case"mouseleave":case"pointerenter":case"pointerleave":return 4;case"message":switch(Ze()){case $e:return 1;case et:return 4;case tt:case at:return 16;case it:return 536870912;default:return 16}default:return 16}}var Xt=null,Zt=null,$t=null;function ea(){if($t)return $t;var e,t,a=Zt,i=a.length,n="value"in Xt?Xt.value:Xt.textContent,o=n.length;for(e=0;e<i&&a[e]===n[e];e++);var s=i-e;for(t=1;t<=s&&a[i-t]===n[o-t];t++);return $t=n.slice(e,1<t?1-t:void 0)}function ta(e){var t=e.keyCode;return"charCode"in e?0===(e=e.charCode)&&13===t&&(e=13):e=t,10===e&&(e=13),32<=e||13===e?e:0}function aa(){return!0}function ia(){return!1}function na(e){function t(t,a,i,n,o){for(var s in this._reactName=t,this._targetInst=i,this.type=a,this.nativeEvent=n,this.target=o,this.currentTarget=null,e)e.hasOwnProperty(s)&&(t=e[s],this[s]=t?t(n):n[s]);return this.isDefaultPrevented=(null!=n.defaultPrevented?n.defaultPrevented:!1===n.returnValue)?aa:ia,this.isPropagationStopped=ia,this}return _(t.prototype,{preventDefault:function(){this.defaultPrevented=!0;var e=this.nativeEvent;e&&(e.preventDefault?e.preventDefault():"unknown"!==typeof e.returnValue&&(e.returnValue=!1),this.isDefaultPrevented=aa)},stopPropagation:function(){var e=this.nativeEvent;e&&(e.stopPropagation?e.stopPropagation():"unknown"!==typeof e.cancelBubble&&(e.cancelBubble=!0),this.isPropagationStopped=aa)},persist:function(){},isPersistent:aa}),t}var oa,sa,ra,ca={eventPhase:0,bubbles:0,cancelable:0,timeStamp:function(e){return e.timeStamp||Date.now()},defaultPrevented:0,isTrusted:0},la=na(ca),da=_({},ca,{view:0,detail:0}),ua=na(da),ha=_({},da,{screenX:0,screenY:0,clientX:0,clientY:0,pageX:0,pageY:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,getModifierState:Sa,button:0,buttons:0,relatedTarget:function(e){return void 0===e.relatedTarget?e.fromElement===e.srcElement?e.toElement:e.fromElement:e.relatedTarget},movementX:function(e){return"movementX"in e?e.movementX:(e!==ra&&(ra&&"mousemove"===e.type?(oa=e.screenX-ra.screenX,sa=e.screenY-ra.screenY):sa=oa=0,ra=e),oa)},movementY:function(e){return"movementY"in e?e.movementY:sa}}),ma=na(ha),pa=na(_({},ha,{dataTransfer:0})),fa=na(_({},da,{relatedTarget:0})),ga=na(_({},ca,{animationName:0,elapsedTime:0,pseudoElement:0})),ba=_({},ca,{clipboardData:function(e){return"clipboardData"in e?e.clipboardData:window.clipboardData}}),va=na(ba),ya=na(_({},ca,{data:0})),wa={Esc:"Escape",Spacebar:" ",Left:"ArrowLeft",Up:"ArrowUp",Right:"ArrowRight",Down:"ArrowDown",Del:"Delete",Win:"OS",Menu:"ContextMenu",Apps:"ContextMenu",Scroll:"ScrollLock",MozPrintableKey:"Unidentified"},Da={8:"Backspace",9:"Tab",12:"Clear",13:"Enter",16:"Shift",17:"Control",18:"Alt",19:"Pause",20:"CapsLock",27:"Escape",32:" ",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"ArrowLeft",38:"ArrowUp",39:"ArrowRight",40:"ArrowDown",45:"Insert",46:"Delete",112:"F1",113:"F2",114:"F3",115:"F4",116:"F5",117:"F6",118:"F7",119:"F8",120:"F9",121:"F10",122:"F11",123:"F12",144:"NumLock",145:"ScrollLock",224:"Meta"},Aa={Alt:"altKey",Control:"ctrlKey",Meta:"metaKey",Shift:"shiftKey"};function Ra(e){var t=this.nativeEvent;return t.getModifierState?t.getModifierState(e):!!(e=Aa[e])&&!!t[e]}function Sa(){return Ra}var Ta=_({},da,{key:function(e){if(e.key){var t=wa[e.key]||e.key;if("Unidentified"!==t)return t}return"keypress"===e.type?13===(e=ta(e))?"Enter":String.fromCharCode(e):"keydown"===e.type||"keyup"===e.type?Da[e.keyCode]||"Unidentified":""},code:0,location:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,repeat:0,locale:0,getModifierState:Sa,charCode:function(e){return"keypress"===e.type?ta(e):0},keyCode:function(e){return"keydown"===e.type||"keyup"===e.type?e.keyCode:0},which:function(e){return"keypress"===e.type?ta(e):"keydown"===e.type||"keyup"===e.type?e.keyCode:0}}),Ca=na(Ta),Ea=na(_({},ha,{pointerId:0,width:0,height:0,pressure:0,tangentialPressure:0,tiltX:0,tiltY:0,twist:0,pointerType:0,isPrimary:0})),ka=na(_({},da,{touches:0,targetTouches:0,changedTouches:0,altKey:0,metaKey:0,ctrlKey:0,shiftKey:0,getModifierState:Sa})),Ia=na(_({},ca,{propertyName:0,elapsedTime:0,pseudoElement:0})),Ma=_({},ha,{deltaX:function(e){return"deltaX"in e?e.deltaX:"wheelDeltaX"in e?-e.wheelDeltaX:0},deltaY:function(e){return"deltaY"in e?e.deltaY:"wheelDeltaY"in e?-e.wheelDeltaY:"wheelDelta"in e?-e.wheelDelta:0},deltaZ:0,deltaMode:0}),Oa=na(Ma),La=[9,13,27,32],xa=d&&"CompositionEvent"in window,Pa=null;d&&"documentMode"in document&&(Pa=document.documentMode);var Ba=d&&"TextEvent"in window&&!Pa,Na=d&&(!xa||Pa&&8<Pa&&11>=Pa),_a=String.fromCharCode(32),Va=!1;function Wa(e,t){switch(e){case"keyup":return-1!==La.indexOf(t.keyCode);case"keydown":return 229!==t.keyCode;case"keypress":case"mousedown":case"focusout":return!0;default:return!1}}function Fa(e){return"object"===typeof(e=e.detail)&&"data"in e?e.data:null}var ja=!1;var Ua={color:!0,date:!0,datetime:!0,"datetime-local":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0};function za(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return"input"===t?!!Ua[e.type]:"textarea"===t}function Ga(e,t,a,i){Ce(i),0<(t=Hi(t,"onChange")).length&&(a=new la("onChange","change",null,a,i),e.push({event:a,listeners:t}))}var Ha=null,qa=null;function Ka(e){_i(e,0)}function Qa(e){if(K(wn(e)))return e}function Ja(e,t){if("change"===e)return t}var Ya=!1;if(d){var Xa;if(d){var Za="oninput"in document;if(!Za){var $a=document.createElement("div");$a.setAttribute("oninput","return;"),Za="function"===typeof $a.oninput}Xa=Za}else Xa=!1;Ya=Xa&&(!document.documentMode||9<document.documentMode)}function ei(){Ha&&(Ha.detachEvent("onpropertychange",ti),qa=Ha=null)}function ti(e){if("value"===e.propertyName&&Qa(qa)){var t=[];Ga(t,qa,e,De(e)),Oe(Ka,t)}}function ai(e,t,a){"focusin"===e?(ei(),qa=a,(Ha=t).attachEvent("onpropertychange",ti)):"focusout"===e&&ei()}function ii(e){if("selectionchange"===e||"keyup"===e||"keydown"===e)return Qa(qa)}function ni(e,t){if("click"===e)return Qa(t)}function oi(e,t){if("input"===e||"change"===e)return Qa(t)}var si="function"===typeof Object.is?Object.is:function(e,t){return e===t&&(0!==e||1/e===1/t)||e!==e&&t!==t};function ri(e,t){if(si(e,t))return!0;if("object"!==typeof e||null===e||"object"!==typeof t||null===t)return!1;var a=Object.keys(e),i=Object.keys(t);if(a.length!==i.length)return!1;for(i=0;i<a.length;i++){var n=a[i];if(!u.call(t,n)||!si(e[n],t[n]))return!1}return!0}function ci(e){for(;e&&e.firstChild;)e=e.firstChild;return e}function li(e,t){var a,i=ci(e);for(e=0;i;){if(3===i.nodeType){if(a=e+i.textContent.length,e<=t&&a>=t)return{node:i,offset:t-e};e=a}e:{for(;i;){if(i.nextSibling){i=i.nextSibling;break e}i=i.parentNode}i=void 0}i=ci(i)}}function di(e,t){return!(!e||!t)&&(e===t||(!e||3!==e.nodeType)&&(t&&3===t.nodeType?di(e,t.parentNode):"contains"in e?e.contains(t):!!e.compareDocumentPosition&&!!(16&e.compareDocumentPosition(t))))}function ui(){for(var e=window,t=Q();t instanceof e.HTMLIFrameElement;){try{var a="string"===typeof t.contentWindow.location.href}catch(i){a=!1}if(!a)break;t=Q((e=t.contentWindow).document)}return t}function hi(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return t&&("input"===t&&("text"===e.type||"search"===e.type||"tel"===e.type||"url"===e.type||"password"===e.type)||"textarea"===t||"true"===e.contentEditable)}function mi(e){var t=ui(),a=e.focusedElem,i=e.selectionRange;if(t!==a&&a&&a.ownerDocument&&di(a.ownerDocument.documentElement,a)){if(null!==i&&hi(a))if(t=i.start,void 0===(e=i.end)&&(e=t),"selectionStart"in a)a.selectionStart=t,a.selectionEnd=Math.min(e,a.value.length);else if((e=(t=a.ownerDocument||document)&&t.defaultView||window).getSelection){e=e.getSelection();var n=a.textContent.length,o=Math.min(i.start,n);i=void 0===i.end?o:Math.min(i.end,n),!e.extend&&o>i&&(n=i,i=o,o=n),n=li(a,o);var s=li(a,i);n&&s&&(1!==e.rangeCount||e.anchorNode!==n.node||e.anchorOffset!==n.offset||e.focusNode!==s.node||e.focusOffset!==s.offset)&&((t=t.createRange()).setStart(n.node,n.offset),e.removeAllRanges(),o>i?(e.addRange(t),e.extend(s.node,s.offset)):(t.setEnd(s.node,s.offset),e.addRange(t)))}for(t=[],e=a;e=e.parentNode;)1===e.nodeType&&t.push({element:e,left:e.scrollLeft,top:e.scrollTop});for("function"===typeof a.focus&&a.focus(),a=0;a<t.length;a++)(e=t[a]).element.scrollLeft=e.left,e.element.scrollTop=e.top}}var pi=d&&"documentMode"in document&&11>=document.documentMode,fi=null,gi=null,bi=null,vi=!1;function yi(e,t,a){var i=a.window===a?a.document:9===a.nodeType?a:a.ownerDocument;vi||null==fi||fi!==Q(i)||("selectionStart"in(i=fi)&&hi(i)?i={start:i.selectionStart,end:i.selectionEnd}:i={anchorNode:(i=(i.ownerDocument&&i.ownerDocument.defaultView||window).getSelection()).anchorNode,anchorOffset:i.anchorOffset,focusNode:i.focusNode,focusOffset:i.focusOffset},bi&&ri(bi,i)||(bi=i,0<(i=Hi(gi,"onSelect")).length&&(t=new la("onSelect","select",null,t,a),e.push({event:t,listeners:i}),t.target=fi)))}function wi(e,t){var a={};return a[e.toLowerCase()]=t.toLowerCase(),a["Webkit"+e]="webkit"+t,a["Moz"+e]="moz"+t,a}var Di={animationend:wi("Animation","AnimationEnd"),animationiteration:wi("Animation","AnimationIteration"),animationstart:wi("Animation","AnimationStart"),transitionend:wi("Transition","TransitionEnd")},Ai={},Ri={};function Si(e){if(Ai[e])return Ai[e];if(!Di[e])return e;var t,a=Di[e];for(t in a)if(a.hasOwnProperty(t)&&t in Ri)return Ai[e]=a[t];return e}d&&(Ri=document.createElement("div").style,"AnimationEvent"in window||(delete Di.animationend.animation,delete Di.animationiteration.animation,delete Di.animationstart.animation),"TransitionEvent"in window||delete Di.transitionend.transition);var Ti=Si("animationend"),Ci=Si("animationiteration"),Ei=Si("animationstart"),ki=Si("transitionend"),Ii=new Map,Mi="abort auxClick cancel canPlay canPlayThrough click close contextMenu copy cut drag dragEnd dragEnter dragExit dragLeave dragOver dragStart drop durationChange emptied encrypted ended error gotPointerCapture input invalid keyDown keyPress keyUp load loadedData loadedMetadata loadStart lostPointerCapture mouseDown mouseMove mouseOut mouseOver mouseUp paste pause play playing pointerCancel pointerDown pointerMove pointerOut pointerOver pointerUp progress rateChange reset resize seeked seeking stalled submit suspend timeUpdate touchCancel touchEnd touchStart volumeChange scroll toggle touchMove waiting wheel".split(" ");function Oi(e,t){Ii.set(e,t),c(t,[e])}for(var Li=0;Li<Mi.length;Li++){var xi=Mi[Li];Oi(xi.toLowerCase(),"on"+(xi[0].toUpperCase()+xi.slice(1)))}Oi(Ti,"onAnimationEnd"),Oi(Ci,"onAnimationIteration"),Oi(Ei,"onAnimationStart"),Oi("dblclick","onDoubleClick"),Oi("focusin","onFocus"),Oi("focusout","onBlur"),Oi(ki,"onTransitionEnd"),l("onMouseEnter",["mouseout","mouseover"]),l("onMouseLeave",["mouseout","mouseover"]),l("onPointerEnter",["pointerout","pointerover"]),l("onPointerLeave",["pointerout","pointerover"]),c("onChange","change click focusin focusout input keydown keyup selectionchange".split(" ")),c("onSelect","focusout contextmenu dragend focusin keydown keyup mousedown mouseup selectionchange".split(" ")),c("onBeforeInput",["compositionend","keypress","textInput","paste"]),c("onCompositionEnd","compositionend focusout keydown keypress keyup mousedown".split(" ")),c("onCompositionStart","compositionstart focusout keydown keypress keyup mousedown".split(" ")),c("onCompositionUpdate","compositionupdate focusout keydown keypress keyup mousedown".split(" "));var Pi="abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange resize seeked seeking stalled suspend timeupdate volumechange waiting".split(" "),Bi=new Set("cancel close invalid load scroll toggle".split(" ").concat(Pi));function Ni(e,t,a){var i=e.type||"unknown-event";e.currentTarget=a,function(e,t,a,i,n,s,r,c,l){if(je.apply(this,arguments),Ne){if(!Ne)throw Error(o(198));var d=_e;Ne=!1,_e=null,Ve||(Ve=!0,We=d)}}(i,t,void 0,e),e.currentTarget=null}function _i(e,t){t=0!==(4&t);for(var a=0;a<e.length;a++){var i=e[a],n=i.event;i=i.listeners;e:{var o=void 0;if(t)for(var s=i.length-1;0<=s;s--){var r=i[s],c=r.instance,l=r.currentTarget;if(r=r.listener,c!==o&&n.isPropagationStopped())break e;Ni(n,r,l),o=c}else for(s=0;s<i.length;s++){if(c=(r=i[s]).instance,l=r.currentTarget,r=r.listener,c!==o&&n.isPropagationStopped())break e;Ni(n,r,l),o=c}}}if(Ve)throw e=We,Ve=!1,We=null,e}function Vi(e,t){var a=t[fn];void 0===a&&(a=t[fn]=new Set);var i=e+"__bubble";a.has(i)||(Ui(t,e,2,!1),a.add(i))}function Wi(e,t,a){var i=0;t&&(i|=4),Ui(a,e,i,t)}var Fi="_reactListening"+Math.random().toString(36).slice(2);function ji(e){if(!e[Fi]){e[Fi]=!0,s.forEach((function(t){"selectionchange"!==t&&(Bi.has(t)||Wi(t,!1,e),Wi(t,!0,e))}));var t=9===e.nodeType?e:e.ownerDocument;null===t||t[Fi]||(t[Fi]=!0,Wi("selectionchange",!1,t))}}function Ui(e,t,a,i){switch(Yt(t)){case 1:var n=Ht;break;case 4:n=qt;break;default:n=Kt}a=n.bind(null,t,a,e),n=void 0,!xe||"touchstart"!==t&&"touchmove"!==t&&"wheel"!==t||(n=!0),i?void 0!==n?e.addEventListener(t,a,{capture:!0,passive:n}):e.addEventListener(t,a,!0):void 0!==n?e.addEventListener(t,a,{passive:n}):e.addEventListener(t,a,!1)}function zi(e,t,a,i,n){var o=i;if(0===(1&t)&&0===(2&t)&&null!==i)e:for(;;){if(null===i)return;var s=i.tag;if(3===s||4===s){var r=i.stateNode.containerInfo;if(r===n||8===r.nodeType&&r.parentNode===n)break;if(4===s)for(s=i.return;null!==s;){var c=s.tag;if((3===c||4===c)&&((c=s.stateNode.containerInfo)===n||8===c.nodeType&&c.parentNode===n))return;s=s.return}for(;null!==r;){if(null===(s=vn(r)))return;if(5===(c=s.tag)||6===c){i=o=s;continue e}r=r.parentNode}}i=i.return}Oe((function(){var i=o,n=De(a),s=[];e:{var r=Ii.get(e);if(void 0!==r){var c=la,l=e;switch(e){case"keypress":if(0===ta(a))break e;case"keydown":case"keyup":c=Ca;break;case"focusin":l="focus",c=fa;break;case"focusout":l="blur",c=fa;break;case"beforeblur":case"afterblur":c=fa;break;case"click":if(2===a.button)break e;case"auxclick":case"dblclick":case"mousedown":case"mousemove":case"mouseup":case"mouseout":case"mouseover":case"contextmenu":c=ma;break;case"drag":case"dragend":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"dragstart":case"drop":c=pa;break;case"touchcancel":case"touchend":case"touchmove":case"touchstart":c=ka;break;case Ti:case Ci:case Ei:c=ga;break;case ki:c=Ia;break;case"scroll":c=ua;break;case"wheel":c=Oa;break;case"copy":case"cut":case"paste":c=va;break;case"gotpointercapture":case"lostpointercapture":case"pointercancel":case"pointerdown":case"pointermove":case"pointerout":case"pointerover":case"pointerup":c=Ea}var d=0!==(4&t),u=!d&&"scroll"===e,h=d?null!==r?r+"Capture":null:r;d=[];for(var m,p=i;null!==p;){var f=(m=p).stateNode;if(5===m.tag&&null!==f&&(m=f,null!==h&&(null!=(f=Le(p,h))&&d.push(Gi(p,f,m)))),u)break;p=p.return}0<d.length&&(r=new c(r,l,null,a,n),s.push({event:r,listeners:d}))}}if(0===(7&t)){if(c="mouseout"===e||"pointerout"===e,(!(r="mouseover"===e||"pointerover"===e)||a===we||!(l=a.relatedTarget||a.fromElement)||!vn(l)&&!l[pn])&&(c||r)&&(r=n.window===n?n:(r=n.ownerDocument)?r.defaultView||r.parentWindow:window,c?(c=i,null!==(l=(l=a.relatedTarget||a.toElement)?vn(l):null)&&(l!==(u=Ue(l))||5!==l.tag&&6!==l.tag)&&(l=null)):(c=null,l=i),c!==l)){if(d=ma,f="onMouseLeave",h="onMouseEnter",p="mouse","pointerout"!==e&&"pointerover"!==e||(d=Ea,f="onPointerLeave",h="onPointerEnter",p="pointer"),u=null==c?r:wn(c),m=null==l?r:wn(l),(r=new d(f,p+"leave",c,a,n)).target=u,r.relatedTarget=m,f=null,vn(n)===i&&((d=new d(h,p+"enter",l,a,n)).target=m,d.relatedTarget=u,f=d),u=f,c&&l)e:{for(h=l,p=0,m=d=c;m;m=qi(m))p++;for(m=0,f=h;f;f=qi(f))m++;for(;0<p-m;)d=qi(d),p--;for(;0<m-p;)h=qi(h),m--;for(;p--;){if(d===h||null!==h&&d===h.alternate)break e;d=qi(d),h=qi(h)}d=null}else d=null;null!==c&&Ki(s,r,c,d,!1),null!==l&&null!==u&&Ki(s,u,l,d,!0)}if("select"===(c=(r=i?wn(i):window).nodeName&&r.nodeName.toLowerCase())||"input"===c&&"file"===r.type)var g=Ja;else if(za(r))if(Ya)g=oi;else{g=ii;var b=ai}else(c=r.nodeName)&&"input"===c.toLowerCase()&&("checkbox"===r.type||"radio"===r.type)&&(g=ni);switch(g&&(g=g(e,i))?Ga(s,g,a,n):(b&&b(e,r,i),"focusout"===e&&(b=r._wrapperState)&&b.controlled&&"number"===r.type&&ee(r,"number",r.value)),b=i?wn(i):window,e){case"focusin":(za(b)||"true"===b.contentEditable)&&(fi=b,gi=i,bi=null);break;case"focusout":bi=gi=fi=null;break;case"mousedown":vi=!0;break;case"contextmenu":case"mouseup":case"dragend":vi=!1,yi(s,a,n);break;case"selectionchange":if(pi)break;case"keydown":case"keyup":yi(s,a,n)}var v;if(xa)e:{switch(e){case"compositionstart":var y="onCompositionStart";break e;case"compositionend":y="onCompositionEnd";break e;case"compositionupdate":y="onCompositionUpdate";break e}y=void 0}else ja?Wa(e,a)&&(y="onCompositionEnd"):"keydown"===e&&229===a.keyCode&&(y="onCompositionStart");y&&(Na&&"ko"!==a.locale&&(ja||"onCompositionStart"!==y?"onCompositionEnd"===y&&ja&&(v=ea()):(Zt="value"in(Xt=n)?Xt.value:Xt.textContent,ja=!0)),0<(b=Hi(i,y)).length&&(y=new ya(y,e,null,a,n),s.push({event:y,listeners:b}),v?y.data=v:null!==(v=Fa(a))&&(y.data=v))),(v=Ba?function(e,t){switch(e){case"compositionend":return Fa(t);case"keypress":return 32!==t.which?null:(Va=!0,_a);case"textInput":return(e=t.data)===_a&&Va?null:e;default:return null}}(e,a):function(e,t){if(ja)return"compositionend"===e||!xa&&Wa(e,t)?(e=ea(),$t=Zt=Xt=null,ja=!1,e):null;switch(e){case"paste":default:return null;case"keypress":if(!(t.ctrlKey||t.altKey||t.metaKey)||t.ctrlKey&&t.altKey){if(t.char&&1<t.char.length)return t.char;if(t.which)return String.fromCharCode(t.which)}return null;case"compositionend":return Na&&"ko"!==t.locale?null:t.data}}(e,a))&&(0<(i=Hi(i,"onBeforeInput")).length&&(n=new ya("onBeforeInput","beforeinput",null,a,n),s.push({event:n,listeners:i}),n.data=v))}_i(s,t)}))}function Gi(e,t,a){return{instance:e,listener:t,currentTarget:a}}function Hi(e,t){for(var a=t+"Capture",i=[];null!==e;){var n=e,o=n.stateNode;5===n.tag&&null!==o&&(n=o,null!=(o=Le(e,a))&&i.unshift(Gi(e,o,n)),null!=(o=Le(e,t))&&i.push(Gi(e,o,n))),e=e.return}return i}function qi(e){if(null===e)return null;do{e=e.return}while(e&&5!==e.tag);return e||null}function Ki(e,t,a,i,n){for(var o=t._reactName,s=[];null!==a&&a!==i;){var r=a,c=r.alternate,l=r.stateNode;if(null!==c&&c===i)break;5===r.tag&&null!==l&&(r=l,n?null!=(c=Le(a,o))&&s.unshift(Gi(a,c,r)):n||null!=(c=Le(a,o))&&s.push(Gi(a,c,r))),a=a.return}0!==s.length&&e.push({event:t,listeners:s})}var Qi=/\r\n?/g,Ji=/\u0000|\uFFFD/g;function Yi(e){return("string"===typeof e?e:""+e).replace(Qi,"\n").replace(Ji,"")}function Xi(e,t,a){if(t=Yi(t),Yi(e)!==t&&a)throw Error(o(425))}function Zi(){}var $i=null,en=null;function tn(e,t){return"textarea"===e||"noscript"===e||"string"===typeof t.children||"number"===typeof t.children||"object"===typeof t.dangerouslySetInnerHTML&&null!==t.dangerouslySetInnerHTML&&null!=t.dangerouslySetInnerHTML.__html}var an="function"===typeof setTimeout?setTimeout:void 0,nn="function"===typeof clearTimeout?clearTimeout:void 0,on="function"===typeof Promise?Promise:void 0,sn="function"===typeof queueMicrotask?queueMicrotask:"undefined"!==typeof on?function(e){return on.resolve(null).then(e).catch(rn)}:an;function rn(e){setTimeout((function(){throw e}))}function cn(e,t){var a=t,i=0;do{var n=a.nextSibling;if(e.removeChild(a),n&&8===n.nodeType)if("/$"===(a=n.data)){if(0===i)return e.removeChild(n),void Ut(t);i--}else"$"!==a&&"$?"!==a&&"$!"!==a||i++;a=n}while(a);Ut(t)}function ln(e){for(;null!=e;e=e.nextSibling){var t=e.nodeType;if(1===t||3===t)break;if(8===t){if("$"===(t=e.data)||"$!"===t||"$?"===t)break;if("/$"===t)return null}}return e}function dn(e){e=e.previousSibling;for(var t=0;e;){if(8===e.nodeType){var a=e.data;if("$"===a||"$!"===a||"$?"===a){if(0===t)return e;t--}else"/$"===a&&t++}e=e.previousSibling}return null}var un=Math.random().toString(36).slice(2),hn="__reactFiber$"+un,mn="__reactProps$"+un,pn="__reactContainer$"+un,fn="__reactEvents$"+un,gn="__reactListeners$"+un,bn="__reactHandles$"+un;function vn(e){var t=e[hn];if(t)return t;for(var a=e.parentNode;a;){if(t=a[pn]||a[hn]){if(a=t.alternate,null!==t.child||null!==a&&null!==a.child)for(e=dn(e);null!==e;){if(a=e[hn])return a;e=dn(e)}return t}a=(e=a).parentNode}return null}function yn(e){return!(e=e[hn]||e[pn])||5!==e.tag&&6!==e.tag&&13!==e.tag&&3!==e.tag?null:e}function wn(e){if(5===e.tag||6===e.tag)return e.stateNode;throw Error(o(33))}function Dn(e){return e[mn]||null}var An=[],Rn=-1;function Sn(e){return{current:e}}function Tn(e){0>Rn||(e.current=An[Rn],An[Rn]=null,Rn--)}function Cn(e,t){Rn++,An[Rn]=e.current,e.current=t}var En={},kn=Sn(En),In=Sn(!1),Mn=En;function On(e,t){var a=e.type.contextTypes;if(!a)return En;var i=e.stateNode;if(i&&i.__reactInternalMemoizedUnmaskedChildContext===t)return i.__reactInternalMemoizedMaskedChildContext;var n,o={};for(n in a)o[n]=t[n];return i&&((e=e.stateNode).__reactInternalMemoizedUnmaskedChildContext=t,e.__reactInternalMemoizedMaskedChildContext=o),o}function Ln(e){return null!==(e=e.childContextTypes)&&void 0!==e}function xn(){Tn(In),Tn(kn)}function Pn(e,t,a){if(kn.current!==En)throw Error(o(168));Cn(kn,t),Cn(In,a)}function Bn(e,t,a){var i=e.stateNode;if(t=t.childContextTypes,"function"!==typeof i.getChildContext)return a;for(var n in i=i.getChildContext())if(!(n in t))throw Error(o(108,z(e)||"Unknown",n));return _({},a,i)}function Nn(e){return e=(e=e.stateNode)&&e.__reactInternalMemoizedMergedChildContext||En,Mn=kn.current,Cn(kn,e),Cn(In,In.current),!0}function _n(e,t,a){var i=e.stateNode;if(!i)throw Error(o(169));a?(e=Bn(e,t,Mn),i.__reactInternalMemoizedMergedChildContext=e,Tn(In),Tn(kn),Cn(kn,e)):Tn(In),Cn(In,a)}var Vn=null,Wn=!1,Fn=!1;function jn(e){null===Vn?Vn=[e]:Vn.push(e)}function Un(){if(!Fn&&null!==Vn){Fn=!0;var e=0,t=yt;try{var a=Vn;for(yt=1;e<a.length;e++){var i=a[e];do{i=i(!0)}while(null!==i)}Vn=null,Wn=!1}catch(n){throw null!==Vn&&(Vn=Vn.slice(e+1)),Ke($e,Un),n}finally{yt=t,Fn=!1}}return null}var zn=[],Gn=0,Hn=null,qn=0,Kn=[],Qn=0,Jn=null,Yn=1,Xn="";function Zn(e,t){zn[Gn++]=qn,zn[Gn++]=Hn,Hn=e,qn=t}function $n(e,t,a){Kn[Qn++]=Yn,Kn[Qn++]=Xn,Kn[Qn++]=Jn,Jn=e;var i=Yn;e=Xn;var n=32-st(i)-1;i&=~(1<<n),a+=1;var o=32-st(t)+n;if(30<o){var s=n-n%5;o=(i&(1<<s)-1).toString(32),i>>=s,n-=s,Yn=1<<32-st(t)+n|a<<n|i,Xn=o+e}else Yn=1<<o|a<<n|i,Xn=e}function eo(e){null!==e.return&&(Zn(e,1),$n(e,1,0))}function to(e){for(;e===Hn;)Hn=zn[--Gn],zn[Gn]=null,qn=zn[--Gn],zn[Gn]=null;for(;e===Jn;)Jn=Kn[--Qn],Kn[Qn]=null,Xn=Kn[--Qn],Kn[Qn]=null,Yn=Kn[--Qn],Kn[Qn]=null}var ao=null,io=null,no=!1,oo=null;function so(e,t){var a=Ll(5,null,null,0);a.elementType="DELETED",a.stateNode=t,a.return=e,null===(t=e.deletions)?(e.deletions=[a],e.flags|=16):t.push(a)}function ro(e,t){switch(e.tag){case 5:var a=e.type;return null!==(t=1!==t.nodeType||a.toLowerCase()!==t.nodeName.toLowerCase()?null:t)&&(e.stateNode=t,ao=e,io=ln(t.firstChild),!0);case 6:return null!==(t=""===e.pendingProps||3!==t.nodeType?null:t)&&(e.stateNode=t,ao=e,io=null,!0);case 13:return null!==(t=8!==t.nodeType?null:t)&&(a=null!==Jn?{id:Yn,overflow:Xn}:null,e.memoizedState={dehydrated:t,treeContext:a,retryLane:1073741824},(a=Ll(18,null,null,0)).stateNode=t,a.return=e,e.child=a,ao=e,io=null,!0);default:return!1}}function co(e){return 0!==(1&e.mode)&&0===(128&e.flags)}function lo(e){if(no){var t=io;if(t){var a=t;if(!ro(e,t)){if(co(e))throw Error(o(418));t=ln(a.nextSibling);var i=ao;t&&ro(e,t)?so(i,a):(e.flags=-4097&e.flags|2,no=!1,ao=e)}}else{if(co(e))throw Error(o(418));e.flags=-4097&e.flags|2,no=!1,ao=e}}}function uo(e){for(e=e.return;null!==e&&5!==e.tag&&3!==e.tag&&13!==e.tag;)e=e.return;ao=e}function ho(e){if(e!==ao)return!1;if(!no)return uo(e),no=!0,!1;var t;if((t=3!==e.tag)&&!(t=5!==e.tag)&&(t="head"!==(t=e.type)&&"body"!==t&&!tn(e.type,e.memoizedProps)),t&&(t=io)){if(co(e))throw mo(),Error(o(418));for(;t;)so(e,t),t=ln(t.nextSibling)}if(uo(e),13===e.tag){if(!(e=null!==(e=e.memoizedState)?e.dehydrated:null))throw Error(o(317));e:{for(e=e.nextSibling,t=0;e;){if(8===e.nodeType){var a=e.data;if("/$"===a){if(0===t){io=ln(e.nextSibling);break e}t--}else"$"!==a&&"$!"!==a&&"$?"!==a||t++}e=e.nextSibling}io=null}}else io=ao?ln(e.stateNode.nextSibling):null;return!0}function mo(){for(var e=io;e;)e=ln(e.nextSibling)}function po(){io=ao=null,no=!1}function fo(e){null===oo?oo=[e]:oo.push(e)}var go=w.ReactCurrentBatchConfig;function bo(e,t){if(e&&e.defaultProps){for(var a in t=_({},t),e=e.defaultProps)void 0===t[a]&&(t[a]=e[a]);return t}return t}var vo=Sn(null),yo=null,wo=null,Do=null;function Ao(){Do=wo=yo=null}function Ro(e){var t=vo.current;Tn(vo),e._currentValue=t}function So(e,t,a){for(;null!==e;){var i=e.alternate;if((e.childLanes&t)!==t?(e.childLanes|=t,null!==i&&(i.childLanes|=t)):null!==i&&(i.childLanes&t)!==t&&(i.childLanes|=t),e===a)break;e=e.return}}function To(e,t){yo=e,Do=wo=null,null!==(e=e.dependencies)&&null!==e.firstContext&&(0!==(e.lanes&t)&&(wr=!0),e.firstContext=null)}function Co(e){var t=e._currentValue;if(Do!==e)if(e={context:e,memoizedValue:t,next:null},null===wo){if(null===yo)throw Error(o(308));wo=e,yo.dependencies={lanes:0,firstContext:e}}else wo=wo.next=e;return t}var Eo=null;function ko(e){null===Eo?Eo=[e]:Eo.push(e)}function Io(e,t,a,i){var n=t.interleaved;return null===n?(a.next=a,ko(t)):(a.next=n.next,n.next=a),t.interleaved=a,Mo(e,i)}function Mo(e,t){e.lanes|=t;var a=e.alternate;for(null!==a&&(a.lanes|=t),a=e,e=e.return;null!==e;)e.childLanes|=t,null!==(a=e.alternate)&&(a.childLanes|=t),a=e,e=e.return;return 3===a.tag?a.stateNode:null}var Oo=!1;function Lo(e){e.updateQueue={baseState:e.memoizedState,firstBaseUpdate:null,lastBaseUpdate:null,shared:{pending:null,interleaved:null,lanes:0},effects:null}}function xo(e,t){e=e.updateQueue,t.updateQueue===e&&(t.updateQueue={baseState:e.baseState,firstBaseUpdate:e.firstBaseUpdate,lastBaseUpdate:e.lastBaseUpdate,shared:e.shared,effects:e.effects})}function Po(e,t){return{eventTime:e,lane:t,tag:0,payload:null,callback:null,next:null}}function Bo(e,t,a){var i=e.updateQueue;if(null===i)return null;if(i=i.shared,0!==(2&Ic)){var n=i.pending;return null===n?t.next=t:(t.next=n.next,n.next=t),i.pending=t,Mo(e,a)}return null===(n=i.interleaved)?(t.next=t,ko(i)):(t.next=n.next,n.next=t),i.interleaved=t,Mo(e,a)}function No(e,t,a){if(null!==(t=t.updateQueue)&&(t=t.shared,0!==(4194240&a))){var i=t.lanes;a|=i&=e.pendingLanes,t.lanes=a,vt(e,a)}}function _o(e,t){var a=e.updateQueue,i=e.alternate;if(null!==i&&a===(i=i.updateQueue)){var n=null,o=null;if(null!==(a=a.firstBaseUpdate)){do{var s={eventTime:a.eventTime,lane:a.lane,tag:a.tag,payload:a.payload,callback:a.callback,next:null};null===o?n=o=s:o=o.next=s,a=a.next}while(null!==a);null===o?n=o=t:o=o.next=t}else n=o=t;return a={baseState:i.baseState,firstBaseUpdate:n,lastBaseUpdate:o,shared:i.shared,effects:i.effects},void(e.updateQueue=a)}null===(e=a.lastBaseUpdate)?a.firstBaseUpdate=t:e.next=t,a.lastBaseUpdate=t}function Vo(e,t,a,i){var n=e.updateQueue;Oo=!1;var o=n.firstBaseUpdate,s=n.lastBaseUpdate,r=n.shared.pending;if(null!==r){n.shared.pending=null;var c=r,l=c.next;c.next=null,null===s?o=l:s.next=l,s=c;var d=e.alternate;null!==d&&((r=(d=d.updateQueue).lastBaseUpdate)!==s&&(null===r?d.firstBaseUpdate=l:r.next=l,d.lastBaseUpdate=c))}if(null!==o){var u=n.baseState;for(s=0,d=l=c=null,r=o;;){var h=r.lane,m=r.eventTime;if((i&h)===h){null!==d&&(d=d.next={eventTime:m,lane:0,tag:r.tag,payload:r.payload,callback:r.callback,next:null});e:{var p=e,f=r;switch(h=t,m=a,f.tag){case 1:if("function"===typeof(p=f.payload)){u=p.call(m,u,h);break e}u=p;break e;case 3:p.flags=-65537&p.flags|128;case 0:if(null===(h="function"===typeof(p=f.payload)?p.call(m,u,h):p)||void 0===h)break e;u=_({},u,h);break e;case 2:Oo=!0}}null!==r.callback&&0!==r.lane&&(e.flags|=64,null===(h=n.effects)?n.effects=[r]:h.push(r))}else m={eventTime:m,lane:h,tag:r.tag,payload:r.payload,callback:r.callback,next:null},null===d?(l=d=m,c=u):d=d.next=m,s|=h;if(null===(r=r.next)){if(null===(r=n.shared.pending))break;r=(h=r).next,h.next=null,n.lastBaseUpdate=h,n.shared.pending=null}}if(null===d&&(c=u),n.baseState=c,n.firstBaseUpdate=l,n.lastBaseUpdate=d,null!==(t=n.shared.interleaved)){n=t;do{s|=n.lane,n=n.next}while(n!==t)}else null===o&&(n.shared.lanes=0);_c|=s,e.lanes=s,e.memoizedState=u}}function Wo(e,t,a){if(e=t.effects,t.effects=null,null!==e)for(t=0;t<e.length;t++){var i=e[t],n=i.callback;if(null!==n){if(i.callback=null,i=a,"function"!==typeof n)throw Error(o(191,n));n.call(i)}}}var Fo=(new i.Component).refs;function jo(e,t,a,i){a=null===(a=a(i,t=e.memoizedState))||void 0===a?t:_({},t,a),e.memoizedState=a,0===e.lanes&&(e.updateQueue.baseState=a)}var Uo={isMounted:function(e){return!!(e=e._reactInternals)&&Ue(e)===e},enqueueSetState:function(e,t,a){e=e._reactInternals;var i=tl(),n=al(e),o=Po(i,n);o.payload=t,void 0!==a&&null!==a&&(o.callback=a),null!==(t=Bo(e,o,n))&&(il(t,e,n,i),No(t,e,n))},enqueueReplaceState:function(e,t,a){e=e._reactInternals;var i=tl(),n=al(e),o=Po(i,n);o.tag=1,o.payload=t,void 0!==a&&null!==a&&(o.callback=a),null!==(t=Bo(e,o,n))&&(il(t,e,n,i),No(t,e,n))},enqueueForceUpdate:function(e,t){e=e._reactInternals;var a=tl(),i=al(e),n=Po(a,i);n.tag=2,void 0!==t&&null!==t&&(n.callback=t),null!==(t=Bo(e,n,i))&&(il(t,e,i,a),No(t,e,i))}};function zo(e,t,a,i,n,o,s){return"function"===typeof(e=e.stateNode).shouldComponentUpdate?e.shouldComponentUpdate(i,o,s):!t.prototype||!t.prototype.isPureReactComponent||(!ri(a,i)||!ri(n,o))}function Go(e,t,a){var i=!1,n=En,o=t.contextType;return"object"===typeof o&&null!==o?o=Co(o):(n=Ln(t)?Mn:kn.current,o=(i=null!==(i=t.contextTypes)&&void 0!==i)?On(e,n):En),t=new t(a,o),e.memoizedState=null!==t.state&&void 0!==t.state?t.state:null,t.updater=Uo,e.stateNode=t,t._reactInternals=e,i&&((e=e.stateNode).__reactInternalMemoizedUnmaskedChildContext=n,e.__reactInternalMemoizedMaskedChildContext=o),t}function Ho(e,t,a,i){e=t.state,"function"===typeof t.componentWillReceiveProps&&t.componentWillReceiveProps(a,i),"function"===typeof t.UNSAFE_componentWillReceiveProps&&t.UNSAFE_componentWillReceiveProps(a,i),t.state!==e&&Uo.enqueueReplaceState(t,t.state,null)}function qo(e,t,a,i){var n=e.stateNode;n.props=a,n.state=e.memoizedState,n.refs=Fo,Lo(e);var o=t.contextType;"object"===typeof o&&null!==o?n.context=Co(o):(o=Ln(t)?Mn:kn.current,n.context=On(e,o)),n.state=e.memoizedState,"function"===typeof(o=t.getDerivedStateFromProps)&&(jo(e,t,o,a),n.state=e.memoizedState),"function"===typeof t.getDerivedStateFromProps||"function"===typeof n.getSnapshotBeforeUpdate||"function"!==typeof n.UNSAFE_componentWillMount&&"function"!==typeof n.componentWillMount||(t=n.state,"function"===typeof n.componentWillMount&&n.componentWillMount(),"function"===typeof n.UNSAFE_componentWillMount&&n.UNSAFE_componentWillMount(),t!==n.state&&Uo.enqueueReplaceState(n,n.state,null),Vo(e,a,n,i),n.state=e.memoizedState),"function"===typeof n.componentDidMount&&(e.flags|=4194308)}function Ko(e,t,a){if(null!==(e=a.ref)&&"function"!==typeof e&&"object"!==typeof e){if(a._owner){if(a=a._owner){if(1!==a.tag)throw Error(o(309));var i=a.stateNode}if(!i)throw Error(o(147,e));var n=i,s=""+e;return null!==t&&null!==t.ref&&"function"===typeof t.ref&&t.ref._stringRef===s?t.ref:(t=function(e){var t=n.refs;t===Fo&&(t=n.refs={}),null===e?delete t[s]:t[s]=e},t._stringRef=s,t)}if("string"!==typeof e)throw Error(o(284));if(!a._owner)throw Error(o(290,e))}return e}function Qo(e,t){throw e=Object.prototype.toString.call(t),Error(o(31,"[object Object]"===e?"object with keys {"+Object.keys(t).join(", ")+"}":e))}function Jo(e){return(0,e._init)(e._payload)}function Yo(e){function t(t,a){if(e){var i=t.deletions;null===i?(t.deletions=[a],t.flags|=16):i.push(a)}}function a(a,i){if(!e)return null;for(;null!==i;)t(a,i),i=i.sibling;return null}function i(e,t){for(e=new Map;null!==t;)null!==t.key?e.set(t.key,t):e.set(t.index,t),t=t.sibling;return e}function n(e,t){return(e=Pl(e,t)).index=0,e.sibling=null,e}function s(t,a,i){return t.index=i,e?null!==(i=t.alternate)?(i=i.index)<a?(t.flags|=2,a):i:(t.flags|=2,a):(t.flags|=1048576,a)}function r(t){return e&&null===t.alternate&&(t.flags|=2),t}function c(e,t,a,i){return null===t||6!==t.tag?((t=Vl(a,e.mode,i)).return=e,t):((t=n(t,a)).return=e,t)}function l(e,t,a,i){var o=a.type;return o===R?u(e,t,a.props.children,i,a.key):null!==t&&(t.elementType===o||"object"===typeof o&&null!==o&&o.$$typeof===L&&Jo(o)===t.type)?((i=n(t,a.props)).ref=Ko(e,t,a),i.return=e,i):((i=Bl(a.type,a.key,a.props,null,e.mode,i)).ref=Ko(e,t,a),i.return=e,i)}function d(e,t,a,i){return null===t||4!==t.tag||t.stateNode.containerInfo!==a.containerInfo||t.stateNode.implementation!==a.implementation?((t=Wl(a,e.mode,i)).return=e,t):((t=n(t,a.children||[])).return=e,t)}function u(e,t,a,i,o){return null===t||7!==t.tag?((t=Nl(a,e.mode,i,o)).return=e,t):((t=n(t,a)).return=e,t)}function h(e,t,a){if("string"===typeof t&&""!==t||"number"===typeof t)return(t=Vl(""+t,e.mode,a)).return=e,t;if("object"===typeof t&&null!==t){switch(t.$$typeof){case D:return(a=Bl(t.type,t.key,t.props,null,e.mode,a)).ref=Ko(e,null,t),a.return=e,a;case A:return(t=Wl(t,e.mode,a)).return=e,t;case L:return h(e,(0,t._init)(t._payload),a)}if(te(t)||B(t))return(t=Nl(t,e.mode,a,null)).return=e,t;Qo(e,t)}return null}function m(e,t,a,i){var n=null!==t?t.key:null;if("string"===typeof a&&""!==a||"number"===typeof a)return null!==n?null:c(e,t,""+a,i);if("object"===typeof a&&null!==a){switch(a.$$typeof){case D:return a.key===n?l(e,t,a,i):null;case A:return a.key===n?d(e,t,a,i):null;case L:return m(e,t,(n=a._init)(a._payload),i)}if(te(a)||B(a))return null!==n?null:u(e,t,a,i,null);Qo(e,a)}return null}function p(e,t,a,i,n){if("string"===typeof i&&""!==i||"number"===typeof i)return c(t,e=e.get(a)||null,""+i,n);if("object"===typeof i&&null!==i){switch(i.$$typeof){case D:return l(t,e=e.get(null===i.key?a:i.key)||null,i,n);case A:return d(t,e=e.get(null===i.key?a:i.key)||null,i,n);case L:return p(e,t,a,(0,i._init)(i._payload),n)}if(te(i)||B(i))return u(t,e=e.get(a)||null,i,n,null);Qo(t,i)}return null}function f(n,o,r,c){for(var l=null,d=null,u=o,f=o=0,g=null;null!==u&&f<r.length;f++){u.index>f?(g=u,u=null):g=u.sibling;var b=m(n,u,r[f],c);if(null===b){null===u&&(u=g);break}e&&u&&null===b.alternate&&t(n,u),o=s(b,o,f),null===d?l=b:d.sibling=b,d=b,u=g}if(f===r.length)return a(n,u),no&&Zn(n,f),l;if(null===u){for(;f<r.length;f++)null!==(u=h(n,r[f],c))&&(o=s(u,o,f),null===d?l=u:d.sibling=u,d=u);return no&&Zn(n,f),l}for(u=i(n,u);f<r.length;f++)null!==(g=p(u,n,f,r[f],c))&&(e&&null!==g.alternate&&u.delete(null===g.key?f:g.key),o=s(g,o,f),null===d?l=g:d.sibling=g,d=g);return e&&u.forEach((function(e){return t(n,e)})),no&&Zn(n,f),l}function g(n,r,c,l){var d=B(c);if("function"!==typeof d)throw Error(o(150));if(null==(c=d.call(c)))throw Error(o(151));for(var u=d=null,f=r,g=r=0,b=null,v=c.next();null!==f&&!v.done;g++,v=c.next()){f.index>g?(b=f,f=null):b=f.sibling;var y=m(n,f,v.value,l);if(null===y){null===f&&(f=b);break}e&&f&&null===y.alternate&&t(n,f),r=s(y,r,g),null===u?d=y:u.sibling=y,u=y,f=b}if(v.done)return a(n,f),no&&Zn(n,g),d;if(null===f){for(;!v.done;g++,v=c.next())null!==(v=h(n,v.value,l))&&(r=s(v,r,g),null===u?d=v:u.sibling=v,u=v);return no&&Zn(n,g),d}for(f=i(n,f);!v.done;g++,v=c.next())null!==(v=p(f,n,g,v.value,l))&&(e&&null!==v.alternate&&f.delete(null===v.key?g:v.key),r=s(v,r,g),null===u?d=v:u.sibling=v,u=v);return e&&f.forEach((function(e){return t(n,e)})),no&&Zn(n,g),d}return function e(i,o,s,c){if("object"===typeof s&&null!==s&&s.type===R&&null===s.key&&(s=s.props.children),"object"===typeof s&&null!==s){switch(s.$$typeof){case D:e:{for(var l=s.key,d=o;null!==d;){if(d.key===l){if((l=s.type)===R){if(7===d.tag){a(i,d.sibling),(o=n(d,s.props.children)).return=i,i=o;break e}}else if(d.elementType===l||"object"===typeof l&&null!==l&&l.$$typeof===L&&Jo(l)===d.type){a(i,d.sibling),(o=n(d,s.props)).ref=Ko(i,d,s),o.return=i,i=o;break e}a(i,d);break}t(i,d),d=d.sibling}s.type===R?((o=Nl(s.props.children,i.mode,c,s.key)).return=i,i=o):((c=Bl(s.type,s.key,s.props,null,i.mode,c)).ref=Ko(i,o,s),c.return=i,i=c)}return r(i);case A:e:{for(d=s.key;null!==o;){if(o.key===d){if(4===o.tag&&o.stateNode.containerInfo===s.containerInfo&&o.stateNode.implementation===s.implementation){a(i,o.sibling),(o=n(o,s.children||[])).return=i,i=o;break e}a(i,o);break}t(i,o),o=o.sibling}(o=Wl(s,i.mode,c)).return=i,i=o}return r(i);case L:return e(i,o,(d=s._init)(s._payload),c)}if(te(s))return f(i,o,s,c);if(B(s))return g(i,o,s,c);Qo(i,s)}return"string"===typeof s&&""!==s||"number"===typeof s?(s=""+s,null!==o&&6===o.tag?(a(i,o.sibling),(o=n(o,s)).return=i,i=o):(a(i,o),(o=Vl(s,i.mode,c)).return=i,i=o),r(i)):a(i,o)}}var Xo=Yo(!0),Zo=Yo(!1),$o={},es=Sn($o),ts=Sn($o),as=Sn($o);function is(e){if(e===$o)throw Error(o(174));return e}function ns(e,t){switch(Cn(as,t),Cn(ts,e),Cn(es,$o),e=t.nodeType){case 9:case 11:t=(t=t.documentElement)?t.namespaceURI:ce(null,"");break;default:t=ce(t=(e=8===e?t.parentNode:t).namespaceURI||null,e=e.tagName)}Tn(es),Cn(es,t)}function os(){Tn(es),Tn(ts),Tn(as)}function ss(e){is(as.current);var t=is(es.current),a=ce(t,e.type);t!==a&&(Cn(ts,e),Cn(es,a))}function rs(e){ts.current===e&&(Tn(es),Tn(ts))}var cs=Sn(0);function ls(e){for(var t=e;null!==t;){if(13===t.tag){var a=t.memoizedState;if(null!==a&&(null===(a=a.dehydrated)||"$?"===a.data||"$!"===a.data))return t}else if(19===t.tag&&void 0!==t.memoizedProps.revealOrder){if(0!==(128&t.flags))return t}else if(null!==t.child){t.child.return=t,t=t.child;continue}if(t===e)break;for(;null===t.sibling;){if(null===t.return||t.return===e)return null;t=t.return}t.sibling.return=t.return,t=t.sibling}return null}var ds=[];function us(){for(var e=0;e<ds.length;e++)ds[e]._workInProgressVersionPrimary=null;ds.length=0}var hs=w.ReactCurrentDispatcher,ms=w.ReactCurrentBatchConfig,ps=0,fs=null,gs=null,bs=null,vs=!1,ys=!1,ws=0,Ds=0;function As(){throw Error(o(321))}function Rs(e,t){if(null===t)return!1;for(var a=0;a<t.length&&a<e.length;a++)if(!si(e[a],t[a]))return!1;return!0}function Ss(e,t,a,i,n,s){if(ps=s,fs=t,t.memoizedState=null,t.updateQueue=null,t.lanes=0,hs.current=null===e||null===e.memoizedState?rr:cr,e=a(i,n),ys){s=0;do{if(ys=!1,ws=0,25<=s)throw Error(o(301));s+=1,bs=gs=null,t.updateQueue=null,hs.current=lr,e=a(i,n)}while(ys)}if(hs.current=sr,t=null!==gs&&null!==gs.next,ps=0,bs=gs=fs=null,vs=!1,t)throw Error(o(300));return e}function Ts(){var e=0!==ws;return ws=0,e}function Cs(){var e={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};return null===bs?fs.memoizedState=bs=e:bs=bs.next=e,bs}function Es(){if(null===gs){var e=fs.alternate;e=null!==e?e.memoizedState:null}else e=gs.next;var t=null===bs?fs.memoizedState:bs.next;if(null!==t)bs=t,gs=e;else{if(null===e)throw Error(o(310));e={memoizedState:(gs=e).memoizedState,baseState:gs.baseState,baseQueue:gs.baseQueue,queue:gs.queue,next:null},null===bs?fs.memoizedState=bs=e:bs=bs.next=e}return bs}function ks(e,t){return"function"===typeof t?t(e):t}function Is(e){var t=Es(),a=t.queue;if(null===a)throw Error(o(311));a.lastRenderedReducer=e;var i=gs,n=i.baseQueue,s=a.pending;if(null!==s){if(null!==n){var r=n.next;n.next=s.next,s.next=r}i.baseQueue=n=s,a.pending=null}if(null!==n){s=n.next,i=i.baseState;var c=r=null,l=null,d=s;do{var u=d.lane;if((ps&u)===u)null!==l&&(l=l.next={lane:0,action:d.action,hasEagerState:d.hasEagerState,eagerState:d.eagerState,next:null}),i=d.hasEagerState?d.eagerState:e(i,d.action);else{var h={lane:u,action:d.action,hasEagerState:d.hasEagerState,eagerState:d.eagerState,next:null};null===l?(c=l=h,r=i):l=l.next=h,fs.lanes|=u,_c|=u}d=d.next}while(null!==d&&d!==s);null===l?r=i:l.next=c,si(i,t.memoizedState)||(wr=!0),t.memoizedState=i,t.baseState=r,t.baseQueue=l,a.lastRenderedState=i}if(null!==(e=a.interleaved)){n=e;do{s=n.lane,fs.lanes|=s,_c|=s,n=n.next}while(n!==e)}else null===n&&(a.lanes=0);return[t.memoizedState,a.dispatch]}function Ms(e){var t=Es(),a=t.queue;if(null===a)throw Error(o(311));a.lastRenderedReducer=e;var i=a.dispatch,n=a.pending,s=t.memoizedState;if(null!==n){a.pending=null;var r=n=n.next;do{s=e(s,r.action),r=r.next}while(r!==n);si(s,t.memoizedState)||(wr=!0),t.memoizedState=s,null===t.baseQueue&&(t.baseState=s),a.lastRenderedState=s}return[s,i]}function Os(){}function Ls(e,t){var a=fs,i=Es(),n=t(),s=!si(i.memoizedState,n);if(s&&(i.memoizedState=n,wr=!0),i=i.queue,Gs(Bs.bind(null,a,i,e),[e]),i.getSnapshot!==t||s||null!==bs&&1&bs.memoizedState.tag){if(a.flags|=2048,Ws(9,Ps.bind(null,a,i,n,t),void 0,null),null===Mc)throw Error(o(349));0!==(30&ps)||xs(a,t,n)}return n}function xs(e,t,a){e.flags|=16384,e={getSnapshot:t,value:a},null===(t=fs.updateQueue)?(t={lastEffect:null,stores:null},fs.updateQueue=t,t.stores=[e]):null===(a=t.stores)?t.stores=[e]:a.push(e)}function Ps(e,t,a,i){t.value=a,t.getSnapshot=i,Ns(t)&&_s(e)}function Bs(e,t,a){return a((function(){Ns(t)&&_s(e)}))}function Ns(e){var t=e.getSnapshot;e=e.value;try{var a=t();return!si(e,a)}catch(i){return!0}}function _s(e){var t=Mo(e,1);null!==t&&il(t,e,1,-1)}function Vs(e){var t=Cs();return"function"===typeof e&&(e=e()),t.memoizedState=t.baseState=e,e={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:ks,lastRenderedState:e},t.queue=e,e=e.dispatch=ar.bind(null,fs,e),[t.memoizedState,e]}function Ws(e,t,a,i){return e={tag:e,create:t,destroy:a,deps:i,next:null},null===(t=fs.updateQueue)?(t={lastEffect:null,stores:null},fs.updateQueue=t,t.lastEffect=e.next=e):null===(a=t.lastEffect)?t.lastEffect=e.next=e:(i=a.next,a.next=e,e.next=i,t.lastEffect=e),e}function Fs(){return Es().memoizedState}function js(e,t,a,i){var n=Cs();fs.flags|=e,n.memoizedState=Ws(1|t,a,void 0,void 0===i?null:i)}function Us(e,t,a,i){var n=Es();i=void 0===i?null:i;var o=void 0;if(null!==gs){var s=gs.memoizedState;if(o=s.destroy,null!==i&&Rs(i,s.deps))return void(n.memoizedState=Ws(t,a,o,i))}fs.flags|=e,n.memoizedState=Ws(1|t,a,o,i)}function zs(e,t){return js(8390656,8,e,t)}function Gs(e,t){return Us(2048,8,e,t)}function Hs(e,t){return Us(4,2,e,t)}function qs(e,t){return Us(4,4,e,t)}function Ks(e,t){return"function"===typeof t?(e=e(),t(e),function(){t(null)}):null!==t&&void 0!==t?(e=e(),t.current=e,function(){t.current=null}):void 0}function Qs(e,t,a){return a=null!==a&&void 0!==a?a.concat([e]):null,Us(4,4,Ks.bind(null,t,e),a)}function Js(){}function Ys(e,t){var a=Es();t=void 0===t?null:t;var i=a.memoizedState;return null!==i&&null!==t&&Rs(t,i[1])?i[0]:(a.memoizedState=[e,t],e)}function Xs(e,t){var a=Es();t=void 0===t?null:t;var i=a.memoizedState;return null!==i&&null!==t&&Rs(t,i[1])?i[0]:(e=e(),a.memoizedState=[e,t],e)}function Zs(e,t,a){return 0===(21&ps)?(e.baseState&&(e.baseState=!1,wr=!0),e.memoizedState=a):(si(a,t)||(a=ft(),fs.lanes|=a,_c|=a,e.baseState=!0),t)}function $s(e,t){var a=yt;yt=0!==a&&4>a?a:4,e(!0);var i=ms.transition;ms.transition={};try{e(!1),t()}finally{yt=a,ms.transition=i}}function er(){return Es().memoizedState}function tr(e,t,a){var i=al(e);if(a={lane:i,action:a,hasEagerState:!1,eagerState:null,next:null},ir(e))nr(t,a);else if(null!==(a=Io(e,t,a,i))){il(a,e,i,tl()),or(a,t,i)}}function ar(e,t,a){var i=al(e),n={lane:i,action:a,hasEagerState:!1,eagerState:null,next:null};if(ir(e))nr(t,n);else{var o=e.alternate;if(0===e.lanes&&(null===o||0===o.lanes)&&null!==(o=t.lastRenderedReducer))try{var s=t.lastRenderedState,r=o(s,a);if(n.hasEagerState=!0,n.eagerState=r,si(r,s)){var c=t.interleaved;return null===c?(n.next=n,ko(t)):(n.next=c.next,c.next=n),void(t.interleaved=n)}}catch(l){}null!==(a=Io(e,t,n,i))&&(il(a,e,i,n=tl()),or(a,t,i))}}function ir(e){var t=e.alternate;return e===fs||null!==t&&t===fs}function nr(e,t){ys=vs=!0;var a=e.pending;null===a?t.next=t:(t.next=a.next,a.next=t),e.pending=t}function or(e,t,a){if(0!==(4194240&a)){var i=t.lanes;a|=i&=e.pendingLanes,t.lanes=a,vt(e,a)}}var sr={readContext:Co,useCallback:As,useContext:As,useEffect:As,useImperativeHandle:As,useInsertionEffect:As,useLayoutEffect:As,useMemo:As,useReducer:As,useRef:As,useState:As,useDebugValue:As,useDeferredValue:As,useTransition:As,useMutableSource:As,useSyncExternalStore:As,useId:As,unstable_isNewReconciler:!1},rr={readContext:Co,useCallback:function(e,t){return Cs().memoizedState=[e,void 0===t?null:t],e},useContext:Co,useEffect:zs,useImperativeHandle:function(e,t,a){return a=null!==a&&void 0!==a?a.concat([e]):null,js(4194308,4,Ks.bind(null,t,e),a)},useLayoutEffect:function(e,t){return js(4194308,4,e,t)},useInsertionEffect:function(e,t){return js(4,2,e,t)},useMemo:function(e,t){var a=Cs();return t=void 0===t?null:t,e=e(),a.memoizedState=[e,t],e},useReducer:function(e,t,a){var i=Cs();return t=void 0!==a?a(t):t,i.memoizedState=i.baseState=t,e={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:e,lastRenderedState:t},i.queue=e,e=e.dispatch=tr.bind(null,fs,e),[i.memoizedState,e]},useRef:function(e){return e={current:e},Cs().memoizedState=e},useState:Vs,useDebugValue:Js,useDeferredValue:function(e){return Cs().memoizedState=e},useTransition:function(){var e=Vs(!1),t=e[0];return e=$s.bind(null,e[1]),Cs().memoizedState=e,[t,e]},useMutableSource:function(){},useSyncExternalStore:function(e,t,a){var i=fs,n=Cs();if(no){if(void 0===a)throw Error(o(407));a=a()}else{if(a=t(),null===Mc)throw Error(o(349));0!==(30&ps)||xs(i,t,a)}n.memoizedState=a;var s={value:a,getSnapshot:t};return n.queue=s,zs(Bs.bind(null,i,s,e),[e]),i.flags|=2048,Ws(9,Ps.bind(null,i,s,a,t),void 0,null),a},useId:function(){var e=Cs(),t=Mc.identifierPrefix;if(no){var a=Xn;t=":"+t+"R"+(a=(Yn&~(1<<32-st(Yn)-1)).toString(32)+a),0<(a=ws++)&&(t+="H"+a.toString(32)),t+=":"}else t=":"+t+"r"+(a=Ds++).toString(32)+":";return e.memoizedState=t},unstable_isNewReconciler:!1},cr={readContext:Co,useCallback:Ys,useContext:Co,useEffect:Gs,useImperativeHandle:Qs,useInsertionEffect:Hs,useLayoutEffect:qs,useMemo:Xs,useReducer:Is,useRef:Fs,useState:function(){return Is(ks)},useDebugValue:Js,useDeferredValue:function(e){return Zs(Es(),gs.memoizedState,e)},useTransition:function(){return[Is(ks)[0],Es().memoizedState]},useMutableSource:Os,useSyncExternalStore:Ls,useId:er,unstable_isNewReconciler:!1},lr={readContext:Co,useCallback:Ys,useContext:Co,useEffect:Gs,useImperativeHandle:Qs,useInsertionEffect:Hs,useLayoutEffect:qs,useMemo:Xs,useReducer:Ms,useRef:Fs,useState:function(){return Ms(ks)},useDebugValue:Js,useDeferredValue:function(e){var t=Es();return null===gs?t.memoizedState=e:Zs(t,gs.memoizedState,e)},useTransition:function(){return[Ms(ks)[0],Es().memoizedState]},useMutableSource:Os,useSyncExternalStore:Ls,useId:er,unstable_isNewReconciler:!1};function dr(e,t){try{var a="",i=t;do{a+=j(i),i=i.return}while(i);var n=a}catch(o){n="\nError generating stack: "+o.message+"\n"+o.stack}return{value:e,source:t,stack:n,digest:null}}function ur(e,t,a){return{value:e,source:null,stack:null!=a?a:null,digest:null!=t?t:null}}function hr(e,t){try{console.error(t.value)}catch(a){setTimeout((function(){throw a}))}}var mr="function"===typeof WeakMap?WeakMap:Map;function pr(e,t,a){(a=Po(-1,a)).tag=3,a.payload={element:null};var i=t.value;return a.callback=function(){Hc||(Hc=!0,qc=i),hr(0,t)},a}function fr(e,t,a){(a=Po(-1,a)).tag=3;var i=e.type.getDerivedStateFromError;if("function"===typeof i){var n=t.value;a.payload=function(){return i(n)},a.callback=function(){hr(0,t)}}var o=e.stateNode;return null!==o&&"function"===typeof o.componentDidCatch&&(a.callback=function(){hr(0,t),"function"!==typeof i&&(null===Kc?Kc=new Set([this]):Kc.add(this));var e=t.stack;this.componentDidCatch(t.value,{componentStack:null!==e?e:""})}),a}function gr(e,t,a){var i=e.pingCache;if(null===i){i=e.pingCache=new mr;var n=new Set;i.set(t,n)}else void 0===(n=i.get(t))&&(n=new Set,i.set(t,n));n.has(a)||(n.add(a),e=Cl.bind(null,e,t,a),t.then(e,e))}function br(e){do{var t;if((t=13===e.tag)&&(t=null===(t=e.memoizedState)||null!==t.dehydrated),t)return e;e=e.return}while(null!==e);return null}function vr(e,t,a,i,n){return 0===(1&e.mode)?(e===t?e.flags|=65536:(e.flags|=128,a.flags|=131072,a.flags&=-52805,1===a.tag&&(null===a.alternate?a.tag=17:((t=Po(-1,1)).tag=2,Bo(a,t,1))),a.lanes|=1),e):(e.flags|=65536,e.lanes=n,e)}var yr=w.ReactCurrentOwner,wr=!1;function Dr(e,t,a,i){t.child=null===e?Zo(t,null,a,i):Xo(t,e.child,a,i)}function Ar(e,t,a,i,n){a=a.render;var o=t.ref;return To(t,n),i=Ss(e,t,a,i,o,n),a=Ts(),null===e||wr?(no&&a&&eo(t),t.flags|=1,Dr(e,t,i,n),t.child):(t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~n,Hr(e,t,n))}function Rr(e,t,a,i,n){if(null===e){var o=a.type;return"function"!==typeof o||xl(o)||void 0!==o.defaultProps||null!==a.compare||void 0!==a.defaultProps?((e=Bl(a.type,null,i,t,t.mode,n)).ref=t.ref,e.return=t,t.child=e):(t.tag=15,t.type=o,Sr(e,t,o,i,n))}if(o=e.child,0===(e.lanes&n)){var s=o.memoizedProps;if((a=null!==(a=a.compare)?a:ri)(s,i)&&e.ref===t.ref)return Hr(e,t,n)}return t.flags|=1,(e=Pl(o,i)).ref=t.ref,e.return=t,t.child=e}function Sr(e,t,a,i,n){if(null!==e){var o=e.memoizedProps;if(ri(o,i)&&e.ref===t.ref){if(wr=!1,t.pendingProps=i=o,0===(e.lanes&n))return t.lanes=e.lanes,Hr(e,t,n);0!==(131072&e.flags)&&(wr=!0)}}return Er(e,t,a,i,n)}function Tr(e,t,a){var i=t.pendingProps,n=i.children,o=null!==e?e.memoizedState:null;if("hidden"===i.mode)if(0===(1&t.mode))t.memoizedState={baseLanes:0,cachePool:null,transitions:null},Cn(Pc,xc),xc|=a;else{if(0===(1073741824&a))return e=null!==o?o.baseLanes|a:a,t.lanes=t.childLanes=1073741824,t.memoizedState={baseLanes:e,cachePool:null,transitions:null},t.updateQueue=null,Cn(Pc,xc),xc|=e,null;t.memoizedState={baseLanes:0,cachePool:null,transitions:null},i=null!==o?o.baseLanes:a,Cn(Pc,xc),xc|=i}else null!==o?(i=o.baseLanes|a,t.memoizedState=null):i=a,Cn(Pc,xc),xc|=i;return Dr(e,t,n,a),t.child}function Cr(e,t){var a=t.ref;(null===e&&null!==a||null!==e&&e.ref!==a)&&(t.flags|=512,t.flags|=2097152)}function Er(e,t,a,i,n){var o=Ln(a)?Mn:kn.current;return o=On(t,o),To(t,n),a=Ss(e,t,a,i,o,n),i=Ts(),null===e||wr?(no&&i&&eo(t),t.flags|=1,Dr(e,t,a,n),t.child):(t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~n,Hr(e,t,n))}function kr(e,t,a,i,n){if(Ln(a)){var o=!0;Nn(t)}else o=!1;if(To(t,n),null===t.stateNode)Gr(e,t),Go(t,a,i),qo(t,a,i,n),i=!0;else if(null===e){var s=t.stateNode,r=t.memoizedProps;s.props=r;var c=s.context,l=a.contextType;"object"===typeof l&&null!==l?l=Co(l):l=On(t,l=Ln(a)?Mn:kn.current);var d=a.getDerivedStateFromProps,u="function"===typeof d||"function"===typeof s.getSnapshotBeforeUpdate;u||"function"!==typeof s.UNSAFE_componentWillReceiveProps&&"function"!==typeof s.componentWillReceiveProps||(r!==i||c!==l)&&Ho(t,s,i,l),Oo=!1;var h=t.memoizedState;s.state=h,Vo(t,i,s,n),c=t.memoizedState,r!==i||h!==c||In.current||Oo?("function"===typeof d&&(jo(t,a,d,i),c=t.memoizedState),(r=Oo||zo(t,a,r,i,h,c,l))?(u||"function"!==typeof s.UNSAFE_componentWillMount&&"function"!==typeof s.componentWillMount||("function"===typeof s.componentWillMount&&s.componentWillMount(),"function"===typeof s.UNSAFE_componentWillMount&&s.UNSAFE_componentWillMount()),"function"===typeof s.componentDidMount&&(t.flags|=4194308)):("function"===typeof s.componentDidMount&&(t.flags|=4194308),t.memoizedProps=i,t.memoizedState=c),s.props=i,s.state=c,s.context=l,i=r):("function"===typeof s.componentDidMount&&(t.flags|=4194308),i=!1)}else{s=t.stateNode,xo(e,t),r=t.memoizedProps,l=t.type===t.elementType?r:bo(t.type,r),s.props=l,u=t.pendingProps,h=s.context,"object"===typeof(c=a.contextType)&&null!==c?c=Co(c):c=On(t,c=Ln(a)?Mn:kn.current);var m=a.getDerivedStateFromProps;(d="function"===typeof m||"function"===typeof s.getSnapshotBeforeUpdate)||"function"!==typeof s.UNSAFE_componentWillReceiveProps&&"function"!==typeof s.componentWillReceiveProps||(r!==u||h!==c)&&Ho(t,s,i,c),Oo=!1,h=t.memoizedState,s.state=h,Vo(t,i,s,n);var p=t.memoizedState;r!==u||h!==p||In.current||Oo?("function"===typeof m&&(jo(t,a,m,i),p=t.memoizedState),(l=Oo||zo(t,a,l,i,h,p,c)||!1)?(d||"function"!==typeof s.UNSAFE_componentWillUpdate&&"function"!==typeof s.componentWillUpdate||("function"===typeof s.componentWillUpdate&&s.componentWillUpdate(i,p,c),"function"===typeof s.UNSAFE_componentWillUpdate&&s.UNSAFE_componentWillUpdate(i,p,c)),"function"===typeof s.componentDidUpdate&&(t.flags|=4),"function"===typeof s.getSnapshotBeforeUpdate&&(t.flags|=1024)):("function"!==typeof s.componentDidUpdate||r===e.memoizedProps&&h===e.memoizedState||(t.flags|=4),"function"!==typeof s.getSnapshotBeforeUpdate||r===e.memoizedProps&&h===e.memoizedState||(t.flags|=1024),t.memoizedProps=i,t.memoizedState=p),s.props=i,s.state=p,s.context=c,i=l):("function"!==typeof s.componentDidUpdate||r===e.memoizedProps&&h===e.memoizedState||(t.flags|=4),"function"!==typeof s.getSnapshotBeforeUpdate||r===e.memoizedProps&&h===e.memoizedState||(t.flags|=1024),i=!1)}return Ir(e,t,a,i,o,n)}function Ir(e,t,a,i,n,o){Cr(e,t);var s=0!==(128&t.flags);if(!i&&!s)return n&&_n(t,a,!1),Hr(e,t,o);i=t.stateNode,yr.current=t;var r=s&&"function"!==typeof a.getDerivedStateFromError?null:i.render();return t.flags|=1,null!==e&&s?(t.child=Xo(t,e.child,null,o),t.child=Xo(t,null,r,o)):Dr(e,t,r,o),t.memoizedState=i.state,n&&_n(t,a,!0),t.child}function Mr(e){var t=e.stateNode;t.pendingContext?Pn(0,t.pendingContext,t.pendingContext!==t.context):t.context&&Pn(0,t.context,!1),ns(e,t.containerInfo)}function Or(e,t,a,i,n){return po(),fo(n),t.flags|=256,Dr(e,t,a,i),t.child}var Lr,xr,Pr,Br,Nr={dehydrated:null,treeContext:null,retryLane:0};function _r(e){return{baseLanes:e,cachePool:null,transitions:null}}function Vr(e,t,a){var i,n=t.pendingProps,s=cs.current,r=!1,c=0!==(128&t.flags);if((i=c)||(i=(null===e||null!==e.memoizedState)&&0!==(2&s)),i?(r=!0,t.flags&=-129):null!==e&&null===e.memoizedState||(s|=1),Cn(cs,1&s),null===e)return lo(t),null!==(e=t.memoizedState)&&null!==(e=e.dehydrated)?(0===(1&t.mode)?t.lanes=1:"$!"===e.data?t.lanes=8:t.lanes=1073741824,null):(c=n.children,e=n.fallback,r?(n=t.mode,r=t.child,c={mode:"hidden",children:c},0===(1&n)&&null!==r?(r.childLanes=0,r.pendingProps=c):r=_l(c,n,0,null),e=Nl(e,n,a,null),r.return=t,e.return=t,r.sibling=e,t.child=r,t.child.memoizedState=_r(a),t.memoizedState=Nr,e):Wr(t,c));if(null!==(s=e.memoizedState)&&null!==(i=s.dehydrated))return function(e,t,a,i,n,s,r){if(a)return 256&t.flags?(t.flags&=-257,Fr(e,t,r,i=ur(Error(o(422))))):null!==t.memoizedState?(t.child=e.child,t.flags|=128,null):(s=i.fallback,n=t.mode,i=_l({mode:"visible",children:i.children},n,0,null),(s=Nl(s,n,r,null)).flags|=2,i.return=t,s.return=t,i.sibling=s,t.child=i,0!==(1&t.mode)&&Xo(t,e.child,null,r),t.child.memoizedState=_r(r),t.memoizedState=Nr,s);if(0===(1&t.mode))return Fr(e,t,r,null);if("$!"===n.data){if(i=n.nextSibling&&n.nextSibling.dataset)var c=i.dgst;return i=c,Fr(e,t,r,i=ur(s=Error(o(419)),i,void 0))}if(c=0!==(r&e.childLanes),wr||c){if(null!==(i=Mc)){switch(r&-r){case 4:n=2;break;case 16:n=8;break;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:n=32;break;case 536870912:n=268435456;break;default:n=0}0!==(n=0!==(n&(i.suspendedLanes|r))?0:n)&&n!==s.retryLane&&(s.retryLane=n,Mo(e,n),il(i,e,n,-1))}return gl(),Fr(e,t,r,i=ur(Error(o(421))))}return"$?"===n.data?(t.flags|=128,t.child=e.child,t=kl.bind(null,e),n._reactRetry=t,null):(e=s.treeContext,io=ln(n.nextSibling),ao=t,no=!0,oo=null,null!==e&&(Kn[Qn++]=Yn,Kn[Qn++]=Xn,Kn[Qn++]=Jn,Yn=e.id,Xn=e.overflow,Jn=t),t=Wr(t,i.children),t.flags|=4096,t)}(e,t,c,n,i,s,a);if(r){r=n.fallback,c=t.mode,i=(s=e.child).sibling;var l={mode:"hidden",children:n.children};return 0===(1&c)&&t.child!==s?((n=t.child).childLanes=0,n.pendingProps=l,t.deletions=null):(n=Pl(s,l)).subtreeFlags=14680064&s.subtreeFlags,null!==i?r=Pl(i,r):(r=Nl(r,c,a,null)).flags|=2,r.return=t,n.return=t,n.sibling=r,t.child=n,n=r,r=t.child,c=null===(c=e.child.memoizedState)?_r(a):{baseLanes:c.baseLanes|a,cachePool:null,transitions:c.transitions},r.memoizedState=c,r.childLanes=e.childLanes&~a,t.memoizedState=Nr,n}return e=(r=e.child).sibling,n=Pl(r,{mode:"visible",children:n.children}),0===(1&t.mode)&&(n.lanes=a),n.return=t,n.sibling=null,null!==e&&(null===(a=t.deletions)?(t.deletions=[e],t.flags|=16):a.push(e)),t.child=n,t.memoizedState=null,n}function Wr(e,t){return(t=_l({mode:"visible",children:t},e.mode,0,null)).return=e,e.child=t}function Fr(e,t,a,i){return null!==i&&fo(i),Xo(t,e.child,null,a),(e=Wr(t,t.pendingProps.children)).flags|=2,t.memoizedState=null,e}function jr(e,t,a){e.lanes|=t;var i=e.alternate;null!==i&&(i.lanes|=t),So(e.return,t,a)}function Ur(e,t,a,i,n){var o=e.memoizedState;null===o?e.memoizedState={isBackwards:t,rendering:null,renderingStartTime:0,last:i,tail:a,tailMode:n}:(o.isBackwards=t,o.rendering=null,o.renderingStartTime=0,o.last=i,o.tail=a,o.tailMode=n)}function zr(e,t,a){var i=t.pendingProps,n=i.revealOrder,o=i.tail;if(Dr(e,t,i.children,a),0!==(2&(i=cs.current)))i=1&i|2,t.flags|=128;else{if(null!==e&&0!==(128&e.flags))e:for(e=t.child;null!==e;){if(13===e.tag)null!==e.memoizedState&&jr(e,a,t);else if(19===e.tag)jr(e,a,t);else if(null!==e.child){e.child.return=e,e=e.child;continue}if(e===t)break e;for(;null===e.sibling;){if(null===e.return||e.return===t)break e;e=e.return}e.sibling.return=e.return,e=e.sibling}i&=1}if(Cn(cs,i),0===(1&t.mode))t.memoizedState=null;else switch(n){case"forwards":for(a=t.child,n=null;null!==a;)null!==(e=a.alternate)&&null===ls(e)&&(n=a),a=a.sibling;null===(a=n)?(n=t.child,t.child=null):(n=a.sibling,a.sibling=null),Ur(t,!1,n,a,o);break;case"backwards":for(a=null,n=t.child,t.child=null;null!==n;){if(null!==(e=n.alternate)&&null===ls(e)){t.child=n;break}e=n.sibling,n.sibling=a,a=n,n=e}Ur(t,!0,a,null,o);break;case"together":Ur(t,!1,null,null,void 0);break;default:t.memoizedState=null}return t.child}function Gr(e,t){0===(1&t.mode)&&null!==e&&(e.alternate=null,t.alternate=null,t.flags|=2)}function Hr(e,t,a){if(null!==e&&(t.dependencies=e.dependencies),_c|=t.lanes,0===(a&t.childLanes))return null;if(null!==e&&t.child!==e.child)throw Error(o(153));if(null!==t.child){for(a=Pl(e=t.child,e.pendingProps),t.child=a,a.return=t;null!==e.sibling;)e=e.sibling,(a=a.sibling=Pl(e,e.pendingProps)).return=t;a.sibling=null}return t.child}function qr(e,t){if(!no)switch(e.tailMode){case"hidden":t=e.tail;for(var a=null;null!==t;)null!==t.alternate&&(a=t),t=t.sibling;null===a?e.tail=null:a.sibling=null;break;case"collapsed":a=e.tail;for(var i=null;null!==a;)null!==a.alternate&&(i=a),a=a.sibling;null===i?t||null===e.tail?e.tail=null:e.tail.sibling=null:i.sibling=null}}function Kr(e){var t=null!==e.alternate&&e.alternate.child===e.child,a=0,i=0;if(t)for(var n=e.child;null!==n;)a|=n.lanes|n.childLanes,i|=14680064&n.subtreeFlags,i|=14680064&n.flags,n.return=e,n=n.sibling;else for(n=e.child;null!==n;)a|=n.lanes|n.childLanes,i|=n.subtreeFlags,i|=n.flags,n.return=e,n=n.sibling;return e.subtreeFlags|=i,e.childLanes=a,t}function Qr(e,t,a){var i=t.pendingProps;switch(to(t),t.tag){case 2:case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:return Kr(t),null;case 1:case 17:return Ln(t.type)&&xn(),Kr(t),null;case 3:return i=t.stateNode,os(),Tn(In),Tn(kn),us(),i.pendingContext&&(i.context=i.pendingContext,i.pendingContext=null),null!==e&&null!==e.child||(ho(t)?t.flags|=4:null===e||e.memoizedState.isDehydrated&&0===(256&t.flags)||(t.flags|=1024,null!==oo&&(rl(oo),oo=null))),xr(e,t),Kr(t),null;case 5:rs(t);var n=is(as.current);if(a=t.type,null!==e&&null!=t.stateNode)Pr(e,t,a,i,n),e.ref!==t.ref&&(t.flags|=512,t.flags|=2097152);else{if(!i){if(null===t.stateNode)throw Error(o(166));return Kr(t),null}if(e=is(es.current),ho(t)){i=t.stateNode,a=t.type;var s=t.memoizedProps;switch(i[hn]=t,i[mn]=s,e=0!==(1&t.mode),a){case"dialog":Vi("cancel",i),Vi("close",i);break;case"iframe":case"object":case"embed":Vi("load",i);break;case"video":case"audio":for(n=0;n<Pi.length;n++)Vi(Pi[n],i);break;case"source":Vi("error",i);break;case"img":case"image":case"link":Vi("error",i),Vi("load",i);break;case"details":Vi("toggle",i);break;case"input":Y(i,s),Vi("invalid",i);break;case"select":i._wrapperState={wasMultiple:!!s.multiple},Vi("invalid",i);break;case"textarea":ne(i,s),Vi("invalid",i)}for(var c in ve(a,s),n=null,s)if(s.hasOwnProperty(c)){var l=s[c];"children"===c?"string"===typeof l?i.textContent!==l&&(!0!==s.suppressHydrationWarning&&Xi(i.textContent,l,e),n=["children",l]):"number"===typeof l&&i.textContent!==""+l&&(!0!==s.suppressHydrationWarning&&Xi(i.textContent,l,e),n=["children",""+l]):r.hasOwnProperty(c)&&null!=l&&"onScroll"===c&&Vi("scroll",i)}switch(a){case"input":q(i),$(i,s,!0);break;case"textarea":q(i),se(i);break;case"select":case"option":break;default:"function"===typeof s.onClick&&(i.onclick=Zi)}i=n,t.updateQueue=i,null!==i&&(t.flags|=4)}else{c=9===n.nodeType?n:n.ownerDocument,"http://www.w3.org/1999/xhtml"===e&&(e=re(a)),"http://www.w3.org/1999/xhtml"===e?"script"===a?((e=c.createElement("div")).innerHTML="<script><\/script>",e=e.removeChild(e.firstChild)):"string"===typeof i.is?e=c.createElement(a,{is:i.is}):(e=c.createElement(a),"select"===a&&(c=e,i.multiple?c.multiple=!0:i.size&&(c.size=i.size))):e=c.createElementNS(e,a),e[hn]=t,e[mn]=i,Lr(e,t,!1,!1),t.stateNode=e;e:{switch(c=ye(a,i),a){case"dialog":Vi("cancel",e),Vi("close",e),n=i;break;case"iframe":case"object":case"embed":Vi("load",e),n=i;break;case"video":case"audio":for(n=0;n<Pi.length;n++)Vi(Pi[n],e);n=i;break;case"source":Vi("error",e),n=i;break;case"img":case"image":case"link":Vi("error",e),Vi("load",e),n=i;break;case"details":Vi("toggle",e),n=i;break;case"input":Y(e,i),n=J(e,i),Vi("invalid",e);break;case"option":default:n=i;break;case"select":e._wrapperState={wasMultiple:!!i.multiple},n=_({},i,{value:void 0}),Vi("invalid",e);break;case"textarea":ne(e,i),n=ie(e,i),Vi("invalid",e)}for(s in ve(a,n),l=n)if(l.hasOwnProperty(s)){var d=l[s];"style"===s?ge(e,d):"dangerouslySetInnerHTML"===s?null!=(d=d?d.__html:void 0)&&ue(e,d):"children"===s?"string"===typeof d?("textarea"!==a||""!==d)&&he(e,d):"number"===typeof d&&he(e,""+d):"suppressContentEditableWarning"!==s&&"suppressHydrationWarning"!==s&&"autoFocus"!==s&&(r.hasOwnProperty(s)?null!=d&&"onScroll"===s&&Vi("scroll",e):null!=d&&y(e,s,d,c))}switch(a){case"input":q(e),$(e,i,!1);break;case"textarea":q(e),se(e);break;case"option":null!=i.value&&e.setAttribute("value",""+G(i.value));break;case"select":e.multiple=!!i.multiple,null!=(s=i.value)?ae(e,!!i.multiple,s,!1):null!=i.defaultValue&&ae(e,!!i.multiple,i.defaultValue,!0);break;default:"function"===typeof n.onClick&&(e.onclick=Zi)}switch(a){case"button":case"input":case"select":case"textarea":i=!!i.autoFocus;break e;case"img":i=!0;break e;default:i=!1}}i&&(t.flags|=4)}null!==t.ref&&(t.flags|=512,t.flags|=2097152)}return Kr(t),null;case 6:if(e&&null!=t.stateNode)Br(e,t,e.memoizedProps,i);else{if("string"!==typeof i&&null===t.stateNode)throw Error(o(166));if(a=is(as.current),is(es.current),ho(t)){if(i=t.stateNode,a=t.memoizedProps,i[hn]=t,(s=i.nodeValue!==a)&&null!==(e=ao))switch(e.tag){case 3:Xi(i.nodeValue,a,0!==(1&e.mode));break;case 5:!0!==e.memoizedProps.suppressHydrationWarning&&Xi(i.nodeValue,a,0!==(1&e.mode))}s&&(t.flags|=4)}else(i=(9===a.nodeType?a:a.ownerDocument).createTextNode(i))[hn]=t,t.stateNode=i}return Kr(t),null;case 13:if(Tn(cs),i=t.memoizedState,null===e||null!==e.memoizedState&&null!==e.memoizedState.dehydrated){if(no&&null!==io&&0!==(1&t.mode)&&0===(128&t.flags))mo(),po(),t.flags|=98560,s=!1;else if(s=ho(t),null!==i&&null!==i.dehydrated){if(null===e){if(!s)throw Error(o(318));if(!(s=null!==(s=t.memoizedState)?s.dehydrated:null))throw Error(o(317));s[hn]=t}else po(),0===(128&t.flags)&&(t.memoizedState=null),t.flags|=4;Kr(t),s=!1}else null!==oo&&(rl(oo),oo=null),s=!0;if(!s)return 65536&t.flags?t:null}return 0!==(128&t.flags)?(t.lanes=a,t):((i=null!==i)!==(null!==e&&null!==e.memoizedState)&&i&&(t.child.flags|=8192,0!==(1&t.mode)&&(null===e||0!==(1&cs.current)?0===Bc&&(Bc=3):gl())),null!==t.updateQueue&&(t.flags|=4),Kr(t),null);case 4:return os(),xr(e,t),null===e&&ji(t.stateNode.containerInfo),Kr(t),null;case 10:return Ro(t.type._context),Kr(t),null;case 19:if(Tn(cs),null===(s=t.memoizedState))return Kr(t),null;if(i=0!==(128&t.flags),null===(c=s.rendering))if(i)qr(s,!1);else{if(0!==Bc||null!==e&&0!==(128&e.flags))for(e=t.child;null!==e;){if(null!==(c=ls(e))){for(t.flags|=128,qr(s,!1),null!==(i=c.updateQueue)&&(t.updateQueue=i,t.flags|=4),t.subtreeFlags=0,i=a,a=t.child;null!==a;)e=i,(s=a).flags&=14680066,null===(c=s.alternate)?(s.childLanes=0,s.lanes=e,s.child=null,s.subtreeFlags=0,s.memoizedProps=null,s.memoizedState=null,s.updateQueue=null,s.dependencies=null,s.stateNode=null):(s.childLanes=c.childLanes,s.lanes=c.lanes,s.child=c.child,s.subtreeFlags=0,s.deletions=null,s.memoizedProps=c.memoizedProps,s.memoizedState=c.memoizedState,s.updateQueue=c.updateQueue,s.type=c.type,e=c.dependencies,s.dependencies=null===e?null:{lanes:e.lanes,firstContext:e.firstContext}),a=a.sibling;return Cn(cs,1&cs.current|2),t.child}e=e.sibling}null!==s.tail&&Xe()>zc&&(t.flags|=128,i=!0,qr(s,!1),t.lanes=4194304)}else{if(!i)if(null!==(e=ls(c))){if(t.flags|=128,i=!0,null!==(a=e.updateQueue)&&(t.updateQueue=a,t.flags|=4),qr(s,!0),null===s.tail&&"hidden"===s.tailMode&&!c.alternate&&!no)return Kr(t),null}else 2*Xe()-s.renderingStartTime>zc&&1073741824!==a&&(t.flags|=128,i=!0,qr(s,!1),t.lanes=4194304);s.isBackwards?(c.sibling=t.child,t.child=c):(null!==(a=s.last)?a.sibling=c:t.child=c,s.last=c)}return null!==s.tail?(t=s.tail,s.rendering=t,s.tail=t.sibling,s.renderingStartTime=Xe(),t.sibling=null,a=cs.current,Cn(cs,i?1&a|2:1&a),t):(Kr(t),null);case 22:case 23:return hl(),i=null!==t.memoizedState,null!==e&&null!==e.memoizedState!==i&&(t.flags|=8192),i&&0!==(1&t.mode)?0!==(1073741824&xc)&&(Kr(t),6&t.subtreeFlags&&(t.flags|=8192)):Kr(t),null;case 24:case 25:return null}throw Error(o(156,t.tag))}function Jr(e,t){switch(to(t),t.tag){case 1:return Ln(t.type)&&xn(),65536&(e=t.flags)?(t.flags=-65537&e|128,t):null;case 3:return os(),Tn(In),Tn(kn),us(),0!==(65536&(e=t.flags))&&0===(128&e)?(t.flags=-65537&e|128,t):null;case 5:return rs(t),null;case 13:if(Tn(cs),null!==(e=t.memoizedState)&&null!==e.dehydrated){if(null===t.alternate)throw Error(o(340));po()}return 65536&(e=t.flags)?(t.flags=-65537&e|128,t):null;case 19:return Tn(cs),null;case 4:return os(),null;case 10:return Ro(t.type._context),null;case 22:case 23:return hl(),null;default:return null}}Lr=function(e,t){for(var a=t.child;null!==a;){if(5===a.tag||6===a.tag)e.appendChild(a.stateNode);else if(4!==a.tag&&null!==a.child){a.child.return=a,a=a.child;continue}if(a===t)break;for(;null===a.sibling;){if(null===a.return||a.return===t)return;a=a.return}a.sibling.return=a.return,a=a.sibling}},xr=function(){},Pr=function(e,t,a,i){var n=e.memoizedProps;if(n!==i){e=t.stateNode,is(es.current);var o,s=null;switch(a){case"input":n=J(e,n),i=J(e,i),s=[];break;case"select":n=_({},n,{value:void 0}),i=_({},i,{value:void 0}),s=[];break;case"textarea":n=ie(e,n),i=ie(e,i),s=[];break;default:"function"!==typeof n.onClick&&"function"===typeof i.onClick&&(e.onclick=Zi)}for(d in ve(a,i),a=null,n)if(!i.hasOwnProperty(d)&&n.hasOwnProperty(d)&&null!=n[d])if("style"===d){var c=n[d];for(o in c)c.hasOwnProperty(o)&&(a||(a={}),a[o]="")}else"dangerouslySetInnerHTML"!==d&&"children"!==d&&"suppressContentEditableWarning"!==d&&"suppressHydrationWarning"!==d&&"autoFocus"!==d&&(r.hasOwnProperty(d)?s||(s=[]):(s=s||[]).push(d,null));for(d in i){var l=i[d];if(c=null!=n?n[d]:void 0,i.hasOwnProperty(d)&&l!==c&&(null!=l||null!=c))if("style"===d)if(c){for(o in c)!c.hasOwnProperty(o)||l&&l.hasOwnProperty(o)||(a||(a={}),a[o]="");for(o in l)l.hasOwnProperty(o)&&c[o]!==l[o]&&(a||(a={}),a[o]=l[o])}else a||(s||(s=[]),s.push(d,a)),a=l;else"dangerouslySetInnerHTML"===d?(l=l?l.__html:void 0,c=c?c.__html:void 0,null!=l&&c!==l&&(s=s||[]).push(d,l)):"children"===d?"string"!==typeof l&&"number"!==typeof l||(s=s||[]).push(d,""+l):"suppressContentEditableWarning"!==d&&"suppressHydrationWarning"!==d&&(r.hasOwnProperty(d)?(null!=l&&"onScroll"===d&&Vi("scroll",e),s||c===l||(s=[])):(s=s||[]).push(d,l))}a&&(s=s||[]).push("style",a);var d=s;(t.updateQueue=d)&&(t.flags|=4)}},Br=function(e,t,a,i){a!==i&&(t.flags|=4)};var Yr=!1,Xr=!1,Zr="function"===typeof WeakSet?WeakSet:Set,$r=null;function ec(e,t){var a=e.ref;if(null!==a)if("function"===typeof a)try{a(null)}catch(i){Tl(e,t,i)}else a.current=null}function tc(e,t,a){try{a()}catch(i){Tl(e,t,i)}}var ac=!1;function ic(e,t,a){var i=t.updateQueue;if(null!==(i=null!==i?i.lastEffect:null)){var n=i=i.next;do{if((n.tag&e)===e){var o=n.destroy;n.destroy=void 0,void 0!==o&&tc(t,a,o)}n=n.next}while(n!==i)}}function nc(e,t){if(null!==(t=null!==(t=t.updateQueue)?t.lastEffect:null)){var a=t=t.next;do{if((a.tag&e)===e){var i=a.create;a.destroy=i()}a=a.next}while(a!==t)}}function oc(e){var t=e.ref;if(null!==t){var a=e.stateNode;e.tag,e=a,"function"===typeof t?t(e):t.current=e}}function sc(e){var t=e.alternate;null!==t&&(e.alternate=null,sc(t)),e.child=null,e.deletions=null,e.sibling=null,5===e.tag&&(null!==(t=e.stateNode)&&(delete t[hn],delete t[mn],delete t[fn],delete t[gn],delete t[bn])),e.stateNode=null,e.return=null,e.dependencies=null,e.memoizedProps=null,e.memoizedState=null,e.pendingProps=null,e.stateNode=null,e.updateQueue=null}function rc(e){return 5===e.tag||3===e.tag||4===e.tag}function cc(e){e:for(;;){for(;null===e.sibling;){if(null===e.return||rc(e.return))return null;e=e.return}for(e.sibling.return=e.return,e=e.sibling;5!==e.tag&&6!==e.tag&&18!==e.tag;){if(2&e.flags)continue e;if(null===e.child||4===e.tag)continue e;e.child.return=e,e=e.child}if(!(2&e.flags))return e.stateNode}}function lc(e,t,a){var i=e.tag;if(5===i||6===i)e=e.stateNode,t?8===a.nodeType?a.parentNode.insertBefore(e,t):a.insertBefore(e,t):(8===a.nodeType?(t=a.parentNode).insertBefore(e,a):(t=a).appendChild(e),null!==(a=a._reactRootContainer)&&void 0!==a||null!==t.onclick||(t.onclick=Zi));else if(4!==i&&null!==(e=e.child))for(lc(e,t,a),e=e.sibling;null!==e;)lc(e,t,a),e=e.sibling}function dc(e,t,a){var i=e.tag;if(5===i||6===i)e=e.stateNode,t?a.insertBefore(e,t):a.appendChild(e);else if(4!==i&&null!==(e=e.child))for(dc(e,t,a),e=e.sibling;null!==e;)dc(e,t,a),e=e.sibling}var uc=null,hc=!1;function mc(e,t,a){for(a=a.child;null!==a;)pc(e,t,a),a=a.sibling}function pc(e,t,a){if(ot&&"function"===typeof ot.onCommitFiberUnmount)try{ot.onCommitFiberUnmount(nt,a)}catch(r){}switch(a.tag){case 5:Xr||ec(a,t);case 6:var i=uc,n=hc;uc=null,mc(e,t,a),hc=n,null!==(uc=i)&&(hc?(e=uc,a=a.stateNode,8===e.nodeType?e.parentNode.removeChild(a):e.removeChild(a)):uc.removeChild(a.stateNode));break;case 18:null!==uc&&(hc?(e=uc,a=a.stateNode,8===e.nodeType?cn(e.parentNode,a):1===e.nodeType&&cn(e,a),Ut(e)):cn(uc,a.stateNode));break;case 4:i=uc,n=hc,uc=a.stateNode.containerInfo,hc=!0,mc(e,t,a),uc=i,hc=n;break;case 0:case 11:case 14:case 15:if(!Xr&&(null!==(i=a.updateQueue)&&null!==(i=i.lastEffect))){n=i=i.next;do{var o=n,s=o.destroy;o=o.tag,void 0!==s&&(0!==(2&o)||0!==(4&o))&&tc(a,t,s),n=n.next}while(n!==i)}mc(e,t,a);break;case 1:if(!Xr&&(ec(a,t),"function"===typeof(i=a.stateNode).componentWillUnmount))try{i.props=a.memoizedProps,i.state=a.memoizedState,i.componentWillUnmount()}catch(r){Tl(a,t,r)}mc(e,t,a);break;case 21:mc(e,t,a);break;case 22:1&a.mode?(Xr=(i=Xr)||null!==a.memoizedState,mc(e,t,a),Xr=i):mc(e,t,a);break;default:mc(e,t,a)}}function fc(e){var t=e.updateQueue;if(null!==t){e.updateQueue=null;var a=e.stateNode;null===a&&(a=e.stateNode=new Zr),t.forEach((function(t){var i=Il.bind(null,e,t);a.has(t)||(a.add(t),t.then(i,i))}))}}function gc(e,t){var a=t.deletions;if(null!==a)for(var i=0;i<a.length;i++){var n=a[i];try{var s=e,r=t,c=r;e:for(;null!==c;){switch(c.tag){case 5:uc=c.stateNode,hc=!1;break e;case 3:case 4:uc=c.stateNode.containerInfo,hc=!0;break e}c=c.return}if(null===uc)throw Error(o(160));pc(s,r,n),uc=null,hc=!1;var l=n.alternate;null!==l&&(l.return=null),n.return=null}catch(d){Tl(n,t,d)}}if(12854&t.subtreeFlags)for(t=t.child;null!==t;)bc(t,e),t=t.sibling}function bc(e,t){var a=e.alternate,i=e.flags;switch(e.tag){case 0:case 11:case 14:case 15:if(gc(t,e),vc(e),4&i){try{ic(3,e,e.return),nc(3,e)}catch(g){Tl(e,e.return,g)}try{ic(5,e,e.return)}catch(g){Tl(e,e.return,g)}}break;case 1:gc(t,e),vc(e),512&i&&null!==a&&ec(a,a.return);break;case 5:if(gc(t,e),vc(e),512&i&&null!==a&&ec(a,a.return),32&e.flags){var n=e.stateNode;try{he(n,"")}catch(g){Tl(e,e.return,g)}}if(4&i&&null!=(n=e.stateNode)){var s=e.memoizedProps,r=null!==a?a.memoizedProps:s,c=e.type,l=e.updateQueue;if(e.updateQueue=null,null!==l)try{"input"===c&&"radio"===s.type&&null!=s.name&&X(n,s),ye(c,r);var d=ye(c,s);for(r=0;r<l.length;r+=2){var u=l[r],h=l[r+1];"style"===u?ge(n,h):"dangerouslySetInnerHTML"===u?ue(n,h):"children"===u?he(n,h):y(n,u,h,d)}switch(c){case"input":Z(n,s);break;case"textarea":oe(n,s);break;case"select":var m=n._wrapperState.wasMultiple;n._wrapperState.wasMultiple=!!s.multiple;var p=s.value;null!=p?ae(n,!!s.multiple,p,!1):m!==!!s.multiple&&(null!=s.defaultValue?ae(n,!!s.multiple,s.defaultValue,!0):ae(n,!!s.multiple,s.multiple?[]:"",!1))}n[mn]=s}catch(g){Tl(e,e.return,g)}}break;case 6:if(gc(t,e),vc(e),4&i){if(null===e.stateNode)throw Error(o(162));n=e.stateNode,s=e.memoizedProps;try{n.nodeValue=s}catch(g){Tl(e,e.return,g)}}break;case 3:if(gc(t,e),vc(e),4&i&&null!==a&&a.memoizedState.isDehydrated)try{Ut(t.containerInfo)}catch(g){Tl(e,e.return,g)}break;case 4:default:gc(t,e),vc(e);break;case 13:gc(t,e),vc(e),8192&(n=e.child).flags&&(s=null!==n.memoizedState,n.stateNode.isHidden=s,!s||null!==n.alternate&&null!==n.alternate.memoizedState||(Uc=Xe())),4&i&&fc(e);break;case 22:if(u=null!==a&&null!==a.memoizedState,1&e.mode?(Xr=(d=Xr)||u,gc(t,e),Xr=d):gc(t,e),vc(e),8192&i){if(d=null!==e.memoizedState,(e.stateNode.isHidden=d)&&!u&&0!==(1&e.mode))for($r=e,u=e.child;null!==u;){for(h=$r=u;null!==$r;){switch(p=(m=$r).child,m.tag){case 0:case 11:case 14:case 15:ic(4,m,m.return);break;case 1:ec(m,m.return);var f=m.stateNode;if("function"===typeof f.componentWillUnmount){i=m,a=m.return;try{t=i,f.props=t.memoizedProps,f.state=t.memoizedState,f.componentWillUnmount()}catch(g){Tl(i,a,g)}}break;case 5:ec(m,m.return);break;case 22:if(null!==m.memoizedState){Ac(h);continue}}null!==p?(p.return=m,$r=p):Ac(h)}u=u.sibling}e:for(u=null,h=e;;){if(5===h.tag){if(null===u){u=h;try{n=h.stateNode,d?"function"===typeof(s=n.style).setProperty?s.setProperty("display","none","important"):s.display="none":(c=h.stateNode,r=void 0!==(l=h.memoizedProps.style)&&null!==l&&l.hasOwnProperty("display")?l.display:null,c.style.display=fe("display",r))}catch(g){Tl(e,e.return,g)}}}else if(6===h.tag){if(null===u)try{h.stateNode.nodeValue=d?"":h.memoizedProps}catch(g){Tl(e,e.return,g)}}else if((22!==h.tag&&23!==h.tag||null===h.memoizedState||h===e)&&null!==h.child){h.child.return=h,h=h.child;continue}if(h===e)break e;for(;null===h.sibling;){if(null===h.return||h.return===e)break e;u===h&&(u=null),h=h.return}u===h&&(u=null),h.sibling.return=h.return,h=h.sibling}}break;case 19:gc(t,e),vc(e),4&i&&fc(e);case 21:}}function vc(e){var t=e.flags;if(2&t){try{e:{for(var a=e.return;null!==a;){if(rc(a)){var i=a;break e}a=a.return}throw Error(o(160))}switch(i.tag){case 5:var n=i.stateNode;32&i.flags&&(he(n,""),i.flags&=-33),dc(e,cc(e),n);break;case 3:case 4:var s=i.stateNode.containerInfo;lc(e,cc(e),s);break;default:throw Error(o(161))}}catch(r){Tl(e,e.return,r)}e.flags&=-3}4096&t&&(e.flags&=-4097)}function yc(e,t,a){$r=e,wc(e,t,a)}function wc(e,t,a){for(var i=0!==(1&e.mode);null!==$r;){var n=$r,o=n.child;if(22===n.tag&&i){var s=null!==n.memoizedState||Yr;if(!s){var r=n.alternate,c=null!==r&&null!==r.memoizedState||Xr;r=Yr;var l=Xr;if(Yr=s,(Xr=c)&&!l)for($r=n;null!==$r;)c=(s=$r).child,22===s.tag&&null!==s.memoizedState?Rc(n):null!==c?(c.return=s,$r=c):Rc(n);for(;null!==o;)$r=o,wc(o,t,a),o=o.sibling;$r=n,Yr=r,Xr=l}Dc(e)}else 0!==(8772&n.subtreeFlags)&&null!==o?(o.return=n,$r=o):Dc(e)}}function Dc(e){for(;null!==$r;){var t=$r;if(0!==(8772&t.flags)){var a=t.alternate;try{if(0!==(8772&t.flags))switch(t.tag){case 0:case 11:case 15:Xr||nc(5,t);break;case 1:var i=t.stateNode;if(4&t.flags&&!Xr)if(null===a)i.componentDidMount();else{var n=t.elementType===t.type?a.memoizedProps:bo(t.type,a.memoizedProps);i.componentDidUpdate(n,a.memoizedState,i.__reactInternalSnapshotBeforeUpdate)}var s=t.updateQueue;null!==s&&Wo(t,s,i);break;case 3:var r=t.updateQueue;if(null!==r){if(a=null,null!==t.child)switch(t.child.tag){case 5:case 1:a=t.child.stateNode}Wo(t,r,a)}break;case 5:var c=t.stateNode;if(null===a&&4&t.flags){a=c;var l=t.memoizedProps;switch(t.type){case"button":case"input":case"select":case"textarea":l.autoFocus&&a.focus();break;case"img":l.src&&(a.src=l.src)}}break;case 6:case 4:case 12:case 19:case 17:case 21:case 22:case 23:case 25:break;case 13:if(null===t.memoizedState){var d=t.alternate;if(null!==d){var u=d.memoizedState;if(null!==u){var h=u.dehydrated;null!==h&&Ut(h)}}}break;default:throw Error(o(163))}Xr||512&t.flags&&oc(t)}catch(m){Tl(t,t.return,m)}}if(t===e){$r=null;break}if(null!==(a=t.sibling)){a.return=t.return,$r=a;break}$r=t.return}}function Ac(e){for(;null!==$r;){var t=$r;if(t===e){$r=null;break}var a=t.sibling;if(null!==a){a.return=t.return,$r=a;break}$r=t.return}}function Rc(e){for(;null!==$r;){var t=$r;try{switch(t.tag){case 0:case 11:case 15:var a=t.return;try{nc(4,t)}catch(c){Tl(t,a,c)}break;case 1:var i=t.stateNode;if("function"===typeof i.componentDidMount){var n=t.return;try{i.componentDidMount()}catch(c){Tl(t,n,c)}}var o=t.return;try{oc(t)}catch(c){Tl(t,o,c)}break;case 5:var s=t.return;try{oc(t)}catch(c){Tl(t,s,c)}}}catch(c){Tl(t,t.return,c)}if(t===e){$r=null;break}var r=t.sibling;if(null!==r){r.return=t.return,$r=r;break}$r=t.return}}var Sc,Tc=Math.ceil,Cc=w.ReactCurrentDispatcher,Ec=w.ReactCurrentOwner,kc=w.ReactCurrentBatchConfig,Ic=0,Mc=null,Oc=null,Lc=0,xc=0,Pc=Sn(0),Bc=0,Nc=null,_c=0,Vc=0,Wc=0,Fc=null,jc=null,Uc=0,zc=1/0,Gc=null,Hc=!1,qc=null,Kc=null,Qc=!1,Jc=null,Yc=0,Xc=0,Zc=null,$c=-1,el=0;function tl(){return 0!==(6&Ic)?Xe():-1!==$c?$c:$c=Xe()}function al(e){return 0===(1&e.mode)?1:0!==(2&Ic)&&0!==Lc?Lc&-Lc:null!==go.transition?(0===el&&(el=ft()),el):0!==(e=yt)?e:e=void 0===(e=window.event)?16:Yt(e.type)}function il(e,t,a,i){if(50<Xc)throw Xc=0,Zc=null,Error(o(185));bt(e,a,i),0!==(2&Ic)&&e===Mc||(e===Mc&&(0===(2&Ic)&&(Vc|=a),4===Bc&&cl(e,Lc)),nl(e,i),1===a&&0===Ic&&0===(1&t.mode)&&(zc=Xe()+500,Wn&&Un()))}function nl(e,t){var a=e.callbackNode;!function(e,t){for(var a=e.suspendedLanes,i=e.pingedLanes,n=e.expirationTimes,o=e.pendingLanes;0<o;){var s=31-st(o),r=1<<s,c=n[s];-1===c?0!==(r&a)&&0===(r&i)||(n[s]=mt(r,t)):c<=t&&(e.expiredLanes|=r),o&=~r}}(e,t);var i=ht(e,e===Mc?Lc:0);if(0===i)null!==a&&Qe(a),e.callbackNode=null,e.callbackPriority=0;else if(t=i&-i,e.callbackPriority!==t){if(null!=a&&Qe(a),1===t)0===e.tag?function(e){Wn=!0,jn(e)}(ll.bind(null,e)):jn(ll.bind(null,e)),sn((function(){0===(6&Ic)&&Un()})),a=null;else{switch(wt(i)){case 1:a=$e;break;case 4:a=et;break;case 16:default:a=tt;break;case 536870912:a=it}a=Ml(a,ol.bind(null,e))}e.callbackPriority=t,e.callbackNode=a}}function ol(e,t){if($c=-1,el=0,0!==(6&Ic))throw Error(o(327));var a=e.callbackNode;if(Rl()&&e.callbackNode!==a)return null;var i=ht(e,e===Mc?Lc:0);if(0===i)return null;if(0!==(30&i)||0!==(i&e.expiredLanes)||t)t=bl(e,i);else{t=i;var n=Ic;Ic|=2;var s=fl();for(Mc===e&&Lc===t||(Gc=null,zc=Xe()+500,ml(e,t));;)try{yl();break}catch(c){pl(e,c)}Ao(),Cc.current=s,Ic=n,null!==Oc?t=0:(Mc=null,Lc=0,t=Bc)}if(0!==t){if(2===t&&(0!==(n=pt(e))&&(i=n,t=sl(e,n))),1===t)throw a=Nc,ml(e,0),cl(e,i),nl(e,Xe()),a;if(6===t)cl(e,i);else{if(n=e.current.alternate,0===(30&i)&&!function(e){for(var t=e;;){if(16384&t.flags){var a=t.updateQueue;if(null!==a&&null!==(a=a.stores))for(var i=0;i<a.length;i++){var n=a[i],o=n.getSnapshot;n=n.value;try{if(!si(o(),n))return!1}catch(r){return!1}}}if(a=t.child,16384&t.subtreeFlags&&null!==a)a.return=t,t=a;else{if(t===e)break;for(;null===t.sibling;){if(null===t.return||t.return===e)return!0;t=t.return}t.sibling.return=t.return,t=t.sibling}}return!0}(n)&&(2===(t=bl(e,i))&&(0!==(s=pt(e))&&(i=s,t=sl(e,s))),1===t))throw a=Nc,ml(e,0),cl(e,i),nl(e,Xe()),a;switch(e.finishedWork=n,e.finishedLanes=i,t){case 0:case 1:throw Error(o(345));case 2:case 5:Al(e,jc,Gc);break;case 3:if(cl(e,i),(130023424&i)===i&&10<(t=Uc+500-Xe())){if(0!==ht(e,0))break;if(((n=e.suspendedLanes)&i)!==i){tl(),e.pingedLanes|=e.suspendedLanes&n;break}e.timeoutHandle=an(Al.bind(null,e,jc,Gc),t);break}Al(e,jc,Gc);break;case 4:if(cl(e,i),(4194240&i)===i)break;for(t=e.eventTimes,n=-1;0<i;){var r=31-st(i);s=1<<r,(r=t[r])>n&&(n=r),i&=~s}if(i=n,10<(i=(120>(i=Xe()-i)?120:480>i?480:1080>i?1080:1920>i?1920:3e3>i?3e3:4320>i?4320:1960*Tc(i/1960))-i)){e.timeoutHandle=an(Al.bind(null,e,jc,Gc),i);break}Al(e,jc,Gc);break;default:throw Error(o(329))}}}return nl(e,Xe()),e.callbackNode===a?ol.bind(null,e):null}function sl(e,t){var a=Fc;return e.current.memoizedState.isDehydrated&&(ml(e,t).flags|=256),2!==(e=bl(e,t))&&(t=jc,jc=a,null!==t&&rl(t)),e}function rl(e){null===jc?jc=e:jc.push.apply(jc,e)}function cl(e,t){for(t&=~Wc,t&=~Vc,e.suspendedLanes|=t,e.pingedLanes&=~t,e=e.expirationTimes;0<t;){var a=31-st(t),i=1<<a;e[a]=-1,t&=~i}}function ll(e){if(0!==(6&Ic))throw Error(o(327));Rl();var t=ht(e,0);if(0===(1&t))return nl(e,Xe()),null;var a=bl(e,t);if(0!==e.tag&&2===a){var i=pt(e);0!==i&&(t=i,a=sl(e,i))}if(1===a)throw a=Nc,ml(e,0),cl(e,t),nl(e,Xe()),a;if(6===a)throw Error(o(345));return e.finishedWork=e.current.alternate,e.finishedLanes=t,Al(e,jc,Gc),nl(e,Xe()),null}function dl(e,t){var a=Ic;Ic|=1;try{return e(t)}finally{0===(Ic=a)&&(zc=Xe()+500,Wn&&Un())}}function ul(e){null!==Jc&&0===Jc.tag&&0===(6&Ic)&&Rl();var t=Ic;Ic|=1;var a=kc.transition,i=yt;try{if(kc.transition=null,yt=1,e)return e()}finally{yt=i,kc.transition=a,0===(6&(Ic=t))&&Un()}}function hl(){xc=Pc.current,Tn(Pc)}function ml(e,t){e.finishedWork=null,e.finishedLanes=0;var a=e.timeoutHandle;if(-1!==a&&(e.timeoutHandle=-1,nn(a)),null!==Oc)for(a=Oc.return;null!==a;){var i=a;switch(to(i),i.tag){case 1:null!==(i=i.type.childContextTypes)&&void 0!==i&&xn();break;case 3:os(),Tn(In),Tn(kn),us();break;case 5:rs(i);break;case 4:os();break;case 13:case 19:Tn(cs);break;case 10:Ro(i.type._context);break;case 22:case 23:hl()}a=a.return}if(Mc=e,Oc=e=Pl(e.current,null),Lc=xc=t,Bc=0,Nc=null,Wc=Vc=_c=0,jc=Fc=null,null!==Eo){for(t=0;t<Eo.length;t++)if(null!==(i=(a=Eo[t]).interleaved)){a.interleaved=null;var n=i.next,o=a.pending;if(null!==o){var s=o.next;o.next=n,i.next=s}a.pending=i}Eo=null}return e}function pl(e,t){for(;;){var a=Oc;try{if(Ao(),hs.current=sr,vs){for(var i=fs.memoizedState;null!==i;){var n=i.queue;null!==n&&(n.pending=null),i=i.next}vs=!1}if(ps=0,bs=gs=fs=null,ys=!1,ws=0,Ec.current=null,null===a||null===a.return){Bc=1,Nc=t,Oc=null;break}e:{var s=e,r=a.return,c=a,l=t;if(t=Lc,c.flags|=32768,null!==l&&"object"===typeof l&&"function"===typeof l.then){var d=l,u=c,h=u.tag;if(0===(1&u.mode)&&(0===h||11===h||15===h)){var m=u.alternate;m?(u.updateQueue=m.updateQueue,u.memoizedState=m.memoizedState,u.lanes=m.lanes):(u.updateQueue=null,u.memoizedState=null)}var p=br(r);if(null!==p){p.flags&=-257,vr(p,r,c,0,t),1&p.mode&&gr(s,d,t),l=d;var f=(t=p).updateQueue;if(null===f){var g=new Set;g.add(l),t.updateQueue=g}else f.add(l);break e}if(0===(1&t)){gr(s,d,t),gl();break e}l=Error(o(426))}else if(no&&1&c.mode){var b=br(r);if(null!==b){0===(65536&b.flags)&&(b.flags|=256),vr(b,r,c,0,t),fo(dr(l,c));break e}}s=l=dr(l,c),4!==Bc&&(Bc=2),null===Fc?Fc=[s]:Fc.push(s),s=r;do{switch(s.tag){case 3:s.flags|=65536,t&=-t,s.lanes|=t,_o(s,pr(0,l,t));break e;case 1:c=l;var v=s.type,y=s.stateNode;if(0===(128&s.flags)&&("function"===typeof v.getDerivedStateFromError||null!==y&&"function"===typeof y.componentDidCatch&&(null===Kc||!Kc.has(y)))){s.flags|=65536,t&=-t,s.lanes|=t,_o(s,fr(s,c,t));break e}}s=s.return}while(null!==s)}Dl(a)}catch(w){t=w,Oc===a&&null!==a&&(Oc=a=a.return);continue}break}}function fl(){var e=Cc.current;return Cc.current=sr,null===e?sr:e}function gl(){0!==Bc&&3!==Bc&&2!==Bc||(Bc=4),null===Mc||0===(268435455&_c)&&0===(268435455&Vc)||cl(Mc,Lc)}function bl(e,t){var a=Ic;Ic|=2;var i=fl();for(Mc===e&&Lc===t||(Gc=null,ml(e,t));;)try{vl();break}catch(n){pl(e,n)}if(Ao(),Ic=a,Cc.current=i,null!==Oc)throw Error(o(261));return Mc=null,Lc=0,Bc}function vl(){for(;null!==Oc;)wl(Oc)}function yl(){for(;null!==Oc&&!Je();)wl(Oc)}function wl(e){var t=Sc(e.alternate,e,xc);e.memoizedProps=e.pendingProps,null===t?Dl(e):Oc=t,Ec.current=null}function Dl(e){var t=e;do{var a=t.alternate;if(e=t.return,0===(32768&t.flags)){if(null!==(a=Qr(a,t,xc)))return void(Oc=a)}else{if(null!==(a=Jr(a,t)))return a.flags&=32767,void(Oc=a);if(null===e)return Bc=6,void(Oc=null);e.flags|=32768,e.subtreeFlags=0,e.deletions=null}if(null!==(t=t.sibling))return void(Oc=t);Oc=t=e}while(null!==t);0===Bc&&(Bc=5)}function Al(e,t,a){var i=yt,n=kc.transition;try{kc.transition=null,yt=1,function(e,t,a,i){do{Rl()}while(null!==Jc);if(0!==(6&Ic))throw Error(o(327));a=e.finishedWork;var n=e.finishedLanes;if(null===a)return null;if(e.finishedWork=null,e.finishedLanes=0,a===e.current)throw Error(o(177));e.callbackNode=null,e.callbackPriority=0;var s=a.lanes|a.childLanes;if(function(e,t){var a=e.pendingLanes&~t;e.pendingLanes=t,e.suspendedLanes=0,e.pingedLanes=0,e.expiredLanes&=t,e.mutableReadLanes&=t,e.entangledLanes&=t,t=e.entanglements;var i=e.eventTimes;for(e=e.expirationTimes;0<a;){var n=31-st(a),o=1<<n;t[n]=0,i[n]=-1,e[n]=-1,a&=~o}}(e,s),e===Mc&&(Oc=Mc=null,Lc=0),0===(2064&a.subtreeFlags)&&0===(2064&a.flags)||Qc||(Qc=!0,Ml(tt,(function(){return Rl(),null}))),s=0!==(15990&a.flags),0!==(15990&a.subtreeFlags)||s){s=kc.transition,kc.transition=null;var r=yt;yt=1;var c=Ic;Ic|=4,Ec.current=null,function(e,t){if($i=Gt,hi(e=ui())){if("selectionStart"in e)var a={start:e.selectionStart,end:e.selectionEnd};else e:{var i=(a=(a=e.ownerDocument)&&a.defaultView||window).getSelection&&a.getSelection();if(i&&0!==i.rangeCount){a=i.anchorNode;var n=i.anchorOffset,s=i.focusNode;i=i.focusOffset;try{a.nodeType,s.nodeType}catch(D){a=null;break e}var r=0,c=-1,l=-1,d=0,u=0,h=e,m=null;t:for(;;){for(var p;h!==a||0!==n&&3!==h.nodeType||(c=r+n),h!==s||0!==i&&3!==h.nodeType||(l=r+i),3===h.nodeType&&(r+=h.nodeValue.length),null!==(p=h.firstChild);)m=h,h=p;for(;;){if(h===e)break t;if(m===a&&++d===n&&(c=r),m===s&&++u===i&&(l=r),null!==(p=h.nextSibling))break;m=(h=m).parentNode}h=p}a=-1===c||-1===l?null:{start:c,end:l}}else a=null}a=a||{start:0,end:0}}else a=null;for(en={focusedElem:e,selectionRange:a},Gt=!1,$r=t;null!==$r;)if(e=(t=$r).child,0!==(1028&t.subtreeFlags)&&null!==e)e.return=t,$r=e;else for(;null!==$r;){t=$r;try{var f=t.alternate;if(0!==(1024&t.flags))switch(t.tag){case 0:case 11:case 15:case 5:case 6:case 4:case 17:break;case 1:if(null!==f){var g=f.memoizedProps,b=f.memoizedState,v=t.stateNode,y=v.getSnapshotBeforeUpdate(t.elementType===t.type?g:bo(t.type,g),b);v.__reactInternalSnapshotBeforeUpdate=y}break;case 3:var w=t.stateNode.containerInfo;1===w.nodeType?w.textContent="":9===w.nodeType&&w.documentElement&&w.removeChild(w.documentElement);break;default:throw Error(o(163))}}catch(D){Tl(t,t.return,D)}if(null!==(e=t.sibling)){e.return=t.return,$r=e;break}$r=t.return}f=ac,ac=!1}(e,a),bc(a,e),mi(en),Gt=!!$i,en=$i=null,e.current=a,yc(a,e,n),Ye(),Ic=c,yt=r,kc.transition=s}else e.current=a;if(Qc&&(Qc=!1,Jc=e,Yc=n),s=e.pendingLanes,0===s&&(Kc=null),function(e){if(ot&&"function"===typeof ot.onCommitFiberRoot)try{ot.onCommitFiberRoot(nt,e,void 0,128===(128&e.current.flags))}catch(t){}}(a.stateNode),nl(e,Xe()),null!==t)for(i=e.onRecoverableError,a=0;a<t.length;a++)n=t[a],i(n.value,{componentStack:n.stack,digest:n.digest});if(Hc)throw Hc=!1,e=qc,qc=null,e;0!==(1&Yc)&&0!==e.tag&&Rl(),s=e.pendingLanes,0!==(1&s)?e===Zc?Xc++:(Xc=0,Zc=e):Xc=0,Un()}(e,t,a,i)}finally{kc.transition=n,yt=i}return null}function Rl(){if(null!==Jc){var e=wt(Yc),t=kc.transition,a=yt;try{if(kc.transition=null,yt=16>e?16:e,null===Jc)var i=!1;else{if(e=Jc,Jc=null,Yc=0,0!==(6&Ic))throw Error(o(331));var n=Ic;for(Ic|=4,$r=e.current;null!==$r;){var s=$r,r=s.child;if(0!==(16&$r.flags)){var c=s.deletions;if(null!==c){for(var l=0;l<c.length;l++){var d=c[l];for($r=d;null!==$r;){var u=$r;switch(u.tag){case 0:case 11:case 15:ic(8,u,s)}var h=u.child;if(null!==h)h.return=u,$r=h;else for(;null!==$r;){var m=(u=$r).sibling,p=u.return;if(sc(u),u===d){$r=null;break}if(null!==m){m.return=p,$r=m;break}$r=p}}}var f=s.alternate;if(null!==f){var g=f.child;if(null!==g){f.child=null;do{var b=g.sibling;g.sibling=null,g=b}while(null!==g)}}$r=s}}if(0!==(2064&s.subtreeFlags)&&null!==r)r.return=s,$r=r;else e:for(;null!==$r;){if(0!==(2048&(s=$r).flags))switch(s.tag){case 0:case 11:case 15:ic(9,s,s.return)}var v=s.sibling;if(null!==v){v.return=s.return,$r=v;break e}$r=s.return}}var y=e.current;for($r=y;null!==$r;){var w=(r=$r).child;if(0!==(2064&r.subtreeFlags)&&null!==w)w.return=r,$r=w;else e:for(r=y;null!==$r;){if(0!==(2048&(c=$r).flags))try{switch(c.tag){case 0:case 11:case 15:nc(9,c)}}catch(A){Tl(c,c.return,A)}if(c===r){$r=null;break e}var D=c.sibling;if(null!==D){D.return=c.return,$r=D;break e}$r=c.return}}if(Ic=n,Un(),ot&&"function"===typeof ot.onPostCommitFiberRoot)try{ot.onPostCommitFiberRoot(nt,e)}catch(A){}i=!0}return i}finally{yt=a,kc.transition=t}}return!1}function Sl(e,t,a){e=Bo(e,t=pr(0,t=dr(a,t),1),1),t=tl(),null!==e&&(bt(e,1,t),nl(e,t))}function Tl(e,t,a){if(3===e.tag)Sl(e,e,a);else for(;null!==t;){if(3===t.tag){Sl(t,e,a);break}if(1===t.tag){var i=t.stateNode;if("function"===typeof t.type.getDerivedStateFromError||"function"===typeof i.componentDidCatch&&(null===Kc||!Kc.has(i))){t=Bo(t,e=fr(t,e=dr(a,e),1),1),e=tl(),null!==t&&(bt(t,1,e),nl(t,e));break}}t=t.return}}function Cl(e,t,a){var i=e.pingCache;null!==i&&i.delete(t),t=tl(),e.pingedLanes|=e.suspendedLanes&a,Mc===e&&(Lc&a)===a&&(4===Bc||3===Bc&&(130023424&Lc)===Lc&&500>Xe()-Uc?ml(e,0):Wc|=a),nl(e,t)}function El(e,t){0===t&&(0===(1&e.mode)?t=1:(t=dt,0===(130023424&(dt<<=1))&&(dt=4194304)));var a=tl();null!==(e=Mo(e,t))&&(bt(e,t,a),nl(e,a))}function kl(e){var t=e.memoizedState,a=0;null!==t&&(a=t.retryLane),El(e,a)}function Il(e,t){var a=0;switch(e.tag){case 13:var i=e.stateNode,n=e.memoizedState;null!==n&&(a=n.retryLane);break;case 19:i=e.stateNode;break;default:throw Error(o(314))}null!==i&&i.delete(t),El(e,a)}function Ml(e,t){return Ke(e,t)}function Ol(e,t,a,i){this.tag=e,this.key=a,this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null,this.index=0,this.ref=null,this.pendingProps=t,this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null,this.mode=i,this.subtreeFlags=this.flags=0,this.deletions=null,this.childLanes=this.lanes=0,this.alternate=null}function Ll(e,t,a,i){return new Ol(e,t,a,i)}function xl(e){return!(!(e=e.prototype)||!e.isReactComponent)}function Pl(e,t){var a=e.alternate;return null===a?((a=Ll(e.tag,t,e.key,e.mode)).elementType=e.elementType,a.type=e.type,a.stateNode=e.stateNode,a.alternate=e,e.alternate=a):(a.pendingProps=t,a.type=e.type,a.flags=0,a.subtreeFlags=0,a.deletions=null),a.flags=14680064&e.flags,a.childLanes=e.childLanes,a.lanes=e.lanes,a.child=e.child,a.memoizedProps=e.memoizedProps,a.memoizedState=e.memoizedState,a.updateQueue=e.updateQueue,t=e.dependencies,a.dependencies=null===t?null:{lanes:t.lanes,firstContext:t.firstContext},a.sibling=e.sibling,a.index=e.index,a.ref=e.ref,a}function Bl(e,t,a,i,n,s){var r=2;if(i=e,"function"===typeof e)xl(e)&&(r=1);else if("string"===typeof e)r=5;else e:switch(e){case R:return Nl(a.children,n,s,t);case S:r=8,n|=8;break;case T:return(e=Ll(12,a,t,2|n)).elementType=T,e.lanes=s,e;case I:return(e=Ll(13,a,t,n)).elementType=I,e.lanes=s,e;case M:return(e=Ll(19,a,t,n)).elementType=M,e.lanes=s,e;case x:return _l(a,n,s,t);default:if("object"===typeof e&&null!==e)switch(e.$$typeof){case C:r=10;break e;case E:r=9;break e;case k:r=11;break e;case O:r=14;break e;case L:r=16,i=null;break e}throw Error(o(130,null==e?e:typeof e,""))}return(t=Ll(r,a,t,n)).elementType=e,t.type=i,t.lanes=s,t}function Nl(e,t,a,i){return(e=Ll(7,e,i,t)).lanes=a,e}function _l(e,t,a,i){return(e=Ll(22,e,i,t)).elementType=x,e.lanes=a,e.stateNode={isHidden:!1},e}function Vl(e,t,a){return(e=Ll(6,e,null,t)).lanes=a,e}function Wl(e,t,a){return(t=Ll(4,null!==e.children?e.children:[],e.key,t)).lanes=a,t.stateNode={containerInfo:e.containerInfo,pendingChildren:null,implementation:e.implementation},t}function Fl(e,t,a,i,n){this.tag=t,this.containerInfo=e,this.finishedWork=this.pingCache=this.current=this.pendingChildren=null,this.timeoutHandle=-1,this.callbackNode=this.pendingContext=this.context=null,this.callbackPriority=0,this.eventTimes=gt(0),this.expirationTimes=gt(-1),this.entangledLanes=this.finishedLanes=this.mutableReadLanes=this.expiredLanes=this.pingedLanes=this.suspendedLanes=this.pendingLanes=0,this.entanglements=gt(0),this.identifierPrefix=i,this.onRecoverableError=n,this.mutableSourceEagerHydrationData=null}function jl(e,t,a,i,n,o,s,r,c){return e=new Fl(e,t,a,r,c),1===t?(t=1,!0===o&&(t|=8)):t=0,o=Ll(3,null,null,t),e.current=o,o.stateNode=e,o.memoizedState={element:i,isDehydrated:a,cache:null,transitions:null,pendingSuspenseBoundaries:null},Lo(o),e}function Ul(e){if(!e)return En;e:{if(Ue(e=e._reactInternals)!==e||1!==e.tag)throw Error(o(170));var t=e;do{switch(t.tag){case 3:t=t.stateNode.context;break e;case 1:if(Ln(t.type)){t=t.stateNode.__reactInternalMemoizedMergedChildContext;break e}}t=t.return}while(null!==t);throw Error(o(171))}if(1===e.tag){var a=e.type;if(Ln(a))return Bn(e,a,t)}return t}function zl(e,t,a,i,n,o,s,r,c){return(e=jl(a,i,!0,e,0,o,0,r,c)).context=Ul(null),a=e.current,(o=Po(i=tl(),n=al(a))).callback=void 0!==t&&null!==t?t:null,Bo(a,o,n),e.current.lanes=n,bt(e,n,i),nl(e,i),e}function Gl(e,t,a,i){var n=t.current,o=tl(),s=al(n);return a=Ul(a),null===t.context?t.context=a:t.pendingContext=a,(t=Po(o,s)).payload={element:e},null!==(i=void 0===i?null:i)&&(t.callback=i),null!==(e=Bo(n,t,s))&&(il(e,n,s,o),No(e,n,s)),s}function Hl(e){return(e=e.current).child?(e.child.tag,e.child.stateNode):null}function ql(e,t){if(null!==(e=e.memoizedState)&&null!==e.dehydrated){var a=e.retryLane;e.retryLane=0!==a&&a<t?a:t}}function Kl(e,t){ql(e,t),(e=e.alternate)&&ql(e,t)}Sc=function(e,t,a){if(null!==e)if(e.memoizedProps!==t.pendingProps||In.current)wr=!0;else{if(0===(e.lanes&a)&&0===(128&t.flags))return wr=!1,function(e,t,a){switch(t.tag){case 3:Mr(t),po();break;case 5:ss(t);break;case 1:Ln(t.type)&&Nn(t);break;case 4:ns(t,t.stateNode.containerInfo);break;case 10:var i=t.type._context,n=t.memoizedProps.value;Cn(vo,i._currentValue),i._currentValue=n;break;case 13:if(null!==(i=t.memoizedState))return null!==i.dehydrated?(Cn(cs,1&cs.current),t.flags|=128,null):0!==(a&t.child.childLanes)?Vr(e,t,a):(Cn(cs,1&cs.current),null!==(e=Hr(e,t,a))?e.sibling:null);Cn(cs,1&cs.current);break;case 19:if(i=0!==(a&t.childLanes),0!==(128&e.flags)){if(i)return zr(e,t,a);t.flags|=128}if(null!==(n=t.memoizedState)&&(n.rendering=null,n.tail=null,n.lastEffect=null),Cn(cs,cs.current),i)break;return null;case 22:case 23:return t.lanes=0,Tr(e,t,a)}return Hr(e,t,a)}(e,t,a);wr=0!==(131072&e.flags)}else wr=!1,no&&0!==(1048576&t.flags)&&$n(t,qn,t.index);switch(t.lanes=0,t.tag){case 2:var i=t.type;Gr(e,t),e=t.pendingProps;var n=On(t,kn.current);To(t,a),n=Ss(null,t,i,e,n,a);var s=Ts();return t.flags|=1,"object"===typeof n&&null!==n&&"function"===typeof n.render&&void 0===n.$$typeof?(t.tag=1,t.memoizedState=null,t.updateQueue=null,Ln(i)?(s=!0,Nn(t)):s=!1,t.memoizedState=null!==n.state&&void 0!==n.state?n.state:null,Lo(t),n.updater=Uo,t.stateNode=n,n._reactInternals=t,qo(t,i,e,a),t=Ir(null,t,i,!0,s,a)):(t.tag=0,no&&s&&eo(t),Dr(null,t,n,a),t=t.child),t;case 16:i=t.elementType;e:{switch(Gr(e,t),e=t.pendingProps,i=(n=i._init)(i._payload),t.type=i,n=t.tag=function(e){if("function"===typeof e)return xl(e)?1:0;if(void 0!==e&&null!==e){if((e=e.$$typeof)===k)return 11;if(e===O)return 14}return 2}(i),e=bo(i,e),n){case 0:t=Er(null,t,i,e,a);break e;case 1:t=kr(null,t,i,e,a);break e;case 11:t=Ar(null,t,i,e,a);break e;case 14:t=Rr(null,t,i,bo(i.type,e),a);break e}throw Error(o(306,i,""))}return t;case 0:return i=t.type,n=t.pendingProps,Er(e,t,i,n=t.elementType===i?n:bo(i,n),a);case 1:return i=t.type,n=t.pendingProps,kr(e,t,i,n=t.elementType===i?n:bo(i,n),a);case 3:e:{if(Mr(t),null===e)throw Error(o(387));i=t.pendingProps,n=(s=t.memoizedState).element,xo(e,t),Vo(t,i,null,a);var r=t.memoizedState;if(i=r.element,s.isDehydrated){if(s={element:i,isDehydrated:!1,cache:r.cache,pendingSuspenseBoundaries:r.pendingSuspenseBoundaries,transitions:r.transitions},t.updateQueue.baseState=s,t.memoizedState=s,256&t.flags){t=Or(e,t,i,a,n=dr(Error(o(423)),t));break e}if(i!==n){t=Or(e,t,i,a,n=dr(Error(o(424)),t));break e}for(io=ln(t.stateNode.containerInfo.firstChild),ao=t,no=!0,oo=null,a=Zo(t,null,i,a),t.child=a;a;)a.flags=-3&a.flags|4096,a=a.sibling}else{if(po(),i===n){t=Hr(e,t,a);break e}Dr(e,t,i,a)}t=t.child}return t;case 5:return ss(t),null===e&&lo(t),i=t.type,n=t.pendingProps,s=null!==e?e.memoizedProps:null,r=n.children,tn(i,n)?r=null:null!==s&&tn(i,s)&&(t.flags|=32),Cr(e,t),Dr(e,t,r,a),t.child;case 6:return null===e&&lo(t),null;case 13:return Vr(e,t,a);case 4:return ns(t,t.stateNode.containerInfo),i=t.pendingProps,null===e?t.child=Xo(t,null,i,a):Dr(e,t,i,a),t.child;case 11:return i=t.type,n=t.pendingProps,Ar(e,t,i,n=t.elementType===i?n:bo(i,n),a);case 7:return Dr(e,t,t.pendingProps,a),t.child;case 8:case 12:return Dr(e,t,t.pendingProps.children,a),t.child;case 10:e:{if(i=t.type._context,n=t.pendingProps,s=t.memoizedProps,r=n.value,Cn(vo,i._currentValue),i._currentValue=r,null!==s)if(si(s.value,r)){if(s.children===n.children&&!In.current){t=Hr(e,t,a);break e}}else for(null!==(s=t.child)&&(s.return=t);null!==s;){var c=s.dependencies;if(null!==c){r=s.child;for(var l=c.firstContext;null!==l;){if(l.context===i){if(1===s.tag){(l=Po(-1,a&-a)).tag=2;var d=s.updateQueue;if(null!==d){var u=(d=d.shared).pending;null===u?l.next=l:(l.next=u.next,u.next=l),d.pending=l}}s.lanes|=a,null!==(l=s.alternate)&&(l.lanes|=a),So(s.return,a,t),c.lanes|=a;break}l=l.next}}else if(10===s.tag)r=s.type===t.type?null:s.child;else if(18===s.tag){if(null===(r=s.return))throw Error(o(341));r.lanes|=a,null!==(c=r.alternate)&&(c.lanes|=a),So(r,a,t),r=s.sibling}else r=s.child;if(null!==r)r.return=s;else for(r=s;null!==r;){if(r===t){r=null;break}if(null!==(s=r.sibling)){s.return=r.return,r=s;break}r=r.return}s=r}Dr(e,t,n.children,a),t=t.child}return t;case 9:return n=t.type,i=t.pendingProps.children,To(t,a),i=i(n=Co(n)),t.flags|=1,Dr(e,t,i,a),t.child;case 14:return n=bo(i=t.type,t.pendingProps),Rr(e,t,i,n=bo(i.type,n),a);case 15:return Sr(e,t,t.type,t.pendingProps,a);case 17:return i=t.type,n=t.pendingProps,n=t.elementType===i?n:bo(i,n),Gr(e,t),t.tag=1,Ln(i)?(e=!0,Nn(t)):e=!1,To(t,a),Go(t,i,n),qo(t,i,n,a),Ir(null,t,i,!0,e,a);case 19:return zr(e,t,a);case 22:return Tr(e,t,a)}throw Error(o(156,t.tag))};var Ql="function"===typeof reportError?reportError:function(e){console.error(e)};function Jl(e){this._internalRoot=e}function Yl(e){this._internalRoot=e}function Xl(e){return!(!e||1!==e.nodeType&&9!==e.nodeType&&11!==e.nodeType)}function Zl(e){return!(!e||1!==e.nodeType&&9!==e.nodeType&&11!==e.nodeType&&(8!==e.nodeType||" react-mount-point-unstable "!==e.nodeValue))}function $l(){}function ed(e,t,a,i,n){var o=a._reactRootContainer;if(o){var s=o;if("function"===typeof n){var r=n;n=function(){var e=Hl(s);r.call(e)}}Gl(t,s,e,n)}else s=function(e,t,a,i,n){if(n){if("function"===typeof i){var o=i;i=function(){var e=Hl(s);o.call(e)}}var s=zl(t,i,e,0,null,!1,0,"",$l);return e._reactRootContainer=s,e[pn]=s.current,ji(8===e.nodeType?e.parentNode:e),ul(),s}for(;n=e.lastChild;)e.removeChild(n);if("function"===typeof i){var r=i;i=function(){var e=Hl(c);r.call(e)}}var c=jl(e,0,!1,null,0,!1,0,"",$l);return e._reactRootContainer=c,e[pn]=c.current,ji(8===e.nodeType?e.parentNode:e),ul((function(){Gl(t,c,a,i)})),c}(a,t,e,n,i);return Hl(s)}Yl.prototype.render=Jl.prototype.render=function(e){var t=this._internalRoot;if(null===t)throw Error(o(409));Gl(e,t,null,null)},Yl.prototype.unmount=Jl.prototype.unmount=function(){var e=this._internalRoot;if(null!==e){this._internalRoot=null;var t=e.containerInfo;ul((function(){Gl(null,e,null,null)})),t[pn]=null}},Yl.prototype.unstable_scheduleHydration=function(e){if(e){var t=St();e={blockedOn:null,target:e,priority:t};for(var a=0;a<xt.length&&0!==t&&t<xt[a].priority;a++);xt.splice(a,0,e),0===a&&_t(e)}},Dt=function(e){switch(e.tag){case 3:var t=e.stateNode;if(t.current.memoizedState.isDehydrated){var a=ut(t.pendingLanes);0!==a&&(vt(t,1|a),nl(t,Xe()),0===(6&Ic)&&(zc=Xe()+500,Un()))}break;case 13:ul((function(){var t=Mo(e,1);if(null!==t){var a=tl();il(t,e,1,a)}})),Kl(e,1)}},At=function(e){if(13===e.tag){var t=Mo(e,134217728);if(null!==t)il(t,e,134217728,tl());Kl(e,134217728)}},Rt=function(e){if(13===e.tag){var t=al(e),a=Mo(e,t);if(null!==a)il(a,e,t,tl());Kl(e,t)}},St=function(){return yt},Tt=function(e,t){var a=yt;try{return yt=e,t()}finally{yt=a}},Ae=function(e,t,a){switch(t){case"input":if(Z(e,a),t=a.name,"radio"===a.type&&null!=t){for(a=e;a.parentNode;)a=a.parentNode;for(a=a.querySelectorAll("input[name="+JSON.stringify(""+t)+'][type="radio"]'),t=0;t<a.length;t++){var i=a[t];if(i!==e&&i.form===e.form){var n=Dn(i);if(!n)throw Error(o(90));K(i),Z(i,n)}}}break;case"textarea":oe(e,a);break;case"select":null!=(t=a.value)&&ae(e,!!a.multiple,t,!1)}},ke=dl,Ie=ul;var td={usingClientEntryPoint:!1,Events:[yn,wn,Dn,Ce,Ee,dl]},ad={findFiberByHostInstance:vn,bundleType:0,version:"18.2.0",rendererPackageName:"react-dom"},id={bundleType:ad.bundleType,version:ad.version,rendererPackageName:ad.rendererPackageName,rendererConfig:ad.rendererConfig,overrideHookState:null,overrideHookStateDeletePath:null,overrideHookStateRenamePath:null,overrideProps:null,overridePropsDeletePath:null,overridePropsRenamePath:null,setErrorHandler:null,setSuspenseHandler:null,scheduleUpdate:null,currentDispatcherRef:w.ReactCurrentDispatcher,findHostInstanceByFiber:function(e){return null===(e=He(e))?null:e.stateNode},findFiberByHostInstance:ad.findFiberByHostInstance||function(){return null},findHostInstancesForRefresh:null,scheduleRefresh:null,scheduleRoot:null,setRefreshHandler:null,getCurrentFiber:null,reconcilerVersion:"18.2.0-next-9e3b772b8-20220608"};if("undefined"!==typeof __REACT_DEVTOOLS_GLOBAL_HOOK__){var nd=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(!nd.isDisabled&&nd.supportsFiber)try{nt=nd.inject(id),ot=nd}catch(de){}}t.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=td,t.createPortal=function(e,t){var a=2<arguments.length&&void 0!==arguments[2]?arguments[2]:null;if(!Xl(t))throw Error(o(200));return function(e,t,a){var i=3<arguments.length&&void 0!==arguments[3]?arguments[3]:null;return{$$typeof:A,key:null==i?null:""+i,children:e,containerInfo:t,implementation:a}}(e,t,null,a)},t.createRoot=function(e,t){if(!Xl(e))throw Error(o(299));var a=!1,i="",n=Ql;return null!==t&&void 0!==t&&(!0===t.unstable_strictMode&&(a=!0),void 0!==t.identifierPrefix&&(i=t.identifierPrefix),void 0!==t.onRecoverableError&&(n=t.onRecoverableError)),t=jl(e,1,!1,null,0,a,0,i,n),e[pn]=t.current,ji(8===e.nodeType?e.parentNode:e),new Jl(t)},t.findDOMNode=function(e){if(null==e)return null;if(1===e.nodeType)return e;var t=e._reactInternals;if(void 0===t){if("function"===typeof e.render)throw Error(o(188));throw e=Object.keys(e).join(","),Error(o(268,e))}return e=null===(e=He(t))?null:e.stateNode},t.flushSync=function(e){return ul(e)},t.hydrate=function(e,t,a){if(!Zl(t))throw Error(o(200));return ed(null,e,t,!0,a)},t.hydrateRoot=function(e,t,a){if(!Xl(e))throw Error(o(405));var i=null!=a&&a.hydratedSources||null,n=!1,s="",r=Ql;if(null!==a&&void 0!==a&&(!0===a.unstable_strictMode&&(n=!0),void 0!==a.identifierPrefix&&(s=a.identifierPrefix),void 0!==a.onRecoverableError&&(r=a.onRecoverableError)),t=zl(t,null,e,1,null!=a?a:null,n,0,s,r),e[pn]=t.current,ji(e),i)for(e=0;e<i.length;e++)n=(n=(a=i[e])._getVersion)(a._source),null==t.mutableSourceEagerHydrationData?t.mutableSourceEagerHydrationData=[a,n]:t.mutableSourceEagerHydrationData.push(a,n);return new Yl(t)},t.render=function(e,t,a){if(!Zl(t))throw Error(o(200));return ed(null,e,t,!1,a)},t.unmountComponentAtNode=function(e){if(!Zl(e))throw Error(o(40));return!!e._reactRootContainer&&(ul((function(){ed(null,null,e,!1,(function(){e._reactRootContainer=null,e[pn]=null}))})),!0)},t.unstable_batchedUpdates=dl,t.unstable_renderSubtreeIntoContainer=function(e,t,a,i){if(!Zl(a))throw Error(o(200));if(null==e||void 0===e._reactInternals)throw Error(o(38));return ed(e,t,a,!1,i)},t.version="18.2.0-next-9e3b772b8-20220608"},250:function(e,t,a){"use strict";var i=a(164);t.createRoot=i.createRoot,t.hydrateRoot=i.hydrateRoot},164:function(e,t,a){"use strict";!function e(){if("undefined"!==typeof __REACT_DEVTOOLS_GLOBAL_HOOK__&&"function"===typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE)try{__REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE(e)}catch(t){console.error(t)}}(),e.exports=a(463)},374:function(e,t,a){"use strict";var i=a(791),n=Symbol.for("react.element"),o=Symbol.for("react.fragment"),s=Object.prototype.hasOwnProperty,r=i.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.ReactCurrentOwner,c={key:!0,ref:!0,__self:!0,__source:!0};function l(e,t,a){var i,o={},l=null,d=null;for(i in void 0!==a&&(l=""+a),void 0!==t.key&&(l=""+t.key),void 0!==t.ref&&(d=t.ref),t)s.call(t,i)&&!c.hasOwnProperty(i)&&(o[i]=t[i]);if(e&&e.defaultProps)for(i in t=e.defaultProps)void 0===o[i]&&(o[i]=t[i]);return{$$typeof:n,type:e,key:l,ref:d,props:o,_owner:r.current}}t.Fragment=o,t.jsx=l,t.jsxs=l},117:function(e,t){"use strict";var a=Symbol.for("react.element"),i=Symbol.for("react.portal"),n=Symbol.for("react.fragment"),o=Symbol.for("react.strict_mode"),s=Symbol.for("react.profiler"),r=Symbol.for("react.provider"),c=Symbol.for("react.context"),l=Symbol.for("react.forward_ref"),d=Symbol.for("react.suspense"),u=Symbol.for("react.memo"),h=Symbol.for("react.lazy"),m=Symbol.iterator;var p={isMounted:function(){return!1},enqueueForceUpdate:function(){},enqueueReplaceState:function(){},enqueueSetState:function(){}},f=Object.assign,g={};function b(e,t,a){this.props=e,this.context=t,this.refs=g,this.updater=a||p}function v(){}function y(e,t,a){this.props=e,this.context=t,this.refs=g,this.updater=a||p}b.prototype.isReactComponent={},b.prototype.setState=function(e,t){if("object"!==typeof e&&"function"!==typeof e&&null!=e)throw Error("setState(...): takes an object of state variables to update or a function which returns an object of state variables.");this.updater.enqueueSetState(this,e,t,"setState")},b.prototype.forceUpdate=function(e){this.updater.enqueueForceUpdate(this,e,"forceUpdate")},v.prototype=b.prototype;var w=y.prototype=new v;w.constructor=y,f(w,b.prototype),w.isPureReactComponent=!0;var D=Array.isArray,A=Object.prototype.hasOwnProperty,R={current:null},S={key:!0,ref:!0,__self:!0,__source:!0};function T(e,t,i){var n,o={},s=null,r=null;if(null!=t)for(n in void 0!==t.ref&&(r=t.ref),void 0!==t.key&&(s=""+t.key),t)A.call(t,n)&&!S.hasOwnProperty(n)&&(o[n]=t[n]);var c=arguments.length-2;if(1===c)o.children=i;else if(1<c){for(var l=Array(c),d=0;d<c;d++)l[d]=arguments[d+2];o.children=l}if(e&&e.defaultProps)for(n in c=e.defaultProps)void 0===o[n]&&(o[n]=c[n]);return{$$typeof:a,type:e,key:s,ref:r,props:o,_owner:R.current}}function C(e){return"object"===typeof e&&null!==e&&e.$$typeof===a}var E=/\/+/g;function k(e,t){return"object"===typeof e&&null!==e&&null!=e.key?function(e){var t={"=":"=0",":":"=2"};return"$"+e.replace(/[=:]/g,(function(e){return t[e]}))}(""+e.key):t.toString(36)}function I(e,t,n,o,s){var r=typeof e;"undefined"!==r&&"boolean"!==r||(e=null);var c=!1;if(null===e)c=!0;else switch(r){case"string":case"number":c=!0;break;case"object":switch(e.$$typeof){case a:case i:c=!0}}if(c)return s=s(c=e),e=""===o?"."+k(c,0):o,D(s)?(n="",null!=e&&(n=e.replace(E,"$&/")+"/"),I(s,t,n,"",(function(e){return e}))):null!=s&&(C(s)&&(s=function(e,t){return{$$typeof:a,type:e.type,key:t,ref:e.ref,props:e.props,_owner:e._owner}}(s,n+(!s.key||c&&c.key===s.key?"":(""+s.key).replace(E,"$&/")+"/")+e)),t.push(s)),1;if(c=0,o=""===o?".":o+":",D(e))for(var l=0;l<e.length;l++){var d=o+k(r=e[l],l);c+=I(r,t,n,d,s)}else if(d=function(e){return null===e||"object"!==typeof e?null:"function"===typeof(e=m&&e[m]||e["@@iterator"])?e:null}(e),"function"===typeof d)for(e=d.call(e),l=0;!(r=e.next()).done;)c+=I(r=r.value,t,n,d=o+k(r,l++),s);else if("object"===r)throw t=String(e),Error("Objects are not valid as a React child (found: "+("[object Object]"===t?"object with keys {"+Object.keys(e).join(", ")+"}":t)+"). If you meant to render a collection of children, use an array instead.");return c}function M(e,t,a){if(null==e)return e;var i=[],n=0;return I(e,i,"","",(function(e){return t.call(a,e,n++)})),i}function O(e){if(-1===e._status){var t=e._result;(t=t()).then((function(t){0!==e._status&&-1!==e._status||(e._status=1,e._result=t)}),(function(t){0!==e._status&&-1!==e._status||(e._status=2,e._result=t)})),-1===e._status&&(e._status=0,e._result=t)}if(1===e._status)return e._result.default;throw e._result}var L={current:null},x={transition:null},P={ReactCurrentDispatcher:L,ReactCurrentBatchConfig:x,ReactCurrentOwner:R};t.Children={map:M,forEach:function(e,t,a){M(e,(function(){t.apply(this,arguments)}),a)},count:function(e){var t=0;return M(e,(function(){t++})),t},toArray:function(e){return M(e,(function(e){return e}))||[]},only:function(e){if(!C(e))throw Error("React.Children.only expected to receive a single React element child.");return e}},t.Component=b,t.Fragment=n,t.Profiler=s,t.PureComponent=y,t.StrictMode=o,t.Suspense=d,t.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=P,t.cloneElement=function(e,t,i){if(null===e||void 0===e)throw Error("React.cloneElement(...): The argument must be a React element, but you passed "+e+".");var n=f({},e.props),o=e.key,s=e.ref,r=e._owner;if(null!=t){if(void 0!==t.ref&&(s=t.ref,r=R.current),void 0!==t.key&&(o=""+t.key),e.type&&e.type.defaultProps)var c=e.type.defaultProps;for(l in t)A.call(t,l)&&!S.hasOwnProperty(l)&&(n[l]=void 0===t[l]&&void 0!==c?c[l]:t[l])}var l=arguments.length-2;if(1===l)n.children=i;else if(1<l){c=Array(l);for(var d=0;d<l;d++)c[d]=arguments[d+2];n.children=c}return{$$typeof:a,type:e.type,key:o,ref:s,props:n,_owner:r}},t.createContext=function(e){return(e={$$typeof:c,_currentValue:e,_currentValue2:e,_threadCount:0,Provider:null,Consumer:null,_defaultValue:null,_globalName:null}).Provider={$$typeof:r,_context:e},e.Consumer=e},t.createElement=T,t.createFactory=function(e){var t=T.bind(null,e);return t.type=e,t},t.createRef=function(){return{current:null}},t.forwardRef=function(e){return{$$typeof:l,render:e}},t.isValidElement=C,t.lazy=function(e){return{$$typeof:h,_payload:{_status:-1,_result:e},_init:O}},t.memo=function(e,t){return{$$typeof:u,type:e,compare:void 0===t?null:t}},t.startTransition=function(e){var t=x.transition;x.transition={};try{e()}finally{x.transition=t}},t.unstable_act=function(){throw Error("act(...) is not supported in production builds of React.")},t.useCallback=function(e,t){return L.current.useCallback(e,t)},t.useContext=function(e){return L.current.useContext(e)},t.useDebugValue=function(){},t.useDeferredValue=function(e){return L.current.useDeferredValue(e)},t.useEffect=function(e,t){return L.current.useEffect(e,t)},t.useId=function(){return L.current.useId()},t.useImperativeHandle=function(e,t,a){return L.current.useImperativeHandle(e,t,a)},t.useInsertionEffect=function(e,t){return L.current.useInsertionEffect(e,t)},t.useLayoutEffect=function(e,t){return L.current.useLayoutEffect(e,t)},t.useMemo=function(e,t){return L.current.useMemo(e,t)},t.useReducer=function(e,t,a){return L.current.useReducer(e,t,a)},t.useRef=function(e){return L.current.useRef(e)},t.useState=function(e){return L.current.useState(e)},t.useSyncExternalStore=function(e,t,a){return L.current.useSyncExternalStore(e,t,a)},t.useTransition=function(){return L.current.useTransition()},t.version="18.2.0"},791:function(e,t,a){"use strict";e.exports=a(117)},184:function(e,t,a){"use strict";e.exports=a(374)},813:function(e,t){"use strict";function a(e,t){var a=e.length;e.push(t);e:for(;0<a;){var i=a-1>>>1,n=e[i];if(!(0<o(n,t)))break e;e[i]=t,e[a]=n,a=i}}function i(e){return 0===e.length?null:e[0]}function n(e){if(0===e.length)return null;var t=e[0],a=e.pop();if(a!==t){e[0]=a;e:for(var i=0,n=e.length,s=n>>>1;i<s;){var r=2*(i+1)-1,c=e[r],l=r+1,d=e[l];if(0>o(c,a))l<n&&0>o(d,c)?(e[i]=d,e[l]=a,i=l):(e[i]=c,e[r]=a,i=r);else{if(!(l<n&&0>o(d,a)))break e;e[i]=d,e[l]=a,i=l}}}return t}function o(e,t){var a=e.sortIndex-t.sortIndex;return 0!==a?a:e.id-t.id}if("object"===typeof performance&&"function"===typeof performance.now){var s=performance;t.unstable_now=function(){return s.now()}}else{var r=Date,c=r.now();t.unstable_now=function(){return r.now()-c}}var l=[],d=[],u=1,h=null,m=3,p=!1,f=!1,g=!1,b="function"===typeof setTimeout?setTimeout:null,v="function"===typeof clearTimeout?clearTimeout:null,y="undefined"!==typeof setImmediate?setImmediate:null;function w(e){for(var t=i(d);null!==t;){if(null===t.callback)n(d);else{if(!(t.startTime<=e))break;n(d),t.sortIndex=t.expirationTime,a(l,t)}t=i(d)}}function D(e){if(g=!1,w(e),!f)if(null!==i(l))f=!0,x(A);else{var t=i(d);null!==t&&P(D,t.startTime-e)}}function A(e,a){f=!1,g&&(g=!1,v(C),C=-1),p=!0;var o=m;try{for(w(a),h=i(l);null!==h&&(!(h.expirationTime>a)||e&&!I());){var s=h.callback;if("function"===typeof s){h.callback=null,m=h.priorityLevel;var r=s(h.expirationTime<=a);a=t.unstable_now(),"function"===typeof r?h.callback=r:h===i(l)&&n(l),w(a)}else n(l);h=i(l)}if(null!==h)var c=!0;else{var u=i(d);null!==u&&P(D,u.startTime-a),c=!1}return c}finally{h=null,m=o,p=!1}}"undefined"!==typeof navigator&&void 0!==navigator.scheduling&&void 0!==navigator.scheduling.isInputPending&&navigator.scheduling.isInputPending.bind(navigator.scheduling);var R,S=!1,T=null,C=-1,E=5,k=-1;function I(){return!(t.unstable_now()-k<E)}function M(){if(null!==T){var e=t.unstable_now();k=e;var a=!0;try{a=T(!0,e)}finally{a?R():(S=!1,T=null)}}else S=!1}if("function"===typeof y)R=function(){y(M)};else if("undefined"!==typeof MessageChannel){var O=new MessageChannel,L=O.port2;O.port1.onmessage=M,R=function(){L.postMessage(null)}}else R=function(){b(M,0)};function x(e){T=e,S||(S=!0,R())}function P(e,a){C=b((function(){e(t.unstable_now())}),a)}t.unstable_IdlePriority=5,t.unstable_ImmediatePriority=1,t.unstable_LowPriority=4,t.unstable_NormalPriority=3,t.unstable_Profiling=null,t.unstable_UserBlockingPriority=2,t.unstable_cancelCallback=function(e){e.callback=null},t.unstable_continueExecution=function(){f||p||(f=!0,x(A))},t.unstable_forceFrameRate=function(e){0>e||125<e?console.error("forceFrameRate takes a positive int between 0 and 125, forcing frame rates higher than 125 fps is not supported"):E=0<e?Math.floor(1e3/e):5},t.unstable_getCurrentPriorityLevel=function(){return m},t.unstable_getFirstCallbackNode=function(){return i(l)},t.unstable_next=function(e){switch(m){case 1:case 2:case 3:var t=3;break;default:t=m}var a=m;m=t;try{return e()}finally{m=a}},t.unstable_pauseExecution=function(){},t.unstable_requestPaint=function(){},t.unstable_runWithPriority=function(e,t){switch(e){case 1:case 2:case 3:case 4:case 5:break;default:e=3}var a=m;m=e;try{return t()}finally{m=a}},t.unstable_scheduleCallback=function(e,n,o){var s=t.unstable_now();switch("object"===typeof o&&null!==o?o="number"===typeof(o=o.delay)&&0<o?s+o:s:o=s,e){case 1:var r=-1;break;case 2:r=250;break;case 5:r=1073741823;break;case 4:r=1e4;break;default:r=5e3}return e={id:u++,callback:n,priorityLevel:e,startTime:o,expirationTime:r=o+r,sortIndex:-1},o>s?(e.sortIndex=o,a(d,e),null===i(l)&&e===i(d)&&(g?(v(C),C=-1):g=!0,P(D,o-s))):(e.sortIndex=r,a(l,e),f||p||(f=!0,x(A))),e},t.unstable_shouldYield=I,t.unstable_wrapCallback=function(e){var t=m;return function(){var a=m;m=t;try{return e.apply(this,arguments)}finally{m=a}}}},296:function(e,t,a){"use strict";e.exports=a(813)},824:function(e,t){var a;!function(){"use strict";var i={}.hasOwnProperty;function n(){for(var e=[],t=0;t<arguments.length;t++){var a=arguments[t];if(a){var o=typeof a;if("string"===o||"number"===o)e.push(a);else if(Array.isArray(a)){if(a.length){var s=n.apply(null,a);s&&e.push(s)}}else if("object"===o){if(a.toString!==Object.prototype.toString&&!a.toString.toString().includes("[native code]")){e.push(a.toString());continue}for(var r in a)i.call(a,r)&&a[r]&&e.push(r)}}}return e.join(" ")}e.exports?(n.default=n,e.exports=n):void 0===(a=function(){return n}.apply(t,[]))||(e.exports=a)}()},154:function(e,t,a){"use strict";var i=a(526);function n(){}function o(){}o.resetWarningCache=n,e.exports=function(){function e(e,t,a,n,o,s){if(s!==i){var r=new Error("Calling PropTypes validators directly is not supported by the `prop-types` package. Use PropTypes.checkPropTypes() to call them. Read more at http://fb.me/use-check-prop-types");throw r.name="Invariant Violation",r}}function t(){return e}e.isRequired=e;var a={array:e,bigint:e,bool:e,func:e,number:e,object:e,string:e,symbol:e,any:e,arrayOf:t,element:e,elementType:e,instanceOf:t,node:e,objectOf:t,oneOf:t,oneOfType:t,shape:t,exact:t,checkPropTypes:o,resetWarningCache:n};return a.PropTypes=a,a}},863:function(e,t,a){e.exports=a(154)()},526:function(e){"use strict";e.exports="SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED"},889:function(e,t){"use strict";var a=Symbol.for("react.element"),i=Symbol.for("react.portal"),n=Symbol.for("react.fragment"),o=Symbol.for("react.strict_mode"),s=Symbol.for("react.profiler"),r=Symbol.for("react.provider"),c=Symbol.for("react.context"),l=Symbol.for("react.forward_ref"),d=Symbol.for("react.suspense"),u=Symbol.for("react.memo"),h=Symbol.for("react.lazy"),m=Symbol.iterator;var p={isMounted:function(){return!1},enqueueForceUpdate:function(){},enqueueReplaceState:function(){},enqueueSetState:function(){}},f=Object.assign,g={};function b(e,t,a){this.props=e,this.context=t,this.refs=g,this.updater=a||p}function v(){}function y(e,t,a){this.props=e,this.context=t,this.refs=g,this.updater=a||p}b.prototype.isReactComponent={},b.prototype.setState=function(e,t){if("object"!==typeof e&&"function"!==typeof e&&null!=e)throw Error("setState(...): takes an object of state variables to update or a function which returns an object of state variables.");this.updater.enqueueSetState(this,e,t,"setState")},b.prototype.forceUpdate=function(e){this.updater.enqueueForceUpdate(this,e,"forceUpdate")},v.prototype=b.prototype;var w=y.prototype=new v;w.constructor=y,f(w,b.prototype),w.isPureReactComponent=!0;var D=Array.isArray,A=Object.prototype.hasOwnProperty,R={current:null},S={key:!0,ref:!0,__self:!0,__source:!0};function T(e,t,i){var n,o={},s=null,r=null;if(null!=t)for(n in void 0!==t.ref&&(r=t.ref),void 0!==t.key&&(s=""+t.key),t)A.call(t,n)&&!S.hasOwnProperty(n)&&(o[n]=t[n]);var c=arguments.length-2;if(1===c)o.children=i;else if(1<c){for(var l=Array(c),d=0;d<c;d++)l[d]=arguments[d+2];o.children=l}if(e&&e.defaultProps)for(n in c=e.defaultProps)void 0===o[n]&&(o[n]=c[n]);return{$$typeof:a,type:e,key:s,ref:r,props:o,_owner:R.current}}function C(e){return"object"===typeof e&&null!==e&&e.$$typeof===a}var E=/\/+/g;function k(e,t){return"object"===typeof e&&null!==e&&null!=e.key?function(e){var t={"=":"=0",":":"=2"};return"$"+e.replace(/[=:]/g,(function(e){return t[e]}))}(""+e.key):t.toString(36)}function I(e,t,n,o,s){var r=typeof e;"undefined"!==r&&"boolean"!==r||(e=null);var c=!1;if(null===e)c=!0;else switch(r){case"string":case"number":c=!0;break;case"object":switch(e.$$typeof){case a:case i:c=!0}}if(c)return s=s(c=e),e=""===o?"."+k(c,0):o,D(s)?(n="",null!=e&&(n=e.replace(E,"$&/")+"/"),I(s,t,n,"",(function(e){return e}))):null!=s&&(C(s)&&(s=function(e,t){return{$$typeof:a,type:e.type,key:t,ref:e.ref,props:e.props,_owner:e._owner}}(s,n+(!s.key||c&&c.key===s.key?"":(""+s.key).replace(E,"$&/")+"/")+e)),t.push(s)),1;if(c=0,o=""===o?".":o+":",D(e))for(var l=0;l<e.length;l++){var d=o+k(r=e[l],l);c+=I(r,t,n,d,s)}else if(d=function(e){return null===e||"object"!==typeof e?null:"function"===typeof(e=m&&e[m]||e["@@iterator"])?e:null}(e),"function"===typeof d)for(e=d.call(e),l=0;!(r=e.next()).done;)c+=I(r=r.value,t,n,d=o+k(r,l++),s);else if("object"===r)throw t=String(e),Error("Objects are not valid as a React child (found: "+("[object Object]"===t?"object with keys {"+Object.keys(e).join(", ")+"}":t)+"). If you meant to render a collection of children, use an array instead.");return c}function M(e,t,a){if(null==e)return e;var i=[],n=0;return I(e,i,"","",(function(e){return t.call(a,e,n++)})),i}function O(e){if(-1===e._status){var t=e._result;(t=t()).then((function(t){0!==e._status&&-1!==e._status||(e._status=1,e._result=t)}),(function(t){0!==e._status&&-1!==e._status||(e._status=2,e._result=t)})),-1===e._status&&(e._status=0,e._result=t)}if(1===e._status)return e._result.default;throw e._result}var L={current:null},x={transition:null},P={ReactCurrentDispatcher:L,ReactCurrentBatchConfig:x,ReactCurrentOwner:R};t.Children={map:M,forEach:function(e,t,a){M(e,(function(){t.apply(this,arguments)}),a)},count:function(e){var t=0;return M(e,(function(){t++})),t},toArray:function(e){return M(e,(function(e){return e}))||[]},only:function(e){if(!C(e))throw Error("React.Children.only expected to receive a single React element child.");return e}},t.Component=b,t.Fragment=n,t.Profiler=s,t.PureComponent=y,t.StrictMode=o,t.Suspense=d,t.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=P,t.cloneElement=function(e,t,i){if(null===e||void 0===e)throw Error("React.cloneElement(...): The argument must be a React element, but you passed "+e+".");var n=f({},e.props),o=e.key,s=e.ref,r=e._owner;if(null!=t){if(void 0!==t.ref&&(s=t.ref,r=R.current),void 0!==t.key&&(o=""+t.key),e.type&&e.type.defaultProps)var c=e.type.defaultProps;for(l in t)A.call(t,l)&&!S.hasOwnProperty(l)&&(n[l]=void 0===t[l]&&void 0!==c?c[l]:t[l])}var l=arguments.length-2;if(1===l)n.children=i;else if(1<l){c=Array(l);for(var d=0;d<l;d++)c[d]=arguments[d+2];n.children=c}return{$$typeof:a,type:e.type,key:o,ref:s,props:n,_owner:r}},t.createContext=function(e){return(e={$$typeof:c,_currentValue:e,_currentValue2:e,_threadCount:0,Provider:null,Consumer:null,_defaultValue:null,_globalName:null}).Provider={$$typeof:r,_context:e},e.Consumer=e},t.createElement=T,t.createFactory=function(e){var t=T.bind(null,e);return t.type=e,t},t.createRef=function(){return{current:null}},t.forwardRef=function(e){return{$$typeof:l,render:e}},t.isValidElement=C,t.lazy=function(e){return{$$typeof:h,_payload:{_status:-1,_result:e},_init:O}},t.memo=function(e,t){return{$$typeof:u,type:e,compare:void 0===t?null:t}},t.startTransition=function(e){var t=x.transition;x.transition={};try{e()}finally{x.transition=t}},t.unstable_act=function(){throw Error("act(...) is not supported in production builds of React.")},t.useCallback=function(e,t){return L.current.useCallback(e,t)},t.useContext=function(e){return L.current.useContext(e)},t.useDebugValue=function(){},t.useDeferredValue=function(e){return L.current.useDeferredValue(e)},t.useEffect=function(e,t){return L.current.useEffect(e,t)},t.useId=function(){return L.current.useId()},t.useImperativeHandle=function(e,t,a){return L.current.useImperativeHandle(e,t,a)},t.useInsertionEffect=function(e,t){return L.current.useInsertionEffect(e,t)},t.useLayoutEffect=function(e,t){return L.current.useLayoutEffect(e,t)},t.useMemo=function(e,t){return L.current.useMemo(e,t)},t.useReducer=function(e,t,a){return L.current.useReducer(e,t,a)},t.useRef=function(e){return L.current.useRef(e)},t.useState=function(e){return L.current.useState(e)},t.useSyncExternalStore=function(e,t,a){return L.current.useSyncExternalStore(e,t,a)},t.useTransition=function(){return L.current.useTransition()},t.version="18.2.0"},719:function(e,t,a){"use strict";e.exports=a(889)}},t={};function a(i){var n=t[i];if(void 0!==n)return n.exports;var o=t[i]={exports:{}};return e[i](o,o.exports,a),o.exports}a.m=e,a.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return a.d(t,{a:t}),t},function(){var e,t=Object.getPrototypeOf?function(e){return Object.getPrototypeOf(e)}:function(e){return e.__proto__};a.t=function(i,n){if(1&n&&(i=this(i)),8&n)return i;if("object"===typeof i&&i){if(4&n&&i.__esModule)return i;if(16&n&&"function"===typeof i.then)return i}var o=Object.create(null);a.r(o);var s={};e=e||[null,t({}),t([]),t(t)];for(var r=2&n&&i;"object"==typeof r&&!~e.indexOf(r);r=t(r))Object.getOwnPropertyNames(r).forEach((function(e){s[e]=function(){return i[e]}}));return s.default=function(){return i},a.d(o,s),o}}(),a.d=function(e,t){for(var i in t)a.o(t,i)&&!a.o(e,i)&&Object.defineProperty(e,i,{enumerable:!0,get:t[i]})},a.f={},a.e=function(e){return Promise.all(Object.keys(a.f).reduce((function(t,i){return a.f[i](e,t),t}),[]))},a.u=function(e){return"static/js/"+e+".e740e6cc.chunk.js"},a.miniCssF=function(e){},a.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},function(){var e={},t="info-extraction:";a.l=function(i,n,o,s){if(e[i])e[i].push(n);else{var r,c;if(void 0!==o)for(var l=document.getElementsByTagName("script"),d=0;d<l.length;d++){var u=l[d];if(u.getAttribute("src")==i||u.getAttribute("data-webpack")==t+o){r=u;break}}r||(c=!0,(r=document.createElement("script")).charset="utf-8",r.timeout=120,a.nc&&r.setAttribute("nonce",a.nc),r.setAttribute("data-webpack",t+o),r.src=i),e[i]=[n];var h=function(t,a){r.onerror=r.onload=null,clearTimeout(m);var n=e[i];if(delete e[i],r.parentNode&&r.parentNode.removeChild(r),n&&n.forEach((function(e){return e(a)})),t)return t(a)},m=setTimeout(h.bind(null,void 0,{type:"timeout",target:r}),12e4);r.onerror=h.bind(null,r.onerror),r.onload=h.bind(null,r.onload),c&&document.head.appendChild(r)}}}(),a.r=function(e){"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},a.p="/",function(){var e={179:0};a.f.j=function(t,i){var n=a.o(e,t)?e[t]:void 0;if(0!==n)if(n)i.push(n[2]);else{var o=new Promise((function(a,i){n=e[t]=[a,i]}));i.push(n[2]=o);var s=a.p+a.u(t),r=new Error;a.l(s,(function(i){if(a.o(e,t)&&(0!==(n=e[t])&&(e[t]=void 0),n)){var o=i&&("load"===i.type?"missing":i.type),s=i&&i.target&&i.target.src;r.message="Loading chunk "+t+" failed.\n("+o+": "+s+")",r.name="ChunkLoadError",r.type=o,r.request=s,n[1](r)}}),"chunk-"+t,t)}};var t=function(t,i){var n,o,s=i[0],r=i[1],c=i[2],l=0;if(s.some((function(t){return 0!==e[t]}))){for(n in r)a.o(r,n)&&(a.m[n]=r[n]);if(c)c(a)}for(t&&t(i);l<s.length;l++)o=s[l],a.o(e,o)&&e[o]&&e[o][0](),e[o]=0},i=self.webpackChunkinfo_extraction=self.webpackChunkinfo_extraction||[];i.forEach(t.bind(null,0)),i.push=t.bind(null,i.push.bind(i))}(),function(){"use strict";var e=a(791),t=a.t(e,2),i=a(250);function n(e,t){if(!(e instanceof t))throw new TypeError("Cannot call a class as a function")}function o(e){return o="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&"function"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?"symbol":typeof e},o(e)}function s(e){var t=function(e,t){if("object"!==o(e)||null===e)return e;var a=e[Symbol.toPrimitive];if(void 0!==a){var i=a.call(e,t||"default");if("object"!==o(i))return i;throw new TypeError("@@toPrimitive must return a primitive value.")}return("string"===t?String:Number)(e)}(e,"string");return"symbol"===o(t)?t:String(t)}function r(e,t){for(var a=0;a<t.length;a++){var i=t[a];i.enumerable=i.enumerable||!1,i.configurable=!0,"value"in i&&(i.writable=!0),Object.defineProperty(e,s(i.key),i)}}function c(e,t,a){return t&&r(e.prototype,t),a&&r(e,a),Object.defineProperty(e,"prototype",{writable:!1}),e}function l(e,t){return l=Object.setPrototypeOf?Object.setPrototypeOf.bind():function(e,t){return e.__proto__=t,e},l(e,t)}function d(e,t){if("function"!==typeof t&&null!==t)throw new TypeError("Super expression must either be null or a function");e.prototype=Object.create(t&&t.prototype,{constructor:{value:e,writable:!0,configurable:!0}}),Object.defineProperty(e,"prototype",{writable:!1}),t&&l(e,t)}function u(e){return u=Object.setPrototypeOf?Object.getPrototypeOf.bind():function(e){return e.__proto__||Object.getPrototypeOf(e)},u(e)}function h(){if("undefined"===typeof Reflect||!Reflect.construct)return!1;if(Reflect.construct.sham)return!1;if("function"===typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Reflect.construct(Boolean,[],(function(){}))),!0}catch(e){return!1}}function m(e,t){if(t&&("object"===o(t)||"function"===typeof t))return t;if(void 0!==t)throw new TypeError("Derived constructors may only return object or undefined");return function(e){if(void 0===e)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return e}(e)}function p(e){var t=h();return function(){var a,i=u(e);if(t){var n=u(this).constructor;a=Reflect.construct(i,arguments,n)}else a=i.apply(this,arguments);return m(this,a)}}var f,g=a(719),b=a(863),v=a.n(b),y=a(824),w=a.n(y);function D(e){return D="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&"function"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?"symbol":typeof e},D(e)}function A(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:"",t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:f;return t?e.split(" ").map((function(e){return t[e]||e})).join(" "):e}var R={};var S="object"===("undefined"===typeof window?"undefined":D(window))&&window.Element||function(){};v().oneOfType([v().string,v().func,function(e,t,a){if(!(e[t]instanceof S))return new Error("Invalid prop `"+t+"` supplied to `"+a+"`. Expected prop to be an instance of Element. Validation failed.")},v().shape({current:v().any})]);var T=v().oneOfType([v().func,v().string,v().shape({$$typeof:v().symbol,render:v().func}),v().arrayOf(v().oneOfType([v().func,v().string,v().shape({$$typeof:v().symbol,render:v().func})]))]);"undefined"===typeof window||!window.document||window.document.createElement;function C(e){var t=D(e);return null!=e&&("object"===t||"function"===t)}var E=["className","cssModule","noGutters","tag","widths"];function k(){return k=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var a=arguments[t];for(var i in a)Object.prototype.hasOwnProperty.call(a,i)&&(e[i]=a[i])}return e},k.apply(this,arguments)}function I(e,t){if(null==e)return{};var a,i,n=function(e,t){if(null==e)return{};var a,i,n={},o=Object.keys(e);for(i=0;i<o.length;i++)a=o[i],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)a=o[i],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var M,O,L=["xs","sm","md","lg","xl","xxl"],x=v().oneOfType([v().number,v().string]),P={tag:T,noGutters:(M=v().bool,O="Please use Bootstrap 5 gutter utility classes. https://getbootstrap.com/docs/5.0/layout/gutters/",function(e,t,a){var i;null!==e[t]&&"undefined"!==typeof e[t]&&(i='"'.concat(t,'" property of "').concat(a,'" has been deprecated.\n').concat(O),R[i]||("undefined"!==typeof console&&console.error(i),R[i]=!0));for(var n=arguments.length,o=new Array(n>3?n-3:0),s=3;s<n;s++)o[s-3]=arguments[s];return M.apply(void 0,[e,t,a].concat(o))}),className:v().string,cssModule:v().object,xs:x,sm:x,md:x,lg:x,xl:x,xxl:x,widths:v().array};function B(e){var t=e.className,a=e.cssModule,i=e.noGutters,n=e.tag,o=void 0===n?"div":n,s=e.widths,r=void 0===s?L:s,c=I(e,E),l=[];r.forEach((function(t,a){var i=e[t];if(delete c[t],i){var n=!a;l.push(n?"row-cols-".concat(i):"row-cols-".concat(t,"-").concat(i))}}));var d=A(w()(t,i?"gx-0":null,"row",l),a);return g.createElement(o,k({},c,{className:d}))}B.propTypes=P;var N=B,_=["className","cssModule","widths","tag"];function V(){return V=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var a=arguments[t];for(var i in a)Object.prototype.hasOwnProperty.call(a,i)&&(e[i]=a[i])}return e},V.apply(this,arguments)}function W(e,t){if(null==e)return{};var a,i,n=function(e,t){if(null==e)return{};var a,i,n={},o=Object.keys(e);for(i=0;i<o.length;i++)a=o[i],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)a=o[i],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}function F(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}var j=["xs","sm","md","lg","xl","xxl"],U=v().oneOfType([v().number,v().string]),z=v().oneOfType([v().bool,v().number,v().string,v().shape({size:v().oneOfType([v().bool,v().number,v().string]),order:U,offset:U})]),G={tag:T,xs:z,sm:z,md:z,lg:z,xl:z,xxl:z,className:v().string,cssModule:v().object,widths:v().array},H=function(e,t,a){return!0===a||""===a?e?"col":"col-".concat(t):"auto"===a?e?"col-auto":"col-".concat(t,"-auto"):e?"col-".concat(a):"col-".concat(t,"-").concat(a)};function q(e){var t=e.className,a=e.cssModule,i=e.widths,n=void 0===i?j:i,o=e.tag,s=void 0===o?"div":o,r=function(e,t){var a=e,i=[];return(arguments.length>2&&void 0!==arguments[2]?arguments[2]:j).forEach((function(e,n){var o=a[e];if(delete a[e],o||""===o){var s=!n;if(C(o)){var r,c=s?"-":"-".concat(e,"-"),l=H(s,e,o.size);i.push(A(w()((F(r={},l,o.size||""===o.size),F(r,"order".concat(c).concat(o.order),o.order||0===o.order),F(r,"offset".concat(c).concat(o.offset),o.offset||0===o.offset),r)),t))}else{var d=H(s,e,o);i.push(d)}}})),{colClasses:i,modifiedAttributes:a}}(W(e,_),a,n),c=r.modifiedAttributes,l=r.colClasses;l.length||l.push("col");var d=A(w()(t,l),a);return g.createElement(s,V({},c,{className:d}))}q.propTypes=G;var K=q,Q=["expand","className","cssModule","light","dark","fixed","sticky","color","container","tag","children"];function J(){return J=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var a=arguments[t];for(var i in a)Object.prototype.hasOwnProperty.call(a,i)&&(e[i]=a[i])}return e},J.apply(this,arguments)}function Y(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function X(e,t){if(null==e)return{};var a,i,n=function(e,t){if(null==e)return{};var a,i,n={},o=Object.keys(e);for(i=0;i<o.length;i++)a=o[i],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)a=o[i],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var Z={children:v().node,className:v().string,color:v().string,container:v().oneOfType([v().bool,v().string]),cssModule:v().object,dark:v().bool,expand:v().oneOfType([v().bool,v().string]),fixed:v().string,light:v().bool,role:v().string,sticky:v().string,tag:T};function $(e){var t,a=e.expand,i=void 0!==a&&a,n=e.className,o=e.cssModule,s=e.light,r=e.dark,c=e.fixed,l=e.sticky,d=e.color,u=e.container,h=void 0===u?"fluid":u,m=e.tag,p=void 0===m?"nav":m,f=e.children,b=X(e,Q),v=A(w()(n,"navbar",function(e){return!1!==e&&(!0===e||"xs"===e?"navbar-expand":"navbar-expand-".concat(e))}(i),(Y(t={"navbar-light":s,"navbar-dark":r},"bg-".concat(d),d),Y(t,"fixed-".concat(c),c),Y(t,"sticky-".concat(l),l),t)),o),y=h&&!0===h?"container":"container-".concat(h);return g.createElement(p,J({},b,{className:v}),h?g.createElement("div",{className:y},f):f)}$.propTypes=Z;var ee=$,te=["className","cssModule","tag"];function ae(){return ae=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var a=arguments[t];for(var i in a)Object.prototype.hasOwnProperty.call(a,i)&&(e[i]=a[i])}return e},ae.apply(this,arguments)}function ie(e,t){if(null==e)return{};var a,i,n=function(e,t){if(null==e)return{};var a,i,n={},o=Object.keys(e);for(i=0;i<o.length;i++)a=o[i],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)a=o[i],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var ne={className:v().string,cssModule:v().object,tag:T};function oe(e){var t=e.className,a=e.cssModule,i=e.tag,n=void 0===i?"a":i,o=ie(e,te),s=A(w()(t,"navbar-brand"),a);return g.createElement(n,ae({},o,{className:s}))}oe.propTypes=ne;var se,re=oe;function ce(e){if(Array.isArray(e))return e}function le(e,t){(null==t||t>e.length)&&(t=e.length);for(var a=0,i=new Array(t);a<t;a++)i[a]=e[a];return i}function de(e,t){if(e){if("string"===typeof e)return le(e,t);var a=Object.prototype.toString.call(e).slice(8,-1);return"Object"===a&&e.constructor&&(a=e.constructor.name),"Map"===a||"Set"===a?Array.from(e):"Arguments"===a||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(a)?le(e,t):void 0}}function ue(){throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}function he(e,t){return ce(e)||function(e,t){var a=null==e?null:"undefined"!=typeof Symbol&&e[Symbol.iterator]||e["@@iterator"];if(null!=a){var i,n,o,s,r=[],c=!0,l=!1;try{if(o=(a=a.call(e)).next,0===t){if(Object(a)!==a)return;c=!1}else for(;!(c=(i=o.call(a)).done)&&(r.push(i.value),r.length!==t);c=!0);}catch(d){l=!0,n=d}finally{try{if(!c&&null!=a.return&&(s=a.return(),Object(s)!==s))return}finally{if(l)throw n}}return r}}(e,t)||de(e,t)||ue()}function me(e){if("undefined"!==typeof Symbol&&null!=e[Symbol.iterator]||null!=e["@@iterator"])return Array.from(e)}function pe(e){return function(e){if(Array.isArray(e))return le(e)}(e)||me(e)||de(e)||function(){throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}function fe(e,t,a){return fe=h()?Reflect.construct.bind():function(e,t,a){var i=[null];i.push.apply(i,t);var n=new(Function.bind.apply(e,i));return a&&l(n,a.prototype),n},fe.apply(null,arguments)}function ge(e){var t="function"===typeof Map?new Map:void 0;return ge=function(e){if(null===e||(a=e,-1===Function.toString.call(a).indexOf("[native code]")))return e;var a;if("function"!==typeof e)throw new TypeError("Super expression must either be null or a function");if("undefined"!==typeof t){if(t.has(e))return t.get(e);t.set(e,i)}function i(){return fe(e,arguments,u(this).constructor)}return i.prototype=Object.create(e.prototype,{constructor:{value:i,enumerable:!1,writable:!0,configurable:!0}}),l(i,e)},ge(e)}function be(){return be=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var a=arguments[t];for(var i in a)Object.prototype.hasOwnProperty.call(a,i)&&(e[i]=a[i])}return e},be.apply(this,arguments)}!function(e){e.Pop="POP",e.Push="PUSH",e.Replace="REPLACE"}(se||(se={}));var ve,ye="popstate";function we(e,t){if(!1===e||null===e||"undefined"===typeof e)throw new Error(t)}function De(e,t){if(!e){"undefined"!==typeof console&&console.warn(t);try{throw new Error(t)}catch(a){}}}function Ae(e,t){return{usr:e.state,key:e.key,idx:t}}function Re(e,t,a,i){return void 0===a&&(a=null),be({pathname:"string"===typeof e?e:e.pathname,search:"",hash:""},"string"===typeof t?Te(t):t,{state:a,key:t&&t.key||i||Math.random().toString(36).substr(2,8)})}function Se(e){var t=e.pathname,a=void 0===t?"/":t,i=e.search,n=void 0===i?"":i,o=e.hash,s=void 0===o?"":o;return n&&"?"!==n&&(a+="?"===n.charAt(0)?n:"?"+n),s&&"#"!==s&&(a+="#"===s.charAt(0)?s:"#"+s),a}function Te(e){var t={};if(e){var a=e.indexOf("#");a>=0&&(t.hash=e.substr(a),e=e.substr(0,a));var i=e.indexOf("?");i>=0&&(t.search=e.substr(i),e=e.substr(0,i)),e&&(t.pathname=e)}return t}function Ce(e,t,a,i){void 0===i&&(i={});var n=i,o=n.window,s=void 0===o?document.defaultView:o,r=n.v5Compat,c=void 0!==r&&r,l=s.history,d=se.Pop,u=null,h=m();function m(){return(l.state||{idx:null}).idx}function p(){d=se.Pop;var e=m(),t=null==e?null:e-h;h=e,u&&u({action:d,location:g.location,delta:t})}function f(e){var t="null"!==s.location.origin?s.location.origin:s.location.href,a="string"===typeof e?e:Se(e);return we(t,"No window.location.(origin|href) available to create URL for href: "+a),new URL(a,t)}null==h&&(h=0,l.replaceState(be({},l.state,{idx:h}),""));var g={get action(){return d},get location(){return e(s,l)},listen:function(e){if(u)throw new Error("A history only accepts one active listener");return s.addEventListener(ye,p),u=e,function(){s.removeEventListener(ye,p),u=null}},createHref:function(e){return t(s,e)},createURL:f,encodeLocation:function(e){var t=f(e);return{pathname:t.pathname,search:t.search,hash:t.hash}},push:function(e,t){d=se.Push;var i=Re(g.location,e,t);a&&a(i,e);var n=Ae(i,h=m()+1),o=g.createHref(i);try{l.pushState(n,"",o)}catch(r){if(r instanceof DOMException&&"DataCloneError"===r.name)throw r;s.location.assign(o)}c&&u&&u({action:d,location:g.location,delta:1})},replace:function(e,t){d=se.Replace;var i=Re(g.location,e,t);a&&a(i,e);var n=Ae(i,h=m()),o=g.createHref(i);l.replaceState(n,"",o),c&&u&&u({action:d,location:g.location,delta:0})},go:function(e){return l.go(e)}};return g}!function(e){e.data="data",e.deferred="deferred",e.redirect="redirect",e.error="error"}(ve||(ve={}));new Set(["lazy","caseSensitive","path","id","index","children"]);function Ee(e,t,a){void 0===a&&(a="/");var i=je(("string"===typeof t?Te(t):t).pathname||"/",a);if(null==i)return null;var n=ke(e);!function(e){e.sort((function(e,t){return e.score!==t.score?t.score-e.score:function(e,t){var a=e.length===t.length&&e.slice(0,-1).every((function(e,a){return e===t[a]}));return a?e[e.length-1]-t[t.length-1]:0}(e.routesMeta.map((function(e){return e.childrenIndex})),t.routesMeta.map((function(e){return e.childrenIndex})))}))}(n);for(var o=null,s=0;null==o&&s<n.length;++s)o=Ve(n[s],Fe(i));return o}function ke(e,t,a,i){void 0===t&&(t=[]),void 0===a&&(a=[]),void 0===i&&(i="");var n=function(e,n,o){var s={relativePath:void 0===o?e.path||"":o,caseSensitive:!0===e.caseSensitive,childrenIndex:n,route:e};s.relativePath.startsWith("/")&&(we(s.relativePath.startsWith(i),'Absolute route path "'+s.relativePath+'" nested under path "'+i+'" is not valid. An absolute child route path must start with the combined path of all its parent routes.'),s.relativePath=s.relativePath.slice(i.length));var r=He([i,s.relativePath]),c=a.concat(s);e.children&&e.children.length>0&&(we(!0!==e.index,'Index routes must not have child routes. Please remove all child routes from route path "'+r+'".'),ke(e.children,t,c,r)),(null!=e.path||e.index)&&t.push({path:r,score:_e(r,e.index),routesMeta:c})};return e.forEach((function(e,t){var a;if(""!==e.path&&null!=(a=e.path)&&a.includes("?")){var i,o=function(e,t){var a="undefined"!==typeof Symbol&&e[Symbol.iterator]||e["@@iterator"];if(!a){if(Array.isArray(e)||(a=de(e))||t&&e&&"number"===typeof e.length){a&&(e=a);var i=0,n=function(){};return{s:n,n:function(){return i>=e.length?{done:!0}:{done:!1,value:e[i++]}},e:function(e){throw e},f:n}}throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}var o,s=!0,r=!1;return{s:function(){a=a.call(e)},n:function(){var e=a.next();return s=e.done,e},e:function(e){r=!0,o=e},f:function(){try{s||null==a.return||a.return()}finally{if(r)throw o}}}}(Ie(e.path));try{for(o.s();!(i=o.n()).done;){var s=i.value;n(e,t,s)}}catch(r){o.e(r)}finally{o.f()}}else n(e,t)})),t}function Ie(e){var t=e.split("/");if(0===t.length)return[];var a,i=ce(a=t)||me(a)||de(a)||ue(),n=i[0],o=i.slice(1),s=n.endsWith("?"),r=n.replace(/\?$/,"");if(0===o.length)return s?[r,""]:[r];var c=Ie(o.join("/")),l=[];return l.push.apply(l,pe(c.map((function(e){return""===e?r:[r,e].join("/")})))),s&&l.push.apply(l,pe(c)),l.map((function(t){return e.startsWith("/")&&""===t?"/":t}))}var Me=/^:\w+$/,Oe=3,Le=2,xe=1,Pe=10,Be=-2,Ne=function(e){return"*"===e};function _e(e,t){var a=e.split("/"),i=a.length;return a.some(Ne)&&(i+=Be),t&&(i+=Le),a.filter((function(e){return!Ne(e)})).reduce((function(e,t){return e+(Me.test(t)?Oe:""===t?xe:Pe)}),i)}function Ve(e,t){for(var a=e.routesMeta,i={},n="/",o=[],s=0;s<a.length;++s){var r=a[s],c=s===a.length-1,l="/"===n?t:t.slice(n.length)||"/",d=We({path:r.relativePath,caseSensitive:r.caseSensitive,end:c},l);if(!d)return null;Object.assign(i,d.params);var u=r.route;o.push({params:i,pathname:He([n,d.pathname]),pathnameBase:qe(He([n,d.pathnameBase])),route:u}),"/"!==d.pathnameBase&&(n=He([n,d.pathnameBase]))}return o}function We(e,t){"string"===typeof e&&(e={path:e,caseSensitive:!1,end:!0});var a=function(e,t,a){void 0===t&&(t=!1);void 0===a&&(a=!0);De("*"===e||!e.endsWith("*")||e.endsWith("/*"),'Route path "'+e+'" will be treated as if it were "'+e.replace(/\*$/,"/*")+'" because the `*` character must always follow a `/` in the pattern. To get rid of this warning, please change the route path to "'+e.replace(/\*$/,"/*")+'".');var i=[],n="^"+e.replace(/\/*\*?$/,"").replace(/^\/*/,"/").replace(/[\\.*+^$?{}|()[\]]/g,"\\$&").replace(/\/:(\w+)/g,(function(e,t){return i.push(t),"/([^\\/]+)"}));e.endsWith("*")?(i.push("*"),n+="*"===e||"/*"===e?"(.*)$":"(?:\\/(.+)|\\/*)$"):a?n+="\\/*$":""!==e&&"/"!==e&&(n+="(?:(?=\\/|$))");var o=new RegExp(n,t?void 0:"i");return[o,i]}(e.path,e.caseSensitive,e.end),i=he(a,2),n=i[0],o=i[1],s=t.match(n);if(!s)return null;var r=s[0],c=r.replace(/(.)\/+$/,"$1"),l=s.slice(1);return{params:o.reduce((function(e,t,a){if("*"===t){var i=l[a]||"";c=r.slice(0,r.length-i.length).replace(/(.)\/+$/,"$1")}return e[t]=function(e,t){try{return decodeURIComponent(e)}catch(a){return De(!1,'The value for the URL param "'+t+'" will not be decoded because the string "'+e+'" is a malformed URL segment. This is probably due to a bad percent encoding ('+a+")."),e}}(l[a]||"",t),e}),{}),pathname:r,pathnameBase:c,pattern:e}}function Fe(e){try{return decodeURI(e)}catch(t){return De(!1,'The URL path "'+e+'" could not be decoded because it is is a malformed URL segment. This is probably due to a bad percent encoding ('+t+")."),e}}function je(e,t){if("/"===t)return e;if(!e.toLowerCase().startsWith(t.toLowerCase()))return null;var a=t.endsWith("/")?t.length-1:t.length,i=e.charAt(a);return i&&"/"!==i?null:e.slice(a)||"/"}function Ue(e,t,a,i){return"Cannot include a '"+e+"' character in a manually specified `to."+t+"` field ["+JSON.stringify(i)+"].  Please separate it out to the `to."+a+'` field. Alternatively you may provide the full path as a string in <Link to="..."> and the router will parse it for you.'}function ze(e){return e.filter((function(e,t){return 0===t||e.route.path&&e.route.path.length>0}))}function Ge(e,t,a,i){var n;void 0===i&&(i=!1),"string"===typeof e?n=Te(e):(we(!(n=be({},e)).pathname||!n.pathname.includes("?"),Ue("?","pathname","search",n)),we(!n.pathname||!n.pathname.includes("#"),Ue("#","pathname","hash",n)),we(!n.search||!n.search.includes("#"),Ue("#","search","hash",n)));var o,s=""===e||""===n.pathname,r=s?"/":n.pathname;if(i||null==r)o=a;else{var c=t.length-1;if(r.startsWith("..")){for(var l=r.split("/");".."===l[0];)l.shift(),c-=1;n.pathname=l.join("/")}o=c>=0?t[c]:"/"}var d=function(e,t){void 0===t&&(t="/");var a="string"===typeof e?Te(e):e,i=a.pathname,n=a.search,o=void 0===n?"":n,s=a.hash,r=void 0===s?"":s,c=i?i.startsWith("/")?i:function(e,t){var a=t.replace(/\/+$/,"").split("/");return e.split("/").forEach((function(e){".."===e?a.length>1&&a.pop():"."!==e&&a.push(e)})),a.length>1?a.join("/"):"/"}(i,t):t;return{pathname:c,search:Ke(o),hash:Qe(r)}}(n,o),u=r&&"/"!==r&&r.endsWith("/"),h=(s||"."===r)&&a.endsWith("/");return d.pathname.endsWith("/")||!u&&!h||(d.pathname+="/"),d}var He=function(e){return e.join("/").replace(/\/\/+/g,"/")},qe=function(e){return e.replace(/\/+$/,"").replace(/^\/*/,"/")},Ke=function(e){return e&&"?"!==e?e.startsWith("?")?e:"?"+e:""},Qe=function(e){return e&&"#"!==e?e.startsWith("#")?e:"#"+e:""},Je=function(e){d(a,e);var t=p(a);function a(){return n(this,a),t.apply(this,arguments)}return c(a)}(ge(Error));function Ye(e){return null!=e&&"number"===typeof e.status&&"string"===typeof e.statusText&&"boolean"===typeof e.internal&&"data"in e}var Xe=["post","put","patch","delete"],Ze=(new Set(Xe),["get"].concat(Xe));new Set(Ze),new Set([301,302,303,307,308]),new Set([307,308]);Symbol("deferred");function $e(){return $e=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var a=arguments[t];for(var i in a)Object.prototype.hasOwnProperty.call(a,i)&&(e[i]=a[i])}return e},$e.apply(this,arguments)}var et=e.createContext(null);var tt=e.createContext(null);var at=e.createContext(null);var it=e.createContext(null);var nt=e.createContext(null);var ot=e.createContext({outlet:null,matches:[],isDataRoute:!1});var st=e.createContext(null);function rt(){return null!=e.useContext(nt)}function ct(){return rt()||we(!1),e.useContext(nt).location}function lt(t){e.useContext(it).static||e.useLayoutEffect(t)}function dt(){return e.useContext(ot).isDataRoute?function(){var t=wt(vt.UseNavigateStable).router,a=At(yt.UseNavigateStable),i=e.useRef(!1);return lt((function(){i.current=!0})),e.useCallback((function(e,n){void 0===n&&(n={}),i.current&&("number"===typeof e?t.navigate(e):t.navigate(e,$e({fromRouteId:a},n)))}),[t,a])}():function(){rt()||we(!1);var t=e.useContext(et),a=e.useContext(it),i=a.basename,n=a.navigator,o=e.useContext(ot).matches,s=ct().pathname,r=JSON.stringify(ze(o).map((function(e){return e.pathnameBase}))),c=e.useRef(!1);return lt((function(){c.current=!0})),e.useCallback((function(e,a){if(void 0===a&&(a={}),c.current)if("number"!==typeof e){var o=Ge(e,JSON.parse(r),s,"path"===a.relative);null==t&&"/"!==i&&(o.pathname="/"===o.pathname?i:He([i,o.pathname])),(a.replace?n.replace:n.push)(o,a.state,a)}else n.go(e)}),[i,n,r,s,t])}()}function ut(t,a){var i=(void 0===a?{}:a).relative,n=e.useContext(ot).matches,o=ct().pathname,s=JSON.stringify(ze(n).map((function(e){return e.pathnameBase})));return e.useMemo((function(){return Ge(t,JSON.parse(s),o,"path"===i)}),[t,s,o,i])}function ht(t,a,i){rt()||we(!1);var n,o=e.useContext(it).navigator,s=e.useContext(ot).matches,r=s[s.length-1],c=r?r.params:{},l=(r&&r.pathname,r?r.pathnameBase:"/"),d=(r&&r.route,ct());if(a){var u,h="string"===typeof a?Te(a):a;"/"===l||(null==(u=h.pathname)?void 0:u.startsWith(l))||we(!1),n=h}else n=d;var m=n.pathname||"/",p=Ee(t,{pathname:"/"===l?m:m.slice(l.length)||"/"});var f=bt(p&&p.map((function(e){return Object.assign({},e,{params:Object.assign({},c,e.params),pathname:He([l,o.encodeLocation?o.encodeLocation(e.pathname).pathname:e.pathname]),pathnameBase:"/"===e.pathnameBase?l:He([l,o.encodeLocation?o.encodeLocation(e.pathnameBase).pathname:e.pathnameBase])})})),s,i);return a&&f?e.createElement(nt.Provider,{value:{location:$e({pathname:"/",search:"",hash:"",state:null,key:"default"},n),navigationType:se.Pop}},f):f}function mt(){var t=function(){var t,a=e.useContext(st),i=Dt(yt.UseRouteError),n=At(yt.UseRouteError);if(a)return a;return null==(t=i.errors)?void 0:t[n]}(),a=Ye(t)?t.status+" "+t.statusText:t instanceof Error?t.message:JSON.stringify(t),i=t instanceof Error?t.stack:null,n="rgba(200,200,200, 0.5)",o={padding:"0.5rem",backgroundColor:n};return e.createElement(e.Fragment,null,e.createElement("h2",null,"Unexpected Application Error!"),e.createElement("h3",{style:{fontStyle:"italic"}},a),i?e.createElement("pre",{style:o},i):null,null)}var pt=e.createElement(mt,null),ft=function(t){d(i,t);var a=p(i);function i(e){var t;return n(this,i),(t=a.call(this,e)).state={location:e.location,revalidation:e.revalidation,error:e.error},t}return c(i,[{key:"componentDidCatch",value:function(e,t){console.error("React Router caught the following error during render",e,t)}},{key:"render",value:function(){return this.state.error?e.createElement(ot.Provider,{value:this.props.routeContext},e.createElement(st.Provider,{value:this.state.error,children:this.props.component})):this.props.children}}],[{key:"getDerivedStateFromError",value:function(e){return{error:e}}},{key:"getDerivedStateFromProps",value:function(e,t){return t.location!==e.location||"idle"!==t.revalidation&&"idle"===e.revalidation?{error:e.error,location:e.location,revalidation:e.revalidation}:{error:e.error||t.error,location:t.location,revalidation:e.revalidation||t.revalidation}}}]),i}(e.Component);function gt(t){var a=t.routeContext,i=t.match,n=t.children,o=e.useContext(et);return o&&o.static&&o.staticContext&&(i.route.errorElement||i.route.ErrorBoundary)&&(o.staticContext._deepestRenderedBoundaryId=i.route.id),e.createElement(ot.Provider,{value:a},n)}function bt(t,a,i){var n;if(void 0===a&&(a=[]),void 0===i&&(i=null),null==t){var o;if(null==(o=i)||!o.errors)return null;t=i.matches}var s=t,r=null==(n=i)?void 0:n.errors;if(null!=r){var c=s.findIndex((function(e){return e.route.id&&(null==r?void 0:r[e.route.id])}));c>=0||we(!1),s=s.slice(0,Math.min(s.length,c+1))}return s.reduceRight((function(t,n,o){var c=n.route.id?null==r?void 0:r[n.route.id]:null,l=null;i&&(l=n.route.errorElement||pt);var d=a.concat(s.slice(0,o+1)),u=function(){var a;return a=c?l:n.route.Component?e.createElement(n.route.Component,null):n.route.element?n.route.element:t,e.createElement(gt,{match:n,routeContext:{outlet:t,matches:d,isDataRoute:null!=i},children:a})};return i&&(n.route.ErrorBoundary||n.route.errorElement||0===o)?e.createElement(ft,{location:i.location,revalidation:i.revalidation,component:l,error:c,children:u(),routeContext:{outlet:null,matches:d,isDataRoute:!0}}):u()}),null)}var vt=function(e){return e.UseBlocker="useBlocker",e.UseRevalidator="useRevalidator",e.UseNavigateStable="useNavigate",e}(vt||{}),yt=function(e){return e.UseBlocker="useBlocker",e.UseLoaderData="useLoaderData",e.UseActionData="useActionData",e.UseRouteError="useRouteError",e.UseNavigation="useNavigation",e.UseRouteLoaderData="useRouteLoaderData",e.UseMatches="useMatches",e.UseRevalidator="useRevalidator",e.UseNavigateStable="useNavigate",e.UseRouteId="useRouteId",e}(yt||{});function wt(t){var a=e.useContext(et);return a||we(!1),a}function Dt(t){var a=e.useContext(tt);return a||we(!1),a}function At(t){var a=function(t){var a=e.useContext(ot);return a||we(!1),a}(),i=a.matches[a.matches.length-1];return i.route.id||we(!1),i.route.id}t.startTransition;function Rt(e){we(!1)}function St(t){var a=t.basename,i=void 0===a?"/":a,n=t.children,o=void 0===n?null:n,s=t.location,r=t.navigationType,c=void 0===r?se.Pop:r,l=t.navigator,d=t.static,u=void 0!==d&&d;rt()&&we(!1);var h=i.replace(/^\/*/,"/"),m=e.useMemo((function(){return{basename:h,navigator:l,static:u}}),[h,l,u]);"string"===typeof s&&(s=Te(s));var p=s,f=p.pathname,g=void 0===f?"/":f,b=p.search,v=void 0===b?"":b,y=p.hash,w=void 0===y?"":y,D=p.state,A=void 0===D?null:D,R=p.key,S=void 0===R?"default":R,T=e.useMemo((function(){var e=je(g,h);return null==e?null:{location:{pathname:e,search:v,hash:w,state:A,key:S},navigationType:c}}),[h,g,v,w,A,S,c]);return null==T?null:e.createElement(it.Provider,{value:m},e.createElement(nt.Provider,{children:o,value:T}))}function Tt(e){var t=e.children,a=e.location;return ht(kt(t),a)}var Ct=function(e){return e[e.pending=0]="pending",e[e.success=1]="success",e[e.error=2]="error",e}(Ct||{}),Et=new Promise((function(){}));e.Component;function kt(t,a){void 0===a&&(a=[]);var i=[];return e.Children.forEach(t,(function(t,n){if(e.isValidElement(t)){var o=[].concat(pe(a),[n]);if(t.type!==e.Fragment){t.type!==Rt&&we(!1),t.props.index&&t.props.children&&we(!1);var s={id:t.props.id||o.join("-"),caseSensitive:t.props.caseSensitive,element:t.props.element,Component:t.props.Component,index:t.props.index,path:t.props.path,loader:t.props.loader,action:t.props.action,errorElement:t.props.errorElement,ErrorBoundary:t.props.ErrorBoundary,hasErrorBoundary:null!=t.props.ErrorBoundary||null!=t.props.errorElement,shouldRevalidate:t.props.shouldRevalidate,handle:t.props.handle,lazy:t.props.lazy};t.props.children&&(s.children=kt(t.props.children,o)),i.push(s)}else i.push.apply(i,kt(t.props.children,o))}})),i}function It(){return It=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var a=arguments[t];for(var i in a)Object.prototype.hasOwnProperty.call(a,i)&&(e[i]=a[i])}return e},It.apply(this,arguments)}function Mt(e,t){if(null==e)return{};var a,i,n={},o=Object.keys(e);for(i=0;i<o.length;i++)a=o[i],t.indexOf(a)>=0||(n[a]=e[a]);return n}new Set(["application/x-www-form-urlencoded","multipart/form-data","text/plain"]);var Ot=["onClick","relative","reloadDocument","replace","state","target","to","preventScrollReset"],Lt=["aria-current","caseSensitive","className","end","style","to","children"];var xt=t.startTransition;function Pt(t){var a,i=t.basename,n=t.children,o=t.future,s=t.window,r=e.useRef();null==r.current&&(r.current=(void 0===(a={window:s,v5Compat:!0})&&(a={}),Ce((function(e,t){var a=e.location;return Re("",{pathname:a.pathname,search:a.search,hash:a.hash},t.state&&t.state.usr||null,t.state&&t.state.key||"default")}),(function(e,t){return"string"===typeof t?t:Se(t)}),null,a)));var c=r.current,l=he(e.useState({action:c.action,location:c.location}),2),d=l[0],u=l[1],h=(o||{}).v7_startTransition,m=e.useCallback((function(e){h&&xt?xt((function(){return u(e)})):u(e)}),[u,h]);return e.useLayoutEffect((function(){return c.listen(m)}),[c,m]),e.createElement(St,{basename:i,children:n,location:d.location,navigationType:d.action,navigator:c})}var Bt="undefined"!==typeof window&&"undefined"!==typeof window.document&&"undefined"!==typeof window.document.createElement,Nt=/^(?:[a-z][a-z0-9+.-]*:|\/\/)/i,_t=e.forwardRef((function(t,a){var i,n=t.onClick,o=t.relative,s=t.reloadDocument,r=t.replace,c=t.state,l=t.target,d=t.to,u=t.preventScrollReset,h=Mt(t,Ot),m=e.useContext(it).basename,p=!1;if("string"===typeof d&&Nt.test(d)&&(i=d,Bt))try{var f=new URL(window.location.href),g=d.startsWith("//")?new URL(f.protocol+d):new URL(d),b=je(g.pathname,m);g.origin===f.origin&&null!=b?d=b+g.search+g.hash:p=!0}catch(w){}var v=function(t,a){var i=(void 0===a?{}:a).relative;rt()||we(!1);var n=e.useContext(it),o=n.basename,s=n.navigator,r=ut(t,{relative:i}),c=r.hash,l=r.pathname,d=r.search,u=l;return"/"!==o&&(u="/"===l?o:He([o,l])),s.createHref({pathname:u,search:d,hash:c})}(d,{relative:o}),y=function(t,a){var i=void 0===a?{}:a,n=i.target,o=i.replace,s=i.state,r=i.preventScrollReset,c=i.relative,l=dt(),d=ct(),u=ut(t,{relative:c});return e.useCallback((function(e){if(function(e,t){return 0===e.button&&(!t||"_self"===t)&&!function(e){return!!(e.metaKey||e.altKey||e.ctrlKey||e.shiftKey)}(e)}(e,n)){e.preventDefault();var a=void 0!==o?o:Se(d)===Se(u);l(t,{replace:a,state:s,preventScrollReset:r,relative:c})}}),[d,l,u,o,s,n,t,r,c])}(d,{replace:r,state:c,target:l,preventScrollReset:u,relative:o});return e.createElement("a",It({},h,{href:i||v,onClick:p||s?n:function(e){n&&n(e),e.defaultPrevented||y(e)},ref:a,target:l}))}));var Vt=e.forwardRef((function(t,a){var i=t["aria-current"],n=void 0===i?"page":i,o=t.caseSensitive,s=void 0!==o&&o,r=t.className,c=void 0===r?"":r,l=t.end,d=void 0!==l&&l,u=t.style,h=t.to,m=t.children,p=Mt(t,Lt),f=ut(h,{relative:p.relative}),g=ct(),b=e.useContext(tt),v=e.useContext(it).navigator,y=v.encodeLocation?v.encodeLocation(f).pathname:f.pathname,w=g.pathname,D=b&&b.navigation&&b.navigation.location?b.navigation.location.pathname:null;s||(w=w.toLowerCase(),D=D?D.toLowerCase():null,y=y.toLowerCase());var A,R=w===y||!d&&w.startsWith(y)&&"/"===w.charAt(y.length),S=null!=D&&(D===y||!d&&D.startsWith(y)&&"/"===D.charAt(y.length)),T=R?n:void 0;A="function"===typeof c?c({isActive:R,isPending:S}):[c,R?"active":null,S?"pending":null].filter(Boolean).join(" ");var C="function"===typeof u?u({isActive:R,isPending:S}):u;return e.createElement(_t,It({},p,{"aria-current":T,className:A,ref:a,style:C,to:h}),"function"===typeof m?m({isActive:R,isPending:S}):m)}));var Wt,Ft;(function(e){e.UseScrollRestoration="useScrollRestoration",e.UseSubmit="useSubmit",e.UseSubmitFetcher="useSubmitFetcher",e.UseFetcher="useFetcher"})(Wt||(Wt={})),function(e){e.UseFetchers="useFetchers",e.UseScrollRestoration="useScrollRestoration"}(Ft||(Ft={}));var jt=a.p+"static/media/scinext-logo.116c277c1591fdd737ee.png",Ut=a(184),zt=function(t){d(i,t);var a=p(i);function i(){return n(this,i),a.apply(this,arguments)}return c(i,[{key:"render",value:function(){return(0,Ut.jsx)(e.Fragment,{children:(0,Ut.jsx)(N,{children:(0,Ut.jsx)(K,{children:(0,Ut.jsx)("header",{children:(0,Ut.jsxs)(ee,{className:"header-navbar",light:!0,expand:"md",children:[(0,Ut.jsxs)(re,{href:"/",children:[(0,Ut.jsx)("img",{id:"scinext-logo",src:jt,alt:"SCINEXT Logo"}),(0,Ut.jsx)("img",{id:"orkg-logo",src:"data:image/png;base64,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",alt:"ORKG Logo"})]}),(0,Ut.jsxs)("nav",{children:[(0,Ut.jsx)(Vt,{className:"navlink",to:"/r0-estimates",children:"R0 Estimates"}),(0,Ut.jsx)(Vt,{className:"navlink",to:"/sota",children:"SOTA"})]})]})})})})})}}]),i}(e.Component),Gt=zt,Ht=function(t){d(i,t);var a=p(i);function i(){return n(this,i),a.apply(this,arguments)}return c(i,[{key:"render",value:function(){return(0,Ut.jsx)(e.Fragment,{children:(0,Ut.jsx)(N,{children:(0,Ut.jsx)(K,{children:(0,Ut.jsx)("footer",{className:"footer",children:(0,Ut.jsxs)("p",{className:"footer-content",children:["\xa9 ",(new Date).getFullYear()," SCINEXT - Neural-Symbolic SCholarly InnovatioN EXTraction"]})})})})})}}]),i}(e.Component),qt=Ht,Kt=function(e){d(a,e);var t=p(a);function a(){return n(this,a),t.apply(this,arguments)}return c(a,[{key:"render",value:function(){return(0,Ut.jsxs)("div",{className:"intro-div",children:[(0,Ut.jsxs)("h5",{children:["Neural-Symbolic ",(0,Ut.jsx)("u",{children:"SC"}),"holarly ",(0,Ut.jsx)("u",{children:"I"}),"nnovatio",(0,Ut.jsx)("u",{children:"N"})," ",(0,Ut.jsx)("u",{children:"EXT"}),"raction"]}),(0,Ut.jsxs)("p",{children:[(0,Ut.jsx)("a",{href:"https://sites.google.com/view/jen-web",target:"_blank",rel:"noreferrer",className:"external-link-new-window",children:"Dr. Jennifer D'Souza"}),", a postdoc in the ",(0,Ut.jsx)("a",{href:"https://www.tib.eu/en/research-development/research-groups-and-labs/data-science-digital-libraries",target:"_blank",rel:"noreferrer",className:"external-link-new-window",children:"Data Science and Digital Libraries Department"})," at ",(0,Ut.jsx)("a",{href:"https://www.tib.eu/en/",target:"_blank",rel:"noreferrer",className:"external-link-new-window",children:"TIB"}),' who currently leads the NLP development related to the ORKG has been awarded the BMBF grant for her project proposal "SciNEXT - Neural-Symbolic ',(0,Ut.jsx)("u",{children:"SC"}),"holarly ",(0,Ut.jsx)("u",{children:"I"}),"nnovatio",(0,Ut.jsx)("u",{children:"N"})," ",(0,Ut.jsx)("u",{children:"EXT"}),"raction\". The project will be conducted in the context of the larger Open Research Knowledge Graph project and will be located at the TIB's Data Science and Digital Libraries Department. "]}),(0,Ut.jsx)("h5",{children:"Objectives"}),(0,Ut.jsxs)("p",{children:["The SCINEXT research group aims to set up an AI ecosphere of Neural-Symbolic ",(0,Ut.jsx)("u",{children:"SC"}),"holarly ",(0,Ut.jsx)("u",{children:"I"}),"nnovatio",(0,Ut.jsx)("u",{children:"N"})," ",(0,Ut.jsx)("u",{children:"EXT"}),"raction services of templated, machine-interpretable scientific findings as a Knowledge Graph (KG) in the ORKG. Information on innovations buried in text-based discourse will be automatically extracted as machine-actionable resources, for reuse in novel downstream information technology (IT) applications, e.g. automated comparisons of the state-of-the-art, intuitive research visualization, and question answering. To this end, the SCINEXT AI workload will comprise expert-sourced symbolic templated constructs of scientific findings as extraction targets. E.g., task, dataset, metric, and score template for computer science model leaderboards; basic reproduction number, confidence interval (95%), location, and time period template for Covid-19 reproductive number in epidemiology. The SCINEXT project will implement a series of learners that will combine traditional rules-based AI approaches with modern deep learning techniques that will be selectively applied for highly automated extraction of templated knowledge standardizing the annotation of complex ontologized relationships in a KG, leading to reusable and machine-interpretable knowledge of innovations. The project will create new theoretical foundations in the field of neural-symbolic AI while realizing concretely usable results with direct added value for stakeholders in academia and industry. A conceptual overview of the project is provided in the Figure below."]}),(0,Ut.jsx)("p",{align:"center",className:"scinext_img",children:(0,Ut.jsx)("img",{src:"https://orkg.org/strapi/uploads/concept_ede6097820.png",alt:"SCINEXT"})}),(0,Ut.jsx)("h5",{children:"Management"}),(0,Ut.jsx)("p",{children:"Dr. Jennifer D'Souza"}),(0,Ut.jsx)("h5",{children:"Senior Advisor"}),(0,Ut.jsx)("p",{children:"Prof. Dr. S\xf6ren Auer"}),(0,Ut.jsx)("h5",{children:"Team"}),(0,Ut.jsx)("p",{children:"Julia Evans, Mahsa Shamsabadi, Hamed Babaei Giglou"}),(0,Ut.jsx)("h5",{children:"Funding"}),(0,Ut.jsxs)("p",{children:["Federal Ministry of Education and Research (BMBF) Grant",(0,Ut.jsx)("br",{}),"F\xf6derkennzeichen: 01lS22070"]}),(0,Ut.jsx)("h5",{children:"Duration"}),(0,Ut.jsx)("p",{children:"1 August 2022 \u2013 31 July 2025"})]})}}]),a}(e.Component),Qt=Kt,Jt=function(e){d(a,e);var t=p(a);function a(){return n(this,a),t.apply(this,arguments)}return c(a,[{key:"render",value:function(){return(0,Ut.jsx)(Ut.Fragment,{children:(0,Ut.jsx)(Qt,{})})}}]),a}(e.Component),Yt=Jt,Xt={color:void 0,size:void 0,className:void 0,style:void 0,attr:void 0},Zt=e.createContext&&e.createContext(Xt),$t=function(){return $t=Object.assign||function(e){for(var t,a=1,i=arguments.length;a<i;a++)for(var n in t=arguments[a])Object.prototype.hasOwnProperty.call(t,n)&&(e[n]=t[n]);return e},$t.apply(this,arguments)},ea=function(e,t){var a={};for(var i in e)Object.prototype.hasOwnProperty.call(e,i)&&t.indexOf(i)<0&&(a[i]=e[i]);if(null!=e&&"function"===typeof Object.getOwnPropertySymbols){var n=0;for(i=Object.getOwnPropertySymbols(e);n<i.length;n++)t.indexOf(i[n])<0&&Object.prototype.propertyIsEnumerable.call(e,i[n])&&(a[i[n]]=e[i[n]])}return a};function ta(t){return t&&t.map((function(t,a){return e.createElement(t.tag,$t({key:a},t.attr),ta(t.child))}))}function aa(t){return function(a){return e.createElement(ia,$t({attr:$t({},t.attr)},a),ta(t.child))}}function ia(t){var a=function(a){var i,n=t.attr,o=t.size,s=t.title,r=ea(t,["attr","size","title"]),c=o||a.size||"1em";return a.className&&(i=a.className),t.className&&(i=(i?i+" ":"")+t.className),e.createElement("svg",$t({stroke:"currentColor",fill:"currentColor",strokeWidth:"0"},a.attr,n,r,{className:i,style:$t($t({color:t.color||a.color},a.style),t.style),height:c,width:c,xmlns:"http://www.w3.org/2000/svg"}),s&&e.createElement("title",null,s),t.children)};return void 0!==Zt?e.createElement(Zt.Consumer,null,(function(e){return a(e)})):a(Xt)}function na(e){return aa({tag:"svg",attr:{viewBox:"0 0 512 512"},child:[{tag:"path",attr:{d:"M370.72 133.28C339.458 104.008 298.888 87.962 255.848 88c-77.458.068-144.328 53.178-162.791 126.85-1.344 5.363-6.122 9.15-11.651 9.15H24.103c-7.498 0-13.194-6.807-11.807-14.176C33.933 94.924 134.813 8 256 8c66.448 0 126.791 26.136 171.315 68.685L463.03 40.97C478.149 25.851 504 36.559 504 57.941V192c0 13.255-10.745 24-24 24H345.941c-21.382 0-32.09-25.851-16.971-40.971l41.75-41.749zM32 296h134.059c21.382 0 32.09 25.851 16.971 40.971l-41.75 41.75c31.262 29.273 71.835 45.319 114.876 45.28 77.418-.07 144.315-53.144 162.787-126.849 1.344-5.363 6.122-9.15 11.651-9.15h57.304c7.498 0 13.194 6.807 11.807 14.176C478.067 417.076 377.187 504 256 504c-66.448 0-126.791-26.136-171.315-68.685L48.97 471.03C33.851 486.149 8 475.441 8 454.059V320c0-13.255 10.745-24 24-24z"}}]})(e)}var oa=function(e){d(a,e);var t=p(a);function a(){return n(this,a),t.apply(this,arguments)}return c(a,[{key:"render",value:function(){return(0,Ut.jsx)("div",{className:"abstract-div",children:(0,Ut.jsxs)(N,{className:"abstract-row1",children:[(0,Ut.jsx)(K,{sm:"10",md:{size:10,offset:0},children:(0,Ut.jsxs)("div",{className:"abstract-text",children:[(0,Ut.jsx)("h5",{children:this.props.title}),(0,Ut.jsx)("p",{children:this.props.abstract})]})}),(0,Ut.jsx)(K,{sm:"2",md:{size:2,offset:0},className:"d-flex align-items-center",children:(0,Ut.jsx)("button",{id:"refresh-button",className:"button refresh-button",onClick:this.props.onClick,children:(0,Ut.jsx)(na,{})})})]})})}}]),a}(e.Component),sa=oa,ra=function(e){d(a,e);var t=p(a);function a(){return n(this,a),t.apply(this,arguments)}return c(a,[{key:"render",value:function(){return(0,Ut.jsx)("div",{className:"content",children:(0,Ut.jsx)("pre",{children:JSON.stringify(this.props.value,null,2)})},this.props.id)}}]),a}(e.Component),ca=ra,la=function(e){d(a,e);var t=p(a);function a(){return n(this,a),t.apply(this,arguments)}return c(a,[{key:"render",value:function(){var e="";if("unanswerable"!==this.props.label)try{e=JSON.parse(this.props.label).map((function(e,t){return(0,Ut.jsx)(ca,{id:"label "+t,value:e},"label "+t)}))}catch(a){e=(0,Ut.jsx)(ca,{id:"label",value:this.props.label},"label")}else e=(0,Ut.jsx)(ca,{id:"label",value:{}},"label");var t="";if("unanswerable"!==this.props.prediction)try{t=JSON.parse(this.props.prediction).map((function(e,t){return(0,Ut.jsx)(ca,{id:"prediction "+t,value:e},"prediction "+t)}))}catch(a){t=(0,Ut.jsx)(ca,{id:"prediction",value:this.props.prediction},"prediction")}else t=(0,Ut.jsx)(ca,{id:"prediction",value:{}},"prediction");return(0,Ut.jsxs)("div",{className:"result-div",children:[(0,Ut.jsxs)(N,{children:[(0,Ut.jsx)(K,{xs:"6",children:(0,Ut.jsx)("div",{className:"center-heading",children:(0,Ut.jsx)("h5",{children:this.props.label_heading})})}),(0,Ut.jsx)(K,{xs:"6",children:(0,Ut.jsx)("div",{className:"center-heading",children:(0,Ut.jsx)("h5",{children:this.props.prediction_heading})})})]}),(0,Ut.jsxs)(N,{children:[(0,Ut.jsx)(K,{xs:"6",children:(0,Ut.jsx)("div",{className:"label-div",children:e})}),(0,Ut.jsx)(K,{xs:"6",children:(0,Ut.jsx)("div",{className:"label-div",children:t})})]})]})}}]),a}(e.Component),da=la,ua=function(e){d(a,e);var t=p(a);function a(){return n(this,a),t.apply(this,arguments)}return c(a,[{key:"render",value:function(){return(0,Ut.jsxs)("div",{className:"description-div",children:[(0,Ut.jsx)("h5",{children:"Complex Structured Scientific Information Extraction Demo"}),(0,Ut.jsx)("p",{children:"The Information Extraction (IE) task addressed is Extracting the Reproduction Number (R0) estimate structured scholarly contributions for Infectious Diseases. All extractions are exactly as output by the FLAN-T5-Large (780M) Large Language Model (LLM) and entries were not seen during training."})]})}}]),a}(e.Component),ha=ua,ma=JSON.parse('{"h":[{"main_cord_uid":"85chebix","cord_uid":"85chebix","abstract":"Background: COVID-19 has emerged and spread at great speed globally and has presented one of the greatest public health challenges in modern times with no proven cure or vac-cine. Africa is still early in this epidemic, therefore the spectrum of disease severity is not yet clear. Methods: We used a mathematical model to fit to the observed cases of COVID-19 in South Africa to estimate the basic reproductive number and critical vaccination coverages to con-trol the disease for different hypothetical vaccine efficacy scenarios. We also estimated the percentage reduction in effective contacts due to the social distancing measures imple-mented. Results: Early model estimates show that COVID-19 outbreak in South Africa had a basic reproductive number of 2.95 (95% credible interval [CrI] 2.83-3.33). A vaccine with 70% effi-cacy had the capacity to contain COVID-19 outbreak but at very higher vaccination cover-age 94.44% (95% Crl 92.44-99.92%) with a vaccine of 100% efficacy requiring 66.10% (95% Crl 64.72-69.95%) coverage. Social distancing measures put in place have so far reduced the number of social contacts by 80.31% (95% Crl 79.76-80.85%). Conclusions: Findings suggest a highly efficacious vaccine would have been required to con-tain COVID-19 in South Africa. Therefore, the current social distancing measures to reduce contacts will remain key in controlling the infection in the absence of vaccines and other therapeutics.","title":"Quantifying early COVID-19 outbreak transmission in South Africa and exploring vaccine efficacy scenarios","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: South Africa\\r\\ndate: -\\r\\nR0 value: 2.95\\r\\n%CI values: (95% credible interval [CrI] 2.83-3.33)\\r\\nmethod: mathematical model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"South Africa\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"2.95\\",\\r\\n\\"%CI values\\": \\"(95% credible interval [CrI] 2.83-3.33)\\",\\r\\n\\"method\\": \\"mathematical model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"2.95\\", \\"%CI values\\": \\"(95% credible interval [CrI] 2.83-3.33)\\", \\"method\\": \\"mathematical model\\" } } ]","publish_time":"2020-04-29 10:00:00"},{"main_cord_uid":"4r9vb7ub","cord_uid":"4r9vb7ub","abstract":"Background COVID-19 continues to impose significant morbidity and mortality in Japan even after implementing the vaccination program. It would remain elusive if restrictions for its mitigation were to be lifted or relaxed in the future. Methods A simulation study that explored possible vaccination coverage scenarios and changes in the intensity of nonpharmaceutical intervention restrictions was performed to assess the impact of COVID-19 based on death count. Results Assuming the basic reproduction number of circulating viruses was 5.0, vaccines could prevent 90% of infections and 95% of deaths, and the vaccination coverage rate was high (75%, 80%, and 90% in people aged 12-39 years, 40-59 years, \xc3\xa2\xe2\u20ac\xb0\xc2\xa560 years, respectively), approximately 50 000 deaths would occur over 150 days in Japan if all restrictions were lifted. Most deaths would occur among older adults, even if their vaccination coverage was assumed to be especially high. A low vaccination coverage scenario (45%, 60%, and 80% in people aged 12-39 years, 40-59 years, \xc3\xa2\xe2\u20ac\xb0\xc2\xa560 years, respectively) would require periodic implementation of strict measures even if the modified lifestyle observed in 2020 was sustained and vaccines were very effective. Some restrictions could be relaxed under high vaccination coverage. However, in the worst-case scenario where vaccines had decreased efficacy, as we have observed for the Delta variant, and people lived a relaxed lifestyle, our simulation suggests that even high vaccination coverage would occasionally require strict measures. Conclusions We should carefully explore a manageable degree of restrictions and their relaxation. We will have to keep bracing for occasional surges of COVID-19 infection, which could lead to strict measures, such as those under a state of emergency. Such strategies are essential even after a wide rollout of vaccination.","title":"Simulation of future COVID-19 epidemic by vaccination coverage scenarios in Japan","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"l60snfap","cord_uid":"l60snfap","abstract":"Between April 2012 and June 2014, 820 laboratory-confirmed cases of the Middle East respiratory syndrome coronavirus (MERS-CoV) have been reported in the Arabian Peninsula, Europe, North Africa, Southeast Asia, the Middle East, and the United States. The observed epidemiology is different to SARS, which showed a classic epidemic curve and was over in eight months. The much longer persistence of MERS-CoV in the population, with a lower reproductive number, some evidence of human-to-human transmission but an otherwise sporadic pattern, is difficult to explain. Using available epidemiological data, we implemented mathematical models to explore the transmission dynamics of MERS-CoV in the context of mass gatherings such as the Hajj pilgrimage, and found a discrepancy between the observed and expected epidemiology. The fact that no epidemic occurred in returning Hajj pilgrims in either 2012 or 2013 contradicts the long persistence of the virus in human populations. The explanations for this discrepancy include an ongoing, repeated nonhuman/sporadic source, a large proportion of undetected or unreported human-to-human cases, or a combination of the two. Furthermore, MERS-CoV is occurring in a region that is a major global transport hub and hosts significant mass gatherings, making it imperative to understand the source and means of the yet unexplained and puzzling ongoing persistence of the virus in the human population.","title":"A Scenario-Based Evaluation of the Middle East Respiratory Syndrome Coronavirus and the Hajj","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2014-01-01 00:00:00"},{"main_cord_uid":"b2yalnrx","cord_uid":"b2yalnrx","abstract":"This paper presents a simple mathematical model that answers how much testing and tracing we need to do to suppress new surges of COVID-19 infections after reopening. We derived the model by modifying the SEIR model taking into the effects of testing and tracing. The following equation is one of the essential outcomes of the model: {rho}>(R0S/N-1)/(D(1+{eta}R0)) Where {rho} is the percentage of infectious people that have to be detected per day, R0 is the basic reproduction number, S/N is the percentage of the susceptible population over the entire population, D is the length of the infectious period, and {eta} is the percentage of close contacts that have to be traced. If the above equation is satisfied, we can bring the effective reproduction number Re to below 1 to get the transmission suppressed. This model demonstrates that together with social-distancing measures such as wearing masks in public, with a reasonable amount of testing and tracing, we may suppress the COVID-19 transmission for good. For example, if social distancing measures can bring R0 to below 1.2, for D being 10 days, in places where 15% people have developed antibodies, we can suppress the transmission by detecting only 0.13% of the infectious population daily while tracing 50% of their close contacts. The model provides intuitive insights and quantitative guidance for policymakers and public health practitioners to deploy the testing and tracing resources optimally.","title":"A Model for the Testing and Tracing Needed to Suppress COVID-19","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-06-05 10:00:00"},{"main_cord_uid":"mnrxtd7j","cord_uid":"mnrxtd7j","abstract":"The spread of epidemics has been extensively investigated using susceptible-exposed infectious-recovered-susceptible (SEIRS) models. In this work, we propose a SEIRS pandemic model with infection forces and intervention strategies. The proposed model is characterized by a stochastic differential equation (SDE) framework with arbitrary parameter settings. Based on a Markov semigroup hypothesis, we demonstrate the effect of the proliferation number R(0)(S) on the SDE solution. On the one hand, when R(0)(S) < 1, the SDE has an illness-free solution set under gentle additional conditions. This implies that the epidemic can be eliminated with a likelihood of 1. On the other hand, when R(0)(S) > 1, the SDE has an endemic stationary circulation under mild additional conditions. This prompts the stochastic regeneration of the epidemic. Also, we show that arbitrary fluctuations can reduce the infection outbreak. Hence, valuable procedures can be created to manage and control epidemics.","title":"A Stochastic SEIRS Epidemic Model with Infection Forces and Intervention Strategies","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2022-01-10 00:00:00"},{"main_cord_uid":"edwtagu1","cord_uid":"edwtagu1","abstract":"COVID-19 has globally spread to over 4 million people and the epidemic situation in Japan is very serious. The purpose of this research was to assess the risk of COVID-19 epidemic dissemination in Japan by estimating the current state of epidemic dissemination and providing some epidemic prevention and control recommendations. Firstly, the period from 6 January to 31 March 2020 was divided into four stages and the relevant parameters were estimated according to the imported cases in Japan. The basic reproduction number of the current stage is 1.954 (95% confidence interval (CI) 1.851-2.025), which means COVID-19 will spread quickly, and the self-healing rate of Japanese is about 0.495 (95% CI 0.437-0.506), with small variations in the four stages. Secondly, the results were applied to the actual reported cases from 1 to 5 April 2020, verifying the reliability of the estimated data using the accumulated reported cases located within the 95% confidence interval and the relative error of forecast data of five days being less than 2 . 5 % . Thirdly, considering the medical resources in Japan, the times the epidemic beds and ventilators become fully occupied are predicted as 5 and 15 May 2020, respectively. Keeping with the current situation, the final death toll in Japan may reach into the millions. Finally, based on experience with COVID-19 prevention and control in China, robust measures such as nationwide shutdown, store closures, citizens isolating themselves at home, and increasing PCR testing would quickly and effectively prevent COVID-19 spread.","title":"Forecast Possible Risk for COVID-19 Epidemic Dissemination Under Current Control Strategies in Japan","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Japan\\r\\ndate: 6 January to 31 March 2020\\r\\nR0 value: 1.954\\r\\n%CI values: 95% confidence interval (CI) 1.851-2.025\\r\\nmethod: estimating the current state of epidemic dissemination","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Japan\\",\\r\\n\\"date\\": \\"6 January to 31 March 2020\\",\\r\\n\\"R0 value\\": \\"1.954\\",\\r\\n\\"%CI values\\": \\"95% confidence interval (CI) 1.851-2.025\\",\\r\\n\\"method\\": \\"estimating the current state of epidemic dissemination\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Japan\\", \\"date\\": \\"6 January to 31 March 2020\\", \\"R0 value\\": \\"1.954\\", \\"%CI values\\": \\"(95% confidence interval (CI) 1.851-2.025)\\", \\"method\\": \\"-\\" } } ]","publish_time":"2020"},{"main_cord_uid":"ssrainqk","cord_uid":"ssrainqk","abstract":"The first case of coronavirus disease 2019 (COVID-19) in Algeria was reported on 25 February 2020. Since then, it has progressed rapidly and the number of cases grow exponentially each day. In this article, we utilize SEIR modelling to forecast COVID-19 outbreak in Algeria under two scenarios by using the real-time data from March 01 to April 10, 2020. In the first scenario: no control measures are put into place, we estimate that the basic reproduction number for the epidemic in Algeria is 2.1, the number of new cases in Algeria will peak from around late May to early June and up to 82% of the Algerian population will likely contract the coronavirus. In the second scenario, at a certain date T, drastic control measures are taken, people are being advised to self-isolate or to quarantine and will be able to leave their homes only if necessary. We use SEIR model with fast change between fully protected and risky states. We prove that the final size of the epidemic depends strongly on the cumulative number of cases at the date when we implement intervention and on the fraction of the population in confinement. Our analysis shows that the longer we wait, the worse the situation will be and this very quickly produces.","title":"Prediction of confinement effects on the number of Covid-19 outbreak in Algeria","annotator_investigating_R0":"1","text_response":"disease name: Covid-19\\r\\nlocation: Algeria\\r\\ndate: March 01 to April 10, 2020\\r\\nR0 value: 2.1\\r\\n%CI values: -\\r\\nmethod: SEIR modelling","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"Algeria\\",\\r\\n\\"date\\": \\"March 01 to April 10, 2020\\",\\r\\n\\"R0 value\\": \\"2.1\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SEIR modelling\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease 2019 (COVID-19)\\", \\"location\\": \\"Algeria\\", \\"date\\": \\"March 01 to April 10, 2020\\", \\"R0 value\\": \\"2.1\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SEIR modelling\\" } } ]","publish_time":"2020"},{"main_cord_uid":"j8019gin","cord_uid":"j8019gin","abstract":"As the SARS-CoV-2 pandemic continues its rapid global spread, quantification of local transmission patterns has been, and will continue to be, critical for guiding pandemic response. Understanding the accuracy and limitations of statistical methods to estimate the reproduction number, R0, in the context of emerging epidemics is therefore vital to ensure appropriate interpretation of results and the subsequent implications for control efforts. Using simulated epidemic data we assess the performance of 6 commonly-used statistical methods to estimate R0 as they would be applied in a real-time outbreak analysis scenario - fitting to an increasing number of data points over time and with varying levels of random noise in the data. Method comparison was also conducted on empirical outbreak data, using Zika surveillance data from the 2015-2016 epidemic in Latin America and the Caribbean. We find that all methods considered here frequently over-estimate R0 in the early stages of epidemic growth on simulated data, the magnitude of which decreases when fitted to an increasing number of time points. This trend of decreasing bias over time can easily lead to incorrect conclusions about the course of the epidemic or the need for control efforts. We show that true changes in pathogen transmissibility can be difficult to disentangle from changes in methodological accuracy and precision, particularly for data with significant over-dispersion. As localised epidemics of SARS-CoV-2 take hold around the globe, awareness of this trend will be important for appropriately cautious interpretation of results and subsequent guidance for control efforts.","title":"A comparative analysis of statistical methods to estimate the reproduction number in emerging epidemics with implications for the current COVID-19 pandemic","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-05-16 10:00:00"},{"main_cord_uid":"vd8zhp77","cord_uid":"vd8zhp77","abstract":"BACKGROUND: Undifferentiated carcinoma with osteoclast-like giant cells (UCOGCs) is a rare subtype of pancreatic cancer (PC), and its clinicopathological characteristics are still unclear. Herein, we report a case of initially unresectable UCOGC that was successfully resected after FOLFIRINOX therapy. CASE PRESENTATION: A 63-year-old man was referred to us for evaluation of a pancreatic mass detected by computed tomography (CT) during a medical checkup. Computed tomography showed a 7.5-cm tumor located in the pancreatic head and body, which involved the common hepatic artery (CHA), gastroduodenal artery (GDA), and main portal vein (PV) with tumor thrombus. UCOGC was suspected by endoscopic ultrasonography-guided fine needle aspiration, and the patient was diagnosed with unresectable locally advanced pancreatic cancer. After ten cycles of FOLFIRINOX, the tumor size decreased to 3 cm and the tumor thrombus in the main portal trunk had disappeared in the follow-up CT scan. However, the patient experienced severe adverse drug reactions, including neutropenia and liver dysfunction. Therefore, we performed pancreatoduodenectomy with portal vein resection. The pathological diagnosis was UCOGC with a negative tumor margin. He was treated with FOLFIRINOX, and remains recurrence-free for 6 months after surgery. CONCLUSIONS: We experienced a case undergoing conversion surgery for unresectable UCOGC, which resulted in R0 resection. FOLFIRINOX could be a possible regimen to achieve conversion surgery for UCOGC.","title":"Conversion surgery for undifferentiated carcinoma with osteoclast-like giant cells of the pancreas: a case report","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2022"},{"main_cord_uid":"cm4hhfvk","cord_uid":"cm4hhfvk","abstract":"COVID-19 is reported to have been brought under control in China. To understand the COVID-19 outbreak in China and provide potential lessons for other parts of the world, in this study we apply a mathematical model with multiple datasets to estimate the transmissibility of the SARS-CoV-2 virus and the severity of the illness associated with the infection, and how both were affected by unprecedented control measures. Our analyses show that before 19th January 2020, 3.5% (95% CI 1.7-8.3%) of infected people were detected; this percentage increased to 36.6% (95% CI 26.1-55.4%) thereafter. The basic reproduction number (R0) was 2.33 (95% CI 1.96-3.69) before 8th February 2020; then the effective reproduction number dropped to 0.04(95% CI 0.01-0.10). This estimation also indicates that control measures taken since 23rd January 2020 affected the transmissibility about 2 weeks after they were introduced. The confirmed case fatality rate is estimated at 9.6% (95% CI 8.1-11.4%) before 15 February 2020, and then it reduced to 0.7% (95% CI 0.4-1.0%). This shows that SARS-CoV-2 virus is highly transmissible but may be less severe than SARS-CoV-1 and MERS-CoV. We found that at the early stage, the majority of R0 comes from undetected infectious people. This implies that successful control in China was achieved through reducing the contact rates among people in the general population and increasing the rate of detection and quarantine of the infectious cases.","title":"Transmission dynamics and control measures of COVID-19 outbreak in China: a modelling study","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: China\\r\\ndate: before 8th February 2020\\r\\nR0 value: 2.33\\r\\n%CI values: 95% CI 1.96-3.69\\r\\nmethod: Mathematical Model with Multiple Datasets","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"China\\",\\r\\n\\"date\\": \\"before 8th February 2020\\",\\r\\n\\"R0 value\\": \\"2.33\\",\\r\\n\\"%CI values\\": \\"95% CI 1.96-3.69\\",\\r\\n\\"method\\": \\"Mathematical Model with Multiple Datasets\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"China\\", \\"date\\": \\"before 8th February 2020\\", \\"R0 value\\": \\"2.33\\", \\"%CI values\\": \\"(95% CI 1.96-3.69)\\", \\"method\\": \\"mathematical model with multiple datasets\\" } } ]","publish_time":"2021"},{"main_cord_uid":"zq1pvawa","cord_uid":"zq1pvawa","abstract":"In this paper, a SIRD model is adapted to study the vaccine\'s impact on the spread of coronavirus (COVID19) spread in Lebanon. To describe the epidemic development across the country, a Kalman filter is integrated with the SIRD model in order to estimate the time-varying reproduction number R-t - is the most important indicator that predicts the severity of an epidemic outbreak. R-t denotes the number of healthy persons to whom an infected person can spread the disease. The results show a reduction in the spread of the pandemic after employing the vaccine. All the data and relevant codebase are available at https://www.moph.gov.lb","title":"Tracking R-t of COVID-19 Vaccine Effectiveness Using Kalman Filter and SIRD Model","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"abpp98cz","cord_uid":"abpp98cz","abstract":"Covid-19 poses significant risk of nosocomial transmission, and preventing this requires good estimates of the basic reproduction number R0 in hospitals and care facilities, but these are currently lacking. Such estimates are challenging due to small population sizes in these facilities and inconsistent testing practices. We estimate the patient-to-patient R0 and daily transmission rate of SARS-CoV-2 using data from a closely monitored hospital outbreak in Paris 2020 during the first wave. We use a realistic epidemic model which accounts for progressive stages of infection, stochastic effects and a large proportion of asymptomatic infections. Innovatively, we explicitly include changes in testing capacity over time, as well as the evolving sensitivity of PCR testing at different stages of infection. We conduct rigorous statistical inference using iterative particle filtering to fit the model to the observed patient data and validate this methodology using simulation. We provide estimates for R0 across the entire hospital (2.6) and in individual wards (from 3 to 15), possibly reflecting heterogeneity in contact patterns or control measures. An obligatory mask-wearing policy introduced during the outbreak is likely to have changed the R0, and we estimate values before (8.7) and after (1.3) its introduction, corresponding to a policy efficacy of 85%.","title":"How well does SARS-CoV-2 spread in hospitals?","annotator_investigating_R0":"1","text_response":"disease name: SARS-CoV-2\\r\\nlocation: a closely monitored hospital outbreak in Paris, entire hospital\\r\\ndate: 2020 during the first wave\\r\\nR0 value: 2.6\\r\\n%CI values: -\\r\\nmethod: realistic epidemic model\\r\\n|\\r\\ndisease name: SARS-CoV-2\\r\\nlocation: a closely monitored hospital outbreak in Paris, individual wards\\r\\ndate: 2020 during the first wave\\r\\nR0 value: from 3 to 15\\r\\n%CI values: -\\r\\nmethod: realistic epidemic model\\r\\n|\\r\\ndisease name: SARS-CoV-2\\r\\nlocation: a closely monitored hospital outbreak in Paris\\r\\ndate: 2020 during the first wave, mask-wearing policy: before\\r\\nR0 value: 8.7\\r\\n%CI values: -\\r\\nmethod: realistic epidemic model\\r\\n|\\r\\ndisease name: SARS-CoV-2\\r\\nlocation: a closely monitored hospital outbreak in Paris\\r\\ndate: 2020 during the first wave, mask-wearing policy: after\\r\\nR0 value: 1.3\\r\\n%CI values: -\\r\\nmethod: realistic epidemic model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"SARS-CoV-2\\",\\r\\n\\"location\\": \\"a closely monitored hospital outbreak in Paris, entire hospital\\",\\r\\n\\"date\\": \\"2020 during the first wave\\",\\r\\n\\"R0 value\\": \\"2.6\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"realistic epidemic model\\"}},{\\"contribution\\":{\\"disease name\\": \\"SARS-CoV-2\\",\\r\\n\\"location\\": \\"a closely monitored hospital outbreak in Paris, individual wards\\",\\r\\n\\"date\\": \\"2020 during the first wave\\",\\r\\n\\"R0 value\\": \\"from 3 to 15\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"realistic epidemic model\\"}},{\\"contribution\\":{\\"disease name\\": \\"SARS-CoV-2\\",\\r\\n\\"location\\": \\"a closely monitored hospital outbreak in Paris\\",\\r\\n\\"date\\": \\"2020 during the first wave, mask-wearing policy: before\\",\\r\\n\\"R0 value\\": \\"8.7\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"realistic epidemic model\\"}},{\\"contribution\\":{\\"disease name\\": \\"SARS-CoV-2\\",\\r\\n\\"location\\": \\"a closely monitored hospital outbreak in Paris\\",\\r\\n\\"date\\": \\"2020 during the first wave, mask-wearing policy: after\\",\\r\\n\\"R0 value\\": \\"1.3\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"realistic epidemic model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"SARS-CoV-2\\", \\"location\\": \\"Paris 2020\\", \\"date\\": \\"during the first wave\\", \\"R0 value\\": \\"(2.6)\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"SARS-CoV-2\\", \\"location\\": \\"Paris 2020\\", \\"date\\": \\"during the first wave\\", \\"R0 value\\": \\"(6.7)\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"SARS-CoV-2\\", \\"location\\": \\"Paris 2020\\", \\"date\\": \\"during the first wave\\", \\"R0 value\\": \\"(1.3)\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } } ]","publish_time":"2021","cluster_id":"425"},{"main_cord_uid":"oywlt4wz","cord_uid":"oywlt4wz","abstract":"A new modification of the SIR epidemic model incorporating vaccination is proposed in the present paper. The recent trend of vaccinating against COVID-19 pandemic reveals a strong control of infectious disease. On the other hand, it is observed in some countries that, the vaccine application offers less control over the spread of virus, since some portion of vaccinated people is not totally protected/immuned and viable to infection again after a while due to weak/loss immunity offered by the vaccine. This requires transition from vaccinated department to infected for COVID-19. This character of COVID-19 helps us reconsideration of the vaccinated department by letting some part of it being exposed to the infection again. Taking this into account, as a result of modification of the SIR model, the epidemiology is now governed with three main epidemic dimensionless parameters, having provided an initial fraction of infected individuals. The dimensionless model with these parameters is analyzed initially from the stability point of view. The effects of weak immunity are then illustrated numerically on some chosen parameter range. How some of the countries applying the COVID-19 vaccine programs affected by weak/loss immunity is eventually examined with the modified model. The rate of vaccination as well as the basic Reproduction number are found to affect the epidemic demography of the population subject to weak or loss of immunity. In the case of a high vaccination rate, the countries are not anticipated to be highly influenced by the weak immunity of low level, whereas weak immunity prolongs the contagious disease by appearance of secondary multiple peaks in the epidemic compartments with relatively small vaccination rates and basic Reproductive numbers.","title":"An extended epidemic model with vaccination: Weak-immune SIRVI","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2022-04-22 10:00:00"},{"main_cord_uid":"90ftzrif","cord_uid":"90ftzrif","abstract":"BACKGROUND: Imported COVID-19 cases, if unchecked, can jeopardize the effort of domestic containment. We aim to find out what sustainable border control options for different entities (e.g., countries, states) exist during the reopening phases, given their own choice of domestic control measures. METHODS: We propose a SUIHR model, which has built-in imported risk and (1-tier) contact tracing to study the cross-border spreading and control of COVID-19. Under plausible parameter assumptions, we examine the effectiveness of border control policies, in combination with internal measures, to confine the virus and avoid reverting back to more restrictive life styles again. RESULTS: When the basic reproduction number R0 of COVID-19 exceeds 2.5, even 100% effective contact tracing alone is not enough to contain the spreading. For an entity that has completely eliminated the virus domestically, and resumes \\"normal\\", without mandatory institutional quarantine, even very strict border control measures combined with effective contact tracing can only delay another outbreak by 6 months. For entities employing a confining domestic control policy, non-increasing net imported cases is sufficient to remain open. CONCLUSIONS: Extremely strict border control in entities, where domestic spreading is currently eliminated (e.g., China), is justifiable. However such harsh measure are not necessary for other places. Entities successfully confining the virus by internal measures can open up to similar entities without additional border controls so long as the imported risk stays non-increasing. Opening the borders to entities lacking sufficient internal control of the virus should be exercised in combination with pre-departure screening and tests upon arrival.","title":"Sustainable border control policy in the COVID-19 pandemic: A math modeling study","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"xdjgjeb9","cord_uid":"xdjgjeb9","abstract":"The number of COVID-19 cases is continuously increasing in different countries (as of March 2020) including the Philippines. It is estimated that the basic reproductive number of COVID-19 is around 1.5 to 4. The basic reproductive number characterizes the average number of persons that a primary case can directly infect in a population full of susceptible individuals. However, there can be superspreaders that can infect more than this estimated basic reproductive number. In this study, we formulate a conceptual mathematical model on the transmission dynamics of COVID-19 between the frontliners and the general public. We assume that the general public has a reproductive number between 1.5 to 4, and frontliners (e.g. healthcare workers, customer service and retail personnel, food service crews, and transport or delivery workers) have a higher reproduction number. Our simulations show that both the frontliners and the general public should be protected or resilient against the disease. Protecting only the frontliners will not result in flattening the epidemic curve. Protecting only the general public may flatten the epidemic curve but the infection risk faced by the frontliners is still high, which may eventually affect their work. Our simple model does not consider all factors involved in COVID-19 transmission in a community, but the insights from our model results remind us of the importance of community effort in controlling the transmission of the disease. All in all, the take-home message is that everyone in the community, whether a frontliner or not, should be protected or should implement preventive measures to avoid being infected.","title":"A mathematical model of COVID-19 transmission between frontliners and the general public","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Philippines\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"1.5 to 4\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"mathematical model\\" } } ]","publish_time":"2020-03-30 10:00:00"},{"main_cord_uid":"htd6ocsc","cord_uid":"htd6ocsc","abstract":"Mathematical model for the transition dynamics and control of the novel coronavirus (COVID-19) in Nigeria has been proposed for incorporating the impact of vaccination and prevention. The endemic equilibrium state and the effective reproductive number (R(0)) was obtained and used to find the best recipe for curbing the rate of transmission of the disease. Using the Nigerian demographic data, numerical simulation results showed that 20% coronavirus vaccination when applied in coverage of active individuals is better than 75% preventive individual\'s usage on limiting the spread of COVID-19. In addition, the results also showed that vaccinating 30% of active individuals are better ways of curbing the disease than vaccinating 75% of individuals that are not infected with the virus as shown by the calculated ratio and the simulation results, respectively.","title":"Mathematical recipe for curbing coronavirus (COVID-19) transmition dynamics","annotator_investigating_R0":"0","text_response":"disease name: COVID-19\\r\\nlocation: Nigeria\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: Mathematical model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Nigeria\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Mathematical model\\"}}]","json_model_response":"unanswerable","publish_time":"2021-05-21 10:00:00"},{"main_cord_uid":"lfe5vaz1","cord_uid":"lfe5vaz1","abstract":"BACKGROUND: Emergence of the coronavirus disease (COVID-19) caught the world off guard and unprepared, initiating a global pandemic. In the absence of evidence, individual communities had to take timely action to reduce the rate of disease spread and avoid overburdening their health care systems. Although a few predictive models have been published to guide these decisions, most have not taken into account spatial differences and have included assumptions that do not match the local realities. Access to reliable information that is adapted to local context is critical for policy makers to make informed decisions during a rapidly evolving pandemic. OBJECTIVE: The goal of this study was to develop an adapted susceptible-infected-removed (SIR) model to predict the trajectory of the COVID-19 pandemic in North Carolina and the Charlotte Metropolitan Region, and to incorporate the effect of a public health intervention to reduce disease spread while accounting for unique regional features and imperfect detection. METHODS: Three SIR models were fit to infection prevalence data from North Carolina and the greater Charlotte Region and then rigorously compared. One of these models (SIR-int) accounted for a stay-at-home intervention and imperfect detection of COVID-19 cases. We computed longitudinal total estimates of the susceptible, infected, and removed compartments of both populations, along with other pandemic characteristics such as the basic reproduction number. RESULTS: Prior to March 26, disease spread was rapid at the pandemic onset with the Charlotte Region doubling time of 2.56 days (95% CI 2.11-3.25) and in North Carolina 2.94 days (95% CI 2.33-4.00). Subsequently, disease spread significantly slowed with doubling times increased in the Charlotte Region to 4.70 days (95% CI 3.77-6.22) and in North Carolina to 4.01 days (95% CI 3.43-4.83). Reflecting spatial differences, this deceleration favored the greater Charlotte Region compared to North Carolina as a whole. A comparison of the efficacy of intervention, defined as 1 - the hazard ratio of infection, gave 0.25 for North Carolina and 0.43 for the Charlotte Region. In addition, early in the pandemic, the initial basic SIR model had good fit to the data; however, as the pandemic and local conditions evolved, the SIR-int model emerged as the model with better fit. CONCLUSIONS: Using local data and continuous attention to model adaptation, our findings have enabled policy makers, public health officials, and health systems to proactively plan capacity and evaluate the impact of a public health intervention. Our SIR-int model for estimated latent prevalence was reasonably flexible, highly accurate, and demonstrated efficacy of a stay-at-home order at both the state and regional level. Our results highlight the importance of incorporating local context into pandemic forecast modeling, as well as the need to remain vigilant and informed by the data as we enter into a critical period of the outbreak.","title":"Modeling COVID-19 Latent Prevalence to Assess a Public Health Intervention at a State and Regional Scale: Retrospective Cohort Study","annotator_investigating_R0":"0","text_response":"disease name: COVID-19\\r\\nlocation: North Carolina and the Charlotte Metropolitan Region\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: susceptible-infected-removed (SIR) model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"North Carolina and the Charlotte Metropolitan Region\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"susceptible-infected-removed (SIR) model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease (COVID-19)\\", \\"location\\": \\"North Carolina\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"2.56\\", \\"%CI values\\": \\"(95% CI 2.11-3.25)\\", \\"method\\": \\"adapted susceptible-infected-removed (SIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease (COVID-19)\\", \\"location\\": \\"Charlotte Metropolitan Region\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"4.70\\", \\"%CI values\\": \\"(95% CI 3.77-6.22)\\", \\"method\\": \\"adapted susceptible-infected-removed (SIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease (COVID-19)\\", \\"location\\": \\"North Carolina\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"4.01\\", \\"%CI values\\": \\"(95% CI 3.43-4.83)\\", \\"method\\": \\"adapted susceptible-infected-removed (SIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease (COVID-19)\\", \\"location\\": \\"North Carolina\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"adapted susceptible-infected-removed (SIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease (COVID-19)\\", \\"location\\": \\"Charlotte Metropolitan Region\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"adapted susceptible-infected-removed (SIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease (COVID-19)\\", \\"location\\": \\"North Carolina\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"adapted susceptible-infected-removed (SIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease (COVID-19)\\", \\"location\\": \\"North Carolina\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"adapted susceptible-infected-removed (SIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease (COVID-19)\\", \\"location\\": \\"Charlotte Metropolitan Region\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"adapted susceptible-infected-removed (SIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease (COVID-19)\\", \\"location\\": \\"North Carolina\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"adapted susceptible-infected-removed (SIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease (COVID-19)\\", \\"location\\": \\"North Carolina\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"adapted susceptible-infected-removed (SIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease (COVID-19)\\", \\"location\\": \\"North Carolina\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"adapted susceptible-infected-removed (SIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease (COVID-19)\\", \\"location\\": \\"North Carolina\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"adapted susceptible-infected-removed (SIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease (COVID-19)\\", \\"location\\": \\"Charlotte Metropolitan Region\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"adapted susceptible-infected-removed (SIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease (COVID-19)\\", \\"location\\": \\"North Carolina\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"adapted susceptible-infected-removed (SIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease (COVID-19)\\", \\"location\\": \\"North Carolina\\", \\"date\\": \\"-} } ]\\r\\n","publish_time":"2020"},{"main_cord_uid":"ikqz23pe","cord_uid":"ikqz23pe","abstract":"The basic reproductive number, R(0), is one of the most common and most commonly misapplied numbers in public health. Often used to compare outbreaks and forecast pandemic risk, this single number belies the complexity that different epidemics can exhibit, even when they have the same R(0). Here, we reformulate and extend a classic result from random network theory to forecast the size of an epidemic using estimates of the distribution of secondary infections, leveraging both its average R(0) and the underlying heterogeneity. Importantly, epidemics with lower R(0) can be larger if they spread more homogeneously (and are therefore more robust to stochastic fluctuations). We illustrate the potential of this approach using different real epidemics with known estimates for R(0), heterogeneity and epidemic size in the absence of significant intervention. Further, we discuss the different ways in which this framework can be implemented in the data-scarce reality of emerging pathogens. Lastly, we demonstrate that without data on the heterogeneity in secondary infections for emerging infectious diseases like COVID-19 the uncertainty in outbreak size ranges dramatically. Taken together, our work highlights the critical need for contact tracing during emerging infectious disease outbreaks and the need to look beyond R(0).","title":"Beyond R(0): heterogeneity in secondary infections and probabilistic epidemic forecasting","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-11-04 05:00:00"},{"main_cord_uid":"mip0v988","cord_uid":"ch7nna59","abstract":"As countries in the world review interventions for containing the COVID-19 pandemic, important lessons can be drawn by studying the full transmission dynamics of SARS-CoV-2 in Wuhan, China, where vigorous non-pharmaceutical interventions have suppressed the local COVID-19 outbreak1. Here, we use a modelling approach to reconstruct the full-spectrum dynamics of COVID-19 between January 1, 2020 and March 8, 2020 across five periods marked by events and interventions based on 32,583 laboratory-confirmed cases1. Accounting for presymptomatic infectiousness2, time-varying ascertainment rates, transmission rates and population movements3, we identify two key features of the outbreak: high covertness and high transmissibility. We estimate 87% (lower bound 53%) of the infections before March 8 were unascertained, potentially including asymptomatic and mild-symptomatic cases; and a basic reproduction number R0 of 3.54 (95% credible interval [CrI]: 3.40-3.67) in the early outbreak, much higher than for SARS and MERS4,5. We observe that multi-pronged interventions had considerable positive effects on controlling the outbreak, decreasing the reproduction number to 0.28 (0.23-0.33) and by projection reducing the total infections in Wuhan by 96.0% as of March 8. We furthermore explore the probability of resurgence following lifting of all interventions after 14 days of no ascertained infections, estimating it at 0.32 and 0.06 based on models with 87% and 53% unascertained infections, respectively, highlighting the risk posed by unascertained cases in changing intervention strategies. These results provide important implications for continuing surveillance and interventions to eventually contain COVID-19 outbreaks.","title":"Reconstruction of the full transmission dynamics of COVID-19 in Wuhan.","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Wuhan, China\\r\\ndate: January 1, 2020 and March 8, 2020\\r\\nR0 value: 3.54\\r\\n%CI values: 95% credible interval [CrI]: 3.40-3.67\\r\\nmethod: modelling approach to reconstruct the full-spectrum dynamics of COVID-19\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Wuhan, China\\r\\ndate: as of March 8\\r\\nR0 value: 0.28\\r\\n%CI values: (0.23-0.33)\\r\\nmethod: modelling approach to reconstruct the full-spectrum dynamics of COVID-19","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Wuhan, China\\",\\r\\n\\"date\\": \\"January 1, 2020 and March 8, 2020\\",\\r\\n\\"R0 value\\": \\"3.54\\",\\r\\n\\"%CI values\\": \\"95% credible interval [CrI]: 3.40-3.67\\",\\r\\n\\"method\\": \\"modelling approach to reconstruct the full-spectrum dynamics of COVID-19\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Wuhan, China\\",\\r\\n\\"date\\": \\"as of March 8\\",\\r\\n\\"R0 value\\": \\"0.28\\",\\r\\n\\"%CI values\\": \\"(0.23-0.33)\\",\\r\\n\\"method\\": \\"modelling approach to reconstruct the full-spectrum dynamics of COVID-19\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Wuhan, China\\", \\"date\\": \\"January 1, 2020 and March 8, 2020\\", \\"R0 value\\": \\"3.54\\", \\"%CI values\\": \\"(95% credible interval [CrI]: 3.40-3.67)\\", \\"method\\": \\"a modelling approach\\" } } ]","publish_time":"2020-07-16 00:00:00","action":"change_main_cord_id","cluster_id":"238"},{"main_cord_uid":"ix4w2jcf","cord_uid":"ix4w2jcf","abstract":"Social distancing measures have been imposed across the US in order to stem the spread of COVID-19. We quantify the reduction in doubling rate, by state, that is associated with this intervention. Using the earlier of K-12 school closures and restaurant closures, by state, to define the start of the intervention, and considering daily confirmed cases through April 23rd, 2020, we find that social distancing is associated with a statistically-significant (p < 0.01) reduction in the doubling rate for all states except for Nebraska, North Dakota, and South Dakota, when controlling for false discovery, with the doubling rate averaged across the states falling from 0.302 (0.285, 0.320) days-1 to 0.010 (-0.007, 0.028) days-1. However, we do not find that social distancing has made the spread subcritical. Instead, social distancing has merely stabilized the spread of the disease. We provide an illustration of our findings for each state, including estimates of the effective reproduction number, R, both with and without social distancing. We also discuss the policy implications of our findings.","title":"Social distancing merely stabilized COVID-19 in the US","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"nz9dy3xr","cord_uid":"nz9dy3xr","abstract":"The present paper focuses on the modeling of the COVID-19 infection with the use of hospitalization, isolation and quarantine. Initially, we construct the model by spliting the entire population into different groups. We then rigorously analyze the model by presenting the necessary basic mathematical features including the feasible region and positivity of the problem solution. Further, we evaluate the model possible equilibria. The theoretical expression of the most important mathematical quantity of major public health interest called the basic reproduction number is presented. We are taking into account to study the disease free equilibrium by studying its local and global asymptotical analysis. We considering the cases of the COVID-19 infection of Pakistan population and find the parameters using the estimation with the help of nonlinear least square and have [Formula: see text]. Further, to determine the influence of the model parameters on disease dynamics we perform the sensitivity analysis. Simulations of the model are presented using estimated parameters and the impact of various non-pharmaceutical interventions on disease dynamics is shown with the help of graphical results. The graphical interpretation justify that the effective utilization of keeping the social-distancing, making the quarantine of people (or contact-tracing policy) and to make hospitalization of confirmed infected people that dramatically reduces the number of infected individuals (enhancing the quarantine or contact-tracing by 50% from its baseline reduces 84% in the predicted number of confirmed infected cases). Moreover, it is observed that without quarantine and hospitalization the scenario of the disease in Pakistan is very worse and the infected cases are raising rapidly. Therefore, the present study suggests that still, a proper and effective application of these non-pharmaceutical interventions are necessary to curtail or minimize the COVID-19 infection in Pakistan.","title":"Mathematical modeling and stability analysis of the COVID-19 with quarantine and isolation","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2022-02-08 05:00:00"},{"main_cord_uid":"iibgsr5l","cord_uid":"iibgsr5l","abstract":"Currently the COVID-19 epidemic is developing in the City of Culiac\\\\\'n Sinaloa, Mexico, where up to April 20 of this year there have been 35 deaths associated with this epidemic. The reproduction number $(R_0)$ of an epidemic represents the average number of people infected by an infected person during their period of infection. In this work we use the data published by the Secretary of Health of the State of Sinaloa on the number of new infected cases confirmed per day and we estimate that the value of $R_0$ is 1.562 with a 95% confidence interval given by (1.401,1.742). We also estimate the mortality rate among the confirmed cases, which turned out to be 16.8%. - - - - - Actualmente la epidemia COVID-19 se est\\\\\'a desarrollando en la Ciudad de Culiac\\\\\'an Sinaloa, M\\\\\'exico, donde hasta el 20 de abril del presente a\\\\~no han ocurrido 35 decesos asociados con esta epidemia. El n\\\\\'umero de reproducci\\\\\'on $(R_0)$ de una epidemia representa el n\\\\\'umero promedio de personas contagiadas por una persona infectada durante su periodo de infecci\\\\\'on. En este trabajo usamos los datos publicados por la Secretaria de Salud del Estado de Sinaloa sobre el n\\\\\'umero de nuevos casos infectados confirmados por dia y estimamos que el valor de $R_0$ es de 1.562 con un intervalo del 95% de confianza dado por (1.401,1.742). Estimamos tambi\\\\\'en la tasa de mortalidad entre los casos confirmados, la cual result\\\\\'o ser de 16.8%.","title":"Estimaci\\\\\'on del n\\\\\'umero de reproducci\\\\\'on de la epidemia COVID-19 en Culiac\\\\\'an Sinaloa, M\\\\\'exico","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Culiac\xe1n Sinaloa, Mexico\\r\\ndate: -\\r\\nR0 value: 1.562\\r\\n%CI values: (1.401,1.742)\\r\\nmethod: -","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Culiac\xe1n Sinaloa, Mexico\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"1.562\\",\\r\\n\\"%CI values\\": \\"(1.401,1.742)\\",\\r\\n\\"method\\": \\"-\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Culiac\'n Sinaloa, Mexico\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"1.562\\", \\"%CI values\\": \\"95% confidence interval given by (1.401,1.742)\\", \\"method\\": \\"-\\" } } ]","publish_time":"2020-04-21 10:00:00"},{"main_cord_uid":"yusr53hp","cord_uid":"yusr53hp","abstract":"The reproductive number is an important metric that has been widely used to quantify the infectiousness of communicable diseases. The time-varying instantaneous reproductive number is useful for monitoring the real time dynamics of a disease to inform policy making for disease control. Local estimation of this metric, for instance at a county or city level, allows for more targeted interventions to curb transmission. However, simultaneous estimation of local reproductive numbers must account for potential sources of heterogeneity in these time-varying quantities -- a key element of which is human mobility. We develop a statistical method that incorporates human mobility between multiple regions for estimating region-specific instantaneous reproductive numbers. The model also can account for exogenous cases imported from outside of the regions of interest. We propose two approaches to estimate the reproductive numbers, with mobility data used to adjust incidence in the first approach and to inform a formal priori distribution in the second (Bayesian) approach. Through a simulation study, we show that region-specific reproductive numbers can be well estimated if human mobility is reasonably well approximated by available data. We use this approach to estimate the instantaneous reproductive numbers of COVID-19 for 14 counties in Massachusetts using CDC case report data and the human mobility data collected by SafeGraph. We found that, accounting for mobility, our method produces estimates of reproductive numbers that are distinct across counties. In contrast, independent estimation of county-level reproductive numbers tends to produce similar values, as trends in county case-counts for the state are fairly concordant. These approaches can also be used to estimate any heterogeneity in transmission, for instance, age-dependent instantaneous reproductive number estimates. As people are more mobile and interact frequently in ways that permit transmission, it is important to account for this in the estimation of the reproductive number.","title":"Estimation of heterogeneous instantaneous reproduction numbers with application to characterize SARS-CoV-2 transmission in Massachusetts counties","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-12-05 05:00:00","cluster_id":"411"},{"main_cord_uid":"nkyhcs0c","cord_uid":"nkyhcs0c","abstract":"Background: Pregnant women are at increased risk for severe outcomes from coronavirus disease 2019 (COVID-19), but the pathophysiology underlying this increased morbidity and its potential effect on the developing fetus is not well understood. Methods: We assessed placental histology, ACE2 expression, and viral and immune dynamics at the term placenta in pregnant women with and without respiratory severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection. Findings: The majority (13 of 15) of placentas analyzed had no detectable viral RNA. ACE2 was detected by immunohistochemistry in syncytiotrophoblast cells of the normal placenta during early pregnancy but was rarely seen in healthy placentas at full term, suggesting that low ACE2 expression may protect the term placenta from viral infection. Using immortalized cell lines and primary isolated placental cells, we found that cytotrophoblasts, the trophoblast stem cells and precursors to syncytiotrophoblasts, rather than syncytiotrophoblasts or Hofbauer cells, are most vulnerable to SARS-CoV-2 infection in vitro. To better understand potential immune mechanisms shielding placental cells from infection in vivo, we performed bulk and single-cell transcriptomics analyses and found that the maternal-fetal interface of SARS-CoV-2-infected women exhibited robust immune responses, including increased activation of natural killer (NK) and T cells, increased expression of interferon-related genes, as well as markers associated with pregnancy complications such as preeclampsia. Conclusions: SARS-CoV-2 infection in late pregnancy is associated with immune activation at the maternal-fetal interface even in the absence of detectable local viral invasion. Funding: NIH (T32GM007205, F30HD093350, K23MH118999, R01AI157488, U01DA040588) and Fast Grant funding support from Emergent Ventures at the Mercatus Center.","title":"Maternal respiratory SARS-CoV-2 infection in pregnancy is associated with a robust inflammatory response at the maternal-fetal interface","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"bp1ynsq0","cord_uid":"bp1ynsq0","abstract":"BACKGROUND: Mathematical models can provide insights on the spread of infectious diseases, such as the novel SARS-CoV-2 (COVID-19). This work applied a SEIR epidemiological compartmental model (susceptible-exposed-infected-recovered) with k phases to predict the actual spread of the COVID-19 virus. Fig. 1 \xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153 SEIR model for COVID-19. [Image: see text] METHODS: Four parameters of the SEIR model were obtained by international experiences: the incubation period = 3.7 in days, the proportion of critical cases = 0.05, the overall case-fatality rate = 0.023, and the asymptomatic proportion of COVID-19 = 0.18. The critical step in the prediction of COVID-19 by the model is the value of R0 (the basic reproduction number) and T_infectious (the infectious period, in days). R0 and T_infectious for each phase of the curve are calculated by mathematical constrained optimization, a numerical method. Differently from a statistical modelling, a numerical method is a type of mathematical modelling that is not dependent on a probability distribution. The objective function that measures the model error is minimized with respect to R0 and T_infectious in the presence of constraints on those variables. For R0, constraints are valid range of values (0.5 \xc3\xa2\xe2\u20ac\xb0\xc2\xa4 R0 \xc3\xa2\xe2\u20ac\xb0\xc2\xa4 20). For T_infectious, constraints also are related to its range of values (2 \xc3\xa2\xe2\u20ac\xb0\xc2\xa4 T_infectious \xc3\xa2\xe2\u20ac\xb0\xc2\xa4 14). A Solver from Excel or NEOS Server, for example, can be used for finding numerically minimum of a function Z, that represents the sum of absolute value of errors between COVID-19 new cases observed in one day, and COVID-19 cases predicted by the SEIR model (Fig. 2 and 3). Fig. 2 - Mathematical Modeling of COVID-19 transmission by a SEIR model wiht three phases. [Image: see text] Fig.3 - Algorithm for the SEIR model applied to COVID-19 (calculation of new COVID-19 cases day-by-day). [Image: see text] RESULTS: The ECDC has registered 8,142,129 COVID-19 in the world on Jun/17/2020. R0 and T_infectious calculated for a three phases curve in USA, with a stabilized scenario (Fig. 4: R0_1=1.0; T_infectious_1=2; R0_2=17.4; T_infectious_2=2; R0_3=1.0; T_infectious_3=14), a two phases curve in Brazil (Fig. 5: R0_1=8.0; T_infectious_1=9; R0_2=1.3; T_infectious_2=6), and a three phases model for France (Fig. 6: R0_1=4.3; T_infectious_1=11; R0_2=9.3; T_infectious_2=11; R0_3=0.5; T_infectious_3=12). Fig. 4 - Three phases SEIR models for R0 and T_infectious that minimize the model error in predicting new COVID-19 cases day-by-day in USA. [Image: see text] Fig. 5 - Two phases SEIR models for R0 and T_infectious that minimize the model error in predicting new COVID-19 cases day-by-day in USA. [Image: see text] Fig. 6 - Two phases SEIR models for R0 and T_infectious that minimize the model error in predicting new COVID-19 cases day-by-day in USA. [Image: see text] CONCLUSION: The k phases SEIR model proved to be a useful to measure the COVID-19 transmission in a City, State or Country. More phases can be applied to fit a scenario with a new second COVID wave. DISCLOSURES: All Authors: No reported disclosures","title":"433. Mathematical Modeling of COVID-19 Transmission by a k Phases SEIR Model","annotator_investigating_R0":"1","text_response":"disease name: novel SARS-CoV-2 (COVID-19)\\r\\nlocation: USA\\r\\ndate: -\\r\\nR0 value: R0_1=1.0; R0_2=17.4; R0_3=1.0\\r\\n%CI values: -\\r\\nmethod: SEIR epidemiological compartmental model (susceptible-exposed-infected-recovered) with k phases\\r\\n|\\r\\ndisease name: novel SARS-CoV-2 (COVID-19)\\r\\nlocation: Brazil\\r\\ndate: -\\r\\nR0 value: R0_1=8.0; R0_2=1.3\\r\\n%CI values: -\\r\\nmethod: SEIR epidemiological compartmental model (susceptible-exposed-infected-recovered) with k phases\\r\\n|\\r\\ndisease name: novel SARS-CoV-2 (COVID-19)\\r\\nlocation: France\\r\\ndate: -\\r\\nR0 value: R0_1=4.3; R0_2=9.3; R0_3=0.5\\r\\n%CI values: -\\r\\nmethod: SEIR epidemiological compartmental model (susceptible-exposed-infected-recovered) with k phases","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"novel SARS-CoV-2 (COVID-19)\\",\\r\\n\\"location\\": \\"USA\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"R0_1=1.0; R0_2=17.4; R0_3=1.0\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SEIR epidemiological compartmental model (susceptible-exposed-infected-recovered) with k phases\\"}},{\\"contribution\\":{\\"disease name\\": \\"novel SARS-CoV-2 (COVID-19)\\",\\r\\n\\"location\\": \\"Brazil\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"R0_1=8.0; R0_2=1.3\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SEIR epidemiological compartmental model (susceptible-exposed-infected-recovered) with k phases\\"}},{\\"contribution\\":{\\"disease name\\": \\"novel SARS-CoV-2 (COVID-19)\\",\\r\\n\\"location\\": \\"France\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"R0_1=4.3; R0_2=9.3; R0_3=0.5\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SEIR epidemiological compartmental model (susceptible-exposed-infected-recovered) with k phases\\"}}]","json_model_response":"unanswerable","publish_time":"2020-12-31 00:00:00","cluster_id":"1349"},{"main_cord_uid":"ryraplpe","cord_uid":"ryraplpe","abstract":"Background: Most of the countries are affected with the pandemic outbreak of the coronavirus infection. Understanding the severity and distribution in various regions will help in planning the controlling measures. Objectives: The objective was to assess the distribution and growth rate of COVID-19 infection in Tamil Nadu, India. Methods: The data on the number of infections of COVID-19 have been obtained from the media reports released by the Government of Tamil Nadu. The data contain information on the incidence of the disease for the first 41 days of the outbreak started on March 7, 2020. Log-linear model has been used to estimate the progression of the COVID-19 infection in Tamil Nadu. Separate models were employed to model the growth rate and decay rate of the disease. Spatial Poisson regression was used to identify the high-risk areas in the state. Results: : The models estimated the doubling time for the number of cases in growth phase as 3.96 (95% confidence interval [CI]: 2.70, 9.42) days and halving time in the decay phase as 12.08 (95% CI: 6.79, 54.78) days. The estimated median reproduction numbers were 1.88 (min = 1.09, max = 2.51) and 0.76 (min = 0.56, max = 0.99) in the growth and decay phases, respectively. The spatial Poisson regression identified 11 districts as high risk. Conclusion: The results indicate that the outbreak is showing decay in the number of infections of the disease which highlights the effectiveness of controlling measures.","title":"Distribution and growth rate of COVID-19 outbreak in Tamil Nadu: A log-linear regression approach","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Tamil Nadu, India\\r\\ndate: first 41 days of the outbreak started on March 7, 2020\\r\\nR0 value: 1.88 (min = 1.09, max = 2.51) and 0.76 (min = 0.56, max = 0.99) in the growth and decay phases\\r\\n%CI values: -\\r\\nmethod: log-linear regression approach","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Tamil Nadu, India\\",\\r\\n\\"date\\": \\"first 41 days of the outbreak started on March 7, 2020\\",\\r\\n\\"R0 value\\": \\"1.88 (min = 1.09, max = 2.51) and 0.76 (min = 0.56, max = 0.99) in the growth and decay phases\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"log-linear regression approach\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Tamil Nadu, India\\", \\"date\\": \\"March 7, 2020\\", \\"R0 value\\": \\"1.88\\", \\"%CI values\\": \\"(min = 1.09, max = 2.51)\\", \\"method\\": \\"log-linear model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Tamil Nadu, India\\", \\"date\\": \\"March 7, 2020\\", \\"R0 value\\": \\"0.76\\", \\"%CI values\\": \\"(min = 0.56, max = 0.99)\\", \\"method\\": \\"log-linear model\\" } } ]","publish_time":"2020"},{"main_cord_uid":"kwnteqg1","cord_uid":"kwnteqg1","abstract":"BACKGROUND: Estimates of parameters for disease transmission in large-scale infectious disease outbreaks are often obtained to represent large groups of people, providing an average over a potentially very diverse area. For control measures to be more effective, a measure of the heterogeneity of the parameters is desirable. METHODS: We propose a novel extension of a network-based approach to estimating the reproductive number. With this we can incorporate spatial and/or demographic information through a similarity matrix. We apply this to the 2009 Influenza pandemic in South Africa to understand the spatial variability across provinces. We explore the use of five similarity matrices to illustrate their impact on the subsequent epidemic parameter estimates. RESULTS: When treating South Africa as a single entity with homogeneous transmission characteristics across the country, the basic reproductive number, R(0), (and imputation range) is 1.33 (1.31, 1.36). When fitting a new model for each province with no inter-province connections this estimate varies little (1.23-1.37). Using the proposed method with any of the four similarity measures yields an overall R(0) that varies little across the four new models (1.33 to 1.34). However, when allowed to vary across provinces, the estimated R(0) is greater than one consistently in only two of the nine provinces, the most densely populated provinces of Gauteng and Western Cape. CONCLUSIONS: Our results suggest that the spatial heterogeneity of influenza transmission was compelling in South Africa during the 2009 pandemic. This variability makes a qualitative difference in our understanding of the epidemic. While the cause of this fluctuation might be partially due to reporting differences, there is substantial evidence to warrant further investigation.","title":"Estimating the reproductive number in the presence of spatial heterogeneity of transmission patterns","annotator_investigating_R0":"1","text_response":"disease name: Influenza\\r\\nlocation: South Africa\\r\\ndate: -\\r\\nR0 value: 1.33 (1.31, 1.36)\\r\\n%CI values: -\\r\\nmethod: novel extension of a network-based approach, South Africa as a single entity with homogeneous transmission characteristics\\r\\n|\\r\\ndisease name: Influenza\\r\\nlocation: South Africa\\r\\ndate: -\\r\\nR0 value: (1.23-1.37)\\r\\n%CI values: -\\r\\nmethod: novel extension of a network-based approach, fitting a new model for each province with no inter-province connections\\r\\n|\\r\\ndisease name: Influenza\\r\\nlocation: South Africa\\r\\ndate: -\\r\\nR0 value: (1.33 to 1.34) overall\\r\\n%CI values: -\\r\\nmethod: novel extension of a network-based approach, proposed method with any of the four similarity measures","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Influenza\\",\\r\\n\\"location\\": \\"South Africa\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"1.33 (1.31, 1.36)\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"novel extension of a network-based approach, South Africa as a single entity with homogeneous transmission characteristics\\"}},{\\"contribution\\":{\\"disease name\\": \\"Influenza\\",\\r\\n\\"location\\": \\"South Africa\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"(1.23-1.37)\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"novel extension of a network-based approach, fitting a new model for each province with no inter-province connections\\"}},{\\"contribution\\":{\\"disease name\\": \\"Influenza\\",\\r\\n\\"location\\": \\"South Africa\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"(1.33 to 1.34) overall\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"novel extension of a network-based approach, proposed method with any of the four similarity measures\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"1.33\\", \\"%CI values\\": \\"1.31, 1.36\\", \\"method\\": \\"Network-based approach\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"1.23, 1.36\\", \\"method\\": \\"Network-based approach\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Network-based approach\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Network-based approach\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Network-based approach\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Network-based approach\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Network-based approach\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Network-based approach\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Network-based approach\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Network-based approach\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Network-based approach\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Network-based approach\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Network-based approach\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Network-based approach\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Network-based approach\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Network-based approach\\" } }, { \\"contribution\\": { \\"disease name\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"method\\": \\"Network-based approach\\" } }, { \\"contribution\\": { \\"disease name\\" } }, { \\"contribution\\": { \\"disease name\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"date\\": \\"-\\", \\"R0 value\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 Influenza\\", \\"location\\": \\"South Africa\\", \\"} } ]","publish_time":"2013-07-26 10:00:00","cluster_id":"1180"},{"main_cord_uid":"xplon6eh","cord_uid":"xplon6eh","abstract":"In this study, we formulate a mathematical model incorporating age specific transmission dynamics of COVID-19 to evaluate the role of vaccination and treatment strategies in reducing the size of COVID-19 burden. Initially, we establish the positivity and boundedness of the solutions of the model and calculate the basic reproduction number. We then formulate an optimal control problem with vaccination and treatment as control variables. Optimal vaccination and treatment policies are analysed for different values of the weight constant associated with the cost of vaccination and different transmissibility levels. Findings from these suggested that the combined strategies(vaccination and treatment) worked best in minimizing the infection and disease induced mortality. In order to reduce COVID-19 infection and COVID-19 induced deaths to maximum, it was observed that optimal control strategy should be prioritized to population with age greater than 40 years. Not much difference was found between individual strategies and combined strategies in case of mild epidemic ($R_0 \\\\in (0, 2)$). For higher values of $R_0 (R_0 \\\\in (2, 10))$ the combined strategies was found to be best in terms of minimizing the overall infection. The infection curves varying the efficacies of the vaccines were also analysed and it was found that higher efficacy of the vaccine resulted in lesser number of infection and COVID induced death.","title":"Optimal Vaccination and Treatment Strategies in Reduction of COVID-19 Burden","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"8bf5te4l","cord_uid":"8bf5te4l","abstract":"The ongoing SARS-CoV-2 pandemic is one of the biggest outbreaks after the Spanish flu of 1918. Understanding the epidemiology of viral outbreaks is the first step towards vaccine development programs. This is the first phylodynamics study attempted on of SARS-CoV-2 genomes from India to infer its current evolution in the context of an ongoing pandemic. Out of 286 retrieved SARS-CoV-2 whole genomes from India, 138 haplotypes were generated and analyzed. Median-joining network was built to investigate the relatedness of SARS-CoV-2 haplotypes in India. The BDSIR package of BEAST2 was used to calculate the reproduction number (R0) and the infectious rate of the virus. Past and current population trend was investigated using the stamp date method in coalescent Bayesian skyline plot, implemented in BEAST2 and by exponential growth prior in BEAST 1.10.4. Median-joining network reveals two distinct ancestral clusters A and B showing genetic affinities with Wuhan outbreak sample. The network also illustrates the autochthonous development of isolates in a few instances. High basic reproduction number of SARS-nCoV-2 in India points towards the phase of active community transmission. The Bayesian skyline plot revel exponential rise in the effective population size (Ne) of Indian isolates from the first week of January to the first week of April 2020. More genome sequencing and analyses of the virus will be required in coming days to monitor COVID19 after the upliftment of lock down in India.","title":"Phylogenomics and phylodynamics of SARS-CoV-2 retrieved genomes from India","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"SARS-CoV-2\\", \\"location\\": \\"India\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"BDSIR package of BEAST2\\" } } ]","publish_time":"2020-06-26 00:00:00"},{"main_cord_uid":"ax9x6q6c","cord_uid":"ax9x6q6c","abstract":"Public health interventions have been implemented to contain the outbreak of COVID-19 in New York City. However, the assessment of those interventions, e.g. social distancing, cloth face covering based on the real-world data from filed study is lacking. The SEIR compartmental model was used to evaluate the social distancing and cloth face covering effect on the daily culminative laboratory confirmed cases in NYC, and COVID-19 transmissibility. The latter was measured by Rt reproduction numbers in three phases which were based on two interventions in implemented in the timeline. The transmissibility decreased from phase 1 to phase 3. The Initial, R0 was 4.60 in Phase 1 without any intervention. After social distancing, the Rt value was reduced by 68%, while after the mask recommendation, it was further reduced by ~60%. Interventions resulted in significant reduction of confirmed case numbers, relative to predicted values based on SEIR model without intervention. Our findings highlight the effectiveness of social distancing and cloth face coverings in slowing down the spread of SARS-CoV-2 in NYC.","title":"Do Stay at Home Orders and Cloth Face Coverings Control COVID-19 in New York City? Results from a SIER Model Based on Real World Data","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: New York City\\r\\ndate: -\\r\\nR0 value: 4.60 in Phase 1 without any intervention\\r\\n%CI values: -\\r\\nmethod: SEIR compartmental model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"New York City\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"4.60 in Phase 1 without any intervention\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SEIR compartmental model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"New York City\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"4.60\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SEIR compartmental model\\" } } ]","publish_time":"2020-09-24 00:00:00"},{"main_cord_uid":"36fbcobw","cord_uid":"36fbcobw","abstract":"Objectives: To estimate the basic reproduction number (R0) of COVID-19 in the early stage of the epidemic and predict the expected number of new cases in Shahroud, Northeast of Iran. Methods: The R0 of COVID-19 was estimated using the serial interval distribution and the number of incidence cases. The serial interval was fit with a gamma distribution. The probable incidence and cumulative incidence in the next 30 days were predicted using the assumption that daily incidence follows a Poisson distribution determined by daily infectiousness. Data analysis was done using earlyR and projections packages in R software. Results: The maximum-likelihood value of R0 was 2.7 (95% confidence interval (CI): 2.1 to 3.4) for the COVID-19 epidemic in the early 14 days and decreased to 1.13 (95% CI: 1.03 to 1.25) by the end of the day 41. The expected average number of new cases in Shahroud is 9.0 case/day with a standard deviation of 3.8, which means an estimated total of 271 (95% CI: 178-383) new cases in the next 30 days. Conclusions: It is essential to reduce the R0 to values below one. Therefore, we strongly recommend enforcing and continuing the current preventive measures, restricting travel, and providing screening tests for a larger proportion of the population.","title":"The basic reproduction number and prediction of the epidemic size of the novel coronavirus (COVID-19) in Shahroud, Iran","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Shahroud, Northeast of Iran\\r\\ndate: early 14 days\\r\\nR0 value: 2.7\\r\\n%CI values: 95% confidence interval (CI): 2.1 to 3.4\\r\\nmethod: the serial interval distribution and the number of incidence cases\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Shahroud, Northeast of Iran\\r\\ndate: by the end of the day 41\\r\\nR0 value: 1.13\\r\\n%CI values: 95% CI: 1.03 to 1.25\\r\\nmethod: the serial interval distribution and the number of incidence cases","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Shahroud, Northeast of Iran\\",\\r\\n\\"date\\": \\"early 14 days\\",\\r\\n\\"R0 value\\": \\"2.7\\",\\r\\n\\"%CI values\\": \\"95% confidence interval (CI): 2.1 to 3.4\\",\\r\\n\\"method\\": \\"the serial interval distribution and the number of incidence cases\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Shahroud, Northeast of Iran\\",\\r\\n\\"date\\": \\"by the end of the day 41\\",\\r\\n\\"R0 value\\": \\"1.13\\",\\r\\n\\"%CI values\\": \\"95% CI: 1.03 to 1.25\\",\\r\\n\\"method\\": \\"the serial interval distribution and the number of incidence cases\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Shahroud, Northeast of Iran\\", \\"date\\": \\"in the early 14 days\\", \\"R0 value\\": \\"2.7\\", \\"%CI values\\": \\"(95% confidence interval (CI): 2.1 to 3.4)\\", \\"method\\": \\"serial interval distribution and the number of incidence cases\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Shahroud, Northeast of Iran\\", \\"date\\": \\"by the end of day 41\\", \\"R0 value\\": \\"1.13\\", \\"%CI values\\": \\"(95% CI: 1.03 to 1.25)\\", \\"method\\": \\"serial interval distribution and the number of incidence cases\\" } } ]","publish_time":"2020-04-08 00:00:00","cluster_id":"165"},{"main_cord_uid":"r87zpmkf","cord_uid":"r87zpmkf","abstract":"The current emergence of coronavirus (SARS-CoV-2) puts the world in threat. The structural research on the receptor recognition by SARS-CoV-2 has identified the key interactions between SARS-CoV-2 spike protein and its host (epithelial cell) receptor, also known as angiotensin-converting enzyme 2 (ACE2). It controls both the cross-species and human-to-human transmissions of SARS-CoV-2. In view of this, we propose and analyze a mathematical model for investigating the effect of CTL responses over the viral mutation to control the viral infection when a postinfection immunostimulant drug (pidotimod) is administered at regular intervals. Dynamics of the system with and without impulses have been analyzed using the basic reproduction number. This study shows that the proper dosing interval and drug dose both are important to eradicate the viral infection.","title":"A Model for SARS-CoV-2 Infection with Treatment","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"zanh629x","cord_uid":"zanh629x","abstract":"BACKGROUND The transmission potential of primary pneumonic plague, caused by Yersinia pestis, is one of the key epidemiological determinants of a potential biological weapon, and requires clarification and time dependent interpretation. METHOD This study estimated the reproduction number and its time dependent change through investigations of outbreaks in Mukden, China (1946), and Madagascar (1957). Reconstruction of an epidemic tree, which shows who infected whom, from the observed dates of onset was performed using the serial interval. Furthermore, a likelihood based approach was used for the time inhomogeneous evaluation of the outbreaks for which there was scarcity of cases. RESULTS According to the estimates, the basic reproduction number, R(0), was on the order of 2.8 to 3.5, which is higher than previous estimates. The lower 95% confidence intervals of R(0) exceeded unity. The effective reproduction number declined below unity after control measures were introduced in Mukden, and before the official implementation in Madagascar. CONCLUSION While the time course of the latter outbreak could be explained by intrinsic factors and stochasticity in this remote and scarcely populated area, the former in Mukden suggests the possible continued chains of transmission in highly populated areas. Using the proposed methods, the who infected whom information permitted the evaluation of the time inhomogeneous transmission potential in relation to public health measures. The study also tackles the problem of statistical estimation of R(0) based on similar information, which was previously performed simply by counting the number of secondary transmissions regardless of time.","title":"Transmission potential of primary pneumonic plague: time inhomogeneous evaluation based on historical documents of the transmission network.","annotator_investigating_R0":"1","text_response":"disease name: primary pneumonic plague\\r\\nlocation: Mukden, China\\r\\ndate: 1946\\r\\nR0 value: 2.8 to 3.5\\r\\n%CI values: The lower 95% confidence intervals of R(0) exceeded unity\\r\\nmethod: statistical estimation of R(0) based on similar information\\r\\n|\\r\\ndisease name: primary pneumonic plague\\r\\nlocation: Madagascar\\r\\ndate: 1957\\r\\nR0 value: 2.8 to 3.5\\r\\n%CI values: The lower 95% confidence intervals of R(0) exceeded unity\\r\\nmethod: statistical estimation of R(0) based on similar information","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"primary pneumonic plague\\",\\r\\n\\"location\\": \\"Mukden, China\\",\\r\\n\\"date\\": \\"1946\\",\\r\\n\\"R0 value\\": \\"2.8 to 3.5\\",\\r\\n\\"%CI values\\": \\"The lower 95% confidence intervals of R(0) exceeded unity\\",\\r\\n\\"method\\": \\"statistical estimation of R(0) based on similar information\\"}},{\\"contribution\\":{\\"disease name\\": \\"primary pneumonic plague\\",\\r\\n\\"location\\": \\"Madagascar\\",\\r\\n\\"date\\": \\"1957\\",\\r\\n\\"R0 value\\": \\"2.8 to 3.5\\",\\r\\n\\"%CI values\\": \\"The lower 95% confidence intervals of R(0) exceeded unity\\",\\r\\n\\"method\\": \\"statistical estimation of R(0) based on similar information\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"Yersinia pestis\\", \\"location\\": \\"Mukden, China (1946)\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"2.8 to 3.5\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"serial interval and likelihood based approach\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Yersinia pestis\\", \\"location\\": \\"Madagascar (1957)\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"serial interval and likelihood based approach\\" } } ]","publish_time":"2006","cluster_id":"1245"},{"main_cord_uid":"wgwjwxjb","cord_uid":"wgwjwxjb","abstract":"In this work, a new compartmental mathematical model of COVID-19 pandemic has been proposed incorporating imperfect quarantine and disrespectful behavior of citizens towards lockdown policies, which are evident in most of the developing countries. An integer derivative model has been proposed initially and then the formula for calculating basic reproductive number, R 0 of the model has been presented. Cameroon has been considered as a representative for the developing countries and the epidemic threshold, R 0 has been estimated to be ~ 3.41 ( 95 % CI : 2.2 - 4.4 ) as of July 9, 2020. Using real data compiled by the Cameroonian government, model calibration has been performed through an optimization algorithm based on renowned trust-region-reflective (TRR) algorithm. Based on our projection results, the probable peak date is estimated to be on August 1, 2020 with approximately 1073 ( 95 % CI : 714 - 1654 ) daily confirmed cases. The tally of cumulative infected cases could reach ~ 20, 100 ( 95 % CI : 17 , 343 - 24 , 584 ) cases by the end of August 2020. Later, global sensitivity analysis has been applied to quantify the most dominating model mechanisms that significantly affect the progression dynamics of COVID-19. Importantly, Caputo derivative concept has been performed to formulate a fractional model to gain a deeper insight into the probable peak dates and sizes in Cameroon. By showing the existence and uniqueness of solutions, a numerical scheme has been constructed using the Adams-Bashforth-Moulton method. Numerical simulations have enlightened the fact that if the fractional order &#945; is close to unity, then the solutions will converge to the integer model solutions, and the decrease of the fractional-order parameter (0 < &#945; < 1) leads to the delaying of the epidemic peaks.","title":"Forecasting of COVID-19 pandemic: From integer derivatives to fractional derivatives","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Cameroon\\r\\ndate: -\\r\\nR0 value: 3.41\\r\\n%CI values: ( 95 % CI : 2.2 - 4.4 )\\r\\nmethod: compartmental mathematical model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Cameroon\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"3.41\\",\\r\\n\\"%CI values\\": \\"( 95 % CI : 2.2 - 4.4 )\\",\\r\\n\\"method\\": \\"compartmental mathematical model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Cameroon\\", \\"date\\": \\"as of July 9, 2020\\", \\"R0 value\\": \\"3.31\\", \\"%CI values\\": \\"(95% CI : 2.2 - 4.4)\\", \\"method\\": \\"compartmental mathematical model\\" } } ]","publish_time":"2020"},{"main_cord_uid":"qnuec68y","cord_uid":"qnuec68y","abstract":"We develop an epidemic model to explain and predict the dynamics of the SARS-CoV-2 virus and to assess the economic costs of lockdown scenarios. The standard epidemic three-variable model, SIR (Susceptible, Infected and Removed) is extended into a five-variable model SCARE: Susceptible, Carrier, Affected (i.e. sick), Recovered and Eliminated (i.e. dead). Using WHO and Oxford data on cases and deaths, we rely on indirect inference techniques to estimate the parameters of SIR and SCARE. We consider different observation rates and stringencies of lockdown. Both models are estimated for five countries and provide predictions on the number of cases, the number of deaths, and the basic reproduction number, R0. SCARE is used to test the impact of lockdown policies on economic costs for the well-documented Belgium case. Economic assessments of epidemic results on hospital, morbidity and mortality together with macro-economic impacts show that the total net benefits of the Belgian lockdown policy is negative for low valuations of life years lost. The gains of extending the Belgian lockdown policy are negative even for high valuation of life.","title":"Scare: When Economics Meets Epidemiology with COVID-19","annotator_investigating_R0":"0","text_response":"disease name: COVID-19\\r\\nlocation: Belgium\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: standard epidemic three-variable model, SIR (Susceptible, Infected and Removed) is extended into a five-variable model SCARE: Susceptible, Carrier, Affected (i.e. sick), Recovered and Eliminated (i.e. dead)","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Belgium\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"standard epidemic three-variable model, SIR (Susceptible, Infected and Removed) is extended into a five-variable model SCARE: Susceptible, Carrier, Affected (i.e. sick), Recovered and Eliminated (i.e. dead)\\"}}]","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"r48t4g3k","cord_uid":"r48t4g3k","abstract":"The dynamics of immunity are crucial to understanding the long-term patterns of the SARS-CoV-2 pandemic. Several cases of reinfection with SARS-CoV-2 have been documented 48-142 days after the initial infection and immunity to seasonal circulating coronaviruses is estimated to be shorter than 1 year. Using an age-structured, deterministic model, we explore potential immunity dynamics using contact data from the UK population. In the scenario where immunity to SARS-CoV-2 lasts an average of three months for non-hospitalized individuals, a year for hospitalized individuals, and the effective reproduction number after lockdown ends is 1.2 (our worst-case scenario), we find that the secondary peak occurs in winter 2020 with a daily maximum of 387 000 infectious individuals and 125 000 daily new cases; threefold greater than in a scenario with permanent immunity. Our models suggest that longitudinal serological surveys to determine if immunity in the population is waning will be most informative when sampling takes place from the end of the lockdown in June until autumn 2020. After this period, the proportion of the population with antibodies to SARS-CoV-2 is expected to increase due to the secondary wave. Overall, our analysis presents considerations for policy makers on the longer-term dynamics of SARS-CoV-2 in the UK and suggests that strategies designed to achieve herd immunity may lead to repeated waves of infection as immunity to reinfection is not permanent. This article is part of the theme issue \'Modelling that shaped the early COVID-19 pandemic response in the UK\'.","title":"Dynamics of SARS-CoV-2 with waning immunity in the UK population","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"e5ufj3yt","cord_uid":"e5ufj3yt","abstract":"To investigate the early epidemic of COVID-19, a total of 176 confirmed COVID-19 cases in Shiyan city, Hubei province, China were surveyed. Our data indicated that the rate of emergence of early confirmed COVID-19 cases in Hubei province outside Wuhan was dependent on migration population, and the second-generation of patients were family clusters originating from Wuhan travelers. Epidemiological investigation indicated that the reproductive number (R0) under containment strategies was 1.81, and asymptomatic SARS-CoV-2 carriers were contagious with a transmission rate of 10.7%. Among the 176 patients, 53 were admitted to the Renmin Hospital of Hubei University of Medicine. The clinical characteristics of these 53 patients were collected and compared based on a positive RT-PCR test and presence of pneumonia. Clinical data showed that 47.2% (25/53) of COVID-19 patients were co-infected with Mycoplasma pneumoniae, and COVID-19 patients coinfected with M. pneumoniae had a higher percentage of monocytes (P < 0.0044) and a lower neutrophils percentage (P < 0.0264). Therefore, it is important to assess the transmissibility of infected asymptomatic individuals for SARS-CoV-2 transmission; moreover, clinicians should be alert to the high incidence of co-infection with M. pneumoniae in COVID-19 patients.","title":"Epidemiological and Clinical Characteristics of Patients With Coronavirus Disease-2019 in Shiyan City, China","annotator_investigating_R0":"1","text_response":"disease name: Coronavirus Disease-2019\\r\\nlocation: Shiyan City, Hubei Province, China\\r\\ndate: -\\r\\nR0 value: 1.81\\r\\n%CI values: -\\r\\nmethod: Epidemiological investigation","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Coronavirus Disease-2019\\",\\r\\n\\"location\\": \\"Shiyan City, Hubei Province, China\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"1.81\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Epidemiological investigation\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Shiyan City, Hubei Province, China\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"1.81\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Epidemiological investigation\\" } } ]","publish_time":"2020"},{"main_cord_uid":"hm3lr16i","cord_uid":"hm3lr16i","abstract":"BACKGROUND: Face masks have become commonplace across the USA because of the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) epidemic. Although evidence suggests that masks help to curb the spread of the disease, there is little empirical research at the population level. We investigate the association between self-reported mask-wearing, physical distancing, and SARS-CoV-2 transmission in the USA, along with the effect of statewide mandates on mask uptake. METHODS: Serial cross-sectional surveys were administered via a web platform to randomly surveyed US individuals aged 13 years and older, to query self-reports of face mask-wearing. Survey responses were combined with instantaneous reproductive number (Rt) estimates from two publicly available sources, the outcome of interest. Measures of physical distancing, community demographics, and other potential sources of confounding (from publicly available sources) were also assessed. We fitted multivariate logistic regression models to estimate the association between mask-wearing and community transmission control (Rt<1). Additionally, mask-wearing in 12 states was evaluated 2 weeks before and after statewide mandates. FINDINGS: 378\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020207 individuals responded to the survey between June 3 and July 27, 2020, of which 4186 were excluded for missing data. We observed an increasing trend in reported mask usage across the USA, although uptake varied by geography. A logistic model controlling for physical distancing, population demographics, and other variables found that a 10% increase in self-reported mask-wearing was associated with an increased odds of transmission control (odds ratio 3\xc3\u201a\xc2\xb753, 95% CI 2\xc3\u201a\xc2\xb703-6\xc3\u201a\xc2\xb743). We found that communities with high reported mask-wearing and physical distancing had the highest predicted probability of transmission control. Segmented regression analysis of reported mask-wearing showed no statistically significant change in the slope after mandates were introduced; however, the upward trend in reported mask-wearing was preserved. INTERPRETATION: The widespread reported use of face masks combined with physical distancing increases the odds of SARS-CoV-2 transmission control. Self-reported mask-wearing increased separately from government mask mandates, suggesting that supplemental public health interventions are needed to maximise adoption and help to curb the ongoing epidemic. FUNDING: Flu Lab, Google.org (via the Tides Foundation), National Institutes for Health, National Science Foundation, Morris-Singer Foundation, MOOD, Branco Weiss Fellowship, Ending Pandemics, Centers for Disease Control and Prevention (USA).","title":"Mask-wearing and control of SARS-CoV-2 transmission in the USA: a cross-sectional study","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"mtthwhbm","cord_uid":"mtthwhbm","abstract":"BACKGROUND: Restricting human mobility is an effective strategy used to control disease spread. However, whether mobility restriction is a proportional response to control the ongoing COVID-19 pandemic is unclear. We aimed to develop a model that can quantify the potential effects of various intracity mobility restrictions on the spread of COVID-19. METHODS: In this modelling study, we used anonymous and aggregated mobile phone sightings data to build a susceptible\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153exposed\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153infectious\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153recovered transmission model for COVID-19 based on the city of Shenzhen, China. We simulated how disease spread changed when we varied the type and magnitude of mobility restrictions in different transmission scenarios, with variables such as the basic reproductive number (R(0)), length of infectious period, and the number of initial cases. FINDINGS: 331 COVID-19 cases distributed across the ten regions of Shenzhen were reported on Feb 7, 2020. In our basic scenario (R(0) of 2\xc3\u201a\xc2\xb768), mobility reduction of 20\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u015360% within the city had a notable effect on controlling COVID-19 spread: a flattening of the peak number of cases by 33% (95% UI 21\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u015342) and delay to the peak number by 2 weeks with a 20% restriction, 66% (48\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u015375) reduction and 4 week delay with a 40% restriction, and 91% (79\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u015395) reduction and 14 week delay with a 60% restriction. The effects of mobility restriction were increased when combined with reductions of 25% or 50% in transmissibility of the virus. In specific analyses of mobility restrictions for individuals with symptomatic infections and for high-risk regions, these measures also had substantial effects on reducing the spread of COVID-19. For example, the peak of the epidemic was delayed by 2 weeks if the proportion of individuals with symptomatic infections who could move freely was maintained at 20%, and by 4 weeks if two high-risk regions were locked down. The simulation results were also affected by various transmission parameters. INTERPRETATION: Our model shows the effects of various types and magnitudes of mobility restrictions on controlling COVID-19 outbreaks at the city level in Shenzhen, China. The model could help policy makers to establish the optimal combinations of mobility restrictions during the COVID-19 pandemic, especially to assess the potential positive effects of mobility restriction on public health in view of the potential negative economic and societal effects. FUNDING: Guangdong Medical Science Fund, and National Natural Science Foundation of China.","title":"Effects of human mobility restrictions on the spread of COVID-19 in Shenzhen, China: a modelling study using mobile phone data","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-07-27 10:00:00"},{"main_cord_uid":"t4kkydnm","cord_uid":"t4kkydnm","abstract":"In managing COVID-19 with non-pharmaceutical interventions, occupancy of intensive care units (ICU) is often used as an indicator to inform when to intensify mitigation and thus reduce SARS-CoV-2 transmission, strain on ICUs, and deaths. However, ICU occupancy thresholds at which action should be taken are often selected arbitrarily. We propose a quantitative approach using mathematical modeling to identify ICU occupancy thresholds at which mitigation should be triggered to avoid exceeding the ICU capacity available for COVID-19 patients. We used a stochastic compartmental model to simulate SARS-CoV-2 transmission and disease progression, including critical cases that would require intensive care. We calibrated the model for the United States city of Chicago using daily COVID-19 ICU and hospital census data between March and August 2020. We projected ICU occupancies from September to May 2021 under two possible levels of transmission increase. The effect of combined mitigation measures was modeled as a decrease in the transmission rate that took effect when projected ICU occupancy reached a specified threshold. We found that mitigation did not immediately eliminate the risk of exceeding ICU capacity. Delaying action by 7 days increased the probability of exceeding ICU capacity by 10-60% and this increase could not be counteracted by stronger mitigation. Even under modest transmission increase, a threshold occupancy no higher than 60% was required when mitigation reduced the reproductive number Rt to just below 1. At higher transmission increase, a threshold of at most 40% was required with mitigation that reduced Rt below 0.75 within the first two weeks after mitigation. Our analysis demonstrates a quantitative approach for the selection of ICU occupancy thresholds that considers parameter uncertainty and compares relevant mitigation and transmission scenarios. An appropriate threshold will depend on the location, number of ICU beds available for COVID-19, available mitigation options, feasible mitigation strengths, and tolerated durations of intensified mitigation.","title":"Modeling robust COVID-19 intensive care unit occupancy thresholds for imposing mitigation to prevent exceeding capacities","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"w94v2ozp","cord_uid":"w94v2ozp","abstract":"With the aim of studying the spread of the SARS-CoV-2 infection in the Tuscany region of Italy during the first epidemic wave (February-June 2020), we define a compartmental model that accounts for both detected and undetected infections and assumes that only notified cases can die. We estimate the infection fatality rate, the case fatality rate, and the basic reproduction number, modeled as a time-varying function, by calibrating on the cumulative daily number of observed deaths and notified infected, after fixing to plausible values the other model parameters to assure identifiability. The confidence intervals are estimated by a parametric bootstrap procedure and a Global Sensitivity Analysis is performed to assess the sensitivity of the estimates to changes in the values of the fixed parameters. According to our results, the basic reproduction number drops from an initial value of 6.055 to 0 at the end of the national lockdown, then it grows again, but remaining under 1. At the beginning of the epidemic, the case and the infection fatality rates are estimated to be 13.1% and 2.3%, respectively. Among the parameters considered as fixed, the average time from infection to recovery for the not notified infected appears to be the most impacting one on the model estimates. The probability for an infected to be notified has a relevant impact on the infection fatality rate and on the shape of the epidemic curve. This stresses the need of collecting information on these parameters to better understand the phenomenon and get reliable predictions.","title":"The first wave of the SARS-CoV-2 epidemic in Tuscany (Italy): A SI2R2D compartmental model with uncertainty evaluation","annotator_investigating_R0":"1","text_response":"disease name: SARS-CoV-2\\r\\nlocation: Tuscany , Italy\\r\\ndate: (February-June 2020)\\r\\nR0 value: 6.055\\r\\n%CI values: -\\r\\nmethod: compartmental model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"SARS-CoV-2\\",\\r\\n\\"location\\": \\"Tuscany , Italy\\",\\r\\n\\"date\\": \\"(February-June 2020)\\",\\r\\n\\"R0 value\\": \\"6.055\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"compartmental model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"SARS-CoV-2\\", \\"location\\": \\"Tuscany (Italy)\\", \\"date\\": \\"(February-June 2020)\\", \\"R0 value\\": \\"6.055\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"compartmental model\\" } } ]","publish_time":"2021"},{"main_cord_uid":"rl6yum7n","cord_uid":"rl6yum7n","abstract":"Severe acute respiratory syndrome (SARS) has been the first severe contagious disease to emerge in the 21st century. The available epidemic curves for SARS show marked differences between the affected regions with respect to the total number of cases and epidemic duration, even for those regions in which outbreaks started almost simultaneously and similar control measures were implemented at the same time. The authors developed a likelihood-based estimation procedure that infers the temporal pattern of effective reproduction numbers from an observed epidemic curve. Precise estimates for the effective reproduction numbers were obtained by applying this estimation procedure to available data for SARS outbreaks that occurred in Hong Kong, Vietnam, Singapore, and Canada in 2003. The effective reproduction numbers revealed that epidemics in the various affected regions were characterized by markedly similar disease transmission potentials and similar levels of effectiveness of control measures. In controlling SARS outbreaks, timely alerts have been essential: Delaying the institution of control measures by 1 week would have nearly tripled the epidemic size and would have increased the expected epidemic duration by 4 weeks.","title":"Different Epidemic Curves for Severe Acute Respiratory Syndrome Reveal Similar Impacts of Control Measures","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2004-09-15 10:00:00"},{"main_cord_uid":"jznzhmlp","cord_uid":"jznzhmlp","abstract":"BACKGROUND: Malaria antigen-specific antibodies and polymorphisms in host receptors involved in antibody functionality have been associated with different outcomes of Plasmodium falciparum infections. Thus, to identify key prospective malaria antigens for vaccine development, there is the need to evaluate the associations between malaria antibodies and antibody dependent host factors with more rigorous statistical methods. In this study, different statistical models were used to evaluate the predictive performance of malaria-specific antibodies and host gene polymorphisms on P. falciparum infection in a longitudinal cohort study involving Ghanaian children. METHODS: Models with different functional forms were built using known predictors (age, sickle cell status, blood group status, parasite density, and mosquito bed net use) and malaria antigen-specific immunoglobulin (Ig) G and IgG subclasses and FCGR3B polymorphisms shown to mediate antibody-dependent cellular functions. Malaria antigens studied were Merozoite surface proteins (MSP-1 and MSP-3), Glutamate Rich Protein (GLURP)-R0, R2, and the Apical Membrane Antigen (AMA-1). The models were evaluated through visualization and assessment of differences between the Area Under the Receiver Operating Characteristic Curve and Brier Score estimated by suitable internal cross-validation designs. RESULTS: This study found that the FCGR3B-c.233C>A genotype and IgG against AMA1 were relatively better compared to the other antibodies and FCGR3B genotypes studied in classifying or predicting malaria risk among children. CONCLUSIONS: The data supports the P. falciparum, AMA1 as an important malaria vaccine antigen, while FCGR3B-c.233C>A under the additive and dominant models of inheritance could be an important modifier of the effect of malaria protective antibodies.","title":"Evaluating the predictive performance of malaria antibodies and FCGR3B gene polymorphisms on Plasmodium falciparum infection outcome: a prospective cohort study","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-08-27 00:00:00"},{"main_cord_uid":"nf6tz36s","cord_uid":"nf6tz36s","abstract":"Despite efforts made to model and predict COVID-19 transmission, large predictive uncertainty remains. Failure to understand the dynamics of the nonlinear pandemic prediction model is an important reason. To this end, local and multiple global sensitivity analysis approaches are synthetically applied to analyze the sensitivities of parameters and initial state variables and community size (N) in susceptible-infected-recovered (SIR) and its variant susceptible-exposed-infected-recovered (SEIR) models and basic reproduction number (R0), aiming to provide prior information for parameter estimation and suggestions for COVID-19 prevention and control measures. We found that N influences both the maximum number of actively infected cases and the date on which the maximum number of actively infected cases is reached. The high effect of N on maximum actively infected cases and peak date suggests the necessity of isolating the infected cases in a small community. The protection rate and average quarantined time are most sensitive to the infected populations, with a summation of their first-order sensitivity indices greater than 0.585, and their interactions are also substantial, being 0.389 and 0.334, respectively. The high sensitivities and interaction between the protection rate and average quarantined time suggest that protection and isolation measures should always be implemented in conjunction and started as early as possible. These findings provide insights into the predictability of the pandemic models by estimating influential parameters and suggest how to effectively prevent and control epidemic transmission.","title":"Understanding the dynamics of pandemic models to support predictions of COVID-19 transmission: Parameter sensitivity analysis of the SIR-type model","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2022"},{"main_cord_uid":"sw4g4ble","cord_uid":"sw4g4ble","abstract":"The role of lockdown measures in mitigating COVID-19 in Mexico is investigated using a comprehensive nonlinear ODE model. The model includes both asymptomatic and presymptomatic populations with the latter leading to sickness (with recovery, hospitalization and death as possible outcomes). We consider situations involving the application of social-distancing and other intervention measures in the time series of interest. We find optimal parametric fits to the time series of deaths (only), as well as to the time series of deaths and cumulative infections. We discuss the merits and disadvantages of each approach, we interpret the parameters of the model and assess the realistic nature of the parameters resulting from the optimization procedure. Importantly, we explore a model involving two sub-populations (younger and older than a specific age), to more accurately reflect the observed impact as concerns symptoms and behavior in different age groups. For definiteness and to separate people that are (typically) in the active workforce, our partition of population is with respect to members younger vs. older than the age of 65. The basic reproduction number of the model is computed for both the single- and the two-population variant. Finally, we consider what would be the impact of partial lockdown (involving only the older population) and full lockdown (involving the entire population) on the number of deaths and cumulative infections.","title":"Lockdown measures and their impact on single- and two-age-structured epidemic model for the COVID-19 outbreak in Mexico","annotator_investigating_R0":"0","text_response":"disease name: COVID-19\\r\\nlocation: Mexico\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: comprehensive nonlinear ODE model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Mexico\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"comprehensive nonlinear ODE model\\"}}]","json_model_response":"unanswerable","publish_time":"2021","cluster_id":"102"},{"main_cord_uid":"jc0byl72","cord_uid":"jc0byl72","abstract":"Countries worldwide have adopted various strategies to minimize the socio-economic impact of the ongoing COVID-19 pandemic. Stringency of imposed measures universally reflects the standpoint from which protecting public health and avoiding damage to economy are seen as contradictory objectives. Based on epidemic trajectories of 25 highly developed countries and 10 US states in the (mobility reduction)-(reproduction number) plane we showed that delay in imposition of nation-wide quarantine elevates the number of infections and deaths, surge of which inevitably has to be suppressed by stringent and sustained lockdown. As a consequence, cumulative mobility reduction and population-normalized cumulative number of COVID-19-associated deaths are significantly correlated and this correlation increases with time. Overall, we demonstrated that, as long as epidemic suppression is the aim, the trade-off between the death toll and economic loss is illusory: high death toll correlates with deep and long-lasting lockdown causing a severe economic downturn.","title":"Pareto-based evaluation of national responses to COVID-19 pandemic shows that saving lives and protecting economy are non-trade-off objectives","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"80bn2wgd","cord_uid":"80bn2wgd","abstract":"Non-pharmaceutical interventions (NPIs) are founded to be effective to delay epidemic spread and to reduce the number of patients. Moderate NPIs took in Japan seemed to have reduced the COVID-19 patients and to lower death rates, thus, effects of those NPIs are worthy of investigation. We used open source data and divided the data into three periods: Jan 22 to Feb 25 (Period I), Feb 26 to Apr 6 (Period II), and Apr 7 to May 14 (Period III). We developed the SIRD model and applied the Monte Carlo Simulation to estimate a combination of optimal results, including the peak of infected cases, the peak date, and R0. For Period I, the estimated peak infected cases were smaller than the observed ones, the peak date was earlier than the observed one, and the R0 was about 4.66. For the other two periods, the estimated cases were more, and the peak dates were earlier than the observed ones. The R0 was 2.50 in Period II, and 1.79 in Period III. NPIs took in Japan might have reduced more than 50% of the daily contacts per people compared to that before COVID-19. Owing to the effects of NPIs, the Japanese society had avoided collapse of medical service. Nevertheless, the capacity of daily RT-PCR may have restricted the reported confirmed cases.","title":"The effect of non-pharmaceutical interventions (NPIs) on the spread of COVID-19 pandemic in Japan: A modeling study","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Japan\\r\\ndate: Jan 22 to Feb 25 (Period I)\\r\\nR0 value: 4.66\\r\\n%CI values: -\\r\\nmethod: SIRD model and the Monte Carlo Simulation\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Japan\\r\\ndate: Feb 26 to Apr 6 (Period II)\\r\\nR0 value: 2.50\\r\\n%CI values: -\\r\\nmethod: SIRD model and the Monte Carlo Simulation\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Japan\\r\\ndate: Apr 7 to May 14 (Period III)\\r\\nR0 value: 1.79\\r\\n%CI values: -\\r\\nmethod: SIRD model and the Monte Carlo Simulation","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Japan\\",\\r\\n\\"date\\": \\"Jan 22 to Feb 25 (Period I)\\",\\r\\n\\"R0 value\\": \\"4.66\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SIRD model and the Monte Carlo Simulation\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Japan\\",\\r\\n\\"date\\": \\"Feb 26 to Apr 6 (Period II)\\",\\r\\n\\"R0 value\\": \\"2.50\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SIRD model and the Monte Carlo Simulation\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Japan\\",\\r\\n\\"date\\": \\"Apr 7 to May 14 (Period III)\\",\\r\\n\\"R0 value\\": \\"1.79\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SIRD model and the Monte Carlo Simulation\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Japan\\", \\"date\\": \\"Jan 22 to Feb 25 (Period I)\\", \\"R0 value\\": \\"4.66\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SIRD model and applied the Monte Carlo Simulation\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Japan\\", \\"date\\": \\"Feb 26 to Apr 6 (Period II)\\", \\"R0 value\\": \\"2.55\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SIRD model and applied the Monte Carlo Simulation\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Japan\\", \\"date\\": \\"Apr 7 to May 14 (Period III)\\", \\"R0 value\\": \\"1.79\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SIRD model and applied the Monte Carlo Simulation\\" } } ]","publish_time":"2020-05-23 10:00:00","cluster_id":"860"},{"main_cord_uid":"mhmc3ts8","cord_uid":"mhmc3ts8","abstract":"In the Czech Republic, the first COVID-19 cases were confirmed on 1 March 2020; early population interventions were adopted in the following weeks. A simple epidemiological model was developed to help decision-makers understand the course of the epidemic and perform short-term predictions. In this paper, we present the use of the model and estimated changes in the reproduction number (decrease from > 2.00 to < 1.00 over March and April) following adopted interventions.","title":"Modelling the first wave of the COVID-19 epidemic in the Czech Republic and the role of government interventions","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Czech Republic\\r\\ndate: March and April 2020\\r\\nR0 value: >2.00 to < 1.00\\r\\n%CI values: -\\r\\nmethod: simple epidemiological model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Czech Republic\\",\\r\\n\\"date\\": \\"March and April 2020\\",\\r\\n\\"R0 value\\": \\">2.00 to < 1.00\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"simple epidemiological model\\"}}]","json_model_response":" { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Czech Republic\\", \\"date\\": \\"March and April\\", \\"R0 value\\": \\"decrease from > 2.00 to  1.00\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"simple epidemiological model\\" } } ]","publish_time":"2020-09-11 10:00:00"},{"main_cord_uid":"t9109ckd","cord_uid":"t9109ckd","abstract":"Thailand was hit by the second wave of Coronavirus Disease 2019 (COVID-19) in a densely migrant-populated province (Samut Sakhon). COVID-19 vaccines were known to be effective; however, the supply was limited. Therefore, this study aimed to predict the effectiveness of Thailand\xc3\xa2\xe2\u201a\xac\xe2\u201e\xa2s COVID-19 vaccination strategy. We obtained most of the data from the Ministry of Public Health. Deterministic system dynamics and compartmental models were utilized. The reproduction number (R) between Thais and migrants was estimated at 1.25 and 2.5, respectively. Vaccine effectiveness (VE) to prevent infection was assumed at 50%. In Samut Sakhon, there were 500,000 resident Thais and 360,000 resident migrants. The contribution of migrants to the province\xc3\xa2\xe2\u201a\xac\xe2\u201e\xa2s gross domestic product was estimated at 20%. Different policy scenarios were analyzed. The migrant-centric vaccination policy scenario received the lowest incremental cost per one case or one death averted compared with the other scenarios. The Thai-centric policy scenario yielded an incremental cost of 27,191 Baht per one life saved, while the migrant-centric policy scenario produced a comparable incremental cost of 3782 Baht. Sensitivity analysis also demonstrated that the migrant-centric scenario presented the most cost-effective outcome even when VE diminished to 20%. A migrant-centric policy yielded the smallest volume of cumulative infections and deaths and was the most cost-effective scenario, independent of R and VE values. Further studies should address political feasibility and social acceptability of migrant vaccine prioritization.","title":"Prioritization of the Target Population for Coronavirus Disease 2019 (COVID-19) Vaccination Program in Thailand","annotator_investigating_R0":"1","text_response":"disease name: Coronavirus Disease 2019 (COVID-19)\\r\\nlocation: Thailand\\r\\ndate: -\\r\\nR0 value: reproduction number (R) between Thais and migrants was estimated at 1.25 and 2.5, respectively\\r\\n%CI values: -\\r\\nmethod: Deterministic system dynamics and compartmental models","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\",\\r\\n\\"location\\": \\"Thailand\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"reproduction number (R) between Thais and migrants was estimated at 1.25 and 2.5, respectively\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Deterministic system dynamics and compartmental models\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\", \\"location\\": \\"Thailand\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"1.25\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Deterministic system dynamics and compartmental models\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\", \\"location\\": \\"Middle East\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"2.5\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Deterministic system dynamics and compartmental models\\" } } ]","publish_time":"2021-10-14 00:00:00"},{"main_cord_uid":"bez86xik","cord_uid":"bez86xik","abstract":"Background and aim: A shutdown of businesses enacted during the SARS-CoV-2 pandemic can serve different goals, e.g., preventing the intensive care unit (ICU) capacity from being overwhelmed (\'flattening the curve\') or keeping the reproduction number substantially below one (\'squashing the curve\'). The aim of this study was to determine the clinical and economic value of a shutdown that is successful in \'flattening\' or \'squashing the curve\' in Germany. Methods: In the base case, the study compared a successful shutdown to a worst-case scenario with no ICU capacity left to treat COVID-19 patients. To this end, a decision model was developed using, e.g., information on age-specific fatality rates, ICU outcomes, and the herd protection threshold. The value of an additional life year was borrowed from new, innovative oncological drugs, as cancer reflects a condition with a similar morbidity and mortality burden in the general population in the short term as COVID-19. Results: A shutdown that is successful in \'flattening the curve\' is projected to yield an average health gain between 0.01 and 0.05 life years (0.1 to 0.6 months) per capita in the German population. The corresponding economic value ranges between \xc3\u201a\xe2\u201a\xac616 and \xc3\u201a\xe2\u201a\xac4797 per capita or, extrapolated to the total population, 1% to 12% of the gross domestic product (GDP) in 2019. A shutdown that is successful in \'squashing the curve\' is expected to yield a minimum health gain of 0.8 life years (0.9 months) per capita, corresponding to 19% of the GDP in 2019. Results are particularly sensitive to mortality data and the prevalence of undetected cases. Conclusion: A successful shutdown is forecasted to yield a considerable gain in life years in the German population. Nevertheless, questions around the affordability and underfunding of other parts of the healthcare system emerge.","title":"The Clinical and Economic Value of a Successful Shutdown During the SARS-CoV-2 Pandemic in Germany","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"tvwlvoz6","cord_uid":"tvwlvoz6","abstract":"New habitat-based models for spread of hantavirus are developed which account for interspecies interaction. Existing habitat-based models do not consider interspecies pathogen transmission, a primary route for emergence of new infectious diseases and reservoirs in wildlife and man. The modeling of interspecies transmission has the potential to provide more accurate predictions of disease persistence and emergence dynamics. The new models are motivated by our recent work on hantavirus in rodent communities in Paraguay. Our Paraguayan data illustrate the spatial and temporal overlap among rodent species, one of which is the reservoir species for Jabora virus and others which are spillover species. Disease transmission occurs when their habitats overlap. Two mathematical models, a system of ordinary differential equations (ODE) and a continuous-time Markov chain (CTMC) model, are developed for spread of hantavirus between a reservoir and a spillover species. Analysis of a special case of the ODE model provides an explicit expression for the basic reproduction number, \xc3\xa2\xe2\u20ac\u017e\xe2\u20ac\xba(0), such that if \xc3\xa2\xe2\u20ac\u017e\xe2\u20ac\xba(0) < 1, then the pathogen does not persist in either population but if \xc3\xa2\xe2\u20ac\u017e\xe2\u20ac\xba(0) > 1, pathogen outbreaks or persistence may occur. Numerical simulations of the CTMC model display sporadic disease incidence, a new behavior of our habitat-based model, not present in other models, but which is a prominent feature of the seroprevalence data from Paraguay. Environmental changes that result in greater habitat overlap result in more encounters among various species that may lead to pathogen outbreaks and pathogen establishment in a new host.","title":"A Habitat-Based Model for the Spread of Hantavirus Between Reservoir and Spillover Species","annotator_investigating_R0":"0","text_response":"disease name: Hantavirus\\r\\nlocation: Paraguay\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: System of ordinary differential equations (ODE) and a continuous-time Markov chain (CTMC) model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Hantavirus\\",\\r\\n\\"location\\": \\"Paraguay\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"System of ordinary differential equations (ODE) and a continuous-time Markov chain (CTMC) model\\"}}]","json_model_response":"unanswerable","publish_time":"2009-10-01 10:00:00"},{"main_cord_uid":"op1bes33","cord_uid":"op1bes33","abstract":"BACKGROUND: Bluetongue is a serious disease of ruminants caused by the bluetongue virus (BTV). BTV is transmitted by biting midges (Culicoides spp.). Serological evidence from livestock and the presence of at least one competent vector species of Culicoides suggests that transmission of BTV is possible and may have occurred in Kazakhstan. METHODS: We estimated the risk of transmission using a mathematical model of the reproduction number R(0) for bluetongue. This model depends on livestock density and climatic factors which affect vector density. Data on climate and livestock numbers from the 2466 local communities were used. This, together with previously published model parameters, was used to estimate R(0) for each month of the year. We plotted the results on isopleth maps of Kazakhstan using interpolation to smooth the irregular data. We also mapped the estimated proportion of the population requiring vaccination to prevent outbreaks of bluetongue. RESULTS: The results suggest that transmission of bluetongue in Kazakhstan is not possible in the winter from October to March. Assuming there are vector-competent species of Culicoides endemic in Kazakhstan, then low levels of risk first appear in the south of Kazakhstan in April before spreading north and intensifying, reaching maximum levels in northern Kazakhstan in July. The risk declined in September and had disappeared by October. CONCLUSION: These results should aid in surveillance efforts for the detection and control of bluetongue in Kazakhstan by indicating where and when outbreaks of bluetongue are most likely to occur. The results also indicate where vaccination efforts should be focussed to prevent outbreaks of disease. GRAPHICAL ABSTRACT: [Image: see text] SUPPLEMENTARY INFORMATION: The online version contains supplementary material available at 10.1186/s13071-021-04945-6.","title":"Modelling bluetongue risk in Kazakhstan","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"Bluetongue\\", \\"location\\": \\"Kazakhstan\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"mathematical model\\" } } ]","publish_time":"2021-09-25 00:00:00"},{"main_cord_uid":"li6t5neo","cord_uid":"li6t5neo","abstract":"In December 2019, the first patients in Wuhan, China were diagnosed with a primary atypical pneumonia, which showed to be unknown and contagious. Since then, known as COVID-19 disease, the responsible viral pathogen, SARS-CoV-2, has spread around the world in a pandemic. Decisions on how to deal with the crisis are often based on simulations of the pandemic spread of the virus. The results of some of these, as well as their methodology and possibilities for improvement, will be described in more detail in this paper in order to inform beyond the current public health dogma called \\"flatten-the-curve\\". There are several ways to model an epidemic in order to simulate the spread of diseases. Depending on the timeliness, scope and quality of the associated real data, these multivariable models differ in the value of used parameters, but also in the selection of considered influencing factors. It was exemplarily shown that epidemics in their course are simulated more realistically by models that assume subexponential growth. Furthermore, various simulations of the COVID-19 pandemic were presented in an European perspective, compared against each other and discussed in more detail. It is difficult to estimate how credible the simulations of the pandemic models currently are, so it remains to be seen whether the spread of the pandemic can be effectively reduced by the measures taken. Whether a model works well in reality is largely determined by the quality and scope of its underlying data. Past studies have shown that countermeasures are able to reduce reproduction numbers or transmission rates in epidemics. In addition to that, the presented modelling study provides a good framework for the creation of subexponential-growth-models for assessing the spread of COVID-19.","title":"COVID-19 mitigation strategies and overview on results from relevant studies in Europe","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"gfetl2xg","cord_uid":"gfetl2xg","abstract":"The Distributed Logistic Model and the Adaptive Logistic Model of epidemics are formulated and used to study the course of cases and deaths during the COVID-19 pandemic. The distributed model is designed to account for a spread of initiation times of hot spots across a country; it does especially well at capturing the initial and linear phases of epidemics. The adaptive model accounts for the development of social mitigation factors, and does especially well at capturing the declining phases of epidemics. The historical data for the U.S., Italy, and the U.K. are analyzed in detail. The parameters of the fits to the two models provide complementary information about the pandemic. The initial infection rate constant was r0 {approx} 0.29 per day for each country, and the effective infection rate constants evolved with time in essentially the same way for each. This suggests that mitigation effects were equally effective in all three countries. Analysis with the distributed model suggests that it took somewhat different times T for the epidemic to spread across each country, with T(US) {approx} 50 days significantly greater than the T\'s of Italy or the U.K. The mortality ratio in the U.S. was about 0.061 while in Italy and U.K. it was much larger at about 0.15.","title":"Two New Models for Epidemics with Application to the COVID-19 Pandemic in the United States, Italy, and the United Kingdom","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: United States, Italy, and the United Kingdom\\r\\ndate: -\\r\\nR0 value: 0.29 per day for each country\\r\\n%CI values: -\\r\\nmethod: Distributed Logistic Model and the Adaptive Logistic Model of epidemics","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"United States, Italy, and the United Kingdom\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"0.29 per day for each country\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Distributed Logistic Model and the Adaptive Logistic Model of epidemics\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"the United States\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"The Distributed Logistic Model and the Adaptive Logistic Model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Italy\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"The Distributed Logistic Model and the Adaptive Logistic Model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United Kingdom\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"The Distributed Logistic Model and the Adaptive Logistic Model\\" } } ]","publish_time":"2020-07-14 00:00:00"},{"main_cord_uid":"sqdk57f9","cord_uid":"sqdk57f9","abstract":"Documentation in scientific literature is not available on prospective evaluation of the efficiency of the unlock measure related to COVID-19 transmission change points in India, projecting the infected population, planning suitable measures related to future interventions and lifting of restrictions so that the economic settings are not damaged beyond repair. We have applied SIR model and Bayesian approach combined with Monte Carlo Markov algorithms on the Indian COVID-19 daily new infected cases from 1 August 2020 to 30 September 2020. We showed that the COVID-19 epidemic declined after implementing unlock-4 measure and the identified change-points were consistent with the timelines of announced unlock-3 and unlock-4 measure, on 1 August 2020 and 1 September 2020, respectively, effectiveness of which were quantified as the change in both effective transmission rates (100% reduction) and the basic reproduction number attaining 1, implying measures taken to control and mitigate the COVID-19 epidemic in India managed to flatten and recede the epidemic curve.","title":"Detection of transmission change points during unlock-3 and unlock-4 measures controlling COVID-19 in India","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: India\\r\\ndate: 1 August 2020 to 30 September 2020\\r\\nR0 value: 1\\r\\n%CI values: -\\r\\nmethod: SIR model and Bayesian approach combined with Monte Carlo Markov algorithms","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"India\\",\\r\\n\\"date\\": \\"1 August 2020 to 30 September 2020\\",\\r\\n\\"R0 value\\": \\"1\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SIR model and Bayesian approach combined with Monte Carlo Markov algorithms\\"}}]","json_model_response":"unanswerable","publish_time":"2020-11-18 00:00:00"},{"main_cord_uid":"7kfr88g8","cord_uid":"7kfr88g8","abstract":"Background. The effective reproduction number R(e)(t) is a critical measure of epidemic potential. R(e)(t) can be calculated in near real time using an incidence time series and the generation time distribution: the time between infection events in an infector-infectee pair. In calculating R(e)(t), the generation time distribution is often approximated by the serial interval distribution: the time between symptom onset in an infector-infectee pair. However, while generation time must be positive by definition, serial interval can be negative if transmission can occur before symptoms, such as in covid-19, rendering such an approximation improper in some contexts. Methods. We developed a method to infer the generation time distribution from parametric definitions of the serial interval and incubation period distributions. We then compared estimates of R(e)(t) for covid-19 in the Greater Toronto Area of Canada using: negative-permitting versus non-negative serial interval distributions, versus the inferred generation time distribution. Results. We estimated the generation time of covid-19 to be Gamma-distributed with mean 3.99 and standard deviation 2.96 days. Relative to the generation time distribution, non-negative serial interval distribution caused overestimation of R(e)(t) due to larger mean, while negative-permitting serial interval distribution caused underestimation of R(e)(t) due to larger variance. Implications. Approximation of the generation time distribution of covid-19 with non-negative or negative-permitting serial interval distributions when calculating R(e)(t) may result in over or underestimation of transmission potential, respectively.","title":"Estimating effective reproduction number using generation time versus serial interval, with application to covid-19 in the Greater Toronto Area, Canada","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-11-01 05:00:00"},{"main_cord_uid":"pghy7llh","cord_uid":"pghy7llh","abstract":"This paper introduces a multigroup COVID-19 model with immunity, in which the total population of each group is partitioned into five compartments, that is, susceptible, exposed, infective, infective in treatment and recovered compartment. If the basic reproduction number is less than or equal to one, and the infection graph is strongly connected, then the disease-free equilibrium is globally asymptotically stable and the disease dies out. However, the COVID-19 is already in a pandemic state, and the basic reproduction number is large than one. Hence, in order to make the COVID-19 die out in some groups in an area, we design some appropriate control strategies which reduce the number of exposed people and increase the number of people treated. These two methods have been proved to be the most effective methods at present. An effective algorithm is proposed to identify the groups that need to be controlled. Finally, we use the actual limited data of Hubei, Guangdong and Zhejiang provinces in China to illustrate the effectiveness of the obtained results.","title":"Control of a multigroup COVID-19 model with immunity: treatment and test elimination","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-09-30 10:00:00"},{"main_cord_uid":"q40upcz6","cord_uid":"q40upcz6","abstract":"OBJECTIVES: to describe the epidemic trends of COVID-19 over time and by area in the territory covered by Milan\'s Agency for Health Protection (ATS-MI) from February to May 2020. DESIGN: descriptive study of COVID-19 cases. SETTING AND PARTICIPANTS: a new information system was developed to record COVID-19 cases with positive nasopharyngeal swab. Patients resident in the area covered by ATS-MI with symptom onset between February and May 2020 were selected. Different epidemic periods were considered based on the timeline of the various regional and national containment measures. MAIN OUTCOME MEASURES: case fatality ratios, incidence rates, and reproduction number by epidemic period and sub-area of ATS-MI. RESULTS: a total of 27,017 swab-positive COVID-19 cases were included. Mean age was 65 years and males were 45%. Incidence in the ATS-MI area was 776 per 100,000 population. The number of deaths was 4,660, the crude case fatality ratio was 17.3%, higher in males (21.2%) than in females (14.0%). The estimated reproduction number registered its peak (3.0) in the early stages of the epidemic and subsequently decreased. Territorial differences were observed in the epidemic spread, with a higher incidence in the Lodi area. CONCLUSIONS: estimated incidence and case fatality ratios were higher than national estimates for Italy. Each ATS-MI area had different epidemic spread patterns.","title":"Describing the epidemic trends of COVID-19 in the area covered by Agency for Health Protection of the Metropolitan Area of Milan","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Metropolitan Area of Milan\\r\\ndate: February to May 2020\\r\\nR0 value: 3.0\\r\\n%CI values: -\\r\\nmethod: -","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Metropolitan Area of Milan\\",\\r\\n\\"date\\": \\"February to May 2020\\",\\r\\n\\"R0 value\\": \\"3.0\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"-\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Milan\\", \\"date\\": \\"February to May 2020\\", \\"R0 value\\": \\"3.0\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } } ]","publish_time":"2020"},{"main_cord_uid":"0e0gnsb4","cord_uid":"7styuuzo","abstract":"Background: A novel coronavirus strain, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), emerged in China in late 2019. The resulting disease, Coronavirus Disease 2019 (COVID-2019), soon became a pandemic. This study aims to characterize key attributes of the epidemiology of this infection in China. Methods: An age-stratified mathematical model was constructed to describe the transmission dynamics and estimate the age-specific differences in the biological susceptibility to the infection, age-assortativeness in transmission mixing, case fatality rate (CFR), and transition in rate of infectious contacts (and reproduction number R0) following introduction of mass interventions. Results: The model estimated the infectious contact rate in early epidemic at 0.59 contacts per day (95% uncertainty interval (UI)=0.48-0.71). Relative to those 60-69 years of age, susceptibility to the infection was only 0.06 in those \xc3\xa2\xe2\u20ac\xb0\xc2\xa419 years, 0.34 in 20-29 years, 0.57 in 30-39 years, 0.69 in 40-49 years, 0.79 in 50-59 years, 0.94 in 70-79 years, and 0.88 in \xc3\xa2\xe2\u20ac\xb0\xc2\xa580 years. The assortativeness in transmission mixing by age was very limited at 0.004 (95% UI=0.002-0.008). Final CFR was 5.1% (95% UI=4.8-5.4%). R0 rapidly declined from 2.1 (95% UI=1.8-2.4) to 0.06 (95% UI=0.05-0.07) following onset of interventions. Conclusion: Age appears to be a principal factor in explaining the patterns of COVID-19 transmission dynamics in China. The biological susceptibility to the infection seems limited among children, intermediate among young to mid-age adults, but high among those >50 years of age. There was no evidence for differential contact mixing by age, consistent with most transmission occurring in households rather than in schools or workplaces.","title":"Characterizing key attributes of the epidemiology of COVID-19 in China: Model-based estimations","annotator_investigating_R0":"1","text_response":"disease name: Coronavirus Disease 2019 (COVID-2019)\\r\\nlocation: China\\r\\ndate: late 2019\\r\\nR0 value: 2.1\\r\\n%CI values: (95% UI=1.8-2.4)\\r\\nmethod: age-stratified mathematical model\\r\\n|\\r\\ndisease name: Coronavirus Disease 2019 (COVID-2019)\\r\\nlocation: China\\r\\ndate: following onset of interventions\\r\\nR0 value: 0.06\\r\\n%CI values: (95% UI=0.05-0.07)\\r\\nmethod: age-stratified mathematical model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Coronavirus Disease 2019 (COVID-2019)\\",\\r\\n\\"location\\": \\"China\\",\\r\\n\\"date\\": \\"late 2019\\",\\r\\n\\"R0 value\\": \\"2.1\\",\\r\\n\\"%CI values\\": \\"(95% UI=1.8-2.4)\\",\\r\\n\\"method\\": \\"age-stratified mathematical model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Coronavirus Disease 2019 (COVID-2019)\\",\\r\\n\\"location\\": \\"China\\",\\r\\n\\"date\\": \\"following onset of interventions\\",\\r\\n\\"R0 value\\": \\"0.06\\",\\r\\n\\"%CI values\\": \\"(95% UI=0.05-0.07)\\",\\r\\n\\"method\\": \\"age-stratified mathematical model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (COVID-2019)\\", \\"location\\": \\"China\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"2.1\\", \\"%CI values\\": \\"(95% UI=1.8-2.4)\\", \\"method\\": \\"age-stratified mathematical model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (COVID-2019)\\", \\"location\\": \\"China\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"0.66\\", \\"%CI values\\": \\"(95% UI=0.05-0.07)\\", \\"method\\": \\"age-stratified mathematical model\\" } } ]","publish_time":"2020-04-11 00:00:00","action":"change_main_cord_id","cluster_id":"25"},{"main_cord_uid":"b03s7wsw","cord_uid":"b03s7wsw","abstract":"BACKGROUND: Ambulatory antibiotic prescriptions without a clinic visit or without documentation of infection could represent overuse and contribute to adverse outcomes. We aim to describe US ambulatory antibiotic prescribing, including those without an associated visit or infection diagnosis. METHODS: We conducted an observational cohort study using data of all patients receiving antibacterial, antibiotic prescriptions from 04-01-2016 to 06-30-2018, in a large US private health insurance plan. We identified outpatient antibiotic prescriptions as: (1) associated with a clinician visit and an infection-related diagnosis; (2) associated with a clinician visit, but no infection-related diagnosis; or (3) not associated with an in-person clinician visit in the seven days prior to the prescription (non-visit-based). We then assessed whether non-visit-based antibiotic prescriptions (NVBAP) differed from visit-based antibiotics by patient, clinician, or antibiotic characteristics using multivariable models. FINDINGS: The cohort included 8\xc3\u201a\xc2\xb76M enrollees who filled 22\xc3\u201a\xc2\xb73M antibiotic prescriptions. NVBAP accounted for 31%(6\xc3\u201a\xc2\xb79M) of fills and non-infection-related prescribing accounted for 22%(4\xc3\u201a\xc2\xb79M). NVBAP rates were lower for children than for adults (0-17 years old, 16%; 18-64 years old, 33%; > 65 years old, 34%). Among most commonly-prescribed antibiotic classes, NVBAP was highest for penicillins (36%), and lowest for cephalosporins (25%) and macrolides (25%). Specialist physicians had the highest rate of NVBAP (38%), followed by internists (28%), family medicine (20%), and pediatricians (10%). In multivariable models, NVBAP was associated with increasing age and NVBAP was less likely for patients in the South, with more baseline clinical visits, or with chronic lung disease. INTERPRETATION: Over half of ambulatory antibiotic use was either non-visit based or non-infection-related. Particularly given healthcare changes due to the COVID-19 pandemic, efforts to improve antibiotic prescribing must account for non-visit-based and non-infection-related prescribing. FUNDING: This work was supported by a grant from the Agency for Healthcare Research and Quality (R01HS024930).","title":"Non-visit-based and non-infection-related antibiotic use in the US: a cohort study of privately insured patients during 2016-2018","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-08-01 10:00:00"},{"main_cord_uid":"30sh7zwv","cord_uid":"30sh7zwv","abstract":"We propose a stochastic SIR model, specified as a system of stochastic differential equations, to analyse the data of the Italian COVID-19 epidemic, taking also into account the under-detection of infected and recovered individuals in the population. We find that a correct assessment of the amount of under-detection is important to obtain reliable estimates of the critical model parameters. Moreover, a single SIR model over the whole epidemic period is unable to correctly describe the behaviour of the pandemic. Then, the adaptation of the model in every time-interval between relevant government decrees that implement contagion mitigation measures, provides short-term predictions and a continuously updated assessment of the basic reproduction number.","title":"A stochastic SIR model for the analysis of the COVID-19 Italian epidemic","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"-\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"a stochastic SIR model, specified as a system of stochastic differential equations\\" } } ]","publish_time":"2021"},{"main_cord_uid":"5aur6xd4","cord_uid":"5aur6xd4","abstract":"Coronavirus disease 2019 (COVID-19), caused by severe acute respiratory syndrome coronavirus - 2 (SARS-CoV-2), was declared a global pandemic on 11th March, 2020 by World Health Organization. As of now,27th May,2020, there are about 54,88,825 infected cases and 3,49,095 deaths globally. Coronavirus samples collected from all the countries have been sequenced for advanced studies in a bid to understand the structure and functioning of the virus. In our study we have tried working on every available sequence to setup both comparisons and co-relations. There is no such available study as of now for reference and hence it can become a pioneer stone in this direction. The mortality rate calculated turns out to be 9.19%,34.37% and 6.29% for SARS-2003, MERS-2012 and COVID-19 respectively. The basic reproduction rate R0 was 2-5 for SARS-2003, 0.3-0.8 for MERS-2012 and 1.4- 5.7 for COVID-19. We found out the relation between number of mutations and mortality as well as phylogenetic relations. High number of mutations corresponded to higher mortality rate as in countries like Italy and Spain. Alpha and Beta-coronaviruses show a common ancestor from which they descended. Brazil and Iran have shown similar phylogenetic descent explaining their mortality rate. India however showed a distant relation from the common ancestor of other genome sequences. This study highlights the mutations of the SARS-CoV2 virus as well as sets up a comparison with the previous outbreaks. Similar type of studies should be conducted when more genome samples are present. These results can also contribute towards making an effective anti-viral therapy and vaccines.","title":"Comparative analysis of SARS-CoV2 with special emphasis on genome sequences","annotator_investigating_R0":"1","text_response":"disease name: Coronavirus disease 2019 (COVID-19)\\r\\nlocation: Global\\r\\ndate: 27th May, 2020\\r\\nR0 value: 1.4- 5.7\\r\\n%CI values: -\\r\\nmethod: -","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Coronavirus disease 2019 (COVID-19)\\",\\r\\n\\"location\\": \\"Global\\",\\r\\n\\"date\\": \\"27th May, 2020\\",\\r\\n\\"R0 value\\": \\"1.4- 5.7\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"-\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"SARS-2003\\", \\"location\\": \\"-\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"2-5\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"MERS-2012\\", \\"location\\": \\"-\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"0.3-0.8\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"-\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"1.4- 5.7\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } } ]","publish_time":"2020"},{"main_cord_uid":"103c8wtt","cord_uid":"103c8wtt","abstract":"A series of spreadsheet simulations using SEIS, SEIR, and SEIRS models showed that different durations of effective immunity could have important consequences for the prevalence of an epidemic disease with COVID-19 characteristics. Immunity that lasted four weeks, twelve weeks, six months, one year, and two years was tested with pathogen R0 values of 1.5, 2.3, and 3.0. Shorter durations of immunity resulted in oscillations in disease prevalence. Immunity that lasted from three months to two years produced recurrent disease outbreaks triggered by the expiration of immunity. If immunity faded out gradually instead of persisting at full effectiveness to the end of the immune period, the recurrent outbreaks became more frequent. The duration of effective immunity is an important consideration in the epidemiology of a disease like COVID-19.","title":"The Influence of Time-Limited Immunity on a COVID-19 Epidemic: A Simulation Study","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-06-29 10:00:00"},{"main_cord_uid":"5hn193c7","cord_uid":"5hn193c7","abstract":"As of January 19, 2021, the cumulative number of people infected with coronavirus disease-2019 (COVID-19) in the United States has reached 24,433,486, and the number is still rising. The outbreak of the COVID-19 epidemic has not only affected the development of the global economy but also seriously threatened the lives and health of human beings around the world. According to the transmission characteristics of COVID-19 in the population, this study established a theoretical differential equation mathematical model, estimated model parameters through epidemiological data, obtained accurate mathematical models, and adopted global sensitivity analysis methods to screen sensitive parameters that significantly affect the development of the epidemic. Based on the established precise mathematical model, we calculate the basic reproductive number of the epidemic, evaluate the transmission capacity of the COVID-19 epidemic, and predict the development trend of the epidemic. By analyzing the sensitivity of parameters and finding sensitive parameters, we can provide effective control strategies for epidemic prevention and control. After appropriate modifications, the model can also be used for mathematical modeling of epidemics in other countries or other infectious diseases.","title":"Modeling the COVID-19 Epidemic With Multi-Population and Control Strategies in the United States","annotator_investigating_R0":"0","text_response":"disease name: COVID-19\\r\\nlocation: United States\\r\\ndate: As of January 19, 2021\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: theoretical differential equation mathematical model, estimated model parameters through epidemiological data, obtained accurate mathematical models, and adopted global sensitivity analysis methods","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"United States\\",\\r\\n\\"date\\": \\"As of January 19, 2021\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"theoretical differential equation mathematical model, estimated model parameters through epidemiological data, obtained accurate mathematical models, and adopted global sensitivity analysis methods\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United States\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"theoretical differential equation mathematical model\\" } } ]","publish_time":"2022-01-03 00:00:00"},{"main_cord_uid":"xab2t2j6","cord_uid":"xab2t2j6","abstract":"Social distancing measures have been implemented in the United States (US) since March 2020, to mitigate the spread of SARS-CoV-2, the causative agent of COVID-19. However, by mid-May most states began relaxing these measures to support the resumption of economic activity, even as disease incidence continued to increase in many states. To evaluate the impact of relaxing social distancing restrictions on COVID-19 dynamics and control in the US, we developed a transmission dynamic model and calibrated it to US state-level COVID-19 cases and deaths from March to June 20(th), 2020, using Bayesian methods. We used this model to evaluate the impact of reopening, social distancing, testing, contact tracing, and case isolation on the COVID-19 epidemic in each state. We found that using stay-at-home orders, most states were able to curtail their COVID-19 epidemic curve by reducing and achieving an effective reproductive number below 1. But by June 20(th), 2020, only 19 states and the District of Columbia were on track to curtail their epidemic curve with a 75% confidence, at current levels of reopening. Of the remaining 31 states, 24 may have to double their current testing and/or contact tracing rate to curtail their epidemic curve, and seven need to further restrict social contact by 25% in addition to doubling their testing and contact tracing rates. When social distancing restrictions are being eased, greater state-level testing and contact tracing capacity remains paramount for mitigating the risk of large-scale increases in cases and deaths.","title":"State-level impact of social distancing and testing on COVID-19 in the United States","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-07-07 10:00:00"},{"main_cord_uid":"y63r6v0r","cord_uid":"y63r6v0r","abstract":"Background: Since the beginning of the COVID-19 pandemic, researchers and health authorities have sought to identify the different parameters that govern their infection and death cycles, in order to be able to make better decisions. In particular, a series of reproduction number estimation models have been presented, with different practical results. Objective: This article aims to present an effective and efficient model for estimating the Reproduction Number and to discuss the impacts of sub-notification on these calculations. Methods: The concept of Moving Average Method with Initial value (MAMI) is used, as well as a model for Rt, the Reproduction Number, is derived from experimental data. The models are applied to real data and their performance is presented. Results: Analyses on Rt and sub-notification effects for Germany, Italy, Sweden, United Kingdom, South Korea, and the State of New York are presented to show the performance of the methods here introduced. Conclusions: We show that, with relatively simple mathematical tools, it is possible to obtain reliable values for time-dependent Reproduction Numbers (Rt), as well as we demonstrate that the impact of sub-notification is relatively low, after the initial phase of the epidemic cycle has passed.","title":"COVID-19: Time-Dependent Effective Reproduction Number and Sub-notification Effect Estimation Modeling","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-07-30 10:00:00"},{"main_cord_uid":"b1mp3tn5","cord_uid":"b1mp3tn5","abstract":"The estimation of unknown parameters in simulations, also known as calibration, is crucial for practical management of epidemics and prediction of pandemic risk. A simple yet widely used approach is to estimate the parameters by minimizing the sum of the squared distances between actual observations and simulation outputs. It is shown in this paper that this method is inefficient, particularly when the epidemic models are developed based on certain simplifications of reality, also known as imperfect models which are commonly used in practice. To address this issue, a new estimator is introduced that is asymptotically consistent, has a smaller estimation variance than the least squares estimator, and achieves the semiparametric efficiency. Numerical studies are performed to examine the finite sample performance. The proposed method is applied to the analysis of the COVID-19 pandemic for 20 countries based on the SEIR (Susceptible-Exposed-Infectious-Recovered) model with both deterministic and stochastic simulations. The estimation of the parameters, including the basic reproduction number and the average incubation period, reveal the risk of disease outbreaks in each country and provide insights to the design of public health interventions.","title":"Efficient calibration for imperfect epidemic models with applications to the analysis of COVID-19","annotator_investigating_R0":"0","text_response":"disease name: COVID-19\\r\\nlocation: 20 countries\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: SEIR (Susceptible-Exposed-Infectious-Recovered) model with both deterministic and stochastic simulations","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"20 countries\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SEIR (Susceptible-Exposed-Infectious-Recovered) model with both deterministic and stochastic simulations\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"20 countries\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SEIR (Susceptible-Exposed-Infectious-Recovered) model with both deterministic and stochastic simulations\\" } } ]","publish_time":"2020-09-26 10:00:00"},{"main_cord_uid":"iwdng6fr","cord_uid":"iwdng6fr","abstract":"Colleges and other organizations are considering testing plans to return to operation as the COVID-19 pandemic continues. Pre-symptomatic spread and high false negative rates for testing may make it difficult to stop viral spread. Here, we develop a stochastic agent-based model of COVID-19 in a university sized population, considering the dynamics of both viral load and false negative rate of tests on the ability of testing to combat viral spread. Reported dynamics of SARS-CoV-2 can lead to an apparent false negative rate from ~ 17 to ~ 48%. Nonuniform distributions of viral load and false negative rate lead to higher requirements for frequency and fraction of population tested in order to bring the apparent Reproduction number (Rt) below 1. Thus, it is important to consider non-uniform dynamics of viral spread and false negative rate in order to model effective testing plans.","title":"Temporal dynamics of viral load and false negative rate influence the levels of testing necessary to combat COVID-19 spread","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"frivrm3s","cord_uid":"frivrm3s","abstract":"This paper studies the SEIRD epidemic model for COVID-19. First, I show that the model is poorly identified from the observed number of deaths and confirmed cases. There are many sets of parameters that are observationally equivalent in the short run but lead to markedly different long run forecasts. Second, I show that the basic reproduction number [Formula: see text] can be identified from the data, conditional on epidemiologic parameters, and propose several nonlinear SUR approaches to estimate [Formula: see text]. I study the performance of these methods using Monte Carlo studies and demonstrate that they yield fairly accurate estimates of [Formula: see text]. Next, I apply these methods to estimate [Formula: see text] for the US, California, and Japan, and document heterogeneity in the value of [Formula: see text] across regions. My estimation approach accounts for possible underreporting of the number of cases. I demonstrate that if one fails to take underreporting into account and estimates [Formula: see text] from the reported cases data, the resulting estimate of [Formula: see text] may be biased downward and the resulting forecasts may exaggerate the long run number of deaths. Finally, I discuss how auxiliary information from random tests can be used to calibrate the initial parameters of the model and narrow down the range of possible forecasts of the future number of deaths.","title":"Identification and estimation of the SEIRD epidemic model for COVID-19","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-07-30 10:00:00"},{"main_cord_uid":"mo7yn6mc","cord_uid":"mo7yn6mc","abstract":"This is work in progress. We make it accessible hoping that people might find the idea useful. We propose a discrete, recursive 5-compartment model for the spread of epidemics, which we call {\\\\em SEPIR-model}. Under mild assumptions which typically are fulfilled for the Covid-19 pandemic it can be used to reproduce the development of an epidemic from a small number of parameters closely related to the data. We demonstrate this at the development in Germany and Switzerland. It also allows model predictions assuming nearly constant reproduction numbers. Thus it might be a useful tool for shedding light on which interventions might be most effective in the future. In future work we will discuss other aspects of the model and more countries.","title":"Proposal of a recursive compartment model of epidemics and applications to the Covid-19 pandemic","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-09-01 10:00:00"},{"main_cord_uid":"p8rnoqt6","cord_uid":"p8rnoqt6","abstract":"With the recent outbreak of COVID-19, the reach and scale of COVID-19 cases is top of mind for everyone and many research groups are actively monitoring and exploring the potential spread. A positive consequence of past epidemics and pandemics is that there are sound epidemiological compartmental modelling approaches that can effectively model disease spread. With minor changes to the underlying dynamical system of equations, many different strategies and situations can be explored. In particular, one such strategy of social distancing is top of mind for many Canadians as our political leaders, local businesses, and fellow Canadians promote and adopt this approach with the hopes that it will effectively \'flatten the curve\' and reduce or prevent further spread. In this paper, the baseline SIR model is introduced with its close counterpart, the SEIR model. Social distancing is modelled through the isolation of a subset of the susceptible population and comparative studies are performed considering a range in the proportion of individuals isolated. Robust and accurate numerical approximation techniques are used to simulate the pessimistic base case for which no preventative measures are taken and for various social distancing regimes. The results of social distancing are consolidated into two groups - those that flatten the curve and those that completely halt the disease spread. Mathematical formulations show that the turning point between these two regimes is when the effective reproductive rate, denoted Re, is equal to 1. Conclusions are made regarding the impacts and extent of the spread in relation to the severity of social distancing measures.","title":"A Study of the COVID-19 Impacts on the Canadian Population","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"ajdca6sj","cord_uid":"ajdca6sj","abstract":"Despite the adoption of a national immunization program in China, the incidence of mumps remains high. This study aimed to describe the epidemiological characteristics, including the time, region, occupation, and age, of mumps in Wuhan from 2005 to 2018 and to evaluate its transmissibility. In this study, the susceptible\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153exposed\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153infectious\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153asymptomatic\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153recovered (SEIAR) model fitted the actual incidence data of mumps. The effective reproduction number (R(t)) was used to evaluate and compare the transmission capacity in different areas. From 2005 to 2018, there were 36,415 cases. The incidence of mumps was highest among people aged 5\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u015310 years (460.02 per 100,000). The SEIAR model fitted the reported mumps data well (P < 0.01). The median transmissibility (R(t)) was 1.04 (range = 0\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u01532.50). There were two peak spreads every year (from March to May and from October to December). The R(t) peak always appeared in the first 2 months of the peak incidence rate. The peak time of the epidemic spread of mumps was 1\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u01532 months earlier than the peak incidence rate. The prevention and control measures of vaccination for children aged 5\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u015310 years should be taken before the peak transmission capacity each year, 2 months before the peak of the outbreak, to reduce the spread of mumps.","title":"Estimating the Transmissibility of Mumps: A Modelling Study in Wuhan City, China","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-08-03 00:00:00"},{"main_cord_uid":"i5jq6bgp","cord_uid":"i5jq6bgp","abstract":"OBJECTIVE: This research aimed to explore the application of a mathematical model based on deep learning in hospital infection control of novel coronavirus (COVID-19) pneumonia. METHODS: First, the epidemic data of Beijing, China, were utilized to make a definite susceptible-infected-removed (SIR) model fitting to determine the estimated value of the COVID-19 removal intensity \xc3\u017d\xc2\xb2, which was then used to do a determined SIR model and a stochastic SIR model fitting for the hospital. In addition, the reasonable \xc3\u017d\xc2\xb2 and \xc3\u017d\xc2\xb3 estimates of the hospital were determined, and the spread of the epidemic in hospital was simulated, to discuss the impact of basal reproductive number changes, isolation, vaccination, and so forth on COVID-19. RESULTS: There was a certain gap between the fitting of SIR to the remover and the actual data. The fitting of the number of infections was accurate. The growth rate of the number of infections decreased after measures, such as isolation, were taken. The effect of herd immunity was achieved after the overall immunity reached 70.9%. CONCLUSION: The SIR model based on deep learning and the stochastic SIR fitting model were accurate in judging the development trend of the epidemic, which can provide basis and reference for hospital epidemic infection control.","title":"Susceptible-Infected-Removed Mathematical Model under Deep Learning in Hospital Infection Control of Novel Coronavirus Pneumonia","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-10-27 10:00:00"},{"main_cord_uid":"jpk03ap9","cord_uid":"jpk03ap9","abstract":"Given maximal social distancing duration and intensity, how can one minimize the epidemic final size, or equivalently the total number of individuals infected during the outbreak? A complete answer to this question is provided and demonstrated here for the SIR epidemic model. In this simplified setting, the optimal solution consists in enforcing the highest confinement level during the longest allowed period, beginning at a time instant that is the unique solution to certain 1D optimization problem. Based on this result, we present numerical results showing the best possible performance for a large set of basic reproduction numbers and lockdown durations and intensities.","title":"How best can finite-time social distancing reduce epidemic final size?","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"at1jvlnn","cord_uid":"at1jvlnn","abstract":"COVID-19 is a viral disease that is caused by Severe Acute Respiratory Syndrome coronavirus 2 (SARSCoV-2) which has no approved vaccine. Based on the available non-pharmacological interventions like wearing of face masks, observing social distancing, and lockdown, this work assesses the impact of non-pharmaceutical control measures (social distancing and use of face-masks) and mass testing on the transmission of COVID-19 in Nigeria. A mathematical model for COVID-19 is formulated with intervention measures (observing social distancing and wearing of face masks) and mass testing. The basic reproduction number, R_0, is computed using next-generation method while the disease-free equilibrium is found to be locally and globally asymptotically stable when R_0&lt; 1. The model is parameterized using Nigeria data on COVID-19 in Nigeria. The basic reproduction number is found to be less than unity (R_0 &lt; 1) either when the compliance with intervention measures is moderate (50% &lt;= alpha&lt; 70%) and the testing rate per day is moderate (0,5 &lt;=alpha_2 &lt; 0,7) or when the compliance with intervention measures is strict (alpha&gt;=70%) and the testing rate per day is poor (alpha_2 = 0,3). This implies that Nigeria will be able to halt the spread of COVID-19 under these two conditions. However, it will be easier to enforce strict compliance with intervention measures in the presence of poor testing rate due to the limited availability of testing facilities and manpower in Nigeria. Hence, this study advocates that Nigerian governments (Federal and States) should aim at achieving a testing rate of at least 0.3 per day while ensuring that all the citizens strictly comply with wearing face masks and observing social distancing in public.","title":"The role of mathematical model in curbing COVID-19 in Nigeria","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Nigeria\\r\\ndate: -\\r\\nR0 value: less than unity\\r\\n%CI values: -\\r\\nmethod: next-generation method","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Nigeria\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"less than unity\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"next-generation method\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Nigeria\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"next-generation method\\" } } ]","publish_time":"2020","cluster_id":"546"},{"main_cord_uid":"smznem1d","cord_uid":"smznem1d","abstract":"Pandemics, such as Covid-19 and AIDS, tend to be highly contagious and have the characteristics of global spread and existence of multiple virus strains. To analyze the competition among different strains, a high dimensional SIR model studying multiple strains\' competition in patchy environments is introduced in this work. By introducing the basic reproductive number of different strains, we found global stability conditions of disease-free equilibrium and persistence conditions of the model. The competition exclusion conditions of that model are also given. This work gives some insights into the properties of the multiple strain patchy model and all of the analysis methods used in this work could be used in other related high dimension systems.","title":"The Global dynamics of a SIR model considering competitions among multiple strains in patchy environments","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2022"},{"main_cord_uid":"zb3aybzg","cord_uid":"zb3aybzg","abstract":"BACKGROUND: More than half of the global population is under strict forms of social distancing. Estimating the expected impact of lockdown and exit strategies is critical to inform decision makers on the management of the COVID-19 health crisis. METHODS: We use a stochastic age-structured transmission model integrating data on age profile and social contacts in \xc3\u0192\xc5\xbdle-de-France to (i) assess the epidemic in the region, (ii) evaluate the impact of lockdown, and (iii) propose possible exit strategies and estimate their effectiveness. The model is calibrated to hospital admission data before lockdown. Interventions are modeled by reconstructing the associated changes in the contact matrices and informed by mobility reductions during lockdown evaluated from mobile phone data. Different types and durations of social distancing are simulated, including progressive and targeted strategies, with large-scale testing. RESULTS: We estimate the reproductive number at 3.18 [3.09, 3.24] (95% confidence interval) prior to lockdown and at 0.68 [0.66, 0.69] during lockdown, thanks to an 81% reduction of the average number of contacts. Model predictions capture the disease dynamics during lockdown, showing the epidemic curve reaching ICU system capacity, largely strengthened during the emergency, and slowly decreasing. Results suggest that physical contacts outside households were largely avoided during lockdown. Lifting the lockdown with no exit strategy would lead to a second wave overwhelming the healthcare system, if conditions return to normal. Extensive case finding and isolation are required for social distancing strategies to gradually relax lockdown constraints. CONCLUSIONS: As France experiences the first wave of COVID-19 pandemic in lockdown, intensive forms of social distancing are required in the upcoming months due to the currently low population immunity. Extensive case finding and isolation would allow the partial release of the socio-economic pressure caused by extreme measures, while avoiding healthcare demand exceeding capacity. Response planning needs to urgently prioritize the logistics and capacity for these interventions.","title":"Impact of lockdown on COVID-19 epidemic in \xc3\u0192\xc5\xbdle-de-France and possible exit strategies","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: le-de-France\\r\\ndate: prior to lockdown\\r\\nR0 value: 3.18\\r\\n%CI values: [3.09, 3.24] (95% confidence interval)\\r\\nmethod: stochastic age-structured transmission model\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: le-de-France\\r\\ndate: during lockdown\\r\\nR0 value: 0.68\\r\\n%CI values: [0.66, 0.69]\\r\\nmethod: stochastic age-structured transmission model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"le-de-France\\",\\r\\n\\"date\\": \\"prior to lockdown\\",\\r\\n\\"R0 value\\": \\"3.18\\",\\r\\n\\"%CI values\\": \\"[3.09, 3.24] (95% confidence interval)\\",\\r\\n\\"method\\": \\"stochastic age-structured transmission model\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"le-de-France\\",\\r\\n\\"date\\": \\"during lockdown\\",\\r\\n\\"R0 value\\": \\"0.68\\",\\r\\n\\"%CI values\\": \\"[0.66, 0.69]\\",\\r\\n\\"method\\": \\"stochastic age-structured transmission model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"u00b11.48\\", \\"date\\": \\"prior to lockdown\\", \\"R0 value\\": \\"3.18\\", \\"%CI values\\": \\"[3.09, 3.24]\\", \\"method\\": \\"stochastic age-structured transmission model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"u00b11.48\\", \\"date\\": \\"during lockdown\\", \\"R0 value\\": \\"0.68\\", \\"%CI values\\": \\"[0.66, 0.69]\\", \\"method\\": \\"stochastic age-structured transmission model\\" } } ]","publish_time":"2020","cluster_id":"1397"},{"main_cord_uid":"pys3ueum","cord_uid":"pys3ueum","abstract":"In order to explore the intrinsic laws of the spread of COVID-19 across the globe, this paper applies partial differential equation and related theories to model and carry out theoretical analysis and numerical analysis. Firstly, by adding the free diffusion term to the traditional ordinary differential SEIRS epidemic model, the corresponding partial differential epidemic model is established. Secondly, the basic reproduction number R0 is calculated by using operator theory and spectral method, and it is testified that R0 is monotonically decreasing with respect to the diffusion coefficients of the exposed and infected individuals. Furthermore, we examine the asymptotic property of the endemic equilibrium with respect to the diffusion coefficient. Finally, we take the Canadian epidemic data as an example to carry out numerical simulation and parameter sensitivity analysis by applying difference method and BP neural network, the results show that strengthening the isolation of susceptible and exposed individuals, reducing the infection rate of infected individuals will help to better control the large-scale outbreak of the epidemic. \xc3\u201a\xc2\xa9 2021 IEEE.","title":"Mathematical model establishment and simulation analysis of the spread of COVID-19 epidemic","annotator_investigating_R0":"0","text_response":"disease name: COVID-19\\r\\nlocation: across the globe\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: operator theory and spectral method","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"across the globe\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"operator theory and spectral method\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Canada\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"operator theory and spectral method\\" } } ]","publish_time":"2021"},{"main_cord_uid":"0xb67cv2","cord_uid":"0xb67cv2","abstract":"Following the outbreak of COVID-19 pandemic, governments around the globe coerced their citizens to adhere to preventive health behaviours, aiming to reduce the effective reproduction numbers of the virus. Driven by game theoretic considerations and inspired by the work of US National Research Council\'s Committee on Food Habits (1943) during WWII, and the post-WWII Yale Communication Research Program, the present research shows how to achieve enhanced adherence to health regulations without coercion. To this aim, we combine three elements: (i) indirect measurements, (ii) personalized interventions, and (iii) attitude changing treatments (IMPACT). We find that a cluster of short interventions, such as elaboration on possible consequences, induction of cognitive dissonance, addressing next of kin and similar others and receiving advice following severity judgements, improves individuals\' health-preserving attitudes. We propose extending the use of IMPACT under closure periods and during the resumption of social and economic activities under COVID-19 pandemic, since efficient and lasting adherence should rely on personal attitudes rather than on coercion alone. Finally, we point to the opportunity of international cooperation generated by the pandemic.","title":"The behavioural challenge of the COVID-19 pandemic: indirect measurements and personalized attitude changing treatments (IMPACT)","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-08-26 10:00:00"},{"main_cord_uid":"yt300mbt","cord_uid":"yt300mbt","abstract":"Background: The coronavirus pandemic (COVID-19) is causing a havoc globally, exacerbated by the newly discovered SARS-CoV-2 virus. Due to its high population density, India is one of the most badly effected countries from the first wave of COVID-19. Therefore, it is extremely necessary to accurately predict the state-wise and overall dynamics of COVID-19 to get the effective and efficient organization of resources across India. Methods: In this study, the dynamics of COVID-19 in India and several of its selected states with different demographic structures were analyzed using the SEIRD epidemiological model. The basic reproductive ratio R0 was systemically estimated to predict the dynamics of the temporal progression of COVID-19 in India and eight of its states, Andhra Pradesh, Chhattisgarh, Delhi, Gujarat, Madhya Pradesh, Maharashtra, Tamil Nadu, and Uttar Pradesh. Results: For India, the SEIRD model calculations show that the peak of infection is expected to appear around the middle of October, 2020. Furthermore, we compared the model scenario to a Gaussian fit of the daily infected cases and obtained similar results. The early imposition of a nation-wide lockdown has reduced the number of infected cases but delayed the appearance of the infection peak significantly. Conclusion: After comparing our calculations using India\'s data to the real life dynamics observed in Italy and Russia, we can conclude that the SEIRD model can predict the dynamics of COVID-19 with sufficient accuracy.","title":"A study of the COVID-19 epidemic in India using the SEIRD model","annotator_investigating_R0":"0","text_response":"disease name: coronavirus pandemic (COVID-19)\\r\\nlocation: India\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: SEIRD epidemiological model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"coronavirus pandemic (COVID-19)\\",\\r\\n\\"location\\": \\"India\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SEIRD epidemiological model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"India\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SEIRD epidemiological model\\" } } ]","publish_time":"2021"},{"main_cord_uid":"chpzxo43","cord_uid":"chpzxo43","abstract":"BACKGROUND: Since the first cluster of cases was identified in Wuhan City, China, in December 2019, coronavirus disease 2019 (COVID-19) rapidly spreads globally. Scientists have made strides in estimating key transmission and epidemiological parameters. In particular, accumulating evidence points to a substantial fraction of asymptomatic or subclinical infections, which influences our understanding of the transmission potential and severity of this emerging disease. In this study, we derive estimates of the transmissibility and virulence of COVID-19 in Wuhan City, China, by reconstructing the underlying transmission dynamics using multiple data sources. METHODS: We employ statistical methods and publicly available epidemiological datasets to jointly derive estimates of transmissibility and severity associated with the novel coronavirus. For this purpose, the daily series of laboratory-confirmed COVID-19 cases and deaths in Wuhan City together with epidemiological data of Japanese repatriated from Wuhan City on board government-chartered flights were integrated into our analysis. RESULTS: Our posterior estimates of basic reproduction number (R) in Wuhan City, China, in 2019-2020 reached values at 3.49 (95% CrI 3.39-3.62) with a mean serial interval of 6.0 days, and the enhanced public health intervention after January 23 in 2020 was associated with a significantly reduced R at 0.84 (95% CrI 0.81-0.88), with the total number of infections (i.e., cumulative infections) estimated at 1,906,634 (95% CrI 1,373,500-2,651,124) in Wuhan City, elevating the overall proportion of infected individuals to 19.1% (95% CrI 13.5-26.6%). We also estimated the most recent crude infection fatality ratio (IFR) and time-delay adjusted IFR at 0.04% (95% CrI 0.03-0.06%) and 0.12% (95% CrI 0.08-0.17%), respectively, estimates that are substantially smaller than the crude CFR estimated at 4.06%. CONCLUSIONS: We have estimated key epidemiological parameters of the transmissibility and virulence of COVID-19 in Wuhan, China, during January-February 2020 using an ecological modeling approach that is suitable to infer epidemiological parameters with quantified uncertainty from partial observations collected by surveillance systems. Our estimate of time-delay adjusted IFR falls in the range of the median IFR estimates based on multiple serological studies conducted in several areas of the world.","title":"Early epidemiological assessment of the transmission potential and virulence of coronavirus disease 2019 (COVID-19) in Wuhan City, China, January-February, 2020","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Wuhan City, China\\r\\ndate: 2019-2020\\r\\nR0 value: 3.49\\r\\n%CI values: (95% CrI 3.39-3.62)\\r\\nmethod: statistical methods\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Wuhan City, China\\r\\ndate: after January 23 in 2020\\r\\nR0 value: 0.84\\r\\n%CI values: (95% CrI 0.81-0.88)\\r\\nmethod: statistical methods","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Wuhan City, China\\",\\r\\n\\"date\\": \\"2019-2020\\",\\r\\n\\"R0 value\\": \\"3.49\\",\\r\\n\\"%CI values\\": \\"(95% CrI 3.39-3.62)\\",\\r\\n\\"method\\": \\"statistical methods\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Wuhan City, China\\",\\r\\n\\"date\\": \\"after January 23 in 2020\\",\\r\\n\\"R0 value\\": \\"0.84\\",\\r\\n\\"%CI values\\": \\"(95% CrI 0.81-0.88)\\",\\r\\n\\"method\\": \\"statistical methods\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Wuhan City, China\\", \\"date\\": \\"January-February, 2020\\", \\"R0 value\\": \\"3.49\\", \\"%CI values\\": \\"(95% CrI 3.39-3.62)\\", \\"method\\": \\"statistical methods and publicly available epidemiological datasets\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Wuhan City, China\\", \\"date\\": \\"January-February, 2020\\", \\"R0 value\\": \\"0.84\\", \\"%CI values\\": \\"(95% CrI 0.81-0.88)\\", \\"method\\": \\"statistical methods and publicly available epidemiological datasets\\" } } ]","publish_time":"2020","cluster_id":"497"},{"main_cord_uid":"s2v7b4dv","cord_uid":"s2v7b4dv","abstract":"COVID-19 presents an urgent global challenge because of its contagious nature, frequently changing characteristics, and the lack of a vaccine or effective medicines. A model for measuring and preventing the continued spread of COVID-19 is urgently required to provide smart health care services. This requires using advanced intelligent computing such as artificial intelligence, machine learning, deep learning, cognitive computing, cloud computing, fog computing, and edge computing. This paper proposes a model for predicting COVID-19 using the SIR and machine learning for smart health care and the well-being of the citizens of KSA. Knowing the number of susceptible, infected, and recovered cases each day is critical for mathematical modeling to be able to identify the behavioral effects of the pandemic. It forecasts the situation for the upcoming 700 days. The proposed system predicts whether COVID-19 will spread in the population or die out in the long run. Mathematical analysis and simulation results are presented here as a means to forecast the progress of the outbreak and its possible end for three types of scenarios: \\"no actions,\\" \\"lockdown,\\" and \\"new medicines.\\" The effect of interventions like lockdown and new medicines is compared with the \\"no actions\\" scenario. The lockdown case delays the peak point by decreasing the infection and affects the area equality rule of the infected curves. On the other side, new medicines have a significant impact on infected curve by decreasing the number of infected people about time. Available forecast data on COVID-19 using simulations predict that the highest level of cases might occur between 15 and 30 November 2020. Simulation data suggest that the virus might be fully under control only after June 2021. The reproductive rate shows that measures such as government lockdowns and isolation of individuals are not enough to stop the pandemic. This study recommends that authorities should, as soon as possible, apply a strict long-term containment strategy to reduce the epidemic size successfully.","title":"Measuring and Preventing COVID-19 Using the SIR Model and Machine Learning in Smart Health Care","annotator_investigating_R0":"0","text_response":"disease name: COVID-19\\r\\nlocation: KSA\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: SIR and machine learning","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"KSA\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SIR and machine learning\\"}}]","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"248x096x","cord_uid":"248x096x","abstract":"This report describes an ongoing R03 grant that explores the links between trait reward sensitivity, substance use, and neural responses to social and nonsocial reward. Although previous research has shown that trait reward sensitivity and neural responses to reward are linked to substance use, whether this relationship is impacted by how people process social stimuli remains unclear. We are investigating these questions via a neuroimaging study with college-aged participants, using individual difference measures that examine the relation between substance use, social context, and trait reward sensitivity with tasks that measure reward anticipation, strategic behavior, social reward consumption, and the influence of social context on reward processing. We predict that substance use will be tied to distinct patterns of striatal dysfunction. Specifically, reward hyposensitive individuals will exhibit blunted striatal responses to social and non-social reward and enhanced connectivity with the orbitofrontal cortex; in contrast, reward hypersensitive individuals will exhibit enhanced striatal responses to social and non-social reward and blunted connectivity with the orbitofrontal cortex. We also will examine the relation between self-reported reward sensitivity, substance use, and striatal responses to social reward and social context. We predict that individuals reporting the highest levels of substance use will show exaggerated striatal responses to social reward and social context, independent of self-reported reward sensitivity. Examining corticostriatal responses to reward processing will help characterize the relation between reward sensitivity, social context and substance use while providing a foundation for understanding risk factors and isolating neurocognitive mechanisms that may be targeted to increase the efficacy of interventions.","title":"The Role of Social Reward and Corticostriatal Connectivity in Substance Use","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-10-29 05:00:00"},{"main_cord_uid":"xpy9el86","cord_uid":"xpy9el86","abstract":"The SARS-CoV-2 pandemic is one of the most concerning health problems around the globe. We reported the emergence of SARS-CoV-2 variant B.1.1.519 in Mexico City. We reported the effective reproduction number (Rt) of B.1.1.519 and presented evidence of its geographical origin based on phylogenetic analysis. We also studied its evolution via haplotype analysis and identified the most recurrent haplotypes. Finally, we studied the clinical impact of B.1.1.519. The B.1.1.519 variant was predominant between November 2020 and May 2021, reaching 90% of all cases sequenced in February 2021. It is characterized by three amino acid changes in the spike protein: T478K, P681H, and T732A. Its Rt varies between 0.5 and 2.9. Its geographical origin remain to be investigated. Patients infected with variant B.1.1.519 showed a highly significant adjusted odds ratio (aOR) increase of 1.85 over non-B.1.1.519 patients for developing a severe/critical outcome (p = 0.000296, 1.33\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u01532.6 95% CI) and a 2.35-fold increase for hospitalization (p = 0.005, 1.32\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u01534.34 95% CI). The continuous monitoring of this and other variants will be required to control the ongoing pandemic as it evolves.","title":"The Evolutionary Landscape of SARS-CoV-2 Variant B.1.1.519 and Its Clinical Impact in Mexico City","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-10-29 10:00:00"},{"main_cord_uid":"cut3vf2c","cord_uid":"cut3vf2c","abstract":"Abstract Background: A new type of coronavirus (later named Sars-Cov-2) drew attention on 31 December 2019 after the reporting of 27 unidentified pneumonia cases detected in Wuhan, China to the World Health Organization (WHO). Rapid progression of the COVID-19 pandemic has revealed the necessity of epidemic modeling studies to evaluate the course of the epidemic and its burden on the health system. This study aims to estimate the total number of infected people, evaluate the consequences of social interventions on the healthcare system and predict the expected number of cases, intensive care needs, hospitalizations and mortality rates in Turkey according to possible scenarios via the SEIR-based epidemic modeling method. Methods: This study was carried out in three dimensions. In the first, the actual number of people infected in the community has been estimated using the number of deaths in Turkey. In the second, the expected total numbers of infected people, total deaths, total hospitalizations, and intensive care unit (ICU) bed needs have been predicted in case of no intervention. In third, the distribution of the expected number of infected people and deaths, ICU and non-ICU bed needs over time has predicted based on SEIR modeling. A simulator (TURKSAS) has been developed and predictions made in 4 scenarios for Turkey. Results: According to deaths, the estimated number of infected people in Turkey on March 21 was 123,030. In the case of no intervention (1st scenario), the expected total number of infected people is 72,091,595, the total number of deaths is 445,956, the attack rate is 88.1%, the mortality ratio is 0.54%. The ICU bed capacity in Turkey is expected to exceed 4.4-fold and non-ICU bed capacity exceeds 3.21-fold. In 2nd and 3rd scenarios according to the calculations made by considering the social compliance rates of the NPIs, the value of R0 is estimated to decrease from 3 to 1.38 level. Compliance with NPIs makes a 94,303 difference in the expected number of deaths. In both scenarios, the predicted peak value of occupied ICU and non-ICU beds remains below Turkey healthcare capacity. While this study conducted, curfew for >65 and <20 age groups were in force in Turkey. If the curfew is declared for the 21-64 age population (4th scenario), the R0 value drops below 1 (0.98), the expected deaths are 14,230 and the peak values of daily ICU and non-ICU bed demand are below the healthcare capacity. Discussion: Modeling epidemics with assumptions supported by scientific literature and establishing decision support systems based on objective criteria is an important requirement. According to scientific data for the population of Turkey, the situation is not expected to be of worse than predictions presented in the second dimension. Predictions show that 16 million people can be prevented from being infected and 100,000 deaths can be prevented by full compliance with the measures taken. Complete control of the pandemic is possible by keeping R0 below 1. For this, additional evidence-based measures are needed.","title":"Nowcasting and Forecasting the Spread of COVID-19 and Healthcare Demand In Turkey, A Modelling Study","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Turkey\\r\\ndate: -\\r\\nR0 value: 3\\r\\n%CI values: -\\r\\nmethod: SEIR modeling\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Turkey\\r\\ndate: -\\r\\nR0 value: 1.38\\r\\n%CI values: -\\r\\nmethod: SEIR modeling 2nd scenario\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Turkey\\r\\ndate: -\\r\\nR0 value: 1.38\\r\\n%CI values: -\\r\\nmethod: SEIR modeling 3rd scenario\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Turkey\\r\\ndate: -\\r\\nR0 value: 0.98\\r\\n%CI values: -\\r\\nmethod: SEIR modeling 4th scenario","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Turkey\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"3\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SEIR modeling\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Turkey\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"1.38\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SEIR modeling 2nd scenario\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Turkey\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"1.38\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SEIR modeling 3rd scenario\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Turkey\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"0.98\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SEIR modeling 4th scenario\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Turkey\\", \\"date\\": \\"March 21\\", \\"R0 value\\": \\"declined from 3 to 1.38\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SEIR-based epidemic modeling method\\" } } ]","publish_time":"43938.41667","cluster_id":"715"},{"main_cord_uid":"xjufduyt","cord_uid":"xjufduyt","abstract":"Today, the world is fighting against a dangerous epidemic caused by the novel coronavirus, also known as COVID-19. All have been impacted and countries are trying to recover from the social, economic, and health devastations of COVID-19. Recent epidemiology research has concentrated on using different prediction models to estimate the numbers of infected, recovered, and deceased cases around the world. This study is primarily focused on evaluating two common prediction models: Susceptible - Infected - Recovered (SIR) and Susceptible - Exposed - Infected - Recovered (SEIR). The SIR and SEIR models were compared in estimating the outbreak and identifying the better fitting model for forecasting future spread in Kuwait. Based on the results of the comparison, the SEIR model was selected for predicting COVID-19 infected, recovered, and cumulative cases. The data needed for estimation was collected from official sites of the Kuwait Government between 24 February and 1 December 2020. This study presents estimated values for peak dates and expected eradication of COVID-19 in Kuwait. The proposed estimation model is simulated using the Python Programming language on the collected data. The simulation was performed with various basic reproduction numbers (between 5.2 and 3), the initial exposed population, and the incubation rate. The results show that the SEIR model was better suited than the SIR model for predicting both infection and recovery cases with [Formula: see text] values ranging from 3 to 4, [Formula: see text] = 80 and [Formula: see text] = 0.2.","title":"A Study on the Efficiency of the Estimation Models of COVID-19","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-06-11 10:00:00"},{"main_cord_uid":"er5ozxzl","cord_uid":"er5ozxzl","abstract":"Since December 2020, variants of COVID-19 (especially Delta and Omicron) appeared with different characteristics that influenced death and transmissibility emerged around the world. To address the novel dynamics of the disease, we propose a dynamical model of two strains, namely native and mutant, transmission dynamics with mutation and imperfect vaccination. It is also assumed that the recuperated individuals from the native strain can be infected with mutant strain through the direct contact with individual or contaminated surfaces or aerosols. We compute the basic reproduction number for each strain independently and take the maximum for $R_0$. We prove the nonexistence of backward bifurcation using the center manifold theory, and global stability of disease-free equilibrium when the basic reproduction number $R_0<1. An intermediate mutation rate $\\\\nu_1$ leads to oscillations. When $\\\\nu_1$ increases over a threshold, the system regains its stability and exhibits an interesting dynamics called endemic bubble. An analytical expression for vaccine-induced herd immunity is derived. The model is parameterized using the Indian data of the cumulative number of confirmed cases and deaths of COVID-19 from March 1 to September 27 in 2021, using MCMC method. The cumulative cases and deaths can be reduced by increasing the vaccine efficacies to both native and mutant strains. We observe that by considering the vaccine efficacy to native strain as 90\\\\%, the cumulative cases and deaths would be reduced by 3.27\\\\% and 5.2\\\\%, respectively; and by considering the vaccine efficacy to mutant strain as 90\\\\%, the cumulative cases and deaths would be reduced by 0.9\\\\% and 2.5\\\\%, respectively. Our study demonstrates that the COVID-19 pandemic may be worse due to the occurrence of oscillations for certain mutation rates but better due to stability at a lower infection level with a larger mutation rate.","title":"Mutations make pandemics worse or better: modeling SARS-CoV-2 variants and imperfect vaccination","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2022-01-17 05:00:00"},{"main_cord_uid":"1vf94lg0","cord_uid":"1vf94lg0","abstract":"The Coronavirus disease of 2019 (COVID-19) is an ongoing public health concern worldwide. COVID-19 infections continue to occur and thus, it is important to assess the effects of various public health measures. This study aims to forecast COVID-19 cases by geographical area in Korea, based on the effects of different control-intervention intensities (CII). Methods involved estimating the effective reproduction number ( R t ) by Korean geographical area using the SEIHR model, and the instantaneous reproduction number using statistical model, comparing the epidemic curves and high-, intermediate-, and low-intensity control interventions. Here, short-term four-week forecasts by geographical area were conducted. The mean of delayed instantaneous reproduction number was estimated at 1.36, 1.03, and 0.93 for the low-, intermediate-, and high-intensity control interventions, respectively, in the capital area of Korea from July 16, 2020, to March 4, 2021. The COVID-19 cases were forecasted with an accuracy rate of 11.28%, 13.62%, and 20.19% MAPE in Korea, including both the capital and non-capital areas. High-intensity control measures significantly reduced the reproduction number to be less than one. The proposed model forecasted COVID-19 transmission dynamics with good accuracy and interpretability. High-intensity control intervention, active case detection, and isolation efforts should be maintained to control the pandemic.","title":"Forecasting COVID-19 cases by assessing control-intervention effects in Republic of Korea: a statistical modeling approach","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2022-02-18 05:00:00"},{"main_cord_uid":"z6q11loy","cord_uid":"z6q11loy","abstract":"The coronavirus disease 2019 (COVID-19) pandemic has created unprecedented healthcare emergencies across the globe. The World Health Organization (WHO) has proposed social distancing (SD) as a prudent measure to contain the pandemic and, hence, governments have been enacting lockdowns of varied nature. These lockdowns, causing economic and social strain, warrant the development of quantitative models to optimally manage the pandemic. Similarly, extensive testing aids in early detection and isolation, hence containing the spread of the pandemic. Compartment epidemiology models have been used extensively in modeling such infectious diseases. This paper attempts to utilize the modified Susceptible-Exposed-Infectious-Recovered (SEIR) model incorporating the SD, testing, and infectiousness of exposed and infectious compartments to study the COVID-19 pandemic in Saudi Arabia. Saudi Arabia has put restrictions on the movement of people in different phases to ascertain SD. Time-dependent parameters based on the timeline of restrictions and testing in Saudi Arabia have been introduced to capture SD and testing. The arrived model has been validated through statistical tests. The [Formula: see text] (R naught), basic reproduction number, value has ranged between 0.6014 and 2.7860 with an average of 1.4904 and currently holds at 0.8952. In the absence of SD and testing measures, the model predicts the threshold herd immunity to be 69.31% and [Formula: see text] value as 3.26. Further, scenario analysis has been conducted for alleviating the SD measure. The results show that early lifting of all restrictions may undo all efforts in the containment of the COVID-19 pandemic. The outcome of results will help policymakers and medical practitioners prepare better to manage the pandemic and lockdown.","title":"COVID-19 Modeling in Saudi Arabia Using the Modified Susceptible-Exposed-Infectious-Recovered (SEIR) Model","annotator_investigating_R0":"1","text_response":"disease name: coronavirus disease 2019 (COVID-19)\\r\\nlocation: Saudi Arabia\\r\\ndate: -\\r\\nR0 value: 0.6014 and 2.7860\\r\\n%CI values: -\\r\\nmethod: Modified Susceptible-Exposed-Infectious-Recovered (SEIR) Model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"coronavirus disease 2019 (COVID-19)\\",\\r\\n\\"location\\": \\"Saudi Arabia\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"0.6014 and 2.7860\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Modified Susceptible-Exposed-Infectious-Recovered (SEIR) Model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Saudi Arabia\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"ranged between 0.6014 and 2.7860 with an average of 1.4904 and currently holds at 0.8952\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"(R naught) model\\" } } ]","publish_time":"2020-09-14 00:00:00"},{"main_cord_uid":"204w2huq","cord_uid":"204w2huq","abstract":"BACKGROUND: After more than six months into the coronavirus disease (COVID-19) pandemic, as of August 10, 2020, over 734,664 people had died worldwide. The current study aims to evaluate how mitigating interventions affected the epidemic process in the 30 largest metropolitan areas in the US and whether temperature played a role in the epidemic process. METHODS: Publicly available data for the time series of COVID-19 cases and deaths and weather were analyzed at the metropolitan level. The time-varying reproductive numbers (R(t)) based on retrospective moving average were used to explore the trends. Student t-tests were used to compare temperature and peak R(t) cross-sectionally. RESULTS: We found that virus transmissibility, measured by instantaneous reproduction number (R(t)), had declined since the end of March for all areas and almost all of them reached a R(t) of 1 or below after April 15, 2020. The timing of the main decline was concurrent with the implementation of mitigating interventions. However, the R(t)s remained around 1 for most areas since then and there were some small and short rebounds in some areas, suggesting a persistent epidemic in those areas when interventions were relaxed. Cities with warm temperature also tended to have a lower peak R(t) than that of cities with cold temperature. However, they were not statistically significant and large geographic variations existed. CONCLUSIONS: Aggressive interventions might have mitigated the current pandemic of COVID-19, while temperature might have weak effects on the virus transmission. We may need to prepare for a possible return of the coronavirus outbreak.","title":"Impact of mitigating interventions and temperature on the instantaneous reproduction number in the COVID-19 pandemic among 30 US metropolitan areas","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-08-22 10:00:00"},{"main_cord_uid":"pz9lsaw6","cord_uid":"pz9lsaw6","abstract":"The relationship between epidemiology, mathematical modeling and computational tools allows to build and test theories on the development and battling of a disease. This PhD thesis is motivated by the study of epidemiological models applied to infectious diseases in an Optimal Control perspective, giving particular relevance to Dengue. Dengue is a subtropical and tropical disease transmitted by mosquitoes, that affects about 100 million people per year and is considered by the World Health Organization a major concern for public health. The mathematical models developed and tested in this work, are based on ordinary differential equations that describe the dynamics underlying the disease, including the interaction between humans and mosquitoes. An analytical study is made related to equilibrium points, their stability and basic reproduction number. The spreading of Dengue can be attenuated through measures to control the transmission vector, such as the use of specific insecticides and educational campaigns. Since the development of a potential vaccine has been a recent global bet, models based on the simulation of a hypothetical vaccination process in a population are proposed. Based on Optimal Control theory, we have analyzed the optimal strategies for using these controls, and respective impact on the reduction/eradication of the disease during an outbreak in the population, considering a bioeconomic approach. The formulated problems are numerically solved using direct and indirect methods. The first discretize the problem turning it into a nonlinear optimization problem. Indirect methods use the Pontryagin Maximum Principle as a necessary condition to find the optimal curve for the respective control. In these two strategies several numerical software packages are used.","title":"Optimal Control and Numerical Optimization Applied to Epidemiological Models","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2014-01-29 05:00:00"},{"main_cord_uid":"dy2tige9","cord_uid":"dy2tige9","abstract":"In this article, we develop a mathematical model considering susceptible, exposed, infected, asymptotic, quarantine/isolation and recovered classes as in case of COVID-19 disease. The facility of quarantine/isolation have been provided to both exposed and infected classes. Asymptotic individuals either recovered without undergo treatment or moved to infected class after some duration. We have formulated the reproduction number for the proposed model. Elasticity and sensitivity analysis indicates that model is more sensitive towards the transmission rate from exposed to infected classes rather than transmission rate from susceptible to exposed class. Analysis of global stability for the proposed model is studied through Lyapunov\xc3\xa2\xe2\u201a\xac\xe2\u201e\xa2s function.","title":"A nonlinear epidemiological model considering asymptotic and quarantine classes for SARS CoV-2 virus","annotator_investigating_R0":"0","text_response":"disease name: COVID-19\\r\\nlocation: -\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: A nonlinear epidemiological model considering asymptotic and quarantine classes","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"-\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"A nonlinear epidemiological model considering asymptotic and quarantine classes\\"}}]","json_model_response":"unanswerable","publish_time":"2020-06-04 10:00:00"},{"main_cord_uid":"6a6njt3u","cord_uid":"6a6njt3u","abstract":"Background: Novel coronavirus (SARS-CoV-2) has extended its range of transmission in all parts of the world, with substantial variation in rates of transmission and severity of associated disease. Many countries have implemented social distancing as a measure to control further spread. Methods: We evaluate whether and under which conditions containment or slowing down COVID-19 epidemics are possible by isolation and contact tracing in settings with various levels of social distancing. We use a stochastic transmission model in which every person generates novel infections according to a probability distribution that is affected by the incubation period distribution (time from infection to symptoms), distribution of the latent period (time from infection to onset of infectiousness), and overall transmissibility. The model distinguishes between close contacts (e.g., within a household) and other contacts in the population. Social distancing affects the number of contacts outside but not within the household. Findings: The proportion of asymptomatic or unascertained cases has a strong impact on the controllability of the disease. If the proportion of asymptomatic infections is larger than 30%, contact tracing and isolation cannot achieve containment for an R0 of 2.5. Achieving containment by social distancing requires a reduction of numbers of non-household contacts by around 90%. Depending on the realized level of contact reduction, tracing and isolation of only household contacts, or of household and non-household contacts are necessary to reduce the effective reproduction number to below 1. A combination of social distancing with isolation and contact tracing leads to synergistic effects that increase the prospect of containment. Interpretation: Isolation and contact tracing can be an effective means to slow down epidemics, but only if the majority of cases are ascertained. In a situation with social distancing, contact tracing can act synergistically and tip the scale towards containment, and can therefore be a tool for controlling COVID-19 epidemics as part of an exit strategy from current lockdown measures.","title":"Isolation and contact tracing can tip the scale to containment of COVID-19 in populations with social distancing","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-03-13 05:00:00"},{"main_cord_uid":"eb8ysg2b","cord_uid":"eb8ysg2b","abstract":"We propose a mathematical model to simulate the SARS outbreak in Beijing. The model consists of six subpopulations, namely susceptible, exposed, quarantined, suspect, probable and removed, as China started to report SARS cases as suspect and probable separately from April 27 and cases transferred from suspect class to probable class from May 2. By simplifying the model to a two-compartment suspect-probable model and a single-compartment probable model and using limited data, we are able to simulate the SARS outbreak in Beijing. We estimate that the reproduction number varies from 1.0698 to 3.2524 and obtain certain important epidemiological parameters.","title":"Simulating the SARS outbreak in Beijing with limited data","annotator_investigating_R0":"1","text_response":"disease name: SARS\\r\\nlocation: Beijing\\r\\ndate: from April 27 and cases transferred from suspect class to probable class from May 2\\r\\nR0 value: 1.0698 to 3.2524\\r\\n%CI values: -\\r\\nmethod: two-compartment suspect-probable model and a single-compartment probable model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"SARS\\",\\r\\n\\"location\\": \\"Beijing\\",\\r\\n\\"date\\": \\"from April 27 and cases transferred from suspect class to probable class from May 2\\",\\r\\n\\"R0 value\\": \\"1.0698 to 3.2524\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"two-compartment suspect-probable model and a single-compartment probable model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"SARS\\", \\"location\\": \\"Beijing\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"1.0698 to 3.2524\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"a mathematical model\\" } } ]","publish_time":"2004-04-07 00:00:00"},{"main_cord_uid":"r3gvxz2y","cord_uid":"r3gvxz2y","abstract":"Background: Recent outbreak of 2019-nCoV in Wuhan raised serious public health concerns. By February 15, 2020 in Wuhan, the total number of confirmed infection cases has reached 37 914, and the number of deaths has reached 1123, accounting for 56.9% of the total confirmed cases and 73.7% of the total deaths in China. People are eager to know when the epidemic will be completely controlled and when people\'s work and life will be on the right track. Method: In this study we analyzed the epidemic dynamics and trend of 2019-nCoV in Wuhan by using the data after the closure of Wuhan city till February 12, 2020 based on the SEIR modeling method. Results: The optimal parameters were estimated as R0 = 1.44 (interquartile range: 1.40-1.47), TI = 14 (interquartile range = 14-14) and TE = 3.0 (interquartile range = 2.8-3.1). Based on these parameters, the number of infected individuals in Wuhan city may reach the peak around February 19 at about 47 000 people. Once entering March, the epidemic would gradually decline, and end around the late March. It is worth noting that the above prediction is based on the assumption that the number of susceptible population N = 200 000 will not increase. If the epidemic situation is not properly controlled, the peak of infected number can be further increased and the peak time will be a little postponed. It was expected that the epidemic would subside in early March, and disappear gradually towards the late March. Conclusions: The epidemic situation of 2019-nCoV in Wuhan was effectively controlled after the closure of the city, and the disease transmission index also decreased significantly. It is expected that the peak of epidemic situation would be reached in late February and end in March.","title":"When will the battle against novel coronavirus end in Wuhan: A SEIR modeling analysis","annotator_investigating_R0":"1","text_response":"disease name: 2019-nCoV\\r\\nlocation: Wuhan\\r\\ndate: after the closure of Wuhan city till February 12, 2020\\r\\nR0 value: 1.44\\r\\n%CI values: interquartile range: 1.40-1.47\\r\\nmethod: SEIR modeling method","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"2019-nCoV\\",\\r\\n\\"location\\": \\"Wuhan\\",\\r\\n\\"date\\": \\"after the closure of Wuhan city till February 12, 2020\\",\\r\\n\\"R0 value\\": \\"1.44\\",\\r\\n\\"%CI values\\": \\"interquartile range: 1.40-1.47\\",\\r\\n\\"method\\": \\"SEIR modeling method\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"2019-nCoV\\", \\"location\\": \\"Wuhan\\", \\"date\\": \\"till February 12, 2020\\", \\"R0 value\\": \\"1.44\\", \\"%CI values\\": \\"(interquartile range: 1.40-1.47)\\", \\"method\\": \\"SEIR modeling method\\" } } ]","publish_time":"2020","cluster_id":"814"},{"main_cord_uid":"82nuvva9","cord_uid":"82nuvva9","abstract":"We augment the well-known susceptible - infected - recovered - deceased (SIRD) epidemiological model to include vaccination dynamics, implemented as a piecewise continuous simulation. We calibrate this model to reported case data in the UK at a national level. Our modelling approach decouples the inherent characteristics of the infection from the degree of human interaction (as defined by the effective reproduction number, Re). This allows us to detect and infer a change in the characteristic of the infection, for example the emergence of the Kent variant, We find that that the infection rate constant (k) increases by around 89% as a result of the B.1.1.7 (Kent) COVID-19 variant in England. Through retrospective analysis and modelling of early epidemic case data (between March 2020 and May 2020) we estimate that ~1.2M COVID-19 infections were unreported in the early phase of the epidemic in the UK. We also obtain an estimate of the basic reproduction number as, R0=3.23. We use our model to assess the UK Government\'s roadmap for easing the third national lockdown as a result of the current vaccination programme. To do this we use our estimated model parameters and a future forecast of the daily vaccination rates of the next few months. Our modelling predicts an increased number of daily cases as NPIs are lifted in May and June 2021. We quantify this increase in terms of the vaccine rollout rate and in particular the percentage vaccine uptake rate of eligible individuals, and show that a reduced take up of vaccination by eligible adults may lead to a significant increase in new infections.","title":"Mechanistic model calibration and the dynamics of the COVID-19 epidemic in the UK (the past, the present and the future)","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: UK\\r\\ndate: March 2020 and May 2020\\r\\nR0 value: 3.23\\r\\n%CI values: -\\r\\nmethod: susceptible - infected - recovered - deceased (SIRD) epidemiological model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"UK\\",\\r\\n\\"date\\": \\"March 2020 and May 2020\\",\\r\\n\\"R0 value\\": \\"3.23\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"susceptible - infected - recovered - deceased (SIRD) epidemiological model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"UK\\", \\"date\\": \\"between March 2020 and May 2020\\", \\"R0 value\\": \\"3.23\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } } ]","publish_time":"2021-05-22 10:00:00"},{"main_cord_uid":"b0f5ysxf","cord_uid":"b0f5ysxf","abstract":"Epidemics generally spread through a succession of waves that reflect factors on multiple timescales. On short timescales, super-spreading events lead to burstiness and overdispersion, while long-term persistent heterogeneity in susceptibility is expected to lead to a reduction in the infection peak and the herd immunity threshold (HIT). Here, we develop a general approach to encompass both timescales, including time variations in individual social activity, and demonstrate how to incorporate them phenomenologically into a wide class of epidemiological models through parameterization. We derive a non-linear dependence of the effective reproduction number Re on the susceptible population fraction S. We show that a state of transient collective immunity (TCI) emerges well below the HIT during early, high-paced stages of the epidemic. However, this is a fragile state that wanes over time due to changing levels of social activity, and so the infection peak is not an indication of herd immunity: subsequent waves can and will emerge due to behavioral changes in the population, driven (e.g.) by seasonal factors. Transient and long-term levels of heterogeneity are estimated by using empirical data from the COVID-19 epidemic as well as from real-life face-to-face contact networks. These results suggest that the hardest-hit areas, such as NYC, have achieved TCI following the first wave of the epidemic, but likely remain below the long-term HIT. Thus, in contrast to some previous claims, these regions can still experience subsequent waves.","title":"Time-dependent heterogeneity leads to transient suppression of the COVID-19 epidemic, not herd immunity","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"5t08uwkz","cord_uid":"5t08uwkz","abstract":"Background COVID-19 spread may have a dramatic impact in countries with vulnerable economies and limited availability of, and access to, healthcare resources and infrastructures. However, in sub-Saharan Africa a low prevalence and mortality have been observed so far. Methods We collected data on individual social contacts in Ethiopia across geographical contexts characterized by heterogeneous population density, work and travel opportunities, and access to primary care. We assessed how socio-demographic factors and observed mixing patterns can influence the COVID-19 disease burden, by simulating SARS-CoV-2 transmission in remote settlements, rural villages, and urban neighborhoods, under the current school closure mandate. Results From national surveillance data, we estimated a net reproduction number of 1.62 (95%CI 1.55-1.70). We found that, at the end of an epidemic mitigated by school closure alone, 10-15% of the overall population would have been symptomatic and 0.3-0.4% of the population would require mechanical ventilation and/or possibly result in a fatal outcome. Higher infection attack rates are expected in more urbanized areas, but the highest incidence of critical disease is expected in remote subsistence farming settlements. Conclusions The relatively low burden of COVID-19 in Ethiopia can be explained by the estimated mixing patterns, underlying demography and the enacted school closures. Socio-demographic factors can also determine marked heterogeneities across different geographical contexts within the same country. Our findings can contribute to understand why sub-Saharan Africa is experiencing a relatively lower attack rate of severe cases compared to high income countries.","title":"Demography, social contact patterns and the COVID-19 burden in different settings of Ethiopia: a modeling study","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Ethiopia\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"1.62\\", \\"%CI values\\": \\"(95%CI 1.55-1.75)\\", \\"method\\": \\"simulating SARS-CoV-2 transmission in remote settlements, rural villages, and urban neighborhoods\\" } } ]","publish_time":"2020-11-24 05:00:00"},{"main_cord_uid":"q6pz6l2b","cord_uid":"q6pz6l2b","abstract":"In this paper, we estimate the reproductive number R0 of COVID-19 based on Wallinga and Lipsitch framework {11} and a novel statistical time delay dynamic system. We use the observed data reported in CCDC\'s paper to estimate distribution of the generation interval of the infection and apply the simulation results from the time delay dynamic system as well as released data from CCDC to fit the growth rate. The conclusion is: Based our Fudan-CCDC model, the growth rate r of COVID-19 is almost in [0.30, 0.32] which is larger than the growth rate 0.1 estimated by CCDC {9}, and the reproductive number R0 of COVID-19 is estimated by 3.25\xc3\xa2\xe2\u20ac\xb0\xc2\xa4 R0 \xc3\xa2\xe2\u20ac\xb0\xc2\xa43.4 if we simply use R=1+r*Tc with Tc=7.5, which is bigger than that of SARS. Some evolutions and predictions are listed.","title":"The reproductive number R0 of COVID-19 based on estimate of a statistical time delay dynamical system","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: -\\r\\ndate: -\\r\\nR0 value: 3.25-3.4\\r\\n%CI values: -\\r\\nmethod: Wallinga and Lipsitch framework {11} and a novel statistical time delay dynamic system","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"-\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"3.25-3.4\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Wallinga and Lipsitch framework {11} and a novel statistical time delay dynamic system\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Fudan\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"3.25\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Wallinga and Lipsitch framework and a novel statistical time delay dynamic system\\" } } ]","publish_time":"2020-02-20 05:00:00"},{"main_cord_uid":"p8ido632","cord_uid":"p8ido632","abstract":"BACKGROUND: Wuhan was the first epicentre of COVID-19 in the world, accounting for 80% of cases in China during the first wave. We aimed to assess household transmissibility of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) and risk factors associated with infectivity and susceptibility to infection in Wuhan. METHODS: This retrospective cohort study included the households of all laboratory-confirmed or clinically confirmed COVID-19 cases and laboratory-confirmed asymptomatic SARS-CoV-2 infections identified by the Wuhan Center for Disease Control and Prevention between Dec 2, 2019, and April 18, 2020. We defined households as groups of family members and close relatives who did not necessarily live at the same address and considered households that shared common contacts as epidemiologically linked. We used a statistical transmission model to estimate household secondary attack rates and to quantify risk factors associated with infectivity and susceptibility to infection, accounting for individual-level exposure history. We assessed how intervention policies affected the household reproductive number, defined as the mean number of household contacts a case can infect. FINDINGS: 27\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020101 households with 29\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020578 primary cases and 57\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020581 household contacts were identified. The secondary attack rate estimated with the transmission model was 15\xc3\u201a\xc2\xb76% (95% CI 15\xc3\u201a\xc2\xb72-16\xc3\u201a\xc2\xb70), assuming a mean incubation period of 5 days and a maximum infectious period of 22 days. Individuals aged 60 years or older were at a higher risk of infection with SARS-CoV-2 than all other age groups. Infants aged 0-1 years were significantly more likely to be infected than children aged 2-5 years (odds ratio [OR] 2\xc3\u201a\xc2\xb720, 95% CI 1\xc3\u201a\xc2\xb740-3\xc3\u201a\xc2\xb744) and children aged 6-12 years (1\xc3\u201a\xc2\xb753, 1\xc3\u201a\xc2\xb701-2\xc3\u201a\xc2\xb734). Given the same exposure time, children and adolescents younger than 20 years of age were more likely to infect others than were adults aged 60 years or older (1\xc3\u201a\xc2\xb758, 1\xc3\u201a\xc2\xb728-1\xc3\u201a\xc2\xb795). Asymptomatic individuals were much less likely to infect others than were symptomatic cases (0\xc3\u201a\xc2\xb721, 0\xc3\u201a\xc2\xb714-0\xc3\u201a\xc2\xb731). Symptomatic cases were more likely to infect others before symptom onset than after (1\xc3\u201a\xc2\xb742, 1\xc3\u201a\xc2\xb730-1\xc3\u201a\xc2\xb755). After mass isolation of cases, quarantine of household contacts, and restriction of movement policies were implemented, household reproductive numbers declined by 52% among primary cases (from 0\xc3\u201a\xc2\xb725 [95% CI 0\xc3\u201a\xc2\xb724-0\xc3\u201a\xc2\xb726] to 0\xc3\u201a\xc2\xb712 [0\xc3\u201a\xc2\xb710-0\xc3\u201a\xc2\xb713]) and by 63% among secondary cases (from 0\xc3\u201a\xc2\xb717 [0\xc3\u201a\xc2\xb716-0\xc3\u201a\xc2\xb718] to 0\xc3\u201a\xc2\xb7063 [0\xc3\u201a\xc2\xb7057-0\xc3\u201a\xc2\xb7070]). INTERPRETATION: Within households, children and adolescents were less susceptible to SARS-CoV-2 infection but were more infectious than older individuals. Presymptomatic cases were more infectious and individuals with asymptomatic infection less infectious than symptomatic cases. These findings have implications for devising interventions for blocking household transmission of SARS-CoV-2, such as timely vaccination of eligible children once resources become available. FUNDING: National Natural Science Foundation of China, Fundamental Research Funds for the Central Universities, US National Institutes of Health, and US National Science Foundation.","title":"Household transmission of SARS-CoV-2 and risk factors for susceptibility and infectivity in Wuhan: a retrospective observational study","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":" { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Wuhan\\", \\"date\\": \\"Dec 2, 2019, and April 18, 2020\\", \\"R0 value\\": \\"1.45-1.68\\", \\"%CI values\\": \\"(95% CI 1.2-2.06)\\", \\"method\\": \\"statistical transmission model\\" } } ]","publish_time":"2021"},{"main_cord_uid":"aiz57q5n","cord_uid":"aiz57q5n","abstract":"Multimodal treatment including surgery and chemotherapy is considered the gold standard treatment of pancreatic cancer by most guidelines. Neoadjuvant therapy (NAT) has been seen as a possible treatment option for resectable, borderline resectable and locally advanced PaC. The aim of this paper is to offer a state-of-the-art review on neoadjuvant treatments in the setting of pancreatic ductal adenocarcinoma. A systematic literature search was performed using PubMed, Cochrane, Web of Science and Embase databases, in order to identify relevant studies published up to and including July 2021 that reported and analyzed the role of neoadjuvant therapy in the setting of pancreatic carcinoma. Most authors are concordant on the strong role of neoadjuvant therapy in the setting of borderline resectable pancreatic cancers. Recent randomized trials demonstrated improvement of R0 rate and survival after NAT in this setting. Patients with locally advanced cancers may become resectable after NAT, with better results than those obtained with palliative therapies. Even in the setting of resectable cancers, NAT is being evaluated by ongoing randomized trials. Chemotherapy regimens in the setting of NAT and response to NAT are discussed. NAT has an important role in the multimodal treatment of patients with borderline resectable pancreatic cancer. It has a role in patients with locally advanced tumors as it can allow surgical resection in a relevant proportion of patients. For resectable pancreatic cancers, the role of NAT is under evaluation by several randomized trials.","title":"Neoadjuvant therapy for pancreatic cancer","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-10-09 10:00:00"},{"main_cord_uid":"kqkn7imd","cord_uid":"kqkn7imd","abstract":"We present an epidemic model capable of describing key features of the Covid-19 pandemic. While capturing several qualitative properties of the virus spreading, it allows to compute the basic reproduction number, the number of deaths due to the virus and various other statistics. Numerical integrations are used to illustrate the adherence of the evolutions described by the model to specific well known real features of the present pandemic. In particular, this model is consistent with the well known relevance of quarantine, shows the dramatic role of care houses and accounts for the increase in the death toll when spatial movements are not constrained. ELECTRONIC SUPPLEMENTARY MATERIAL: The online version of this article (10.1186/s13362-020-00090-4) contains supplementary material.","title":"An age and space structured SIR model describing the Covid-19 pandemic","annotator_investigating_R0":"0","text_response":"disease name: Covid-19\\r\\nlocation: -\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: An age and space structured SIR model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"-\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"An age and space structured SIR model\\"}}]","json_model_response":"unanswerable","publish_time":"2020-08-08 10:00:00","cluster_id":"368"},{"main_cord_uid":"yogjoo2a","cord_uid":"yogjoo2a","abstract":"The Mathematical and Theoretical Biology Institute (MTBI) is a national award winning Research Experience for Undergraduates (REU) that has been running every summer since 1996. Since 1997, students have developed and proposed their own research questions and derived their research projects from them as the keystone of the program. Because MTBI\xc3\xa2\xe2\u201a\xac\xe2\u201e\xa2s mentors have no control over what students are interested in, we need to introduce a suite of flexible techniques that can be applied to a broad variety of interests. In this paper, we walk through examples of some of the most popular techniques at MTBI: epidemiological or contagion modeling and reproductive number analysis. We include an overview of the next generation matrix method of finding the basic reproductive number, sensitivity analysis as a technique for investigating the effect of parameters on the reproductive number, and recommendations for interpreting the results. Lastly, we provide some advice to mentors who are looking to advise student-led research projects. All examples are taken from actual student projects that are generally available through the MTBI website.","title":"A Tour of the Basic Reproductive Number and the Next Generation of Researchers","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Disease name\\": \\"Dis} } ]","publish_time":"2020-02-18 00:00:00"},{"main_cord_uid":"zefl5ul8","cord_uid":"zefl5ul8","abstract":"Although many persons in the United States have acquired immunity to COVID-19, either through vaccination or infection with SARS-CoV-2, COVID-19 will pose an ongoing threat to non-immune persons so long as disease transmission continues. We can estimate when sustained disease transmission will end in a population by calculating the population-specific basic reproduction number R_0, the expected number of secondary cases generated by an infected person in the absence of any interventions. The value of R_0 relates to a herd immunity threshold (HIT), which is given by 1-1/R_0. When the immune fraction of a population exceeds this threshold, sustained disease transmission becomes exponentially unlikely (barring mutations allowing SARS-CoV-2 to escape immunity). Here, we report state-level R_0 estimates obtained using Bayesian inference. Maximum a posteriori estimates range from 7.1 for New Jersey to 2.3 for Wyoming, indicating that disease transmission varies considerably across states and that reaching herd immunity will be more difficult in some states than others. R_0 estimates were obtained from compartmental models via the next-generation matrix approach after each model was parameterized using regional daily confirmed case reports of COVID-19 from 21-January-2020 to 21-June-2020. Our R_0 estimates characterize infectiousness of ancestral strains, but they can be used to determine HITs for a distinct, currently dominant circulating strain, such as SARS-CoV-2 variant Delta (lineage B.1.617.2), if the relative infectiousness of the strain can be ascertained. On the basis of Delta-adjusted HITs, vaccination data, and seroprevalence survey data, we find that no state has achieved herd immunity as of 20-September-2021.","title":"Bayesian Inference of State-Level COVID-19 Basic Reproduction Numbers across the United States","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: New Jersey, United States\\r\\ndate: 21-January-2020 to 21-June-2020\\r\\nR0 value: 7.1\\r\\n%CI values: -\\r\\nmethod: Bayesian inference\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Wyoming, United States\\r\\ndate: 21-January-2020 to 21-June-2020\\r\\nR0 value: 2.3\\r\\n%CI values: -\\r\\nmethod: Bayesian inference","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"New Jersey, United States\\",\\r\\n\\"date\\": \\"21-January-2020 to 21-June-2020\\",\\r\\n\\"R0 value\\": \\"7.1\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Bayesian inference\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Wyoming, United States\\",\\r\\n\\"date\\": \\"21-January-2020 to 21-June-2020\\",\\r\\n\\"R0 value\\": \\"2.3\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Bayesian inference\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United States\\", \\"date\\": \\"21-January-2020 to 21-June-2020\\", \\"R0 value\\": \\"7.1\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"compartmental models via the next-generation matrix\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Wyoming\\", \\"date\\": \\"21-January-2020 to 21-June-2020\\", \\"R0 value\\": \\"2.3\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"compartmental models via the next-generation matrix\\" } } ]","publish_time":"2021-09-28 00:00:00","cluster_id":"187"},{"main_cord_uid":"2lkkj1fk","cord_uid":"2lkkj1fk","abstract":"A SEIR model with an added fomite term is used to constrain the contribution of fomites to the spread of COVID-19 under the Spring 2020 lockdown in the UK. Assuming uniform priors on the reproduction number in lockdown and the fomite transmission rate, an upper limit is found on the fomite transmission rate of less than 1 contaminated object in 7 per day per infectious person (95% CL). Basing the prior on the reproduction rate during lockdown instead on the CoMix study results for the reduction in social contacts under lockdown, and assuming the reproduction number scales with the number of social contacts, provides a much more restrictive upper limit on the transmission rate by contaminated objects of fewer than 1 in 30 per day per infectious person (95% CL). Applied to postal deliveries and groceries, the upper limit on the fomite transmission rate corresponds to a probability below 1 in 70 (95% CL) that a contaminated object transmits the infection. Fewer than about half (95% CL) of the total number of deaths during the lockdown are found to arise from fomites, and most likely fewer than a quarter. These findings apply only to fomites with a transmission rate that is unaffected by a lockdown.","title":"The fomite contribution to the transmission of COVID-19 in the UK: an evolutionary population estimate","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"pxvu5wdn","cord_uid":"pxvu5wdn","abstract":"In the recent COVID-19 pandemic, mathematical modeling constitutes an important tool to evaluate the prospective effectiveness of non-pharmaceutical interventions (NPIs) and to guide policy-making. Most research is, however, centered around characterizing the epidemic based on point estimates like the average infectiousness or the average number of contacts. In this work, we use stochastic simulations to investigate the consequences of a population\'s heterogeneity regarding connectivity and individual viral load levels. Therefore, we translate a COVID-19 ODE model to a stochastic multi-agent system. We use contact networks to model complex interaction structures and a probabilistic infection rate to model individual viral load variation. We observe a large dependency of the dispersion and dynamical evolution on the population\'s heterogeneity that is not adequately captured by point estimates, for instance, used in ODE models. In particular, models that assume the same clinical and transmission parameters may lead to different conclusions, depending on different types of heterogeneity in the population. For instance, the existence of hubs in the contact network leads to an initial increase of dispersion and the effective reproduction number, but to a lower herd immunity threshold (HIT) compared to homogeneous populations or a population where the heterogeneity stems solely from individual infectivity variations.","title":"Why ODE models for COVID-19 fail: Heterogeneity shapes epidemic dynamics","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-03-26 05:00:00"},{"main_cord_uid":"733e9ojg","cord_uid":"733e9ojg","abstract":"Mathematical and computational modeling approaches are increasingly used as quantitative tools in the analysis and forecasting of infectious disease epidemics. The growing need for realism in addressing complex public health questions is, however, calling for accurate models of the human contact patterns that govern the disease transmission processes. Here we present a data-driven approach to generate effective population-level contact matrices by using highly detailed macro (census) and micro (survey) data on key socio-demographic features. We produce age-stratified contact matrices for 35 countries, including 277 sub-national administratvie regions of 8 of those countries, covering approximately 3.5 billion people and reflecting the high degree of cultural and societal diversity of the focus countries. We use the derived contact matrices to model the spread of airborne infectious diseases and show that sub-national heterogeneities in human mixing patterns have a marked impact on epidemic indicators such as the reproduction number and overall attack rate of epidemics of the same etiology. The contact patterns derived here are made publicly available as a modeling tool to study the impact of socio-economic differences and demographic heterogeneities across populations on the epidemiology of infectious diseases.","title":"Inferring high-resolution human mixing patterns for disease modeling","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-01-12 00:00:00"},{"main_cord_uid":"v5y9s97b","cord_uid":"v5y9s97b","abstract":"BACKGROUND: Highly refined surveillance data on the 2009 A/H1N1 influenza pandemic are crucial to quantify the spatial and temporal characteristics of the pandemic. There is little information about the spatial-temporal dynamics of pandemic influenza in South America. Here we provide a quantitative description of the age-specific morbidity pandemic patterns across administrative areas of Peru. METHODS: We used daily cases of influenza-like-illness, tests for A/H1N1 influenza virus infections, and laboratory-confirmed A/H1N1 influenza cases reported to the epidemiological surveillance system of Peru\'s Ministry of Health from May 1 to December 31, 2009. We analyzed the geographic spread of the pandemic waves and their association with the winter school vacation period, demographic factors, and absolute humidity. We also estimated the reproduction number and quantified the association between the winter school vacation period and the age distribution of cases. RESULTS: The national pandemic curve revealed a bimodal winter pandemic wave, with the first peak limited to school age children in the Lima metropolitan area, and the second peak more geographically widespread. The reproduction number was estimated at 1.6\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u01532.2 for the Lima metropolitan area and 1.3\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u01531.5 in the rest of Peru. We found a significant association between the timing of the school vacation period and changes in the age distribution of cases, while earlier pandemic onset was correlated with large population size. By contrast there was no association between pandemic dynamics and absolute humidity. CONCLUSIONS: Our results indicate substantial spatial variation in pandemic patterns across Peru, with two pandemic waves of varying timing and impact by age and region. Moreover, the Peru data suggest a hierarchical transmission pattern of pandemic influenza A/H1N1 driven by large population centers. The higher reproduction number of the first pandemic wave could be explained by high contact rates among school-age children, the age group most affected during this early wave.","title":"Spatial and Temporal Characteristics of the 2009 A/H1N1 Influenza Pandemic in Peru","annotator_investigating_R0":"1","text_response":"disease name: 2009 A/H1N1 Influenza\\r\\nlocation: Peru, Lima metropolitan area\\r\\ndate: May 1 to December 31, 2009\\r\\nR0 value: 1.6-2.2\\r\\n%CI values: -\\r\\nmethod: -\\r\\n|\\r\\ndisease name: 2009 A/H1N1 Influenza\\r\\nlocation: Peru, rest of Peru\\r\\ndate: May 1 to December 31, 2009\\r\\nR0 value: 1.3-1.5\\r\\n%CI values: -\\r\\nmethod: -","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"2009 A/H1N1 Influenza\\",\\r\\n\\"location\\": \\"Peru, Lima metropolitan area\\",\\r\\n\\"date\\": \\"May 1 to December 31, 2009\\",\\r\\n\\"R0 value\\": \\"1.6-2.2\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"-\\"}},{\\"contribution\\":{\\"disease name\\": \\"2009 A/H1N1 Influenza\\",\\r\\n\\"location\\": \\"Peru, rest of Peru\\",\\r\\n\\"date\\": \\"May 1 to December 31, 2009\\",\\r\\n\\"R0 value\\": \\"1.3-1.5\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"-\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"2009 A/H1N1 influenza\\", \\"location\\": \\"Lima metropolitan area\\", \\"date\\": \\"May 1 to December 31, 2009\\", \\"R0 value\\": \\"1.6-2.2\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 A/H1N1 influenza\\", \\"location\\": \\"rest of Peru\\", \\"date\\": \\"May 1 to December 31, 2009\\", \\"R0 value\\": \\"1.3-1.5\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } } ]","publish_time":"2011-06-21 10:00:00","cluster_id":"1172"},{"main_cord_uid":"pgkblrw3","cord_uid":"pgkblrw3","abstract":"In February 2020, the exponential growth of COVID-19 cases in Wuhan city posed a huge economic burden to local medical systems. Consequently, Wuhan established Fangcang Shelter hospitals as a One Health approach for responding to and containing the COVID-19 outbreak by isolating and caring for mild-to-moderate cases. However, it is unclear to what degree the hospitals contained COVID-19. This study performed an interrupted time series analysis to compare the number of new confirmed cases of COVID-19 before and after the operation of Fangcang Shelter hospitals. The initial number of confirmed cases in Wuhan increased significantly by 68.54 cases per day prior to February 4, 2020. Compared with the number of cases noted 20 days before the use of Fangcang Shelter hospitals, a sustained reduction in the number of confirmed cases (trend change, \xc3\xa2\xcb\u2020\xe2\u20ac\u2122125.57; P < 0.0001) was noted 41 days after the use of the hospitals. Immediate-level changes were observed for confirmed cases (level change, 725.97; P = 0.025). These changes led to an estimated 5148 fewer confirmed cases (P < 0.0001). According to the mean confirmed cases of 395.71 per day before the intervention, we estimated that Wuhan had advanced the terminal phase of COVID-19 by 13 days. Furthermore, immediately after introduction of Fangcang Shelter Hospitals on February 5, the reproduction number dropped rapidly, from a pre-introduction rate of 4.0 to 2.0. The Fangcang Shelter hospitals most likely to reversed the epidemic trend of COVID-19 while a containment strategy was implemented in Wuhan. In a One Health perspective, Fangcang Shelter hospitals, with their functions of isolation and treatment of confirmed COVID-19 patients, engaging professionals from many disciplines, such as medicine, engineering, architecture, psychology, environmental health, and social sciences. The results of this study provide a valuable reference for health policy makers in other countries.","title":"Fangcang shelter hospitals are a One Health approach for responding to the COVID-19 outbreak in Wuhan, China","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Wuhan, China\\r\\ndate: February 2020\\r\\nR0 value: 4.0 to 2.0\\r\\n%CI values: -\\r\\nmethod: interrupted time series analysis","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Wuhan, China\\",\\r\\n\\"date\\": \\"February 2020\\",\\r\\n\\"R0 value\\": \\"4.0 to 2.0\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"interrupted time series analysis\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Wuhan, China\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"2.0\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Introduced time series analysis\\" } } ]","publish_time":"2020-08-29 00:00:00"},{"main_cord_uid":"i7l6tqdk","cord_uid":"i7l6tqdk","abstract":"Novel coronavirus (COVID-19) caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is an epidemic declared by the World Health Organization (WHO). Till now in June 13, 2020, the total COVID-19 cases in different countries around the world are 77,56,905 with 4,28,576 deaths and 3,974,422 recovered. The virus has taken spread in India as well, whereas of June 13, 2020, 3,09,603 cases are confirmed with 8,890 deaths and 1,54,330 recovery. It this situation, it is vital to know the potential danger posed by the pandemic and the epidemic trajectory. In this paper, the basic reproduction number (R0 ) of COVID-19 from the early epidemic data in India is estimated. The course of the pandemic in India as well as the worst affected seven states in India, namely Maharashtra, Tamil Nadu, Delhi, Gujarat, Uttar Pradesh, Rajasthan and West Bengal is also analyzed. The early outbreak data from the Ministry of Health and Family Welfare (MoHFW), Government of India, are collected for the analysis. The two R packages \xc3\xa2\xe2\u201a\xac\xcb\u0153R0\xc3\xa2\xe2\u201a\xac\xe2\u201e\xa2 and \xc3\xa2\xe2\u201a\xac\xcb\u0153earlyR\xc3\xa2\xe2\u201a\xac\xe2\u201e\xa2 to estimate the basic reproduction number are used. An attempt is also made to forecast near-future incidence cases based on statistical methods. The results show that R0 varies from 1.53 to 3.25 accounting to different methodologies and serial intervals adopted, whereas WHO estimations are from 2 to 2.5. Due to effect of lockdown, the time-dependent reproduction number has reduced to near about 1.22. It is predicted that by July 15, cumulative number of COVID-19 cases may reach around 1.2 million if the current effective reproduction number remains same over the next one month. Finally, it can be concluded that in the coming months, the novel coronavirus will pose a severe challenge to the Indian healthcare system. Thus, it is necessary to predict how the virus may spread so that the healthcare system may be prepared in advance. The time-dependent reproduction number shows the positive effect of lockdown, as this number has gone down. \xc3\u201a\xc2\xa9 Springer International Publishing AG 2018.","title":"Transmission dynamics and estimation of basic reproduction number (R0 ) from early outbreak of novel coronavirus (covid-19) in india","annotator_investigating_R0":"1","text_response":"disease name: Novel Coronavirus (COVID-19)\\r\\nlocation: India\\r\\ndate: -\\r\\nR0 value: 1.53 to 3.25\\r\\n%CI values: -\\r\\nmethod: R packages \'R0\' and \'earlyR\'","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Novel Coronavirus (COVID-19)\\",\\r\\n\\"location\\": \\"India\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"1.53 to 3.25\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"R packages \'R0\' and \'earlyR\'\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"India\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"1.53 to 3.25\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"different methodologies and serial intervals\\" } } ]","publish_time":"2020"},{"main_cord_uid":"duvwdoub","cord_uid":"duvwdoub","abstract":"OBJECTIVES: To assess the potential impacts of successive lockdown-easing measures in England, at a point in the COVID-19 pandemic when community transmission levels were relatively high. DESIGN: We developed a Bayesian model to infer incident cases and reproduction number (R) in England, from incident death data. We then used this to forecast excess cases and deaths in multiple plausible scenarios in which R increases at one or more time points. SETTING: England. PARTICIPANTS: Publicly available national incident death data for COVID-19 were examined. PRIMARY OUTCOME: Excess cumulative cases and deaths forecast at 90 days, in simulated scenarios of plausible increases in R after successive easing of lockdown in England, compared with a baseline scenario where R remained constant. RESULTS: Our model inferred an R of 0.75 on 13 May when England first started easing lockdown. In the most conservative scenario modelled where R increased to 0.80 as lockdown was eased further on 1 June and then remained constant, the model predicted an excess 257 (95% CI 108 to 492) deaths and 26 447 (95% CI 11 105 to 50 549) cumulative cases over 90 days. In the scenario with maximal increases in R (but staying \xc3\xa2\xe2\u20ac\xb0\xc2\xa41), the model predicts 3174 (95% CI 1334 to 6060) excess cumulative deaths and 421 310 (95% CI 177 012 to 804 811) cases. Observed data from the forecasting period aligned most closely to the scenario in which R increased to 0.85 on 1 June, and 0.9 on 4 July. CONCLUSIONS: When levels of transmission are high, even small changes in R with easing of lockdown can have significant impacts on expected cases and deaths, even if R remains \xc3\xa2\xe2\u20ac\xb0\xc2\xa41. This will have a major impact on population health, tracing systems and healthcare services in England. Following an elimination strategy rather than one of maintenance of R \xc3\xa2\xe2\u20ac\xb0\xc2\xa41 would substantially mitigate the impact of the COVID-19 epidemic within England.","title":"Modelling the impact of lockdown-easing measures on cumulative COVID-19 cases and deaths in England","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: England\\r\\ndate: 13 May 2020\\r\\nR0 value: 0.75\\r\\n%CI values: -\\r\\nmethod: Bayesian model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"England\\",\\r\\n\\"date\\": \\"13 May 2020\\",\\r\\n\\"R0 value\\": \\"0.75\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Bayesian model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"England\\", \\"date\\": \\"13 May (before lockdown was eased further on 1 June)\\", \\"R0 value\\": \\"0.75\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Bayesian model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"England\\", \\"date\\": \\"1 June (after lockdown was eased further on 1 June)\\", \\"R0 value\\": \\"0.85\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Bayesian model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"England\\", \\"date\\": \\"4 July (after lockdown was eased further on 1 June)\\", \\"R0 value\\": \\"0.95\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Bayesian model\\" } } ]","publish_time":"2021-09-08 00:00:00"},{"main_cord_uid":"gk1vosah","cord_uid":"gk1vosah","abstract":"RESUMEN Objetivo Predecir el n\xc3\u0192\xc2\xbamero de casos de COVID-19 en la ciudad de Cali-Colombia mediante el desarrollo de un modelo SEIR. M\xc3\u0192\xc2\xa9todos Se utiliz\xc3\u0192\xc2\xb3 un modelo determinista compartimental SEIR considerando los estados: susceptibles (S), expuestos (E), infectados (I) y recuperados (R). Los par\xc3\u0192\xc2\xa1metros del modelo fueron seleccionados de acuerdo a la revisi\xc3\u0192\xc2\xb3n de literatura. En el caso de la tasa de letalidad, se usaron los datos de la Secretar\xc3\u0192\xc2\xada de Salud Municipal de Cali. Se plantearon varios escenarios teniendo en cuenta variaciones en el n\xc3\u0192\xc2\xbamero b\xc3\u0192\xc2\xa1sico de reproducci\xc3\u0192\xc2\xb3n (R0) y en la tasa de letalidad; adem\xc3\u0192\xc2\xa1s, se compar\xc3\u0192\xc2\xb3 la predicci\xc3\u0192\xc2\xb3n hasta el 9 de abril con los datos observados. Resultados A trav\xc3\u0192\xc2\xa9s del modelo SEIR se encontr\xc3\u0192\xc2\xb3 que, con el n\xc3\u0192\xc2\xbamero b\xc3\u0192\xc2\xa1sico de reproducci\xc3\u0192\xc2\xb3n m\xc3\u0192\xc2\xa1s alto (2,6) y utilizando la letalidad calculada para la ciudad de 2,0%, el n\xc3\u0192\xc2\xbamero m\xc3\u0192\xc2\xa1ximo de casos se alcanzar\xc3\u0192\xc2\xada el primero de junio con 195 666 (prevalencia); sin embargo, al comparar los casos observados con los esperados, al inicio la ocurrencia observada estaba por encima de la proyectada; pero luego cambia la tendencia con una disminuci\xc3\u0192\xc2\xb3n marcada de la pendiente. Conclusiones Los modelos epidemiol\xc3\u0192\xc2\xb3gicos SEIR son m\xc3\u0192\xc2\xa9todos muy utilizados para la proyecci\xc3\u0192\xc2\xb3n de casos en enfermedades infecciosas; sin embargo, se debe tener en cuenta que son modelos deterministas que pueden utilizar par\xc3\u0192\xc2\xa1metros supuestos y podr\xc3\u0192\xc2\xadan generar resultados imprecisos.(AU)","title":"Predicciones de un modelo SEIR para casos de COVID-19 en Cali, Colombia/ Predictions of a SEIR model for COVID-19 cases in Cali-Colombia","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"wqw14s93","cord_uid":"wqw14s93","abstract":"Quantifying the effectiveness of large-scale non-pharmaceutical interventions against COVID-19 is critical to adapting responses against future waves of the pandemic. By combining phylogenetic data of 5,198 SARS-CoV-2 genomes with the chronology of non-pharmaceutical interventions in 57 countries, we examine how interventions and combinations thereof alter the divergence rate of viral lineages, which is directly related to the epidemic reproduction number. Home containment and education lockdown had the largest independent impacts and were predicted to reduce the reproduction number by 35% and 26%, respectively. However, we find that in contexts with a reproduction number >2, no individual intervention is sufficient to stop the epidemic and increasingly stringent intervention combinations may be required. Our phylodynamic approach can complement epidemiological models to inform public health strategies against COVID-19.","title":"SARS-CoV-2 phylodynamics differentiates the effectiveness of non-pharmaceutical interventions","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-08-26 10:00:00"},{"main_cord_uid":"kwz6l6a2","cord_uid":"kwz6l6a2","abstract":"On the basis of a semi-realistic SIR microsimulation for Germany and Poland, we show that the R0 parameter interval for which the COVID-19 epidemic stays overcritical but below the capacity limit of the health care system to reach herd immunity is so narrow that a successful implementation of this strategy is likely to fail. Our microsimulation is based on official census data and involves household composition and age distribution as the main population structure variables. Outside household contacts are characterised by an out-reproduction number R* which is the only free parameter of the model. For a subcritical domain we compute the time till extinction and prevalence as a function of the initial number of infected individuals and R*. For the Polish city of Wroclaw we also discuss the combined impact of testing coverage and contact reduction. For both countries we estimate R* for disease progression until 20th of March 2020.","title":"Mitigation and herd immunity strategy for COVID-19 is likely to fail","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-03-30 10:00:00"},{"main_cord_uid":"rd8xazlz","cord_uid":"rd8xazlz","abstract":"Simultaneously controlling COVID-19 epidemics and limiting economic and societal impacts presents a difficult challenge, especially with limited public health budgets. Testing, contact tracing, and isolating/quarantining is a key strategy that has been used to reduce transmission of SARS-CoV-2, the virus that causes COVID-19. However, manual contact tracing is a time-consuming process and as case numbers increase it takes longer to reach each cases\' contacts, leading to additional virus spread. Delays between symptom onset and being tested (and receiving results), and a low fraction of symptomatic cases being tested can also reduce the impact of contact tracing on transmission. We examined the relationship between cases, delays, and participation and the pathogen reproductive number Rt. We also examined implications for infection dynamics using a stochastic compartment model of SARS-CoV-2. We found that Rt increases sigmoidally with the number of cases due to decreasing contact tracing efficacy. This relationship results in accelerating epidemics because Rt increases, rather than declines, as infections increase. Shifting contact tracers from locations with high and low case burdens relative to capacity to locations with intermediate case burdens maximizes their impact in reducing Rt (but minimizing total infections is more complicated). We also found that contact tracing quickly becomes ineffective in reducing Rt with increasing delays between symptom onset and tracing and with lower fraction of symptomatic infections being tested. Finally, we found that when cases are low, testing and tracing reductions in Rt can sometimes greatly delay epidemics due to the highly heterogeneous transmission dynamics of SARS-CoV-2, in which a small fraction of infections often give rise to most of transmission. These results demonstrate the importance of having an expandable or mobile team of contact tracers that can be used to control surges in cases. They also emphasize the value of easy access, high testing capacity and rapid turn-around of testing results, as well as outreach efforts to encourage symptomatic infections to be tested immediately after symptom onset. An efficient and adaptive public health capacity strategy can allow for increased economic activity and should be employed in the current and future pandemics.","title":"Contact tracing efficiency, transmission heterogeneity, and accelerating COVID-19 epidemics","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-09-07 10:00:00","cluster_id":"679"},{"main_cord_uid":"2xl0gp1o","cord_uid":"2xl0gp1o","abstract":"Since the detection of the first case of COVID-19 in Chile on March 3(rd), 2020, a total of 513,188 cases, including ~14,302 deaths have been reported in Chile as of November 2(nd), 2020. Here, we estimate the reproduction number throughout the epidemic in Chile and study the effectiveness of control interventions especially the effectiveness of lockdowns by conducting short-term forecasts based on the early transmission dynamics of COVID-19. Chile\xc3\xa2\xe2\u201a\xac\xe2\u201e\xa2s incidence curve displays early sub-exponential growth dynamics with the deceleration of growth parameter, p, estimated at 0.8 (95% CI: 0.7, 0.8) and the reproduction number, R, estimated at 1.8 (95% CI: 1.6, 1.9). Our findings indicate that the control measures at the start of the epidemic significantly slowed down the spread of the virus. However, the relaxation of restrictions and spread of the virus in low-income neighborhoods in May led to a new surge of infections, followed by the reimposition of lockdowns in Greater Santiago and other municipalities. These measures have decelerated the virus spread with R estimated at ~0.96 (95% CI: 0.95, 0.98) as of November 2(nd), 2020. The early sub-exponential growth trend (p ~0.8) of the COVID-19 epidemic transformed into a linear growth trend (p ~0.5) as of July 7(th), 2020, after the reimposition of lockdowns. While the broad scale social distancing interventions have slowed the virus spread, the number of new COVID-19 cases continue to accrue, underscoring the need for persistent social distancing and active case detection and isolation efforts to maintain the epidemic under control.","title":"Transmission dynamics and control of COVID-19 in Chile, March-October, 2020","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Chile\\r\\ndate: March-October, 2020\\r\\nR0 value: 1.8\\r\\n%CI values: (95% CI: 1.6, 1.9)\\r\\nmethod: short-term forecasts based on the early transmission dynamics of COVID-19\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Chile, Greater Santiago and other municipalities\\r\\ndate: as of November 2(nd), 2020\\r\\nR0 value: 0.96\\r\\n%CI values: (95% CI: 0.95, 0.98)\\r\\nmethod: short-term forecasts based on the early transmission dynamics of COVID-19","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Chile\\",\\r\\n\\"date\\": \\"March-October, 2020\\",\\r\\n\\"R0 value\\": \\"1.8\\",\\r\\n\\"%CI values\\": \\"(95% CI: 1.6, 1.9)\\",\\r\\n\\"method\\": \\"short-term forecasts based on the early transmission dynamics of COVID-19\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Chile, Greater Santiago and other municipalities\\",\\r\\n\\"date\\": \\"as of November 2(nd), 2020\\",\\r\\n\\"R0 value\\": \\"0.96\\",\\r\\n\\"%CI values\\": \\"(95% CI: 0.95, 0.98)\\",\\r\\n\\"method\\": \\"short-term forecasts based on the early transmission dynamics of COVID-19\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Chile\\", \\"date\\": \\"March-October, 2020\\", \\"R0 value\\": \\"1.8\\", \\"%CI values\\": \\"(95% CI: 1.6, 1.9)\\", \\"method\\": \\"Estimation based on early transmission dynamics\\" } } ]","publish_time":"2021-01-22 05:00:00","cluster_id":"1083"},{"main_cord_uid":"ztrmpvbr","cord_uid":"ztrmpvbr","abstract":"BACKGROUND: As one of the strategies to mitigate the COVID-19 pandemic, social distancing (SD) measures are recommended to control disease spread and reduce the attack rate. Therefore, this study aims to estimate the costs and effects of SD measures through school closures, workforce, and community contact reductions for mitigating the COVID-19 pandemic in Indonesia. METHODS: Two mitigation scenarios of SD for 1 month and continuous SD were compared with the baseline (no intervention). A modified Susceptible-Exposed-Infected-Recovered (SEIR) compartmental model accounting for disease spread during the latent period was applied by considering a 1-year time horizon. The costs of healthcare, school closures, and productivity loss due to disease as well as intervention were considered to estimate the total pandemic cost among all scenarios. RESULTS: In a comparison with the baseline, the result showed that total savings in scenarios of SD for 1 month and continuous SD was approximately $415 billion and $699 billion, respectively, while the averted deaths were 4.6 million and 8.5 million, respectively. Sensitivity analysis showed that basic reproduction number, infectious period, daily wage, incubation period, daily ICU admission cost, and case fatality rate were the most influential parameters affecting the savings and the number of averted deaths. CONCLUSIONS: SD measures through school closures, workforce, and community contact reductions were concluded to be cost-saving. Increasing the duration of social distancing tends to increase both the savings and the number of averted deaths.","title":"The cost-effectiveness of social distancing measures for mitigating the COVID-19 pandemic in a highly-populated country: A case study in Indonesia","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-12-23 05:00:00"},{"main_cord_uid":"du5bdjlp","cord_uid":"du5bdjlp","abstract":"Information on severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2) spread in Africa is limited by fragile 2 surveillance systems and insufficient diagnostic capacity. 3 We assessed the coronavirus disease-19 (COVID-19)-related diagnostic workload in Benin, Western Africa, 4 characterized SARS-CoV-2 genomes from 12 acute cases of COVID-19, used those together with public data to 5 estimate SARS-CoV-2 transmission dynamics in a Bayesian framework, validated a widely used diagnostic dual target 6 RT-PCR kit donated to African countries, and conducted serological analyses in 68 sera from confirmed COVID-19 7 cases and from febrile patients sampled before the predicted SARS-CoV-2 introduction. 8 We found a 15-fold increase in the monthly laboratory workload due to COVID-19. Genomic surveillance showed 9 introductions of three distinct SARS-CoV-2 lineages. SARS-CoV-2 genome-based analyses yielded an R0 estimate of 10 4.4 (95% confidence interval: 2.0-7.7), suggesting intense spread of SARS-CoV-2 in Africa. RT-PCR-based tests 11 were highly sensitive but showed variation of internal controls and between diagnostic targets. Commercially available 12 SARS-CoV-2 ELISAs showed up to 25% false-positive results depending on antigen and antibody types, likely due 13 to unspecific antibody responses elicited by acute malaria according to lack of SARS-CoV-2-specific neutralizing 14 antibody responses and relatively higher parasitemia in those sera. 15 We confirm an overload of the diagnostic capacity in Benin and provide baseline information on the usability of 16 genome-based surveillance in resource-limited settings. Sero-epidemiological studies needed to assess SARS-CoV-2 17 spread may be put at stake by low specificity of tests in tropical settings globally. The increasing diagnostic challenges 18 demand continuous support of national and supranational African stakeholders.","title":"Diagnostics and spread of SARS-CoV-2 in Western Africa: An observational laboratory-based study from Benin","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease-19 (COVID-19)\\", \\"location\\": \\"Benin, Western Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"4.4\\", \\"%CI values\\": \\"(95% confidence interval: 2.0-7.7)\\", \\"method\\": \\"SARS-CoV-2 genome-based analyses\\" } } ]","publish_time":"2020-07-08 10:00:00"},{"main_cord_uid":"e05oyl8r","cord_uid":"e05oyl8r","abstract":"We derive a novel hybrid approach, a combination of neural networks and inverse problem, in order to forecast COVID-19 cases, and more generally any infectious disease. For this purpose, we extract a second order nonlinear differential equation for the total confirmed cases from a SIR-like model. That differential equation is the key factor of the present study. The neural network and inverse problems are used to compute the trial functions for total cases and the model parameters, respectively. The number of suspected and infected individuals can be found using the trial function of total confirmed cases. We divide the time domain into two parts, training interval (first 365/395 days) and test interval (first 366 to 395/ 396 to 450 days), and train the neural networks on the preassigned training zones. To examine the efficiency and effectiveness, we apply the proposed method to Canada, and use the Canadian publicly available database to estimate the parameters of the trial function involved with total cases. The trial functions of model parameters show that the basic reproduction number was closed to unity over a wide range, the first from 100 to 365 days of the current pandemic in Canada. The proposed prediction models, based on influence of previous time and social economic policy, show excellent agreement with the data. The test results revel that the single path prediction can forecast a period of 30 days, and forecasting using previous social and economical situation can forecast a range of 55 days.","title":"A hybrid approach to predict COVID-19 cases using neural networks and inverse problem","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Canada\\r\\ndate: from 100 to 365 days of the current pandemic in Canada\\r\\nR0 value: closed to unity over a wide range\\r\\n%CI values: -\\r\\nmethod: second order nonlinear differential equation for the total confirmed cases from a SIR-like model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Canada\\",\\r\\n\\"date\\": \\"from 100 to 365 days of the current pandemic in Canada\\",\\r\\n\\"R0 value\\": \\"closed to unity over a wide range\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"second order nonlinear differential equation for the total confirmed cases from a SIR-like model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Canada\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"a combination of neural networks and inverse problem\\" } } ]","publish_time":"2022-05-17 00:00:00"},{"main_cord_uid":"eg8p2030","cord_uid":"eg8p2030","abstract":"Community quarantine has been resorted to by various governments to address the current COVID-19 pandemic; however, this is not the only non-therapeutic method of effectively controlling the spread of the infection. We study an SEIR model with nonlinear incidence rates, and introduce two parameters, and {varepsilon}, which mimics the effect of quarantine (Q). We compare this with the Q-SEIR model, recently developed, and demonstrate the control of COVID-19 without the stringent conditions of community quarantine. We analyzed the sensitivity and elasticity indices of the parameters with respect to the reproduction number. Results suggest that a control strategy that involves maximizing and {varepsilon} is likely to be successful, although quarantine is still more effective in limiting the spread of the virus. Release from quarantine depends on continuance and strict adherence to recommended social and health-promoting behaviors. Furthermore, maximizing and {varepsilon} is equivalent to a 50% successful quarantine in disease-free equilibrium (DFE). This model reduced the infectious in Quezon City by 3.45% and Iloilo Province by 3.88%; however, earlier peaking by nine and 17 days, respectively, when compared with the results of Q-SEIR.","title":"Protection after Quarantine: Insights from a Q-SEIR Model with Nonlinear Incidence Rates Applied to COVID-19","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-06-09 00:00:00"},{"main_cord_uid":"8uxntauq","cord_uid":"8uxntauq","abstract":"The effectiveness of control measures to contain coronavirus disease 2019 (COVID-19) in Wanzhou, China was assessed. Epidemiological data were analyzed for 183 confirmed COVID-19 cases and their close contacts from five generations of transmission of severe acute respiratory syndrome coronavirus 2 throughout the entire COVID-19 outbreak in Wanzhou. Approximately 67.2% and 32.8% of cases were symptomatic and asymptomatic, respectively. Asymptomatic and presymptomatic transmission accounted for 75.9% of the total recorded transmission. The reproductive number was 1.64 (95% confidence interval: 1.16-2.40) for G1-to-G2 transmission, decreasing to 0.31-0.39 in later generations, concomitant with implementation of rigorous control measures. Substantially higher infection risk was associated with contact within 5 d after the infectors had been infected, frequent contact and \xc3\xa2\xe2\u20ac\xb0\xc2\xa58 h of contact duration. The spread of COVID-19 was effectively controlled in Wanzhou by breaking the transmission chain through social distancing, extensive contact tracing, mass testing and strict quarantine of close contacts.","title":"Effective control of SARS-CoV-2 transmission in Wanzhou, China.","annotator_investigating_R0":"1","text_response":"disease name: coronavirus disease 2019 (COVID-19)\\r\\nlocation: Wanzhou, China\\r\\ndate: -\\r\\nR0 value: 1.64\\r\\n%CI values: 95% confidence interval: 1.16-2.40\\r\\nmethod: -","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"coronavirus disease 2019 (COVID-19)\\",\\r\\n\\"location\\": \\"Wanzhou, China\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"1.64\\",\\r\\n\\"%CI values\\": \\"95% confidence interval: 1.16-2.40\\",\\r\\n\\"method\\": \\"-\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease 2019 (COVID-19)\\", \\"location\\": \\"Wanzhou, China\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"1.64\\", \\"%CI values\\": \\"(95% confidence interval: 1.16-2.40)\\", \\"method\\": \\"Epidemiological data analysis\\" } }, { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease 2019 (COVID-19)\\", \\"location\\": \\"Wanzhou, China\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"(0.31-0.39)\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Epidemiological data analysis\\" } } ]","publish_time":"2020-11-30 00:00:00"},{"main_cord_uid":"emurar4d","cord_uid":"emurar4d","abstract":"Severe acute respiratory syndrome-coronavirus 2 (SARS-CoV-2) is the most significant global health crisis of the 21(st) century. The aim of this study was to develop a model to estimate the effect of undocumented infections, seasonal infectivity, immunity, and non-pharmaceutical interventions (NPIs), such as social distancing, on the transmission, morbidity, and mortality of SARS-CoV-2 in New York State (NYS). Simulations revealed dramatic infectivity driven by undocumented infections, and a peak basic reproductive number in NYS of 5.7. NPIs have been effective, and relaxation >50% will result in tens-of-thousands more deaths. Endemic infection is likely to occur in the absence of profound sustained immunity. As a result, until an effective vaccine or other effective pharmaceutical intervention is developed, it will be critical to not reduce NPIs >50% below current levels. This study establishes fundamental characteristics of SARS-CoV-2 transmission, which can help policymakers navigate combating this virus in the coming years.","title":"Significant Relaxation of SARS-CoV-2-Targeted Non-Pharmaceutical Interventions Will Result in Profound Mortality: A New York State Modelling Study","annotator_investigating_R0":"1","text_response":"disease name: Severe acute respiratory syndrome-coronavirus 2 (SARS-CoV-2)\\r\\nlocation: New York State (NYS)\\r\\ndate: -\\r\\nR0 value: 5.7\\r\\n%CI values: -\\r\\nmethod: -","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Severe acute respiratory syndrome-coronavirus 2 (SARS-CoV-2)\\",\\r\\n\\"location\\": \\"New York State (NYS)\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"5.7\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"-\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"SARS-CoV-2\\", \\"location\\": \\"New York State (NYS)\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"5.7\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Model\\" } } ]","publish_time":"2020-05-14 00:00:00"},{"main_cord_uid":"uzbb6vyc","cord_uid":"uzbb6vyc","abstract":"Following the detection of the new coronavirus1 severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) and its spread outside of China, Europe has experienced large epidemics of coronavirus disease 2019 (COVID-19). In response, many European countries have implemented non-pharmaceutical interventions, such as the closure of schools and national lockdowns. Here we study the effect of major interventions across 11 European countries for the period from the start of the COVID-19 epidemics in February 2020 until 4 May 2020, when lockdowns started to be lifted. Our model calculates backwards from observed deaths to estimate transmission that occurred several weeks previously, allowing for the time lag between infection and death. We use partial pooling of information between countries, with both individual and shared effects on the time-varying reproduction number (Rt). Pooling allows for more information to be used, helps to overcome idiosyncrasies in the data and enables more-timely estimates. Our model relies on fixed estimates of some epidemiological parameters (such as the infection fatality rate), does not include importation or subnational variation and assumes that changes in Rt are an immediate response to interventions rather than gradual changes in behaviour. Amidst the ongoing pandemic, we rely on death data that are incomplete, show systematic biases in reporting and are subject to future consolidation. We estimate that-for all of the countries we consider here-current interventions have been sufficient to drive Rt below 1 (probability Rt < 1.0 is greater than 99%) and achieve control of the epidemic. We estimate that across all 11 countries combined, between 12 and 15 million individuals were infected with SARS-CoV-2 up to 4 May 2020, representing between 3.2% and 4.0% of the population. Our results show that major non-pharmaceutical interventions-and lockdowns in particular-have had a large effect on reducing transmission. Continued intervention should be considered to keep transmission of SARS-CoV-2 under control.","title":"Estimating the effects of non-pharmaceutical interventions on COVID-19 in Europe","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"36fbcobw","cord_uid":"0y4dttsz","abstract":"The aim of this study was to estimate the basic reproduction number (R0) of COVID-19 in the early stage of the epidemic and predict the expected number of new cases in Shahroud in Northeastern Iran. The R0 of COVID-19 was estimated using the serial interval distribution and the number of incidence cases. The 30-day probable incidence and cumulative incidence were predicted using the assumption that daily incidence follows a Poisson distribution determined by daily infectiousness. Data analysis was done using \'earlyR\' and \'projections\' packages in R software. The maximum-likelihood value of R0 was 2.7 (95% confidence interval (CI): 2.1-3.4) for the COVID-19 epidemic in the early 14 days and decreased to 1.13 (95% CI 1.03-1.25) by the end of day 42. The expected average number of new cases in Shahroud was 9.0 \xc3\u201a\xc2\xb1 3.8 cases/day, which means an estimated total of 271 (95% CI: 178-383) new cases for the period between 02 April to 03 May 2020. By day 67 (27 April), the effective reproduction number (Rt), which had a descending trend and was around 1, reduced to 0.70. Based on the Rt for the last 21 days (days 46-67 of the epidemic), the prediction for 27 April to 26 May is a mean daily cases of 2.9 \xc3\u201a\xc2\xb1 2.0 with 87 (48-136) new cases. In order to maintain R below 1, we strongly recommend enforcing and continuing the current preventive measures, restricting travel and providing screening tests for a larger proportion of the population.","title":"The basic reproduction number and prediction of the epidemic size of the novel coronavirus (COVID-19) in Shahroud, Iran","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Shahroud in Northeastern Iran\\r\\ndate: early 14 days\\r\\nR0 value: 2.7\\r\\n%CI values: 95% confidence interval (CI): 2.1-3.4\\r\\nmethod: the serial interval distribution and the number of incidence cases\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Shahroud in Northeastern Iran\\r\\ndate: by the end of day 42.\\r\\nR0 value: 1.13\\r\\n%CI values: 95% CI 1.03-1.25\\r\\nmethod: the serial interval distribution and the number of incidence cases","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Shahroud in Northeastern Iran\\",\\r\\n\\"date\\": \\"early 14 days\\",\\r\\n\\"R0 value\\": \\"2.7\\",\\r\\n\\"%CI values\\": \\"95% confidence interval (CI): 2.1-3.4\\",\\r\\n\\"method\\": \\"the serial interval distribution and the number of incidence cases\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Shahroud in Northeastern Iran\\",\\r\\n\\"date\\": \\"by the end of day 42.\\",\\r\\n\\"R0 value\\": \\"1.13\\",\\r\\n\\"%CI values\\": \\"95% CI 1.03-1.25\\",\\r\\n\\"method\\": \\"the serial interval distribution and the number of incidence cases\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Shahroud, Iran\\", \\"date\\": \\"in the early 14 days\\", \\"R0 value\\": \\"2.7\\", \\"%CI values\\": \\"(95% confidence interval (CI): 2.1-3.4)\\", \\"method\\": \\"serial interval distribution and the number of incidence cases\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Shahroud, Iran\\", \\"date\\": \\"by the end of day 42\\", \\"R0 value\\": \\"1.13\\", \\"%CI values\\": \\"(95% CI 1.03-1.25)\\", \\"method\\": \\"serial interval distribution and the number of incidence cases\\" } } ]","publish_time":"2020","action":"change_main_cord_id","cluster_id":"165"},{"main_cord_uid":"c8vr9gk7","cord_uid":"c8vr9gk7","abstract":"Spain is among the countries worst hit by the Covid-19 pandemic, with one of the highest rate of infections and deaths per million inhabitants. First positive was reported on late January 2020. Mid March, with 7000 confirmed cases, nationwide lockdown was imposed. Mid May the epidemic was stabilized and government eased measures. Here we model the dynamics of the epidemic in Spain over the whole span, and study the effectiveness of control measures. The model is also applied to Italy and Germany. We propose formulas to easily estimate the size of the outbreak and the benefit of early intervention. A susceptible-infectious-recovered (SIR) model was used to simulate the epidemic. The growth and transmission rates, doubling time, and reproductive number were estimated by least-mean-square fitting of daily cases. Time-series data were obtained from official government reports. We forecasted the epidemic curve after lockdown under different effectiveness scenarios, and nowcasted the trend by moving average sliding window. Exponential growth expressions were derived. Outbreak progression remained under the early growth dynamics. The basic reproductive number in Spain was 2.5\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xc2\xaf\xc3\u201a\xc2\xb1\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xc2\xaf0.1 (95% CI 2.3-2.7), and the doubling time was 2.8\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xc2\xaf\xc3\u201a\xc2\xb1\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xc2\xaf0.1 days (95% CI 2.6-3.0). Slight variations in measures effectiveness produce a large divergence in the epidemic size. The effectiveness in Spain was 68%, above control threshold (60%). During lockdown the reproductive number dropped to an average of 0.81\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xc2\xaf\xc3\u201a\xc2\xb1\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xc2\xaf0.02 (95% CI 0.77-0.85). Estimated epidemic size is about 300,000 cases. A 7-days advance of measures yields a reduction to 38%. The dynamics in Spain is similar to other countries. Strong lockdown measures must be adopted if not compensated by rapid detection and isolation of patients, and even a slight relaxation would raise the reproductive number above 1. Simple calculations allow anticipating the size of the epidemic based on when measures are taken and their effectiveness. Spain acted late. Control measures must be implemented immediately in the face on an epidemic.","title":"The Covid-19 outbreak in Spain. A simple dynamics model, some lessons, and a theoretical framework for control response","annotator_investigating_R0":"1","text_response":"disease name: Covid-19\\r\\nlocation: Spain\\r\\ndate: over the whole span\\r\\nR0 value: 2.5\\r\\n%CI values: 95% CI 2.3-2.7\\r\\nmethod: (SIR) model\\r\\n|\\r\\ndisease name: Covid-19\\r\\nlocation: Germany\\r\\ndate: over the whole span\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: (SIR) model\\r\\n|\\r\\ndisease name: Covid-19\\r\\nlocation: Italy\\r\\ndate: over the whole span\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: (SIR) model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"Spain\\",\\r\\n\\"date\\": \\"over the whole span\\",\\r\\n\\"R0 value\\": \\"2.5\\",\\r\\n\\"%CI values\\": \\"95% CI 2.3-2.7\\",\\r\\n\\"method\\": \\"(SIR) model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"Germany\\",\\r\\n\\"date\\": \\"over the whole span\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"(SIR) model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"Italy\\",\\r\\n\\"date\\": \\"over the whole span\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"(SIR) model\\"}}]","json_model_response":" { \\"contribution\\": { \\"disease name\\": \\"Covid-19\\", \\"location\\": \\"Spain\\", \\"date\\": \\"Mid March (before lockdown)\\", \\"R0 value\\": \\"2.5-0.1\\", \\"%CI values\\": \\"(95% CI 2.3-2.7)\\", \\"method\\": \\"susceptible-infectious-recovered (SIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Covid-19\\", \\"location\\": \\"Spain\\", \\"date\\": \\"Mid March (after lockdown)\\", \\"R0 value\\": \\"0.81-0.02\\", \\"%CI values\\": \\"(95% CI 0.77-0.85)\\", \\"method\\": \\"susceptible-infectious-recovered (SIR) model\\" } } ]","publish_time":"2020","cluster_id":"359"},{"main_cord_uid":"pu5czpyz","cord_uid":"pu5czpyz","abstract":"Reemergent local outbreaks of coronavirus disease 2019 (COVID-19) have occurred in China, yet few Chinese response strategies and its evaluation have been reported. This study presents a preliminary assessment of Chinese strategy in controlling reemergent local outbreaks of COVID-19. Time course of accumulative and daily new cases and time-varying reproductive numbers (Rt) of outbreak areas were presented. The asymptomatic rate, days required to control the outbreaks, seeding time (ST), and doubling time (DT) of areas with over 96 reemergent cases were calculated. National and local year-on-year growth rates of gross domestic product (GDP) were presented. Accumulative numbers of 30, 8, 11, 430, 15, 139, 1,067, 382, 42, and 94 confirmed reemergent COVID-19 cases were diagnosed in Hulun Buir, Shanghai, Tianjin, Kashgar, Qingdao, Dalian, Urumchi, Beijing, Jilin, and Harbin, respectively. Among them, maximum rate of asymptomatic infections was 81.9%. Time required to control the local outbreaks in the areas given above varied from 29 to 51 days. After activation of outbreak responses, the late-stage DTs of Kashgar, Urumchi, Beijing, and Dalian were apparently lengthened compared to the early-stage DTs. Although the year-on-year GDP growth rate of Urumchi was slightly affected, the GDP growth rate of Dalian, Beijing, Jilin, and Harbin kept rising during the reemergence. Moreover, the year-on-year GDP growth rate of Mainland China turned positive regardless of the reemergent local outbreaks. In general, the Chinese strategy to maintain the status of no or minimal transmission was effective in balancing the control of COVID-19 reemergent local outbreak and the recovery of economy.","title":"Preliminary Assessment of Chinese Strategy in Controlling Reemergent Local Outbreak of COVID-19","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-07-02 10:00:00"},{"main_cord_uid":"w5d7ho1m","cord_uid":"w5d7ho1m","abstract":"This work aims to model, simulate and provide insights into the dynamics and control of COVID-19 infection rates. Using an established epidemiological model augmented with a time-varying disease transmission rate allows daily model calibration using COVID-19 case data from countries around the world. This hybrid model provides predictive forecasts of the cumulative number of infected cases. It also reveals the dynamics associated with disease suppression, demonstrating the time to reduce the effective, time-dependent, reproduction number. Model simulations provide insights into the outcomes of disease suppression measures and the predicted duration of the pandemic. Visualisation of reported data provides up-to-date condition monitoring, while daily model calibration allows for a continued and updated forecast of the current state of the pandemic.","title":"Insights into the dynamics and control of COVID-19 infection rates","annotator_investigating_R0":"0","text_response":"disease name: COVID-19\\r\\nlocation: countries around the world\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: established epidemiological model augmented with a time-varying disease transmission rate","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"countries around the world\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"established epidemiological model augmented with a time-varying disease transmission rate\\"}}]","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"j852fh90","cord_uid":"j852fh90","abstract":"Most countries around the world are battling to limit the spread of severe acute respiratory syndrome-coronavirus 2 (SARS-CoV-2). As the world strives to get an effective medication to control the disease, appropriate control measures for now remains one of the effective measures to reduce the spread of the disease. In this study, a fractional optimal control model is formulated in Atangana-Baleanu-Caputo derivative sense. The reproduction number and steady state of disease free of the Coronavirus model are examined and found to be globally stable. The existence and uniqueness of solution of the fractional Coronavirus model is established by using the Banach fixed point theorem approach. Three controls are considered in the model and Pontryagins Maximum Principle is used to establish the necessary conditions for optimal control solution. The numerical solution suggests that the best strategy is found to be the utilization of all three controls at the same time.","title":"Fractional optimal control dynamics of coronavirus model with Mittag\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153Leffler law","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-01-31 05:00:00"},{"main_cord_uid":"62b5yddl","cord_uid":"62b5yddl","abstract":"The spread of SARS-CoV-2 created a pandemic crisis with > 150,000 cumulative cases in > 65 countries within a few months. The reproductive number (R) is a metric to estimate the transmission of a pathogen during an outbreak. Preliminary published estimates were based on the initial outbreak in China. Whole genome sequences (WGS) analysis found mutational variations in the viral genome; however, previous comparisons failed to show a direct relationship between viral genome diversity, transmission, and the epidemic severity. COVID-19 incidences from different countries were modeled over the epidemic curve. Estimates of the instantaneous R (Wallinga and Teunis method) with a short and standard serial interval were done. WGS were used to determine the populations genomic variation and that underpinned creation of the pathogen genome identity (GENI) score, which was merged with the outbreak curve in four distinct phases. Inference of transmission time was based on a mutation rate of 2 mutations/month. R estimates revealed differences in the transmission and variable infection dynamics between and within outbreak progression for each country examined. Outside China, our R estimates observed propagating dynamics indicating that other countries were poised to move to the takeoff and exponential stages. Population density and local temperatures had no clear relationship to the outbreak progression. Integration of incidence data with the GENI score directly predicted increases in cases as the genome variation increased that led to new variants. Integrating the outbreak curve, dynamic R, and SNP variation found a direct association between increasing cases and transmission genome evolution. By defining the epidemic curve into four stages and integrating the instantaneous country-specific R with the GENI score, we directly connected changes in individual outbreaks based on changes in the virus genome via SNPs. This resulted in the ability to forecast potential increases in cases as well as mutations that may defeat PCR screening and the infection process. By using instantaneous R estimations and WGS, outbreak dynamics were defined to be linked to viral mutations, indicating that WGS, as a surveillance tool, is required to predict shifts in each outbreak that will provide actionable decision making information. Integrating epidemiology with genome sequencing and modeling allows for evidence-based disease outbreak tracking with predictive therapeutically valuable insights in near real time.","title":"Analysis of SARS-CoV-2 genomic epidemiology reveals disease transmission coupled to variant emergence and allelic variation","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"vm8bq4eo","cord_uid":"vm8bq4eo","abstract":"This paper provides estimates of COVID-19 effective reproduction numbers worldwide and explains their evolution for selected European countries since the start of the pandemic, taking account of changes in voluntary and government-mandated social distancing, incentives to comply, vaccination and the emergence of mutations. Evidence based on panel data modeling indicates that the diversity of outcomes that we document resulted from the non-linear interaction of mandated and voluntary social distancing and the economic incentives that governments provided to support isolation, with no one factor independently capable of lowering the reproduction number below one. However, the importance of these factors declined over time, with vaccine uptake driving heterogeneity in country experiences in 2021. Our approach also allows us to identify the basic reproduction number, R0, and how it changes with mutations. It is precisely estimated and differs little across countries.","title":"Social Distancing, Vaccination and Evolution of Covid-19 Transmission Rates in Europe (preprint)/ en","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"-"},{"main_cord_uid":"kjbflli1","cord_uid":"kjbflli1","abstract":"The 2005 dengue outbreak in Singapore cumulated in > 14,000 cases and 27 reported dengue deaths. We fit the single-phase Richards model to weekly dengue notification numbers to detect the turning point for the outbreak, which enables us to study the impact of intervention measures relating to the turning point. The results indicate that turning point had most likely occurred in late August or early September, before large-scale intervention measures were implemented. The \\"initial\\" reproduction number for the outbreak is estimated to be ~1.89-2.23 (95% confidence interval: 1.15-3.00). One of the lessons learned from the 2003 severe acute respiratory syndrome (SARS) outbreak is that multiple phases of outbreak were observed in some affected countries when efforts to intensify intervention or to sustain vigilance were compromised. Intensive and continuing efforts in the implementation of control measures are essential in reducing further dengue occurrences during any resurgence of dengue.","title":"Intervention measures, turning point, and reproduction number for dengue, Singapore, 2005.","annotator_investigating_R0":"1","text_response":"disease name: Dengue\\r\\nlocation: Singapore\\r\\ndate: -\\r\\nR0 value: 1.89-2.23\\r\\n%CI values: (95% confidence interval: 1.15-3.00)\\r\\nmethod: single-phase Richards model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Dengue\\",\\r\\n\\"location\\": \\"Singapore\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"1.89-2.23\\",\\r\\n\\"%CI values\\": \\"(95% confidence interval: 1.15-3.00)\\",\\r\\n\\"method\\": \\"single-phase Richards model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"Dengue\\", \\"location\\": \\"Singapore\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"1.89-2.23\\", \\"%CI values\\": \\"(95% confidence interval: 1.15-3)\\", \\"method\\": \\"single-phase Richards model\\" } } ]","publish_time":"2009"},{"main_cord_uid":"8tg17wm3","cord_uid":"8tg17wm3","abstract":"The fast-spreading Omicron variant of SARS-CoV-2 overwhelmed Hong Kong, causing the fifth wave of COVID-19. It remains to be determined what mitigation measures might have played a role in reversing the rising trend of confirmed cases in this major outbreak. The government of Hong Kong has launched the mass rapid antigen tests (RAT) in the population and the StayHomeSafe scheme since February 2022. In this study, we examined the impact of the mass RAT on disease transmission and the case fatality ratio. It was suggested that the implementation of RAT plausibly played a role in the steady decrease of the effective reproduction number, leading to diminished SARS-CoV-2 transmission. In addition, we projected the disease burden of the outbreak in a scenario analysis to highlight the necessity of the StayHomeSafe scheme in Hong Kong. The Omicron outbreak experience in Hong Kong may provide actionable insights for navigating the challenges of COVID-19 surges in other regions and countries.","title":"Understanding the impact of rapid antigen tests on SARS-CoV-2 transmission in the fifth wave of COVID-19 in Hong Kong in early 2022","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2022-05-23 10:00:00"},{"main_cord_uid":"weaoecu3","cord_uid":"weaoecu3","abstract":"The outbreak of the novel coronavirus, COVID-19, has been declared a pandemic by the WHO. The structures of social contact critically determine the spread of the infection and, in the absence of vaccines, the control of these structures through large-scale social distancing measures appears to be the most effective means of mitigation. Here we use an age-structured SIR model with social contact matrices obtained from surveys and Bayesian imputation to study the progress of the COVID-19 epidemic in India. The basic reproductive ratio R0 and its time-dependent generalization are computed based on case data, age distribution and social contact structure. The impact of social distancing measures - workplace non-attendance, school closure, lockdown - and their efficacy with durations are then investigated. A three-week lockdown is found insufficient to prevent a resurgence and, instead, protocols of sustained lockdown with periodic relaxation are suggested. Forecasts are provided for the reduction in age-structured morbidity and mortality as a result of these measures. Our study underlines the importance of age and social contact structures in assessing the country-specific impact of mitigatory social distancing.","title":"Age-structured impact of social distancing on the COVID-19 epidemic in India","annotator_investigating_R0":"0","text_response":"disease name: COVID-19\\r\\nlocation: India\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: age-structured SIR model with social contact matrices obtained from surveys and Bayesian imputation","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"India\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"age-structured SIR model with social contact matrices obtained from surveys and Bayesian imputation\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"India\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"age-structured SIR model with social contact matrices\\" } } ]","publish_time":"2020"},{"main_cord_uid":"13tpjcms","cord_uid":"13tpjcms","abstract":"Background: Various mathematical modeling approaches are used to provide a robust framework for understanding the transmission dynamics of infectious diseases in human populations. In an epidemic, models can be used for the analysis of the spread of a disease, forecasting, identifying trends and making parameter estimates which can be used for planning and implementing intervention measures. Methods This study utilizes the classical Susceptible - Infected - Recovered (SIR) model to analyze the evolution of COVID-19 in Zambia during the third wave of infections. The model is fitted to actual COVID-19 data for Zambia for the third wave of the pandemic obtained from the Zambia National Public Health Institute (ZNPHI). The transmission and recovery rates are estimated by minimizing the error between the fitted curve and the real data using the least square approach. Results Model simulations indicate that the basic reproductive number (\\\\({R}_{0}\\\\)) for Zambia is 1.31 meaning that, on average, 1.31 persons are infected for each infected person. At the worst point of the epidemic, we expect that 591,743 people will contract the virus and 7,144 fatalities will be recorded. To prevent the spread of infection, the model estimates that at least 24 percent of the population will need to be vaccinated. With the country\'s projected population of about 18.91 million, this translates to roughly 4.5 million people. Conclusion The severity of COVID-19 infection, hospitalizations, and deaths in Zambia is substantially higher than national testing data suggests, according to model projections. More modeling work is needed to acquire accurate estimates of the disease burden in society, to inform resource allocation, and to aid mitigation planning, especially in countries that may lack adequate national surveillance systems.","title":"Simulation of the Third Wave of COVID 19 Infections in Zambia using the SIR Model (preprint)/ en","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Zambia\\r\\ndate: for the third wave of the pandemic obtained from the Zambia National Public Health Institute (ZNPHI)\\r\\nR0 value: 1.31\\r\\n%CI values: -\\r\\nmethod: classical Susceptible - Infected - Recovered (SIR) model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Zambia\\",\\r\\n\\"date\\": \\"for the third wave of the pandemic obtained from the Zambia National Public Health Institute (ZNPHI)\\",\\r\\n\\"R0 value\\": \\"1.31\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"classical Susceptible - Infected - Recovered (SIR) model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Zambia\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"1.31\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"classical Susceptible - Infected - Recovered (SIR) model\\" } } ]","publish_time":"-"},{"main_cord_uid":"5dd89gnm","cord_uid":"5dd89gnm","abstract":"Since December 8, 2019, the spread of COVID-19 is increasing every day. It is particularly important to predict the trend of the epidemic for the timely adjustment of the economy and industries. We proposed a Flow-SEHIR model in this paper, based on which we further analyzed the trends of 2019-nCoV (COVID-19) in China. The results show that the basic reproductive numbers R0 of COVID-19 is 3.56 (95% CI: 2.31-4.81). The number of daily confirmed new cases reaches the inflection point on Feb. 6-10 outside Hubei. For the maximum of infected cases number, the predicted peak value in China except Hubei was estimated to be 13806 (95% CI: 11926-15845). The peak arrival time is on March 3-9. The temporal number of patients in most areas of China outside Hubei will peak from March 12 to March 15. The peak values of more than 73.5% provinces or regions in China will be controlled within 1000. According to Flow-SEHIR model and estimations from the data of evacuation of nationals from Wuhan, the peak cumulative number of patients in Hubei was estimated to be 403481 (95% CI: 143284-1166936).","title":"Assessing the Tendency of 2019-nCoV (COVID-19) Outbreak in China","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: China\\r\\ndate: Since December 8, 2019\\r\\nR0 value: 3.56\\r\\n%CI values: 95% CI: 2.31-4.81\\r\\nmethod: Flow-SEHIR model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"China\\",\\r\\n\\"date\\": \\"Since December 8, 2019\\",\\r\\n\\"R0 value\\": \\"3.56\\",\\r\\n\\"%CI values\\": \\"95% CI: 2.31-4.81\\",\\r\\n\\"method\\": \\"Flow-SEHIR model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"2019-nCoV (COVID-19)\\", \\"location\\": \\"China\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"3.56\\", \\"%CI values\\": \\"95% CI: 2.31-4.81\\", \\"method\\": \\"Flow-SEHIR model\\" } } ]","publish_time":"2020-02-11 00:00:00"},{"main_cord_uid":"f6owfp5t","cord_uid":"f6owfp5t","abstract":"Epidemic models play a key role in understanding and responding to the emerging COVID-19 pandemic. Widely used compartmental models are static and are of limited use to evaluate intervention strategies with the emerging pandemic. Applying the technology of data assimilation, we propose a Bayesian updating approach for estimating epidemiological parameters using observable information for the purpose of assessing the impacts of different intervention strategies. We adopt a concise renewal model and propose new parameters by disentangling the reduction of instantaneous reproduction number Rt into mitigation and suppression factors for quantifying intervention impacts at a finer granularity. Then we developed a data assimilation framework for estimating these parameters including constructing an observation function and developing a Bayesian updating scheme. A statistical analysis framework is then built to quantify the impact of intervention strategies by monitoring the evolution of these estimated parameters. By Investigating the impacts of intervention measures of European countries, the United States and Wuhan with the framework, we reveal the effects of interventions in these countries and the resurgence risk in the USA.","title":"A Bayesian Updating Scheme for Pandemics: Estimating the Infection Dynamics of COVID-19","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"zz293iy5","cord_uid":"zz293iy5","abstract":"In this paper, we propose a four compartmental model to understand the dynamics of infectious disease COVID-19. We show the boundedness and non-negativity of solutions of the model. We analytically calculate the basic reproduction number of the model and perform the stability analysis at the equilibrium points to understand the epidemic and endemic cases based on the basic reproduction number. Our analytical results show that disease free equilibrium point is asymptotically stable (unstable) and endemic equilibrium point is unstable (asymptotically stable) if the basic reproduction number is less than (greater than) unity. The dispersal rate of the infected population and the social awareness control parameter are the main focus of this study. In our model, these parameters play a vital role to control the spread of COVID-19. Our results reveal that regional lockdown and social awareness (e.g., wearing a face mask, washing hands, social distancing) can reduce the pandemic of the current outbreak of novel coronavirus in a most densely populated country like Bangladesh.","title":"Modeling the dispersal effect to reduce the infection of COVID-19 in Bangladesh","annotator_investigating_R0":"0","text_response":"disease name: COVID-19\\r\\nlocation: -\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: a four compartmental model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"-\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"a four compartmental model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Bangladesh\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"a four compartmental model\\" } } ]","publish_time":"2020-09-28 10:00:00"},{"main_cord_uid":"4sxsyr6k","cord_uid":"4sxsyr6k","abstract":"Background In order to slow down the spread of SARS-CoV-2, the virus causing the COVID-19 pandemic, the UK government has imposed strict physical distancing (lockdown) measures including school \'dismissals\' since 23 March 2020. As evidence is emerging that these measures may have slowed the spread of the pandemic, it is important to assess the impact of any changes in strategy, including scenarios for school reopening and broader relaxation of social distancing. This work uses an individual-based model to predict the impact of a suite of possible strategies to reopen schools in the UK, including that currently proposed by the UK government. Methods We use Covasim, a stochastic agent-based model for transmission of COVID-19, calibrated to the UK epidemic. The model describes individuals\' contact networks stratified as household, school, work and community layers, and uses demographic and epidemiological data from the UK. We simulate a range of different school reopening strategies with a society-wide relaxation of lockdown measures and in the presence of different non-pharmaceutical interventions, to estimate the number of new infections, cumulative cases and deaths, as well as the effective reproduction number with different strategies. To account for uncertainties within the stochastic simulation, we also simulated different levels of infectiousness of children and young adults under 20 years old compared to older ages. Findings We found that with increased levels of testing of people (between 25% and 72% of symptomatic people tested at some point during an active COVID-19 infection depending on scenarios) and effective contact-tracing and isolation for infected individuals, an epidemic rebound may be prevented across all reopening scenarios, with the effective reproduction number (R) remaining below one and the cumulative number of new infections and deaths significantly lower than they would be if testing did not increase. If UK schools reopen in phases from June 2020, prevention of a second wave would require testing 51% of symptomatic infections, tracing of 40% of their contacts, and isolation of symptomatic and diagnosed cases. However, without such measures, reopening of schools together with gradual relaxing of the lockdown measures are likely to induce a secondary pandemic wave, as are other scenarios for reopening. When infectiousness of <20 year olds was varied from 100% to 50% of that of older ages, our findings remained unchanged. Interpretation To prevent a secondary COVID-19 wave, relaxation of social distancing including reopening schools in the UK must be implemented alongside an active large-scale population-wide testing of symptomatic individuals and effective tracing of their contacts, followed by isolation of symptomatic and diagnosed individuals. Such combined measures have a greater likelihood of controlling the transmission of SARS-CoV-2 and preventing a large number of COVID-19 deaths than reopening schools and society with the current level of implementation of testing and isolation of infected individuals.","title":"Determining the optimal strategy for reopening schools, work and society in the UK: balancing earlier opening and the impact of test and trace strategies with the risk of occurrence of a secondary COVID-19 pandemic wave","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-06-01 10:00:00"},{"main_cord_uid":"6w1zqbax","cord_uid":"6w1zqbax","abstract":"The Coronavirus Disease 2019 (COVID-19) has fast spread to over 200 countries and regions worldwide since its outbreak, while in March, Europe became the emerging epicentre. In this study, we aimed to model the epidemic trends and estimate the essential epidemic features of COVID-19 in Italy, Spain, Germany, and France at the initial stage. The numbers of daily confirmed cases and total confirmed cases were extracted from the Coronavirus disease (COVID-19) situation reports of WHO. We applied an extended Susceptible-Exposed-Infectious-Removed (SEIR) model to fit the epidemic trend and estimated corresponding epidemic features. The transmission rate estimates were 1.67 (95% credible interval (CrI), 1.64-1.71), 2.83 (2.72-2.85), 1.91 (1.84-1.98), and 1.89 (1.82-1.96) for Italy, Spain, Germany, and France, corresponding to the basic reproduction numbers (R0) 3.44 (3.35-3.54), 6.25 (5.97-6.55), 4.03 (3.84-4.23), and 4.00 (3.82-4.19), respectively. We found Spain had the lowest ascertainment rate of 0.22 (0.19-0.25), followed by France, Germany, and Italy of 0.45 (0.40-0.50), 0.46 (0.40-0.52), and 0.59 (0.55-0.64). The peaks of daily new confirmed cases would reach on April 16, April 5, April 21, and April 19 for Italy, Spain, Germany, and France if no action was taken by the authorities. Given the high transmissibility and high covertness of COVID-19, strict countermeasures, such as national lockdown and social distancing, were essential to be implemented to reduce the spread of the disease.","title":"Modelling the initial epidemic trends of COVID-19 in Italy, Spain, Germany, and France","annotator_investigating_R0":"1","text_response":"disease name: Coronavirus Disease 2019 (COVID-19)\\r\\nlocation: Italy\\r\\ndate: -\\r\\nR0 value: 3.44\\r\\n%CI values: 3.35-3.54\\r\\nmethod: extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\r\\n|\\r\\ndisease name: Coronavirus Disease 2019 (COVID-19)\\r\\nlocation: Spain\\r\\ndate: -\\r\\nR0 value: 6.25\\r\\n%CI values: 5.97-6.55\\r\\nmethod: extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\r\\n|\\r\\ndisease name: Coronavirus Disease 2019 (COVID-19)\\r\\nlocation: Germany\\r\\ndate: -\\r\\nR0 value: 4.03\\r\\n%CI values: 3.84-4.23\\r\\nmethod: extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\r\\n|\\r\\ndisease name: Coronavirus Disease 2019 (COVID-19)\\r\\nlocation: France\\r\\ndate: -\\r\\nR0 value: 4\\r\\n%CI values: 3.82-4.19\\r\\nmethod: extended Susceptible-Exposed-Infectious-Removed (SEIR) model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\",\\r\\n\\"location\\": \\"Italy\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"3.44\\",\\r\\n\\"%CI values\\": \\"3.35-3.54\\",\\r\\n\\"method\\": \\"extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\",\\r\\n\\"location\\": \\"Spain\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"6.25\\",\\r\\n\\"%CI values\\": \\"5.97-6.55\\",\\r\\n\\"method\\": \\"extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\",\\r\\n\\"location\\": \\"Germany\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"4.03\\",\\r\\n\\"%CI values\\": \\"3.84-4.23\\",\\r\\n\\"method\\": \\"extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\",\\r\\n\\"location\\": \\"France\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"4\\",\\r\\n\\"%CI values\\": \\"3.82-4.19\\",\\r\\n\\"method\\": \\"extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\", \\"location\\": \\"Italy, Spain, Germany, and France\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"6.35\\", \\"%CI values\\": \\"(5.97-6.55)\\", \\"method\\": \\"extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\", \\"location\\": \\"Spain\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"6.25\\", \\"%CI values\\": \\"(6.77-6.55)\\", \\"method\\": \\"extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\", \\"location\\": \\"Germany\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"4.03\\", \\"%CI values\\": \\"(3.84-4.23)\\", \\"method\\": \\"extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\", \\"location\\": \\"France\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\", \\"location\\": \\"Italy\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\", \\"location\\": \\"Italy\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\", \\"location\\": \\"Italy\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\", \\"location\\": \\"Italy\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\", \\"location\\": \\"Italy\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\", \\"location\\": \\"Italy\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\", \\"location\\": \\"Italy\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\", \\"location\\": \\"Italy\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\", \\"location\\": \\"Italy\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"extended Susceptible-Exposed-Infectious-Removed (SEIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus} } ]","publish_time":"2020","cluster_id":"1425"},{"main_cord_uid":"6pb0lpyc","cord_uid":"6pb0lpyc","abstract":"In this work, we estimate the total number of infected and deaths by COVID-19 in Brazil and two Brazilian States (Rio de Janeiro and Sao Paulo). To obtain the unknown data, we use an iterative method in the Gompertz model, whose formulation is well known in the field of biology. Based on data collected from the Ministry of Health from February 26, 2020, to July 2, 2020, we predict, from July 3 to 9 and at the end of the epidemic, the number of infected and killed for the whole country and for the Brazilian states of Sao Paulo and Rio de Janeiro. We estimate, until July 9, 2020, a total of 1,709,755 cases and 65,384 deaths in Brazil, 331,718 cases and 15,621 deaths in Sao Paulo, 134,454 cases and 11,574 deaths in Rio de Janeiro. We also estimate the basic reproduction number R 0 for Brazil and its two states. The estimated values ( R 0 ) were 1.3, 1.3, and 1.4 for Brazil, Sao Paulo, and Rio de Janeiro, respectively. The results show a good fit between the observed data and those obtained by the Gompertz. The proposed methodology can also be applied to other countries and Brazilian states, and we provide an executable as well as the source code for a straightforward application of the method on such data.","title":"Predicting the number of total COVID-19 cases and deaths in Brazil by the Gompertz model","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Brazil\\r\\ndate: February 26, 2020, to July 2, 2020\\r\\nR0 value: 1.3\\r\\n%CI values: -\\r\\nmethod: iterative method in the Gompertz model\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Sao Paulo\\r\\ndate: February 26, 2020, to July 2, 2020\\r\\nR0 value: 1.3\\r\\n%CI values: -\\r\\nmethod: iterative method in the Gompertz model\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Rio de Janeiro\\r\\ndate: February 26, 2020, to July 2, 2020\\r\\nR0 value: 1.4\\r\\n%CI values: -\\r\\nmethod: iterative method in the Gompertz model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Brazil\\",\\r\\n\\"date\\": \\"February 26, 2020, to July 2, 2020\\",\\r\\n\\"R0 value\\": \\"1.3\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"iterative method in the Gompertz model\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Sao Paulo\\",\\r\\n\\"date\\": \\"February 26, 2020, to July 2, 2020\\",\\r\\n\\"R0 value\\": \\"1.3\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"iterative method in the Gompertz model\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Rio de Janeiro\\",\\r\\n\\"date\\": \\"February 26, 2020, to July 2, 2020\\",\\r\\n\\"R0 value\\": \\"1.4\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"iterative method in the Gompertz model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Brazil\\", \\"date\\": \\"February 26, 2020 to July 2, 2020\\", \\"R0 value\\": \\"1.3\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"iterative method in the Gompertz model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Sao Paulo\\", \\"date\\": \\"February 26, 2020 to July 2, 2020\\", \\"R0 value\\": \\"1.3\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"iterative method in the Gompertz model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Rio de Janeiro\\", \\"date\\": \\"February 26 2020 to July 2, 2020\\", \\"R0 value\\": \\"1.4\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"iterative method in the Gompertz model\\" } } ]","publish_time":"2020","cluster_id":"176"},{"main_cord_uid":"jep80bed","cord_uid":"jep80bed","abstract":"Coronaviruses of humans were first identified more than 60 years ago from individuals with respiratory infections, mainly mild. Two different viruses, 229E and OC43 were initially recognized. Because of difficulty in isolating them using standard techniques, many of the early studies of their occurrence were seroepidemiologic. They were confirmed to be worldwide in distribution, and, in the North Temperate Zone, mainly occurring in the winter season. With the development of the reverse transcriptase polymerase chain reaction (PCR) technique, two additional distinct viruses have been identified, HKU1 and NL63. The four viruses have now been recognized as important in the etiology of common respiratory infections, second only to the rhinoviruses. In 2002, a previously unrecognized betacoronavirus emerged from a zoonotic reservoir in Southern China and spread during the following year to several major cities of the world. The resulting illness was termed Severe Acute Respiratory Syndrome (SARS) because of its potential lethality. More than 8,000 probable cases were reported during 2003, mainly from Hong Kong and mainland China, producing social and economic disruption in those areas affected. A constant feature of the outbreak was the importance of nosocomial spread. In spite of an estimated basic reproductive number higher than influenza, the outbreak was ended, in large part because of control of in-hospital transmission. In 2012, another betacoronavirus has emerged in the Arabian peninsula which is producing a somewhat similar illness, termed Middle East Respiratory Syndrome (MERS), also marked by extensive nosocomial transmission. The outcome of this emergence is currently unknown.","title":"Coronaviruses","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2014-02-27 00:00:00"},{"main_cord_uid":"7ws2kleo","cord_uid":"7ws2kleo","abstract":"Since the appearance of the first case of COVID-19 in Morocco on March, 02,2020, the cumulative number of reported infectious cases continues to increase and, up to date, the peak-time of infection is not reached yet. In this study, we propose a Susceptible-Asymptomatic-Infectious deterministic model to evaluate the impact of compulsory containment imposed in Morocco on March, 21 on the spread of COVID-19 epidemic across the country. The model takes account of the unconfined individuals that continue to work or to leave their home for urgent needs and the existence of infectious asymptomatic and unreported individuals within susceptible population. Furthermore, the model is able to predict the peak-size, peak-time, final size and epidemic duration according to different rates of containment. Advanced knowledge of these details will be of great interest to establish an optimal plan-of-action to control or eradicate the epidemic. Indeed, mitigating and delaying the epidemic peak allow the official health authorities to anticipate and control the spread of COVID-19. Moreover, prediction of the epidemic duration can help the government to predict the end time of containment to avoid consequent social-economic damages as well. Using our model, the basic reproduction number R(0) is estimated to be 2.9949, with [Formula: see text] reflecting a high speed of spread of the epidemic. The model shows that the compulsory containment can be efficient if more than 73% of population are confined. In the absence of other efficient measure of control, even with 90% of containment, the end-time is estimated to happen on July, 4,2020 with 7558 final cumulative cases. Furthermore, a threshold value of containment rate, below which the epidemic duration is postponed, has been determined. Finally, the sensitivity analysis is performed and showed that the COVID-19 dynamics strongly depends on the asymptomatic duration as well as the contact and containment rates. Our previsions can help the government to adjust its plan-of-action to fight the disease and to face the social-economic shock induced by the containment.","title":"Impact assessment of containment measure against COVID-19 spread in Morocco","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Morocco\\r\\ndate: -\\r\\nR0 value: 2.9949\\r\\n%CI values: -\\r\\nmethod: Susceptible-Asymptomatic-Infectious deterministic model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Morocco\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"2.9949\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Susceptible-Asymptomatic-Infectious deterministic model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Morocco\\", \\"date\\": \\"March, 21\\", \\"R0 value\\": \\"2.9949\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Susceptible-Asymptomatic-Infectious deterministic model\\" } } ]","publish_time":"2020-08-22 10:00:00"},{"main_cord_uid":"z16o1tps","cord_uid":"z16o1tps","abstract":"Given the worldwide pandemic of the novel coronavirus disease 2019 (COVID-19) and its continuing threat brought by the emergence of virus variants, there are great demands for accurate surveillance and monitoring of outbreaks. A valuable metric for assessing the current risk posed by an outbreak is the time-varying reproduction number ((Formula presented.)). Several methods have been proposed to estimate (Formula presented.) using different types of data. We developed a new tool that integrated two commonly used approaches into a unified and user-friendly platform for the estimation of time-varying reproduction numbers. This tool allows users to perform simulations and yield real-time tracking of local epidemic of COVID-19 with an R package. Copyright \xc3\u201a\xc2\xa9 2022 Liu, Xu, Bai, Xu, Lau, Cowling and Du.","title":"Local Surveillance of the COVID-19 Outbreak","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2022"},{"main_cord_uid":"tu9l6fue","cord_uid":"tu9l6fue","abstract":"How does one interpret the observed increase or decrease in COVID19 case rates? Did the compliance to the non pharmaceutical interventions, seasonal changes in the temperature influence the transmission rates or are they purely an artefact of the number of tests? To answer these questions, we estimate the effect sizes from these different factors on the reproduction ratios (Rt) from the different states of the USA during March 9 to August 9. Ideally Rt should be less than 1 to keep the pandemic under control and our model predicts many of these factors contributed significantly to the Rt: Post-lockdown opening of the restaurants and nightclubs contributed 0.04 (CI 0.04-0.04) and 0.11 (CI. 0.11-0.11) to Rt. The mask mandates helped reduce Rt by 0.28 (CI 0.28-0.29)), whereas the testing rates which may have influenced the number of infections observed, did not influence Rt beyond 10,000 daily tests 0.07 (CI -0.57-0.42). In our attempt to understand the role of temperature, the contribution to the Rt was found to increase on both sides of 55 F, which we infer as a reflection of the climatisation needs. A further analysis using the cooling and heating needs showed contributions of 0.24 (CI 0.18-0.31) and 0.31 (CI 0.28-0.33) respectively. The work thus illustrates a data-driven approach for estimating the effect-sizes on the graded policies, and the possibility of prioritising the interventions, if necessary by weighing the economic costs and ease of acceptance with them.","title":"Estimating Effect-sizes to Infer if COVID-19 transmission rates were low because of Masks, Heat or High because of Air-conditioners, Tests","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-01-20 05:00:00"},{"main_cord_uid":"fcng6yov","cord_uid":"fcng6yov","abstract":"Background: The third wave of COVID-19 in England peaked in January 2022 resulting from the rapid transmission of the Omicron variant. However, rates of hospitalisations and deaths were substantially lower than in the first and second waves Methods: In the REal-time Assessment of Community Transmission-1 (REACT-1) study we obtained data from a random sample of 94,950 participants with valid throat and nose swab results by RT-PCR during round 18 (8 February to 1 March 2022). Findings: We estimated a weighted mean SARS-CoV-2 prevalence of 2.88% (95% credible interval [CrI] 2.76-3.00), with a within-round reproduction number (R) overall of 0.94 (0.91-0.96). While within-round weighted prevalence fell among children (aged 5 to 17 years) and adults aged 18 to 54 years, we observed a level or increasing weighted prevalence among those aged 55 years and older with an R of 1.04 (1.00-1.09). Among 1,195 positive samples with sublineages determined, only one (0.1% [0.0-0.5]) corresponded to AY.39 Delta sublineage and the remainder were Omicron: N=390, 32.7% (30.0-35.4) were BA.1; N=473, 39.6% (36.8-42.5) were BA.1.1; and N=331, 27.7% (25.2-30.4) were BA.2. We estimated an R additive advantage for BA.2 (vs BA.1 or BA.1.1) of 0.40 (0.36-0.43). The highest proportion of BA.2 among positives was found in London. Interpretation: In February 2022, infection prevalence in England remained high with level or increasing rates of infection in older people and an uptick in hospitalisations. Ongoing surveillance of both survey and hospitalisations data is required. Funding: Department of Health and Social Care, England.","title":"The Omicron SARS-CoV-2 epidemic in England during February 2022","annotator_investigating_R0":"1","text_response":"disease name: SARS-CoV-2\\r\\nlocation: England\\r\\ndate: 8 February to 1 March 2022\\r\\nR0 value: 0.94 (0.91-0.96)\\r\\n%CI values: -\\r\\nmethod: -","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"SARS-CoV-2\\",\\r\\n\\"location\\": \\"England\\",\\r\\n\\"date\\": \\"8 February to 1 March 2022\\",\\r\\n\\"R0 value\\": \\"0.94 (0.91-0.96)\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"-\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"England\\", \\"date\\": \\"8 February to 1 March 2022\\", \\"R0 value\\": \\"0.94\\", \\"%CI values\\": \\"(0.91-0.96)\\", \\"method\\": \\"REal-time Assessment of Community Transmission-1 (REACT-1) study\\" } } ]","publish_time":"2022-03-13 05:00:00"},{"main_cord_uid":"guc9d605","cord_uid":"guc9d605","abstract":"INTRODUCTION: Italy became the second epicenter of the novel coronavirus disease 2019 (COVID-19) pandemic after China, surpassing by far China\'s death toll. The disease swept through Lombardy, which remained in lockdown for about two months, starting from the 8th of March. As of that day, the isolation measures taken in Lombardy were extended to the entire country. Here, assuming that effectively there was one case \\"zero\\" that introduced the virus to the region, we provide estimates for: (a) the day-zero of the outbreak in Lombardy, Italy; (b) the actual number of asymptomatic infected cases in the total population until March 8; (c) the basic (R0)and the effective reproduction number (Re) based on the estimation of the actual number of infected cases. To demonstrate the efficiency of the model and approach, we also provide a tentative forecast two months ahead of time, i.e. until May 4, the date on which relaxation of the measures commenced, on the basis of the COVID-19 Community Mobility Reports released by Google on March 29. METHODS: To deal with the uncertainty in the number of the actual asymptomatic infected cases in the total population Volpert et al. (2020), we address a modified compartmental Susceptible/ Exposed/ Infectious Asymptomatic/ Infected Symptomatic/ Recovered/ Dead (SEIIRD) model with two compartments of infectious persons: one modelling the cases in the population that are asymptomatic or experience very mild symptoms and another modelling the infected cases with mild to severe symptoms. The parameters of the model corresponding to the recovery period, the time from the onset of symptoms to death and the time from exposure to the time that an individual starts to be infectious, have been set as reported from clinical studies on COVID-19. For the estimation of the day-zero of the outbreak in Lombardy, as well as of the \\"effective\\" per-day transmission rate for which no clinical data are available, we have used the proposed SEIIRD simulator to fit the numbers of new daily cases from February 21 to the 8th of March. This was accomplished by solving a mixed-integer optimization problem. Based on the computed parameters, we also provide an estimation of the basic reproduction number R0 and the evolution of the effective reproduction number Re. To examine the efficiency of the model and approach, we ran the simulator to \\"forecast\\" the epidemic two months ahead of time, i.e. from March 8 to May 4. For this purpose, we considered the reduction in mobility in Lombardy as released on March 29 by Google COVID-19 Community Mobility Reports, and the effects of social distancing and of the very strict measures taken by the government on March 20 and March 21, 2020. RESULTS: Based on the proposed methodological procedure, we estimated that the expected day-zero was January 14 (min-max rage: January 5 to January 23, interquartile range: January 11 to January 18). The actual cumulative number of asymptomatic infected cases in the total population in Lombardy on March 8 was of the order of 15 times the confirmed cumulative number of infected cases, while the expected value of the basic reproduction number R0 was found to be 4.53 (min-max range: 4.40- 4.65). On May 4, the date on which relaxation of the measures commenced the effective reproduction number was found to be 0.987 (interquartiles: 0.857, 1.133). The model approximated adequately two months ahead of time the evolution of reported cases of infected until May 4, the day on which the phase I of the relaxation of measures was implemented over all of Italy. Furthermore the model predicted that until May 4, around 20% of the population in Lombardy has recovered (interquartile range: \xc3\u0192\xc2\xa2\xc3\u201a\xcb\u2020\xc3\u201a\xc2\xbc10% to \xc3\u0192\xc2\xa2\xc3\u201a\xcb\u2020\xc3\u201a\xc2\xbc30%).","title":"Tracing day-zero and forecasting the COVID-19 outbreak in Lombardy, Italy: A compartmental modelling and numerical optimization approach","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Lombardy, Italy\\r\\ndate: March 20 and March 21, 2020\\r\\nR0 value: 4.53\\r\\n%CI values: min-max range: 4.40- 4.65\\r\\nmethod: modified compartmental Susceptible/ Exposed/ Infectious Asymptomatic/ Infected Symptomatic/ Recovered/ Dead (SEIIRD) model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Lombardy, Italy\\",\\r\\n\\"date\\": \\"March 20 and March 21, 2020\\",\\r\\n\\"R0 value\\": \\"4.53\\",\\r\\n\\"%CI values\\": \\"min-max range: 4.40- 4.65\\",\\r\\n\\"method\\": \\"modified compartmental Susceptible/ Exposed/ Infectious Asymptomatic/ Infected Symptomatic/ Recovered/ Dead (SEIIRD) model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Lombardy, Italy\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"modified compartmental Susceptible/ Exposed/ Infectious Asymptomatic/ Infected Symptomatic/ Recovered/ Dead (SEIIRD) model with two compartments of infectious persons: one modelling the cases in the population that are asymptomatic or experience very mild symptoms and another modelling the infected cases with mild to severe symptoms\\" } } ]","publish_time":"2020"},{"main_cord_uid":"isg4hklm","cord_uid":"isg4hklm","abstract":"INTRODUCTION: The COVID-19 global pandemic has likely led to changes in physical activity as behavioral patterns were disrupted. This is important because sleep and physical activity are interrelated and promote health, and well-being. This study examined whether changes to physical activity were related to changes to sleep health as a result of the COVID-19 pandemic. METHODS: A sample of N=419 US adults completed online surveys about sleep and COVID-19 experiences. Participants were asked to estimate the number of minutes per day they engaged in physical activity during the pandemic, as well as before. These were subtracted from each other, and a difference score was computed. Then, responses were categorized as no change (<=15 mins difference), 16-45 minutes more or less activity, or 46+ minutes more or less activity (5 categories total). Outcome variables included the degree to which participants believed that due to the pandemic, they experienced (1) more schedule regularity, (2) better sleep, (3) worse sleep, (4) more difficulty falling asleep, (5) more difficulty maintaining sleep, (6) more sleepiness, and (7) more napping. Ordinal regressions were adjusted for age, and sex. RESULTS: Those who increased their activity by over 45 minutes per day reported that they were less likely to experience more daytime sleepiness (oOR=0.28, p<0.02). Those who decreased their activity by over 45 minutes per day reported that they were more likely to experience worse sleep (oOR=2.38, p<0.01) and less likely to experience a more regular schedule (oOR=0.37, p<0.003) than prior to the pandemic. CONCLUSION: Overall, those who increased their physical activity since the beginning of the pandemic reported less daytime sleepiness; and those who decreased their physical activity reported worse sleep experiences and a more irregular schedule. The relationship between physical activity and sleep during the pandemic may be bidirectional. SUPPORT (IF ANY): R01MD011600, R01DA051321","title":"204 Changes in Physical Activity During the COVID-19 Pandemic Associated with Changes in Sleep","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-05-03 10:00:00"},{"main_cord_uid":"k78iemm8","cord_uid":"k78iemm8","abstract":"The state of Kuwait is facing a substantial challenge in responding to the spread of the novel coronavirus 2019 (COVID-19). The government\'s decision to repatriate stranded citizens back to Kuwait from various COVID-19 epicenters has generated a great concern. It has heightened the need for prediction models to estimate the epidemic size. Mathematical modeling plays a pivotal role in predicting the spread of infectious diseases to enable policymakers to implement various health and safety measures to contain the spread. This research presents a forecast of the COVID-19 epidemic size in Kuwait based on the confirmed data. Deterministic and stochastic modeling approaches were used to estimate the size of COVID-19 spread in Kuwait and determine its ending phase. In addition, various simulation scenarios were conducted to demonstrate the effectiveness of nonpharmaceutical intervention measures, particularly with time-varying infection rates and individual contact numbers. Results indicate that, with data until 19 April 2020 and before the repatriation plan, the estimated reproduction number in Kuwait is 2.2. It also confirms the efficiency of the containment measures of the state of Kuwait to control the spread even after the repatriation plan. The results show that a high contact rate among the population implies that the epidemic peak value is yet to be reached and that more strict intervention measures must be incorporated.","title":"Forecasting the spread of COVID-19 in kuwait using compartmental and logistic regression models","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Kuwait\\r\\ndate: until 19 April 2020 and before the repatriation plan\\r\\nR0 value: 2.2\\r\\n%CI values: -\\r\\nmethod: Deterministic and stochastic modeling","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Kuwait\\",\\r\\n\\"date\\": \\"until 19 April 2020 and before the repatriation plan\\",\\r\\n\\"R0 value\\": \\"2.2\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Deterministic and stochastic modeling\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Kuwait\\", \\"date\\": \\"until 19 April 2020\\", \\"R0 value\\": \\"2.2\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Deterministic and stochastic modeling\\" } } ]","publish_time":"2020"},{"main_cord_uid":"aqyqofe7","cord_uid":"aqyqofe7","abstract":"Stochastic transmission dynamic models are especially useful for studying the early emergence of novel pathogens given the importance of chance events when the number of infectious individuals is small. However, methods for parameter estimation and prediction for these types of stochastic models remain limited. In this manuscript, we describe a calibration and prediction framework for stochastic compartmental transmission models of epidemics. The proposed method, Multiple Shooting for Stochastic systems (MSS), applies a linear noise approximation to describe the size of the fluctuations, and uses each new surveillance observation to update the belief about the true epidemic state. Using simulated outbreaks of a novel viral pathogen, we evaluate the accuracy of MSS for real-time parameter estimation and prediction during epidemics. We assume that weekly counts for the number of new diagnosed cases are available and serve as an imperfect proxy of incidence. We show that MSS produces accurate estimates of key epidemic parameters (i.e. mean duration of infectiousness, R(0), and R(eff)) and can provide an accurate estimate of the unobserved number of infectious individuals during the course of an epidemic. MSS also allows for accurate prediction of the number and timing of future hospitalizations and the overall attack rate. We compare the performance of MSS to three state-of-the-art benchmark methods: 1) a likelihood approximation with an assumption of independent Poisson observations; 2) a particle filtering method; and 3) an ensemble Kalman filter method. We find that MSS significantly outperforms each of these three benchmark methods in the majority of epidemic scenarios tested. In summary, MSS is a promising method that may improve on current approaches for calibration and prediction using stochastic models of epidemics.","title":"A Likelihood Approach for Real-Time Calibration of Stochastic Compartmental Epidemic Models","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2017-01-17 00:00:00"},{"main_cord_uid":"qrm25ia3","cord_uid":"qrm25ia3","abstract":"BACKGROUND: The new coronavirus disease COVID-19 began in December 2019 and has spread rapidly by human-to-human transmission. This study evaluated the transmissibility of the infectious disease and analyzed its association with temperature and humidity to study the propagation pattern of COVID-19. METHODS: In this study, we revised the reported data in Wuhan based on several assumptions to estimate the actual number of confirmed cases considering that perhaps not all cases could be detected and reported in the complex situation there. Then we used the equation derived from the Susceptible-Exposed-Infectious-Recovered (SEIR) model to calculate R(0) from January 24, 2020 to February 13, 2020 in 11 major cities in China for comparison. With the calculation results, we conducted correlation analysis and regression analysis between R(0) and temperature and humidity for four major cities in China to see the association between the transmissibility of COVID-19 and the weather variables. RESULTS: It was estimated that the cumulative number of confirmed cases had exceeded 45 000 by February 13, 2020 in Wuhan. The average R(0) in Wuhan was 2.7, significantly higher than those in other cities ranging from 1.8 to 2.4. The inflection points in the cities outside Hubei Province were between January 30, 2020 and February 3, 2020, while there had not been an obvious downward trend of R(0) in Wuhan. R(0) negatively correlated with both temperature and humidity, which was significant at the 0.01 level. CONCLUSIONS: The transmissibility of COVID-19 was strong and importance should be attached to the intervention of its transmission especially in Wuhan. According to the correlation between R(0) and weather, the spread of disease will be suppressed as the weather warms.","title":"Transmissibility of COVID-19 in 11 major cities in China and its association with temperature and humidity in Beijing, Shanghai, Guangzhou, and Chengdu","annotator_investigating_R0":"1","text_response":"disease name: new coronavirus disease COVID-19\\r\\nlocation: Wuhan\\r\\ndate: January 24, 2020 to February 13, 2020\\r\\nR0 value: 2.7\\r\\n%CI values: -\\r\\nmethod: equation derived from the Susceptible-Exposed-Infectious-Recovered (SEIR) model\\r\\n|\\r\\ndisease name: new coronavirus disease COVID-19\\r\\nlocation: other cities,china\\r\\ndate: January 24, 2020 to February 13, 2020\\r\\nR0 value: ranging from 1.8 to 2.4\\r\\n%CI values: -\\r\\nmethod: equation derived from the Susceptible-Exposed-Infectious-Recovered (SEIR) model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"new coronavirus disease COVID-19\\",\\r\\n\\"location\\": \\"Wuhan\\",\\r\\n\\"date\\": \\"January 24, 2020 to February 13, 2020\\",\\r\\n\\"R0 value\\": \\"2.7\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"equation derived from the Susceptible-Exposed-Infectious-Recovered (SEIR) model\\"}},{\\"contribution\\":{\\"disease name\\": \\"new coronavirus disease COVID-19\\",\\r\\n\\"location\\": \\"other cities,china\\",\\r\\n\\"date\\": \\"January 24, 2020 to February 13, 2020\\",\\r\\n\\"R0 value\\": \\"ranging from 1.8 to 2.4\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"equation derived from the Susceptible-Exposed-Infectious-Recovered (SEIR) model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Wuhan\\", \\"date\\": \\"January 24, 2020 to February 13, 2020\\", \\"R0 value\\": \\"2.7\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"(SEIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"other cities\\", \\"date\\": \\"January 24, 2020 to February 13, 2020\\", \\"R0 value\\": \\"1.8 to 2.4\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"(SEIR) model\\" } } ]","publish_time":"2020-07-10 00:00:00","cluster_id":"1413"},{"main_cord_uid":"13u8pms3","cord_uid":"13u8pms3","abstract":"We estimate the basic reproductive number and case counts for 15 distinct SARS-CoV-2 outbreaks, distributed across 10 countries and one cruise ship, based solely on phylodynamic analyses of genomic data. Our results indicate that, prior to significant public health interventions, the reproductive numbers for a majority (10) of these outbreaks are similar, with median posterior estimates ranging between 1.4 and 2.8. These estimates provide a view which is complementary to that provided by those based on traditional line listing data. The genomic-based view is arguably less susceptible to biases resulting from differences in testing protocols, testing intensity, and import of cases into the community of interest. In the analyses reported here, the genomic data primarily provides information regarding which samples belong to a particular outbreak. We observe that once these outbreaks are identified, the sampling dates carry the majority of the information regarding the reproductive number. Finally, we provide genome-based estimates of the cumulative case counts for each outbreak, which allow us to speculate on the amount of unreported infections within the populations housing each outbreak. These results indicate that for the majority (7) of the populations studied, the number of recorded cases is much bigger than the estimated cumulative case counts, suggesting the presence of unsequenced pathogen diversity in these populations.","title":"Estimates of outbreak-specific SARS-CoV-2 epidemiological parameters from genomic data","annotator_investigating_R0":"1","text_response":"disease name: SARS-CoV-2\\r\\nlocation: 10 countries and one cruise ship\\r\\ndate: -\\r\\nR0 value: 1.4 and 2.8\\r\\n%CI values: -\\r\\nmethod: phylodynamic analyses of genomic data","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"SARS-CoV-2\\",\\r\\n\\"location\\": \\"10 countries and one cruise ship\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"1.4 and 2.8\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"phylodynamic analyses of genomic data\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"SARS-CoV-2\\", \\"location\\": \\"10 countries and one cruise ship\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"between 1.4 and 2.8\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"phylodynamic analyses of genomic data\\" } } ]","publish_time":"2020-09-14 10:00:00"},{"main_cord_uid":"6sotuqxs","cord_uid":"6sotuqxs","abstract":"Coronavirus disease 2019 (COVID-19) is a contagious disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). This disease has spread globally, causing more than 161.5 million cases and 3.3 million deaths to date. Surveillance and monitoring of new mutations in the virus\xc3\xa2\xe2\u201a\xac\xe2\u201e\xa2 genome are crucial to our understanding of the adaptation of SARS-CoV-2. Moreover, how the temporal dynamics of these mutations is influenced by control measures and non-pharmaceutical interventions (NPIs) is poorly understood. Using 1,058,020 SARS-CoV-2 from sequenced COVID-19 cases from 98 countries (totaling 714 country-month combinations), we perform a normalization by COVID-19 cases to calculate the relative frequency of SARS-CoV-2 mutations and explore their dynamics over time. We found 115 mutations estimated to be present in more than 3% of global COVID-19 cases and determined three types of mutation dynamics: high-frequency, medium-frequency, and low-frequency. Classification of mutations based on temporal dynamics enable us to examine viral adaptation and evaluate the effects of implemented control measures in virus evolution during the pandemic. We showed that medium-frequency mutations are characterized by high prevalence in specific regions and/or in constant competition with other mutations in several regions. Finally, taking N501Y mutation as representative of high-frequency mutations, we showed that level of control measure stringency negatively correlates with the effective reproduction number of SARS-CoV-2 with high-frequency or not-high-frequency and both follows similar trends in different levels of stringency.","title":"Dynamics of SARS-CoV-2 mutations reveals regional-specificity and similar trends of N501 and high-frequency mutation N501Y in different levels of control measures","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-09-07 10:00:00"},{"main_cord_uid":"355guih4","cord_uid":"debcgzrg","abstract":"{\\\\bf Abstract.} \\\\\\\\ {\\\\bf Background:} Bangladesh hosts more than 800,000 Rohingya refugees from Myanmar. The low health immunity, lifestyle, access to good healthcare services, social-security cause this population to be at risk of far more direct effects of COVID-19 than the host population. Therefore, evidence-based forecasting of the COVID-19 burden is vital in this regard. In this study, we aimed to forecast the COVID-19 burden among the Rohingya refugees of Bangladesh to keep up with the disease outbreak\'s pace, health needs, and disaster preparedness. oindent{\\\\bf Methodology and Findings:} To estimate the possible consequences of COVID-19 in the Rohingya camps of Bangladesh, we used a modified Susceptible-Exposed-Infectious Recovered (SEIR) transmission model. All the values of different parameters used in this model were from the Bangladesh Government\xe2\u20ac\u2122s database and the relevant emerging literature. We addressed two different scenarios, i.e., the best-fitting model and good fitting model with unique consequences of COVID-19. Our best fitting model suggests that there will be good control over the transmission of the COVID-19 disease. At the end of December 2020, there will be only 169 confirmed COVID-19 cases in the Rohingya refugee camps. The average basic reproduction number ($ \\\\mathcal{R}_{0} $) has been estimated to be 0.7563. oindent{\\\\bf Conclusion:} Our analysis suggests that, due to the extensive precautions from the Bangladesh government as well as other humanitarian organizations, the coronavirus disease will be under control if the maintenance continues like this. Although detailed and pragmatic preparedness should be adopted for the worst scenario.","title":"SARS-CoV-2 and Rohingya Refugee Camp, Bangladesh: Uncertainty and How the Government Took Over the Situation","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Rohingya Refugee Camp, Bangladesh\\r\\ndate: -\\r\\nR0 value: 0.7563\\r\\n%CI values: -\\r\\nmethod: modified Susceptible-Exposed-Infectious Recovered (SEIR) transmission model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Rohingya Refugee Camp, Bangladesh\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"0.7563\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"modified Susceptible-Exposed-Infectious Recovered (SEIR) transmission model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Rohingya refugee camps of Bangladesh\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"0.7563\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"modified Susceptible-Exposed-Infectious Recovered (SEIR) transmission model\\" } } ]","publish_time":"2020","action":"change_main_cord_id","cluster_id":"1506"},{"main_cord_uid":"bwvtcrno","cord_uid":"bwvtcrno","abstract":"Background: Households appear to be the highest risk setting for transmission of COVID-19. Large household transmission studies were reported in the early stages of the pandemic in Asia with secondary attack rates ranging from 5-30% but few large scale household transmission studies have been conducted outside of Asia. Methods: A prospective case ascertained study design based on the World Health Organization FFX protocol was undertaken in the UK following the detection of the first case in late January 2020. Household contacts of cases were followed using enhanced surveillance forms to establish whether they developed symptoms of COVID-19, became confirmed cases and their outcomes. Household secondary attack rates and serial intervals were estimated. Individual and household basic reproduction numbers were also estimated. The incubation period was estimated using known point source exposures that resulted in secondary cases. Results: A total of 233 households with two or more people were included with a total of 472 contacts. The overall household SAR was 37% (95% CI 31-43%) with a mean serial interval of 4.67 days, an R0 of 1.85 and a household reproduction number of 2.33. We find lower secondary attack rates in larger households. SARs were highest when the primary case was a child. We estimate a mean incubation period of around 4.5 days. Conclusions: High rates of household transmission of COVID-19 were found in the UK emphasising the need for preventative measures in this setting. Careful monitoring of schools reopening is needed to monitor transmission from children.","title":"Transmission dynamics of COVID-19 in household and community settings in the United Kingdom","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: United Kingdom\\r\\ndate: Late January 2020\\r\\nR0 value: 1.85 and a household reproduction number of 2.33\\r\\n%CI values: -\\r\\nmethod: prospective case ascertained study design based on the World Health Organization FFX protocol","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"United Kingdom\\",\\r\\n\\"date\\": \\"Late January 2020\\",\\r\\n\\"R0 value\\": \\"1.85 and a household reproduction number of 2.33\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"prospective case ascertained study design based on the World Health Organization FFX protocol\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"UK\\", \\"date\\": \\"Late January 2020\\", \\"R0 value\\": \\"1.85\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"prospective case ascertained study design based on the World Health Organization FFX protocol\\" } } ]","publish_time":"2020-08-22 00:00:00"},{"main_cord_uid":"5grstp0p","cord_uid":"5grstp0p","abstract":"Between March 5th and July 25th, 2020, the total number of SARS-CoV-2 confirmed cases in Bosnia and Herzegovina (BH) was 10,090, corresponding to a cumulative incidence rate of 285.7/100,000 population. Demographic and clinical information on all the cases along with exposure and contact information were collected using a standardized case report form. In suspected SARS-CoV-2 cases, respiratory specimens were collected and tested by real-time reverse-transcriptase polymerase chain reaction assay. The dynamic of the outbreak was summarized using epidemiological curves, instantaneous reproduction number Rt, and interactive choropleth maps for geographical distribution and spread. The rate of hospitalization was 14.0%(790/5646) in the Federation of Bosnia and Herzegovina (FBH) and 6.2% (267/4299) in the Republic of Srpska (RS). The death rate was 2.2% (122/5646) in FBH and 3.6% in the RS (155/4299). After the authorities lifted mandatory quarantine restrictions, the instantaneous reproduction number increased from 1.13 on May 20th to 1.72 on May 31st. The outbreak concerns both entities, FBH and RS, and it is more pronounced in those aged 20-44 years. It is important to develop the communication and emergency plan for the SARS-CoV-2 outbreak in BH, including the mechanisms to allow the ongoing notification and updates at the national level.","title":"SARS-CoV-2 virus outbreak and the emergency public health measures in Bosnia and Herzegovina: January - July, 2020","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"l82zkd0n","cord_uid":"l82zkd0n","abstract":"This review is aimed at evaluating whether radiation therapy (RT) can be omitted in older adult early-stage low-risk breast cancer (BC) patients. The published data are particularly relevant at present, during the COVID-19 pandemic emergency, to define a treatment strategy and to prioritize essential therapy. Cochrane Database of Systematic Reviews and PubMED were systematically researched from outset through April 2020 using Mesh terms. Only randomized controlled trials (RCT), with one arm without adjuvant whole-breast irradiation (WBI), were included in the analysis. Recent literature regarding the COVID pandemic and BC RT was assessed. The reported RCTs identified a group of BC patients (pT1-2N0M0 R0, grade 1-2, estrogen receptor (ER) positive, human epidermal growth factor receptor 2 (HER2) negative tumours) in which the absolute risk of local recurrence (LR) was considered low enough to omit RT. The most common risk factors were tumor diameter, nodal and receptor status. Adjuvant RT had a significant impact on LR but not on distant metastasis (DM) or death. During the COVID 19 pandemic, results from RTCs were re-considered to define treatment recommendations for BC patients. International scientific societies and radiation oncology experts suggested RT omission, whenever possible, in older adult early-stage BC patients. Adjuvant RT might be omitted in a highly selected group of older adult early-stage BC patients with favourable prognostic factors. Hypofractionated regimens should be the standard. RT omission, partial breast irradiation (PBI), and ultra- hypofractionated regimens could be considered in selected cases due to the pandemic.","title":"Omission of adjuvant radiotherapy for older adults with early-stage breast cancer particularly in the COVID era: A literature review (on the behalf of Italian Association of Radiotherapy and Clinical Oncology)","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"t056gze6","cord_uid":"t056gze6","abstract":"In this paper, we develop a mathematical model for the spread and control of the coronavirus disease. An outbreak of COVID-19 has led to more than one million confirmed cases as of April 3rd, 2020. Understanding the early spread dynamics of the infection and evaluating the effectiveness of control measures is crucial for assessing the potential for sustained transmission to occur in new areas. Combining a mathematical model of severe COVID-19 spread with four datasets from within and outside of Wuhan, China; it is estimated how spread in Wuhan varied between January and February 2020. It is used these estimates to assess the potential for sustained human-to-human spread to occur in locations outside Wuhan if disease holders were introduced. It is combined SEIR framework model with data on cases of COVID-19 in China and International cases that originated in Wuhan to estimate how spread had varied over time during January and February 2020. Based on these estimates, it is calculated the probability that freshly introduced cases might produce outbreaks in other regions. Also, it is calculated approximately the median day by day basic reproduction number in Wuhan, refused from 2\xc3\u201a\xc2\xb745 (95% CI: 1\xc3\u201a\xc2\xb716-4\xc3\u201a\xc2\xb787) one week before travel restrictions were introduced on Jan 23rd, 2020, to 1.05 (0\xc3\u201a\xc2\xb742-2\xc3\u201a\xc2\xb740) one week after. Based on our estimates of, presumptuous SARS approximating disparity, it is computed that in locations with a similar spread potential to Wuhan in near the beginning of January, some time ago there are at least four independently set up cases, there is a more than fifty percent chance the infection will found within those inhabitants. COVID-19 spreading probably refused in Wuhan during delayed January 2020, corresponding with the prologue of voyage control channels. As more cases arrive in international locations with similar spread potential to Wuhan, before these organize measures, it is likely many chains of spread will fail to create initially but might lead to innovative outbreaks ultimately.","title":"Mathematical modelling on diffusion and control of COVID-19","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: within and outside of Wuhan, China\\r\\ndate: January and February 2020 (one week before travel restrictions on Jan 23rd)\\r\\nR0 value: 2\xb745\\r\\n%CI values: (95% CI: 1\xb716-4\xb787)\\r\\nmethod: SEIR framework model\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: within and outside of Wuhan, China\\r\\ndate: January and February 2020 (one week after travel restrictions on Jan 23rd)\\r\\nR0 value: 1.05\\r\\n%CI values: (0\xb742-2\xb740)\\r\\nmethod: SEIR framework model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"within and outside of Wuhan, China\\",\\r\\n\\"date\\": \\"January and February 2020 (one week before travel restrictions on Jan 23rd)\\",\\r\\n\\"R0 value\\": \\"2\xb745\\",\\r\\n\\"%CI values\\": \\"(95% CI: 1\xb716-4\xb787)\\",\\r\\n\\"method\\": \\"SEIR framework model\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"within and outside of Wuhan, China\\",\\r\\n\\"date\\": \\"January and February 2020 (one week after travel restrictions on Jan 23rd)\\",\\r\\n\\"R0 value\\": \\"1.05\\",\\r\\n\\"%CI values\\": \\"(0\xb742-2\xb740)\\",\\r\\n\\"method\\": \\"SEIR framework model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Wuhan, China\\", \\"date\\": \\"January and February 2020\\", \\"R0 value\\": \\"2u00b745\\", \\"%CI values\\": \\"(95% CI: 1u00b767)\\", \\"method\\": \\"combined SEIR framework model with data on cases of COVID-19 in China and International cases that originated in Wuhan\\" } } ]","publish_time":"2020","cluster_id":"275"},{"main_cord_uid":"eemk2z4v","cord_uid":"eemk2z4v","abstract":"Healthcare-associated infections (HAIs) remain a public health problem. Previous work showed intensive care unit (ICU) population structure impacts methicillin-resistant Staphylococcus aureus (MRSA) rates. Unexplored in that work was the transient dynamics of this system. We consider the dynamics of MRSA in an ICU in three different models: 1) a Ross-McDonald model with a single healthcare staff type, 2) a Ross-McDonald model with nurses and doctors considered as separate populations and 3) a meta-population model that segments patients into smaller groups seen by a single nurse. The basic reproduction number, R0 is derived using the Next Generation Matrix method, while the importance of the position of patients within the meta-population model is assessed via stochastic simulation. The single-staff model had an R0 of 0.337, while the other two models had R0s of 0.278. The meta-population model\'s R0 was not sensitive to the time nurses spent with their assigned patients vs. unassigned patients. This suggests previous results showing that simulated infection rates are dependent on this parameter are the result of differences in the transient dynamics between the models, rather than differing long-term equilibria.","title":"Transient Dynamics of Infection Transmission in a Simulated Intensive Care Unit","annotator_investigating_R0":"1","text_response":"disease name: methicillin-resistant Staphylococcus aureus (MRSA)\\r\\nlocation: Intensive Care Unit (ICU)\\r\\ndate: -\\r\\nR0 value: 0.337\\r\\n%CI values: -\\r\\nmethod: Next Generation Matrix method (single-staff model)\\r\\n|\\r\\ndisease name: methicillin-resistant Staphylococcus aureus (MRSA)\\r\\nlocation: Intensive Care Unit (ICU)\\r\\ndate: -\\r\\nR0 value: 0.278\\r\\n%CI values: -\\r\\nmethod: Next Generation Matrix method (other two models)","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"methicillin-resistant Staphylococcus aureus (MRSA)\\",\\r\\n\\"location\\": \\"Intensive Care Unit (ICU)\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"0.337\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Next Generation Matrix method (single-staff model)\\"}},{\\"contribution\\":{\\"disease name\\": \\"methicillin-resistant Staphylococcus aureus (MRSA)\\",\\r\\n\\"location\\": \\"Intensive Care Unit (ICU)\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"0.278\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Next Generation Matrix method (other two models)\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"MRSA\\", \\"location\\": \\"ICU\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"0.337\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Next Generation Matrix method\\" } }, { \\"contribution\\": { \\"disease name\\": \\"MRSA\\", \\"location\\": \\"ICU\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"(0.278)\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Next Generation Matrix method\\" } } ]","publish_time":"2019-09-26 10:00:00","cluster_id":"529"},{"main_cord_uid":"2gt15im7","cord_uid":"2gt15im7","abstract":"A simplified method to compute $R_t$, the Effective Reproduction Number, is presented. The method relates the value of $R_t$ to the estimation of the doubling time performed with a local exponential fit. The condition $R_t = 1$ corresponds to a growth rate equal to zero or equivalently an infinite doubling time. Different assumptions on the probability distribution of the generation time are considered. A simple analytical solution is presented in case the generation time follows a gamma distribution.","title":"A simplified estimate of the Effective Reproduction Number $R_t$ using its relation with the doubling time and application to Italian COVID-19 data","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"e23pdtfn","cord_uid":"e23pdtfn","abstract":"INTRODUCTION: During the COVID-19 pandemic, individuals have faced unprecedented events, which are often stressful. Stress has an important impact on dreams, and stress-induced sleep difficulties may also impact dream recall. The present study evaluated associations between sleep, stress and dream content on dream recall during the pandemic. METHODS: A sample of N=419 US adults completed online surveys about sleep and COVID-19 experiences. Participants were asked if they remember more, fewer or about the same amount of dreams as before the pandemic. They were also asked whether the pandemic was associated with more stress, a more regular schedule, improved sleep, worse sleep, more early insomnia, more middle-of-the-night insomnia, more sleepiness, and more naps. They also completed the Insomnia Severity Index, Fatigue Severity Scale, Epworth Sleepiness Scale, Brief Index of Sleep Control, Assessment of Sleep Environment, GAD-7 anxiety scale, and PHQ9 depression scale. Multinomial logistic regressions examined correlates of increased or decreased recall (versus same), adjusted for age, sex, and race/ethnicity. RESULTS: Those who experienced greater schedule regularity were less likely to report decreased recall (RRR=0.50,p<0.0005), as were those who reported sleep improvement (RRR=0.48,p=0.006). Those whose sleep worsened were more likely to report both increased (RRR=1.64,p=0.003) and decreased (RRR=2.16,p<0.0005) recall. Those suffering maintenance insomnia were more likely to report both increased (RRR=1.70,p=0.001) and decreased (RRR=2.68,p<0.0005) recall, as did those who reported more daytime sleepiness (Increased RRR=1.57,p=0.006; Decreased RRR=1.94,p=0.001). Those whose dream content was more negative were more likely to report both increased (RRR=4.05,p<0.005) and decreased (RRR=3.35,p<0.0005) recall, as did those who reported less negative content (Increased RRR=4.20,p<0.0005; Decreased RRR=5.05,p<0.0005). Similarly, those who reported more positive dream content reported both increased (RRR=17.37,p<0.0005) and decreased (RRR=7.14,p=0.02) recall, as did those who reported less positive content (Increased RRR=4.49,p<0.0005; Decreased RRR=5.59,p<0.0005). Less recall was associated with greater insomnia severity (RRR=1.08,p=0.001), fatigue (RRR=1.04,p=0.001), sleepiness (RRR=1.09,p=0.01), COVID stress (RRR=1.67,p=0.03), anxiety (RRR=1.08,p=0.01), and depression (RRR=1.06,p=0.007), worse sleep environment (RRR=1.06,p=0.005), and less sleep control (RRR=0.56,p=0.001). CONCLUSION: The results of this survey suggest that a sudden decrease in dream recall in reaction to a new stress could be considered as a pejorative indicator regarding sleep quality and mental health. SUPPORT (IF ANY): R01MD011600, R01DA051321","title":"210 Changes in Dream Recall During the COVID-19 Pandemic: Associations with Sleep, Stress and Dream Content","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-05-03 10:00:00"},{"main_cord_uid":"4tuxmhco","cord_uid":"4tuxmhco","abstract":"BACKGROUND: Recent reports have suggested that among individuals previously infected with SARS-CoV-2, a single mRNA vaccine dose is sufficient to elicit high levels of immunity. METHODS: We compared anti-SARS-CoV-2 spike receptor binding domain (RBD) IgG antibody concentrations and antibody-mediated neutralization of spike-angiotensin-converting enzyme (ACE2) receptor binding in vitro following vaccination of non-hospitalized participants by sero-status and acute virus diagnosis history. Participants were analysed before and after mRNA vaccination (BNT162b2/Pfizer or mRNA-1273/Moderna) in a community-based, home-collected, longitudinal serosurvey in the Chicago area (USA); none reported hospitalization for COVID-19. Samples were collected in January and February 2021. Before vaccination, some reported prior positive acute viral diagnostic testing and were seropositive (COVID-19+); the others who did not report acute viral diagnostic testing were categorized as seropositive or seronegative based on anti-spike RBD IgG test results. FINDINGS: Of 307 unique vaccine recipients, 46 reported a prior COVID-19 diagnosis and were seropositive (COVID-19 +). Of the 261 with no history of acute viral diagnostic testing, 117 were seropositive and 144 seronegative before vaccination. The median age was 38 years (range 21\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u015383) with 67 female and 33% male; 40% were non-White. Responses were evaluated after one (n = 142) or two (n = 191) doses of BNT162b2 or mRNA-1273 vaccine. After one dose, median post-vaccine IgG concentration and percent surrogate neutralization were each significantly higher among the COVID-19+ (median 48\xc3\u201a\xc2\xb72 \xc3\u201a\xc2\xb5g/ml, IgG; > 99.9% neutralization) compared to the seropositives (3\xc3\u201a\xc2\xb76 \xc3\u201a\xc2\xb5g /ml IgG; 56.5% neutralization) and seronegatives (2\xc3\u201a\xc2\xb76 \xc3\u201a\xc2\xb5g /ml IgG; 38\xc3\u201a\xc2\xb73% neutralization). The latter two groups reached > 95% neutralization after the second vaccine dose. INTERPRETATION: After one dose of mRNA vaccine, individuals previously diagnosed with COVID-19 responded with high levels of anti-RBD IgG and surrogate neutralization of spike-ACE2 interaction. One dose of mRNA vaccine was not sufficient to generate comparably high responses among most persons previously infected with SARS-CoV-2 without a clinical COVID-19 diagnosis, nor among seronegative persons. FUNDING: National Science Foundation 2035114, NIH 3UL1TR001422\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u015306S4, and Northwestern University Office of Research.","title":"Comparison of IgG and neutralizing antibody responses after one or two doses of COVID-19 mRNA vaccine in previously infected and uninfected individuals.","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-07-13 10:00:00"},{"main_cord_uid":"fg1t15vi","cord_uid":"fg1t15vi","abstract":"The emerging virus, COVID-19, has caused a massive outbreak worldwide. Based on the publicly available contact-tracing data, we identified 509 transmission chains from 20 provinces in China and estimated the serial interval (SI) and generation interval (GI) of COVID-19 in China. Inspired by different possible values of the time-varying reproduction number for the imported cases and the local cases in China, we divided all transmission events into three subsets: imported (the zeroth generation) infecting 1st-generation locals, 1st-generation locals infecting 2nd-generation locals, and other transmissions among 2+. The corresponding SI (GI) is respectively denoted as SI 1 0 ( GI 1 0 ), SI 2 1 ( GI 2 1 ), and SI 3 + 2 + ( GI 3 + 2 + ). A Bayesian approach with doubly interval-censored likelihood is employed to fit the distribution function of the SI and GI. It was found that the estimated SI 1 0 = 6 . 52 ( 95 % CI : 5 . 96 - 7 . 13 ) , SI 2 1 = 6 . 01 ( 95 % CI : 5 . 44 - 6 . 64 ) , SI 3 + 2 + = 4 . 39 ( 95 % CI : 3 . 74 - 5 . 15 ) , and GI 1 0 = 5 . 47 ( 95 % CI : 4 . 57 - 6 . 45 ) , GI 2 1 = 5 . 01 ( 95 % CI : 3 . 58 - 7 . 06 ) , GI 3 + 2 + = 4 . 25 ( 95 % CI : 2 . 82 - 6 . 23 ) . Thus, overall both SI and GI decrease when generation increases.","title":"Serial Interval and Generation Interval for Imported and Local Infectors, Respectively, Estimated Using Reported Contact-Tracing Data of COVID-19 in China","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"ii0ceksc","cord_uid":"ii0ceksc","abstract":"The Omicron variant is the most transmissible variant of the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) we had so far. The BA.1 and BA.2 sublineages of Omicron are circulating in Europe and it is urgent to evaluate the transmissibility of these sub-lineages. Using a mathematical model describing trajectories of variant frequencies that assumes a constant ratio in generation times and a constant ratio in effective reproduction numbers among variants, trajectories of variant frequencies in Denmark from November 22, 2021 to February 26, 2022 were analyzed. We found that the generation times of Omicron BA.1 and BA.2 are 0.60 (95%CI: 0.59-0.62) and 0.51 (95%CI: 0.50-0.52) of the length of that of Delta, respectively. We also found that the effective reproduction number of Omicron BA.1 is 1.99 (95% CI: 1.98-2.02) times and that of Omicron BA.2 is 2.51 (95% CI: 2.48-2.55) times larger than the effective reproduction number of Delta. The generation times of Omicron BA.2 is 0.85 (95% CI:0.84-0.86) the length of that of BA.1 and that the effective reproduction number of Omicron BA.2 is 1.26 (95% CI:1.25-1.26) times larger than that of Omicron BA.1. These estimates on the ratio of generation times and the ratio of effective reproduction numbers has epidemiologically important implications. The duration of quarantine for people who contacted with an Omicron BA.1 and BA.2 patient can be reduced to 60% and 51% of that for Delta, respectively. The control measures against Omicron BA.1 and BA.2 need to reduce contacts between infectious and susceptible people respectively by 50% (95% CI: 49-50%) and 60% (95% CI: 60-61%) compared to that against Delta to achieve the same effect on their control.","title":"Estimating relative generation times and relative reproduction numbers of Omicron BA.1 and BA.2 with respect to Delta in Denmark","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2022-03-04 05:00:00"},{"main_cord_uid":"lpdvpg1y","cord_uid":"lpdvpg1y","abstract":"BACKGROUND: Nosocomial outbreaks of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) are frequent despite implementation of conventional infection control measures. We performed an outbreak investigation using advanced genomic and statistical techniques to reconstruct likely transmission chains and assess the role of healthcare workers (HCWs) in SARS-CoV-2 transmission. METHODS: We investigated a nosocomial SARS-CoV-2 outbreak in a university-affiliated rehabilitation clinic, involving patients and HCWs, with high coverage of pathogen whole genome sequences (WGS). We estimated the time-varying reproduction number from epidemiological data (Rt) and produced a maximum likelihood phylogeny to assess genetic diversity of the pathogen. We combined genomic and epidemiological data into a Bayesian framework to model directionality of transmission. We performed a Case-control study to investigate risk factors for nosocomial SARS-CoV-2 acquisition in patients. FINDINGS: The outbreak spanned from March 14 to April 12, 2020 and involved 37 patients (31 with WGS) and 39 employees (31 with WGS) of whom 37 are HCWs. We estimated a peak R(t) between 2.2 \xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153 3.6. The phylogenetic tree showed very limited genetic diversity, with 60/62 (96.7%) isolates forming one large cluster of identical genomes. Despite the resulting uncertainty in reconstructed transmission events, our analyses suggest that HCWs (one of whom was the index Case) played an essential role in cross-transmission, with a significantly larger fraction of infections (p < 2.2e-16) attributable to HCWs (70.7%) than expected given the number of HCWs cases (46.7%). The excess of transmission from HCWs was larger when considering infection of patients (79.0%; 95%CI 78.5% - 79.5%), and especially frail patients (Clinical Frailty Scale >5: 82.3%; 95%CI 81.8% - 83.4%). Furthermore, frail patients were found to be at greater risk for nosocomial COVID-19 than other patients (adjusted OR 6.94; 95%CI 2.13 \xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153 22.57). INTERPRETATION: This outbreak report highlights the essential role of HCWs in SARS-CoV-2 transmission dynamics in healthcare settings. Limited genetic diversity in pathogen genomes hampered the reconstruction of individual transmission events, resulting in substantial uncertainty in who infected whom. However, our study shows that despite such uncertainty, significant transmission patterns can be observed.","title":"Explosive nosocomial outbreak of SARS-CoV-2 in a rehabilitation clinic: the limits of genomics for outbreak reconstruction","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-08-27 10:00:00"},{"main_cord_uid":"x7jfgb8f","cord_uid":"x7jfgb8f","abstract":"AIM: To estimate the epidemiological parameters related to the Covid-19 outbreak in Iran. BACKGROUND: Estimating the epidemiological parameters of new public health threat (COVID-19) is essential to support and inform public health decision-making in different communities including Iran. METHODS: We established a mathematical model to estimate the epidemiological parameters from 19 Feb to 15 March based on daily COVID-19 confirmed cases in Iran. Then, we estimated the effect of early traffic restriction on our estimation. RESULTS: We estimated the R0 at 2.11 (95% CI, 1.87-2.50) and the infected number at 92,260 (95% CI: 59,263 -152,212) by 15 March. Our estimate for the ascertainment rate was about 1.2% (95% CI: 1.1-1.4). The latent period estimation was 4.24 (95% CI: 2.84-6.65). We observed a decline in our estimate after considering the traffic restriction. CONCLUSION: Our results suggest that health authorities in Iran must take impactful strategies to control the COVID-19 outbreak to reach R0<1. Therefore, the establishment of complementary, multilateral, and cost-effective measures for the treatment of symptomatic and early diagnosis and isolation of asymptomatic cases/contacts are strongly recommended because of low ascertainment rate and large number of infected cases. We additionally recommend that traffic restriction be combined with other controlling measures.","title":"Early estimation of the epidemiological parameters of novel coronavirus disease (COVID-2019) outbreak in Iran: 19 Feb-15 March, 2020","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Iran\\r\\ndate: 19 Feb-15 March, 2020\\r\\nR0 value: 2.11\\r\\n%CI values: (95% CI, 1.87-2.50)\\r\\nmethod: mathematical model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Iran\\",\\r\\n\\"date\\": \\"19 Feb-15 March, 2020\\",\\r\\n\\"R0 value\\": \\"2.11\\",\\r\\n\\"%CI values\\": \\"(95% CI, 1.87-2.50)\\",\\r\\n\\"method\\": \\"mathematical model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Iran\\", \\"date\\": \\"19 Feb to 15 March, 2020\\", \\"R0 value\\": \\"2.11\\", \\"%CI values\\": \\"(95% CI, 1.87-2.55)\\", \\"method\\": \\"mathematical model\\" } } ]","publish_time":"2020"},{"main_cord_uid":"2n7ojlf6","cord_uid":"2n7ojlf6","abstract":"Importance: Taiwan is one of the few countries with initial success in COVID-19 control without strict lockdown or school closure. The reasons remain to be fully elucidated. Objective: To compare and evaluate the effectiveness of case-based (including contact tracing and quarantine) and population-based (including social distancing and facial masking) interventions for COVID-19 in Taiwan. Design, Setting, and Participants: This comparative effectiveness study used a stochastic branching process model using COVID-19 epidemic data from Taiwan, an island nation of 23.6 million people, with no locally acquired cases of COVID-19 reported for 253 days between April and December 2020. Main Outcomes and Measures: Effective reproduction number of COVID-19 cases (the number of secondary cases generated by 1 primary case) and the probability of outbreak extinction (0 new cases within 20 generations). For model development and calibration, an estimation of the incubation period (interval from exposure to symptom onset), serial interval (time between symptom onset in an infector-infectee pair), and the statistical distribution of the number of any subsequent infections generated by 1 primary case was calculated. Results: This study analyzed data from 158 confirmed COVID-19 cases (median age, 45 years; interquartile range, 25-55 years; 84 men [53%]). An estimated 55% (95% credible interval [CrI], 41%-68%) of transmission events occurred during the presymptomatic stage. In our estimated analysis, case detection, contact tracing, and 14-day quarantine of close contacts (regardless of symptoms) was estimated to decrease the reproduction number from the counterfactual value of 2.50 to 1.53 (95% CrI, 1.50-1.57), which would not be sufficient for epidemic control, which requires a value of less than 1. In our estimated analysis, voluntary population-based interventions, if used alone, were estimated to have reduced the reproduction number to 1.30 (95% CrI, 1.03-1.58). Combined case-based and population-based interventions were estimated to reduce the reproduction number to below unity (0.85; 95% CrI, 0.78-0.89). Results were similar for additional analyses with influenza data and sensitivity analyses. Conclusions and Relevance: In this comparative effectiveness research study, the combination of case-based and population-based interventions (with wide adherence) may explain the success of COVID-19 control in Taiwan in 2020. Either category of interventions alone would have been insufficient, even in a country with an effective public health system and comprehensive contact tracing program. Mitigating the COVID-19 pandemic requires the collaborative effort of public health professionals and the general public.","title":"Comparison of Estimated Effectiveness of Case-Based and Population-Based Interventions on COVID-19 Containment in Taiwan","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Taiwan\\r\\ndate: 253 days between April and December 2020\\r\\nR0 value: voluntary population-based interventions, if used alone, were estimated to have reduced the reproduction number to 1.30\\r\\n%CI values: 95% CrI, 1.03-1.58\\r\\nmethod: stochastic branching process model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Taiwan\\",\\r\\n\\"date\\": \\"253 days between April and December 2020\\",\\r\\n\\"R0 value\\": \\"voluntary population-based interventions, if used alone, were estimated to have reduced the reproduction number to 1.30\\",\\r\\n\\"%CI values\\": \\"95% CrI, 1.03-1.58\\",\\r\\n\\"method\\": \\"stochastic branching process model\\"}}]","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"vw5yjxmc","cord_uid":"vw5yjxmc","abstract":"Importance. Incarcerated individuals are a vulnerable population for severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection. Understanding SARS-CoV-2 dynamics in prisons is crucial for curbing transmission both within correctional facilities and in the surrounding community. Objective. The purpose of this study was to identify transmission scenarios that could underly rapid, widespread SARS-CoV-2 infection among inmates in Marion Correctional Institution (MCI). Design. Publicly available data reported by the Ohio Department of Rehabilitation and Corrections (ODRC) was analyzed using mathematical and statistical models. Setting. We consider SARS-CoV-2 transmission dynamics among MCI inmates prior to and including April 16, 2020. Participants. This study uses de-identified, publicly available SARS-CoV-2 test result data for MCI inmates. Exposures. Inmates at MCI were considered exposed to potential infection with SARS-CoV-2. Main outcome and measures. Results from mass testing conducted on April 16, 2020 were analyzed together with time of first reported SARS-CoV-2 infection among MCI inmates. Results. Rapid, widespread infection of MCI inmates was reported, with nearly 80% of inmates infected within three weeks of first reported inmate case. These data are consistent with (i) a basic reproduction number greater than 14, together with a single initially infected inmate, (ii) an initial super-spreading event resulting in several hundred initially infected inmates, together with a basic reproduction number of approximately three, and (iii) earlier undetected circulation of virus among inmates prior to April. Conclusions and relevance. Mass testing data are consistent with extreme transmissibility, super-spreading events, or undetected circulation of virus among inmates. All scenarios consistent with these data attest to the vulnerabilities of prisoners to COVID-19.","title":"COVID-19 dynamics in an Ohio prison","annotator_investigating_R0":"1","text_response":"disease name: SARS-CoV-2\\r\\nlocation: Ohio prison\\r\\ndate: -\\r\\nR0 value: 14 and 3\\r\\n%CI values: -\\r\\nmethod: -","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"SARS-CoV-2\\",\\r\\n\\"location\\": \\"Ohio prison\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"14 and 3\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"-\\"}}]","json_model_response":"unanswerable","publish_time":"44211.20833"},{"main_cord_uid":"n8rikeh8","cord_uid":"n8rikeh8","abstract":"Kuwait has been experiencing a COVID-19 outbreak since the first imported case on Feb 24, 2020. Analysis of data from the early stage of COVID-19 outbreak in Kuwait can provide important information about the potential epidemic and healthcare burdens as well as assist in evaluating the potential impact of various outbreak control measures. Such control measures are essentially implemented to achieve a sufficient reduction in the effective reproduction number during an outbreak. In this study, we use a mathematical modeling framework to simulate the outbreak dynamics of SARS-CoV-2 transmission in Kuwait and forecast the potential burden on the healthcare system. We calibrate the model against daily numbers of detected infection and death cases using a maximum likelihood framework and estimate both the basic and effective reproduction numbers. Our results indicate that the early control measures implemented in Kuwait had the effect of delaying the intensity of the outbreak but were unsuccessful in reducing Rt below 1. This highlights a need for a systematic investigation of the current public health interventions as well as a scientific surveillance tool that is sufficiently sensitive to outbreak temporal dynamics. Meanwhile, the developed model can serve as a public health tool to control the current outbreak and can be used to anticipate effective measures should a second wave re-emerge in Kuwait.","title":"Real-time tracking and forecasting of the of COVID-19 outbreak in Kuwait: a mathematical modeling study","annotator_investigating_R0":"0","text_response":"disease name: COVID-19\\r\\nlocation: Kuwait\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: maximum likelihood framework","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Kuwait\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"maximum likelihood framework\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Kuwait\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"maximum likelihood framework\\" } } ]","publish_time":"2020-05-08 10:00:00"},{"main_cord_uid":"5aikaw84","cord_uid":"5aikaw84","abstract":"BACKGROUND: The pandemic coronavirus disease 2019 (COVID-19) has spread and caused enormous and serious damages to many countries worldwide. One of the most typical interventions is the social distancing such as lockdown that would contribute to reduce the number of contacts among undiagnosed individuals. However, prolongation of the period of such a restrictive intervention could hugely affect the social and economic systems, and the outbreak will come back if the strong social distancing policy will end earlier due to the economic damage. Therefore, the social distancing policy should be followed by massive testing accompanied with quarantine to eradicate the infection. METHODS: In this paper, we construct a mathematical model and discuss the effect of massive testing with quarantine, which would be less likely to affect the social and economic systems, and its efficacy has been proved in South Korea, Taiwan, Vietnam and Hong Kong. RESULTS: By numerical calculation, we show that the control reproduction number is monotone decreasing and convex downward with respect to the testing rate, which implies that the improvement of the testing rate would highly contribute to reduce the epidemic size if the original testing rate is small. Moreover, we show that the recurrence of the COVID-19 epidemic in Japan could be possible after the lifting of the state of emergency if there is no massive testing and quarantine. CONCLUSIONS: If we have entered into an explosive phase of the epidemic, the massive testing could be a strong tool to prevent the disease as long as the positively reacted individuals will be effectively quarantined, no matter whether the positive reaction is pseudo or not. Since total population could be seen as a superposition of smaller communities, we could understand how testing and quarantine policy might be powerful to control the disease.","title":"Possible effects of mixed prevention strategy for COVID-19 epidemic: massive testing, quarantine and social distancing","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-07-06 10:00:00"},{"main_cord_uid":"dks24zau","cord_uid":"dks24zau","abstract":"Greece imposed a nationwide lockdown in March 2020 to mitigate transmission of severe acute respiratory syndrome coronavirus 2 during the first epidemic wave. We conducted a survey on age-specific social contact patterns to assess effects of physical distancing measures and used a susceptible-exposed-infectious-recovered model to simulate the epidemic. Because multiple distancing measures were implemented simultaneously, we assessed their overall effects and the contribution of each measure. Before measures were implemented, the estimated basic reproduction number (R0) was 2.38 (95% CI 2.01-2.80). During lockdown, daily contacts decreased by 86.9% and R0 decreased by 81.0% (95% credible interval [CrI] 71.8%-86.0%); each distancing measure decreased R0 by 10%-24%. By April 26, the attack rate in Greece was 0.12% (95% CrI 0.06%-0.26%), one of the lowest in Europe, and the infection fatality ratio was 1.12% (95% CrI 0.55%-2.31%). Multiple social distancing measures contained the first epidemic wave in Greece.","title":"Effects of Social Distancing Measures during the First Epidemic Wave of Severe Acute Respiratory Syndrome Infection, Greece","annotator_investigating_R0":"1","text_response":"disease name: severe acute respiratory syndrome coronavirus 2\\r\\nlocation: Greece\\r\\ndate: Before measures were implemented\\r\\nR0 value: 2.38\\r\\n%CI values: (95% CI 2.01-2.80)\\r\\nmethod: susceptible-exposed-infectious-recovered model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"severe acute respiratory syndrome coronavirus 2\\",\\r\\n\\"location\\": \\"Greece\\",\\r\\n\\"date\\": \\"Before measures were implemented\\",\\r\\n\\"R0 value\\": \\"2.38\\",\\r\\n\\"%CI values\\": \\"(95% CI 2.01-2.80)\\",\\r\\n\\"method\\": \\"susceptible-exposed-infectious-recovered model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"Severe Acute Respiratory Syndrome Infection\\", \\"location\\": \\"Greece\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"2.38\\", \\"%CI values\\": \\"(95% CI 2.01-2.80)\\", \\"method\\": \\"susceptible-exposed-infectious-recovered model\\" } } ]","publish_time":"2021"},{"main_cord_uid":"39ja79c6","cord_uid":"39ja79c6","abstract":"We develop an agent-based model to assess the cumulative number of deaths during hypothetical Covid-19-like epidemics for various non-pharmaceutical intervention strategies. The model simulates three interrelated stochastic processes: epidemic spreading, availability of respiratory ventilators and changes in death statistics. We consider local and non-local modes of disease transmission. The first simulates transmission through social contacts in the vicinity of the place of residence while the second through social contacts in public places: schools, hospitals, airports, etc., where many people meet, who live in remote geographic locations. Epidemic spreading is modelled as a discrete-time stochastic process on random geometric networks. We use the Monte-Carlo method in the simulations. The following assumptions are made. The basic reproduction number is R0=2.5 and the infectious period lasts approximately ten days. Infections lead to severe acute respiratory syndrome in about one percent of cases, which are likely to lead to respiratory default and death, unless the patient receives an appropriate medical treatment. The healthcare system capacity is simulated by the availability of respiratory ventilators or intensive care beds. Some parameters of the model, like mortality rates or the number of respiratory ventilators per 100,000 inhabitants, are chosen to simulate the real values for the USA and Poland. In the simulations we compare \'do-nothing\' strategy with mitigation strategies based on social distancing and reducing social mixing. We study epidemics in the pre-vacine era, where immunity is obtained only by infection. The model applies only to epidemics for which reinfections are rare and can be neglected. The results of the simulations show that strategies that slow the development of an epidemic too much in the early stages do not significantly reduce the overall number of deaths in the long term, but increase the duration of the epidemic. In particular, a hybrid strategy where lockdown is held for some time and is then completely released, is inefficient.","title":"Modelling Excess Mortality in Covid-19-Like Epidemics","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"3dcbf1fh","cord_uid":"3dcbf1fh","abstract":"Epidemiology models with constant parameters may not capture the infection patterns in the presence of pharmaceutical and non-pharmaceutical mitigation measures during a pandemic, since infectiousness is a function of time. In this paper, Epidemiology Informed Neural Network (EINN) algorithms are introduced to discover time-varying infection rates for the COVID-19 pandemic. Since there are asymptomatic infectives, mostly unreported, EINN learns the probability that an infective individual is asymptomatic. Using cumulative and daily reported cases of infectives, we simulate the impact of non-pharmaceutical mitigation measures such as early detection of infectives, contact tracing, and social distancing on the basic reproduction number. We demonstrate the effectiveness of vaccination, a pharmaceutical mitigation measure, together with non-pharmaceutical mitigation measures on the daily reported infectives. The EINN algorithms discover time-varying infection and recovery rates. The Mean Squared Error is used to demonstrate the accuracy of the proposed EINN algorithms. Simulations are presented for Italy, South Korea, United Kingdom, and the United States.","title":"Data-driven deep learning algorithms for time-varying infection rates of COVID-19 and mitigation measures","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"x05qoh09","cord_uid":"x05qoh09","abstract":"Importance: A significant proportion of COVID-19 transmission occurs silently during the presymptomatic and asymptomatic stages of infection. Children, although important drivers of silent transmission, are not included in the current COVID-19 vaccination campaigns. Objective: To estimate the benefits of identifying silent infections among children as a proxy for their vaccination. Design, Setting, and Participants: This study used an age-structured disease transmission model, parameterized with census data and estimates from published literature, to simulate the estimated synergistic effect of interventions in reducing attack rates during the course of 1 year among a synthetic population representative of the US demographic composition. The population included 6 age groups of 0 to 4, 5 to 10, 11 to 18, 19 to 49, 50 to 64, and 65 years or older based on US census data. Data were analyzed from December 12, 2020, to February 26, 2021. Exposures: In addition to the isolation of symptomatic cases within 24 hours of symptom onset, vaccination of adults was implemented to reach a 40% to 60% coverage during 1 year with an efficacy of 95% against symptomatic and severe COVID-19. Main Outcomes and Measures: The combinations of proportion and speed for detecting silent infections among children that would suppress future attack rates to less than 5%. Results: In the base-case scenarios with an effective reproduction number Re = 1.2, a targeted approach that identifies 11% of silent infections among children within 2 days and 14% within 3 days after infection would bring attack rates to less than 5% with 40% vaccination coverage of adults. If silent infections among children remained undetected, achieving the same attack rates would require an unrealistically high vaccination coverage (&#8805;81%) of this age group, in addition to 40% vaccination coverage of adults. The estimated effect of identifying silent infections was robust in sensitivity analyses with respect to vaccine efficacy against infection and reduced susceptibility of children to infection. Conclusions and Relevance: In this simulation modeling study of a synthetic US population, in the absence of vaccine availability for children, a targeted approach to rapidly identify silent COVID-19 infections in this age group was estimated to significantly mitigate disease burden. These findings suggest that without measures to interrupt transmission chains from silent infections, vaccination of adults is unlikely to contain the outbreaks in the near term.","title":"Simulated Identification of Silent COVID-19 Infections Among Children and Estimated Future Infection Rates With Vaccination","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"j1huk63f","cord_uid":"j1huk63f","abstract":"Each state in the United States exhibited a unique response to the COVID-19 outbreak, along with variable levels of testing, leading to different actual case burdens in the country. In this study, via per-capita testing dependent ascertainment rates, along with case and death data, we fit a minimal epidemic model for each state. We estimate infection-level responsive lockdown entry and exit rates (representing government and behavioral reaction), along with the true number of cases as of May 31, 2020. Ultimately we provide error corrected estimates for commonly used metrics such as infection fatality ratio and overall case ascertainment for all 55 states and territories considered, along with the United States in aggregate, in order to correlate outbreak severity with first wave intervention attributes and suggest potential management strategies for future outbreaks. We observe a theoretically predicted inverse proportionality relation between outbreak size and lockdown rate, with scale dependent on the underlying reproduction number and simulations suggesting a critical population quarantine \\"half-life\\" of 30 days independent of other model parameters.","title":"Modeling COVID-19 outbreaks in United States with distinct testing, lockdown speed and fatigue rates","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-01-06 05:00:00"},{"main_cord_uid":"nlatfc7x","cord_uid":"nlatfc7x","abstract":"BackgroundHealthcare workers (HCWs) and ethnic minority groups are at increased risk of COVID-19 infection and adverse outcome. Severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2) vaccination is now available for frontline UK HCWs; however, demographic/occupational associations with vaccine uptake in this cohort are unknown. We sought to establish these associations in a large UK hospital workforce. MethodsWe conducted cross-sectional surveillance examining vaccine uptake amongst all staff at University Hospitals of Leicester NHS Trust. We examined proportions of vaccinated staff stratified by demographic factors, occupation and previous COVID-19 test results (serology/PCR) and used logistic regression to identify predictors of vaccination status after adjustment for confounders. FindingsWe included 19,044 HCWs; 12,278 (64.5%) had received SARS-CoV-2 vaccination. Compared to White HCWs (70.9% vaccinated), a significantly smaller proportion of ethnic minority HCWs were vaccinated (South Asian 58.5%, Black 36.8% p<0.001 for both). After adjustment, factors found to be negatively associated with vaccine uptake were; younger age, female sex, increasing deprivation and belonging to any non-White ethnic group (Black: aOR0.30, 95%CI 0.26-0.34, South Asian:0.67, 0.62-0.72). Allied health professionals and administrative/executive staff were more likely to be vaccinated than doctors. InterpretationEthnic minority HCWs and those from more deprived areas as well as those from particular occupational groups are less likely to take up SARS-CoV-2 vaccination. These findings have major implications for the delivery of SARS-CoV-2 vaccination programmes, in HCWs and the wider population and should inform the national vaccination programme to prevent the disparities of the pandemic from widening. FundingNIHR, UKRI/MRC","title":"Association of demographic and occupational factors with SARS-CoV-2 vaccine uptake in a multi-ethnic UK healthcare workforce: a rapid real-world analysis","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-02-15 05:00:00"},{"main_cord_uid":"qrm25ia3","cord_uid":"xsurzew3","abstract":"Background: The new coronavirus disease COVID-19 outbroke in Wuhan, Hubei Province, China in December 2019, and has spread by human-to-human transmission to other areas. This study evaluated the transmissibility of the infectious disease and analyzed its association with temperature and humidity, in order to put forward suggestions on how to suppress the transmission. Methods: In this study, we revised the reported data in Wuhan to estimate the actual number of confirmed cases. Then we used the equation derived from the Susceptible\xe2\u20ac\u201cExposed\xe2\u20ac\u201cInfectious\xe2\u20ac\u201cRecovered (SEIR) model to calculate R0 from January 24, 2020 to February 13, 2020 in 11 major cities in China for comparison. With the calculation results, we conducted correlation analysis and regression analysis between R0 and temperature and humidity to see the impact of weather on the transmissibility of COVID-19. Results: It was estimated that the cumulative number of confirmed cases had exceeded 45,000 by February 13, 2020 in Wuhan. The average R0 in Wuhan was 2.7011, significantly higher than those in other cities ranging from 1.7762 to 2.3700. The inflection points in the cities outside Hubei Province were between January 30, 2020 and February 3, 2020, while there had not been an obvious downward trend of R0 in Wuhan. R0 negatively correlated with both temperature and humidity, which was significant at the 0.01 level. Conclusions: The transmissibility of COVID-19 was strong and importance should be attached to the intervention of its transmission especially in Wuhan. According to the correlation between R0 and weather, the spread of disease will be suppressed as the weather warms.","title":"Transmissibility of COVID-19 and its association with temperature and humidity","annotator_investigating_R0":"1","text_response":"disease name: new coronavirus disease COVID-19\\r\\nlocation: Wuhan\\r\\ndate: from January 24, 2020 to February 13, 2020\\r\\nR0 value: 2.7011\\r\\n%CI values: -\\r\\nmethod: Susceptible\xe2\u20ac\u201cExposed\xe2\u20ac\u201cInfectious\xe2\u20ac\u201cRecovered (SEIR) model\\r\\n|\\r\\ndisease name: new coronavirus disease COVID-19\\r\\nlocation: other cities,china\\r\\ndate: from January 24, 2020 to February 13, 2020\\r\\nR0 value: ranging from 1.7762 to 2.3700\\r\\n%CI values: -\\r\\nmethod: Susceptible\xe2\u20ac\u201cExposed\xe2\u20ac\u201cInfectious\xe2\u20ac\u201cRecovered (SEIR) model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"new coronavirus disease COVID-19\\",\\r\\n\\"location\\": \\"Wuhan\\",\\r\\n\\"date\\": \\"from January 24, 2020 to February 13, 2020\\",\\r\\n\\"R0 value\\": \\"2.7011\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Susceptible\xe2\u20ac\u201cExposed\xe2\u20ac\u201cInfectious\xe2\u20ac\u201cRecovered (SEIR) model\\"}},{\\"contribution\\":{\\"disease name\\": \\"new coronavirus disease COVID-19\\",\\r\\n\\"location\\": \\"other cities,china\\",\\r\\n\\"date\\": \\"from January 24, 2020 to February 13, 2020\\",\\r\\n\\"R0 value\\": \\"ranging from 1.7762 to 2.3700\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Susceptible\xe2\u20ac\u201cExposed\xe2\u20ac\u201cInfectious\xe2\u20ac\u201cRecovered (SEIR) model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"new coronavirus disease COVID-19\\", \\"location\\": \\"Wuhan, Hubei Province, China\\", \\"date\\": \\"January 24, 2020 to February 13, 2020\\", \\"R0 value\\": \\"2.701\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"(SEIR) model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"new coronavirus disease COVID-19\\", \\"location\\": \\"other cities\\", \\"date\\": \\"January 24, 2020 to February 13, 2020\\", \\"R0 value\\": \\"1.7762 to 2.3700\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"(SEIR) model\\" } } ]","publish_time":"2020","action":"change_main_cord_id","cluster_id":"1413"},{"main_cord_uid":"4zwn2bus","cord_uid":"4zwn2bus","abstract":"The rapidly spreading Covid-19 that affected almost all countries, was first reported at the end of 2019. As a consequence of its highly infectious nature, countries all over the world have imposed extremely strict measures to control its spread. Since the earliest stages of this major pandemic, academics have done a huge amount of research in order to understand the disease, develop medication, vaccines and tests, and model its spread. Among these studies, a great deal of effort has been invested in the estimation of epidemic parameters in the early stage, for the countries affected by Covid-19, hence to predict the course of the epidemic but the variability of the controls over the course of the epidemic complicated the modeling processes. In this article, the determination of the basic reproduction number, the mean duration of the infectious period, the estimation of the timing of the peak of the epidemic wave is discussed using early phase data. Daily case reports and daily fatalities for ten countries over the period January 22, 2020 - April 18, 2020 are evaluated using the Susceptible-Infected-Removed (SIR) model. For each country, the SIR models fitting cumulative infective case data within 5% error are analysed. It is observed that the basic reproduction number and the mean duration of the infectious period can be estimated only in cases where the spread of the epidemic is over (for China and South Korea in the present case). Nevertheless, it is shown that the timing of the maximum and timings of the inflection points of the proportion of infected individuals can be robustly estimated from the normalized data. The validation of the estimates by comparing the predictions with actual data has shown that the predictions were realised for all countries except USA, as long as lock-down measures were retained.","title":"What Can We Estimate from Fatality and Infectious Case Data using the Susceptible-Infected-Removed (SIR) model? A case Study of Covid-19 Pandemic","annotator_investigating_R0":"0","text_response":"disease name: Covid-19\\r\\nlocation: ten countries\\r\\ndate: anuary 22, 2020 - April 18, 2020\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: Susceptible-Infected-Removed (SIR) model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"ten countries\\",\\r\\n\\"date\\": \\"anuary 22, 2020 - April 18, 2020\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Susceptible-Infected-Removed (SIR) model\\"}}]","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"68p1q0ye","cord_uid":"68p1q0ye","abstract":"BACKGROUND: Transmission of respiratory pathogens such as SARS-CoV-2 depends on patterns of contact and mixing across populations. Understanding this is crucial to predict pathogen spread and the effectiveness of control efforts. Most analyses of contact patterns to date have focused on high-income settings. METHODS: Here, we conduct a systematic review and individual-participant meta-analysis of surveys carried out in low- and middle-income countries and compare patterns of contact in these settings to surveys previously carried out in high-income countries. Using individual-level data from 28,503 participants and 413,069 contacts across 27 surveys, we explored how contact characteristics (number, location, duration, and whether physical) vary across income settings. RESULTS: Contact rates declined with age in high- and upper-middle-income settings, but not in low-income settings, where adults aged 65+ made similar numbers of contacts as younger individuals and mixed with all age groups. Across all settings, increasing household size was a key determinant of contact frequency and characteristics, with low-income settings characterised by the largest, most intergenerational households. A higher proportion of contacts were made at home in low-income settings, and work/school contacts were more frequent in high-income strata. We also observed contrasting effects of gender across income strata on the frequency, duration, and type of contacts individuals made. CONCLUSIONS: These differences in contact patterns between settings have material consequences for both spread of respiratory pathogens and the effectiveness of different non-pharmaceutical interventions. FUNDING: This work is primarily being funded by joint Centre funding from the UK Medical Research Council and DFID (MR/R015600/1).","title":"Social contact patterns and implications for infectious disease transmission \xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153 a systematic review and meta-analysis of contact surveys","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-11-25 05:00:00"},{"main_cord_uid":"l0c69uul","cord_uid":"l0c69uul","abstract":"In this work we propose a simple mathematical model for the analysis of the impact of control measures against an emerging infection, namely, the severe acute respiratory syndrome (SARS). The model provides a testable hypothesis by considering a dynamical equation for the contact parameter, which drops exponentially with time, simulating control measures. We discuss the role of modelling in public health and we analyse the distinction between forecasting and projection models as assessing tools for the estimation of the impact of intervention strategies. The model is applied to the communities of Hong Kong and Toronto (Canada) and it mimics those epidemics with fairly good accuracy. The estimated values for the basic reproduction number, R(0), were 1.2 for Hong Kong and 1.32 for Toronto (Canada). The model projects that, in the absence of control, the final number of cases would be 320,000 in Hong Kong and 36,900 in Toronto (Canada). In contrast, with control measures, which reduce the contact rate to about 25% of its initial value, the expected final number of cases is reduced to 1778 in Hong Kong and 226 in Toronto (Canada). Although SARS can be a devastating infection, early recognition, prompt isolation, and appropriate precaution measures, can be very effective to limit its spread.","title":"Forecasting versus projection models in epidemiology: The case of the SARS epidemics","annotator_investigating_R0":"1","text_response":"disease name: SARS\\r\\nlocation: Hong Kong\\r\\ndate: -\\r\\nR0 value: 1.2\\r\\n%CI values: -\\r\\nmethod: simple mathematical model\\r\\n|\\r\\ndisease name: SARS\\r\\nlocation: Toronto (Canada)\\r\\ndate: -\\r\\nR0 value: 1.32\\r\\n%CI values: -\\r\\nmethod: simple mathematical model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"SARS\\",\\r\\n\\"location\\": \\"Hong Kong\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"1.2\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"simple mathematical model\\"}},{\\"contribution\\":{\\"disease name\\": \\"SARS\\",\\r\\n\\"location\\": \\"Toronto (Canada)\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"1.32\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"simple mathematical model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"SARS\\", \\"location\\": \\"Hong Kong\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"1.2\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"simple mathematical model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"SARS\\", \\"location\\": \\"Toronto (Canada)\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"1.32\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"simple mathematical model\\" } } ]","publish_time":"2005-03-30 10:00:00","cluster_id":"1224"},{"main_cord_uid":"xu33wkt3","cord_uid":"xu33wkt3","abstract":"Full genome sequences are increasingly used to track the geographic spread and transmission dynamics of viral pathogens. Here, with a focus on Israel, we sequence 212 SARS-CoV-2 sequences and use them to perform a comprehensive analysis to trace the origins and spread of the virus. We find that travelers returning from the United States of America significantly contributed to viral spread in Israel, more than their proportion in incoming infected travelers. Using phylodynamic analysis, we estimate that the basic reproduction number of the virus was initially around 2.5, dropping by more than two-thirds following the implementation of social distancing measures. We further report high levels of transmission heterogeneity in SARS-CoV-2 spread, with between 2-10% of infected individuals resulting in 80% of secondary infections. Overall, our findings demonstrate the effectiveness of social distancing measures for reducing viral spread.","title":"Full genome viral sequences inform patterns of SARS-CoV-2 spread into and within Israel","annotator_investigating_R0":"1","text_response":"disease name: SARS-CoV-2\\r\\nlocation: Israel\\r\\ndate: -\\r\\nR0 value: initially around 2.5\\r\\n%CI values: -\\r\\nmethod: phylodynamic analysis","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"SARS-CoV-2\\",\\r\\n\\"location\\": \\"Israel\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"initially around 2.5\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"phylodynamic analysis\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"SARS-CoV-2\\", \\"location\\": \\"Israel\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"2.5\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"phylodynamic analysis\\" } } ]","publish_time":"2020"},{"main_cord_uid":"jmxdbngt","cord_uid":"jmxdbngt","abstract":"Despite having a small footprint origin, COVID-19 has expanded its clutches to being a global pandemic with severe consequences threatening the survival of the human species. Despite international communities closing their corridors to reduce the exponential spread of the coronavirus. The need to study the patterns of transmission and spread gains utmost importance at the grass-root level of the social structure. To determine the impact of lockdown and social distancing in Tamilnadu through epidemiological models in forecasting the \\"effective reproductive number\\" (R0) determining the significance in transmission rate in Tamilnadu after first Covid19 case confirmation on March 07, 2020. Utilizing web scraping techniques to extract data from different online sources to determine the probable transmission rate in Tamilnadu from the rest of the Indian states. Comparing the different epidemiological models (SIR, SIER) in forecasting and assessing the current and future spread of COVID-19. R0 value has a high spike in densely populated districts with the probable flattening of the curve due to lockdown and the rapid rise after the relaxation of lockdown. As of June 03, 2020, there were 25,872 confirmed cases and 208 deaths in Tamilnadu after two and a half months of lockdown with minimal exceptions. As on June 03, 2020, the information published online by the Tamilnadu state government the fatality is at 1.8% (208/11345=1.8%) spread with those aged (0-12) at 1437 and 13-60 at 21899 and 60+ at 2536 the risk of symptomatic infection increases with age and comorbid conditions.","title":"Accessing Covid19 Epidemic Outbreak in Tamilnadu and the Impact of Lockdown through Epidemiological Models and Dynamic systems","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"iokyu7ja","cord_uid":"iokyu7ja","abstract":"Transmission of SARS-CoV-2 appears especially effective in \\"hot zone\\" locations where individuals interact in close proximity. We present mathematical models describing two types of hot zones. First, we consider a metapopulation model of infection spread where transmission hot zones are explicitly described by independent demes in which the same people repeatedly interact (referred to as \\"static\\" hot zones, e.g. nursing homes, food processing plants, prisons, etc.). These are assumed to exists in addition to a \\"community at large\\" compartment in which virus transmission is less effective. This model yields a number of predictions that are relevant to interpreting epidemiological patterns in COVID19 data. Even if the rate of community virus spread is assumed to be relatively slow, outbreaks in hot zones can temporarily accelerate initial community virus growth, which can lead to an overestimation of the viral reproduction number in the general population. Further, the model suggests that hot zones are a reservoir enabling the prolonged persistence of the virus at \\"infection plateaus\\" following implementation of non-pharmaceutical interventions, which has been frequently observed in data. The second model considers \\"dynamic\\" hot zones, which can repeatedly form by drawing random individuals from the community, and subsequently dissolve (e.g. restaurants, bars, movie theaters). While dynamic hot zones can accelerate the average rate of community virus spread and can provide opportunities for targeted interventions, they do not predict the occurrence of infection plateaus or other atypical epidemiological dynamics. The models therefore identify two types of transmission hot zones with very different effects on the infection dynamics, which warrants further epidemiological investigations.","title":"Effect of hot zone infection outbreaks on the dynamics of SARS-CoV-2 spread in the community at large","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-11-24 05:00:00"},{"main_cord_uid":"n7gxgfhi","cord_uid":"n7gxgfhi","abstract":"The death toll for Covid-19 may be reduced by dividing the population into two classes, the vulnerable and the fit, with different lockdown regimes. Instead of one reproduction number there now are four parameters. These make it possible to quantify the effect of the social distancing measures. There is a simple stochastic model for epidemics in a two type population. Apart from the size of the population of the vulnerable and the fit, and the initial number of infected in the two classes, only the four reproduction parameters are needed to run the two type Reed-Frost model. The program is simple and fast. On a pc it takes less than five minutes to do a hundred thousand simulations of the epidemic for a population of the size of the US. Epidemics are non-linear processes. Results may be counterintuitive. The average number of vulnerable persons infected by an infectious fit person is a crucial parameter of the epidemic in the two type population. Intuitively this parameter should be small. However simulations show that even if this parameter is small the death toll may be higher than without shielding. Under certain conditions increasing the value of the parameter may reduce the death toll. The article addresses these blind spots in our intuition.","title":"Shielding the vulnerable in an epidemic: a numerical approach","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"21hwmk1z","cord_uid":"21hwmk1z","abstract":"BACKGROUND: COVID-19 continues to threaten human life worldwide. We explored how human behaviours have been influenced by the COVID-19 pandemic in Hong Kong, and how the transmission of other respiratory diseases (e.g. influenza) has been influenced by human behaviour. METHODS: We focused on the spread of COVID-19 and influenza infections based on reported COVID-19 cases and influenza surveillance data, and investigated the changes in human behaviour due to COVID-19 based on mass transit railway data and the data from a telephone survey. We did the simulation based on SEIR model to assess the risk reduction of influenza transmission caused by the changes in human behaviour. RESULTS: During the COVID-19 pandemic, the number of passengers fell by 52.0% compared with the same period in 2019. Residents spent 32.2% more time at home. Each person on average came into close contact with 17.6 and 7.1 people per day during the normal and pandemic periods, respectively. Students, workers, and older people reduced their daily number of close contacts by 83.0%, 48.1%, and 40.3%, respectively. The close contact rates in residences, workplaces, places of study, restaurants, shopping centres, markets, and public transport decreased by 8.3%, 30.8%, 66.0%, 38.5%, 48.6%, 41.0%, and 36.1%, respectively. Based on the simulation, these changes in human behaviours reduced the effective reproduction number of influenza by 63.1%. CONCLUSIONS: Human behaviours were significantly influenced by the COVID-19 pandemic in Hong Kong. Close contact control contributed more than 47% to the reduction in infection risk of COVID-19.","title":"Effects of human behaviour changes during the COVID-19 pandemic on influenza spread in Hong Kong","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"54x472tr","cord_uid":"54x472tr","abstract":"The pandemic of the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) took the world by surprise. Following the first outbreak of COVID-19 in December 2019, several models have been developed to study and understand its transmission dynamics. Although the spread of COVID-19 is being slowed down by vaccination and other interventions, there is still a need to have a clear understanding of the evolution of the pandemic across countries, states and communities. To this end, there is a need to have a clearer picture of the initial spread of the disease in different regions. In this project, we used a simple SEIR model and a Bayesian inference framework to estimate the basic reproduction number of COVID-19 across Africa. Our estimates vary between 1.98 (Sudan) and 9.66 (Mauritius), with a median of 3.67 (90% CrI: 3.31 - 4.12). The estimates provided in this paper will help to inform COVID-19 modeling in the respective countries/regions.","title":"The basic reproduction number of COVID-19 across Africa","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Sudan\\r\\ndate: -\\r\\nR0 value: 1.98\\r\\n%CI values: -\\r\\nmethod: SEIR model and a Bayesian inference framework\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Mauritius\\r\\ndate: -\\r\\nR0 value: 9.66\\r\\n%CI values: -\\r\\nmethod: SEIR model and a Bayesian inference framework\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Africa\\r\\ndate: -\\r\\nR0 value: a median of 3.67\\r\\n%CI values: 90% CrI: 3.31 - 4.12\\r\\nmethod: SEIR model and a Bayesian inference framework","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Sudan\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"1.98\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SEIR model and a Bayesian inference framework\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Mauritius\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"9.66\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SEIR model and a Bayesian inference framework\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Africa\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"a median of 3.67\\",\\r\\n\\"%CI values\\": \\"90% CrI: 3.31 - 4.12\\",\\r\\n\\"method\\": \\"SEIR model and a Bayesian inference framework\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Africa\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"1.98 (Sudan) and 9.66 (Mauritius), with a median of 3.67\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"simple SEIR model and a Bayesian inference framework\\" } } ]","publish_time":"2021","cluster_id":"1270"},{"main_cord_uid":"o8tus083","cord_uid":"o8tus083","abstract":"The correct evaluation of the reproductive number $R$ for COVID-19 -- which characterizes the average number of secondary cases generated by each typical primary case -- is central in the quantification of the potential scope of the pandemic and the selection of an appropriate course of action. In most models, $R$ is modeled as a universal constant for the virus across outbreak clusters and individuals -- effectively averaging out the inherent variability of the transmission process due to varying individual contact rates, population densities, demographics, or temporal factors amongst many. Yet, due to the exponential nature of epidemic growth, the error due to this simplification can be rapidly amplified and lead to inaccurate predictions and/or risk evaluation. From the statistical modeling perspective, the magnitude of the impact of this averaging remains an open question: how can this intrinsic variability be percolated into epidemic models, and how can its impact on uncertainty quantification and predictive scenarios be better quantified? In this paper, we propose to study this question through a Bayesian perspective, creating a bridge between the agent-based and compartmental approaches commonly used in the literature. After deriving a Bayesian model that captures at scale the heterogeneity of a population and environmental conditions, we simulate the spread of the epidemic as well as the impact of different social distancing strategies, and highlight the strong impact of this added variability on the reported results. We base our discussion on both synthetic experiments -- thereby quantifying of the reliability and the magnitude of the effects -- and real COVID-19 data.","title":"Modeling the Heterogeneity in COVID-19\'s Reproductive Number and its Impact on Predictive Scenarios","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"kmdkbdoe","cord_uid":"kmdkbdoe","abstract":"Background: The outbreak of novel coronavirus disease (COVID-19), started from Wuhan, China, at the end of December 2019, hits almost the entire world. In Bangladesh, the first case was officially reported on March 8, 2020. We estimated the basic reproductive number, R 0 , of COVID-19 for Bangladesh using the first 65-day data of the outbreak.MethodsWith time-varying disease reporting rate, epidemic curves were estimated using the exponential growth model utilizing daily COVID-19 diagnosis data in Bangladesh from March 8 to May 11, 2020. We estimated R 0 using the estimated intrinsic growth rate (?\xb3). Serial intervals (SI) have been used from two well-known coronaviruses\xe2\u20ac\u2122 outbreaks, SARS and MERS;and the early estimate of SI of COVID-19 in Wuhan, China.ResultsThe COVID-19 epidemic in Bangladesh followed an exponential growth model. We found the R 0 to be 1.84 [95% CI: 1.82\xe2\u20ac\u201c1.86], 1.82 [95% CI: 1.81\xe2\u20ac\u201c1.84], and 1.94 [95% CI: 1.92\xe2\u20ac\u201c1.96], for MERS, COVID-19, and SARS SI respectively without adjusting reporting rate. With the adjusted reporting rate, R 0 reduced to 1.63 [95% CI: 1.62\xe2\u20ac\u201c1.65], 1.62 [95% CI: 1.61\xe2\u20ac\u201c1.64], and 1.71 [95% CI: 1.70\xe2\u20ac\u201c1.73] for a five-fold increase. Inverse association between the reporting rate and the basic reproduction number was observed.ConclusionThe R 0 was found to be 1.87 for existing cases and was reduced to 1.65 for the five-fold increase of the early reporting rate. Findings suggest a continued COVID-19 outbreak in Bangladesh and immediate steps need to be taken to control.","title":"Estimation of the basic reproduction number of novel coronavirus (COVID-19) in Bangladesh: A 65-day outbreak data-driven analysis","annotator_investigating_R0":"1","text_response":"disease name: novel coronavirus disease (COVID-19)\\r\\nlocation: Bangladesh\\r\\ndate: March 8 to May 11, 2020\\r\\nR0 value: 1.82\\r\\n%CI values: 95% CI: 1.81-1.84\\r\\nmethod: exponential growth model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"novel coronavirus disease (COVID-19)\\",\\r\\n\\"location\\": \\"Bangladesh\\",\\r\\n\\"date\\": \\"March 8 to May 11, 2020\\",\\r\\n\\"R0 value\\": \\"1.82\\",\\r\\n\\"%CI values\\": \\"95% CI: 1.81-1.84\\",\\r\\n\\"method\\": \\"exponential growth model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Bangladesh\\", \\"date\\": \\"March 8 to May 11, 2020\\", \\"R0 value\\": \\"1.84\\", \\"%CI values\\": \\"[95% CI: 1.82-1.86], [95% CI: 1.81-1.84\\", (with the adjusted reporting rate)\\", \\"method\\": \\"estimated intrinsic growth rate (?3)\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Bangladesh\\", \\"date\\": \\"March 8 to May 11, 2020\\", \\"R0 value\\": \\"1.63\\", \\"%CI values\\": \\"[95% CI: 1.62-1.65\\", (with the adjusted reporting rate)\\", \\"method\\": \\"estimated intrinsic growth rate (?3)\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Bangladesh\\", \\"date\\": \\"March 8 to May 11, 2020\\", \\"R0 value\\": \\"1.62\\", \\"%CI values\\": \\"[95% CI: 1.61-1.64\\", \\"method\\": \\"estimated intrinsic growth rate (?3)\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Bangladesh\\", \\"date\\": \\"March 8 to May 11, 2020\\", \\"R0 value\\": \\"1.71\\", \\"%CI values\\": \\"[95% CI: 1.70-1.73]\\", \\"method\\": \\"estimated intrinsic growth rate (?3)\\" } } ]","publish_time":"2020"},{"main_cord_uid":"foxbu4ec","cord_uid":"foxbu4ec","abstract":"Policy makers around the world are facing unprecedented challenges in making decisions on when and what degrees of measures should be implemented to tackle the COVID-19 pandemic. Here, using a nationwide mobile phone dataset, we developed a networked meta-population model to simulate the impact of intervention in controlling the spread of the virus in China by varying the effectiveness of transmission reduction and the timing of intervention start and relaxation. We estimated basic reproduction number and transition probabilities between health states based on reported cases. Our model demonstrates that both the time of initiating an intervention and its effectiveness had a very large impact on controlling the epidemic, and the current Chinese intense social distancing intervention has reduced the impact substantially but would have been even more effective had it started earlier. The optimal duration of the control measures to avoid resurgence was estimated to be 2 months, although would need to be longer under less effective controls.","title":"Investigating time, strength, and duration of measures in controlling the spread of COVID-19 using a networked meta-population model","annotator_investigating_R0":"0","text_response":"disease name: COVID-19\\r\\nlocation: China\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: networked meta-population model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"China\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"networked meta-population model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"China\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Networked meta-population model\\" } } ]","publish_time":"2020","cluster_id":"562"},{"main_cord_uid":"6xc0w5iv","cord_uid":"6xc0w5iv","abstract":"We present a global analysis of the spread of recently emerged SARS-CoV-2 variants and estimate changes in effective reproduction numbers at country-specific level using sequence data from GISAID. Nearly all investigated countries demonstrated rapid replacement of previously circulating lineages by the World Health Organization-designated variants of concern, with estimated transmissibility increases of 29% (95% CI: 24-33), 25% (95% CI: 20-30), 38% (95% CI: 29-48) and 97% (95% CI: 76-117), respectively, for B.1.1.7, B.1.351, P.1 and B.1.617.2.","title":"Increased transmissibility and global spread of SARS-CoV-2 variants of concern as at June 2021","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"4wnp1u22","cord_uid":"4wnp1u22","abstract":"Background: World Health organization declared Covid-19 as an outbreak, hence preventive measure like lockdown should be taken to control the spread of infection. This study offers an exhaustive analysis of the reproductive number (R0) in India with major intervention for COVID-19 outbreaks and analysed the lockdown effects on the Covid-19. Methodology: Covid-19 data extracted from Ministry of Health and Family Welfare, Government of India. Then, a novel method implemented in the incidence and Optimum function in desolve package to the data of cumulative daily new confirmed cases for robustly estimating the reproduction number in the R software. Result: Analysis has been seen that the lockdown was really quite as effective, India has already shown a major steady decline. The growth rate has fluctuated about 20 percent with trend line projections in various lockdown. A comparative analysis gives an idea of decline in value of R0 from 1.73 to 1.08. Annotation plot showing the predicted R0 values based on previous lockdown in month of June and July. Conclusion: Without lockdown, the growth might not have been contained in India and may have gone into the exponential zone. We show that, the lockdown in India was fairly successful. The effect partial lifting of the lockdown (unlock) is also seen in the results, in terms of increment in R0 values. Hence this study provides a platform for policy makers and government authorities for implementing the strategies to prevent the spread of infection.","title":"A comprehensive analysis of R0 with different lockdown phase during covid-19 in India","annotator_investigating_R0":"1","text_response":"disease name: Covid-19\\r\\nlocation: India\\r\\ndate: June and July\\r\\nR0 value: 1.73 to 1.08\\r\\n%CI values: -\\r\\nmethod: Novel method implemented in the incidence and Optimum function in desolve package to the data of cumulative daily new confirmed cases for robustly estimating the reproduction number in the R software.","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"India\\",\\r\\n\\"date\\": \\"June and July\\",\\r\\n\\"R0 value\\": \\"1.73 to 1.08\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Novel method implemented in the incidence and Optimum function in desolve package to the data of cumulative daily new confirmed cases for robustly estimating the reproduction number in the R software.\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"India\\", \\"date\\": \\"June and July\\", \\"R0 value\\": \\"1.73 to 1.08\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"incidence and Optimum function in desolve package to the data of cumulative daily new confirmed cases for robustly estimating the reproduction number in the R software\\" } } ]","publish_time":"2020-07-11 10:00:00"},{"main_cord_uid":"k5c0ptbk","cord_uid":"k5c0ptbk","abstract":"The SARS-CoV-2 B.1.617.2 (Delta) variant flared up in late May in Guangzhou, China. Transmission characteristics of Delta variant were analysed for 153 confirmed cases and two complete transmission chains with seven generations were fully presented. A rapid transmission occurred in five generations within 10 days. The basic reproduction number (R(0)) was 3.60 (95% confidence interval: 2.50\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u01535.30). After redefining the concept of close contact, the proportion of confirmed cases discovered from close contacts increased from 43% to 100%. With the usage of a yellow health code, the potential exposed individuals were self-motivated to take a nucleic acid test and regained public access with a negative testing result. Facing the massive requirement of screening, novel facilities like makeshift inflatable laboratories were promptly set up as a vital supplement and 17 cases were found, with 1 pre-symptomatic. The dynamic adjustment of these three interventions resulted in the decline of Rt from 5.00 to 1.00 within 9 days. By breaking the transmission chain and eliminating the transmission source through extending the scope of the close-contact tracing, health-code usage and mass testing, the Guangzhou Delta epidemic was effectively contained.","title":"Crucial control measures to contain China\'s first Delta variant outbreak","annotator_investigating_R0":"1","text_response":"disease name: SARS-CoV-2 B.1.617.2 (Delta) variant\\r\\nlocation: Guangzhou, China\\r\\ndate: late May\\r\\nR0 value: 3.6\\r\\n%CI values: 95% confidence interval: 2.50-5.30\\r\\nmethod: Transmission characteristics of Delta variant were analysed for 153 confirmed cases and two complete transmission chains with seven generations were fully presented.","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"SARS-CoV-2 B.1.617.2 (Delta) variant\\",\\r\\n\\"location\\": \\"Guangzhou, China\\",\\r\\n\\"date\\": \\"late May\\",\\r\\n\\"R0 value\\": \\"3.6\\",\\r\\n\\"%CI values\\": \\"95% confidence interval: 2.50-5.30\\",\\r\\n\\"method\\": \\"Transmission characteristics of Delta variant were analysed for 153 confirmed cases and two complete transmission chains with seven generations were fully presented.\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"SARS-CoV-2 B.1.617.2 (Delta) variant\\", \\"location\\": \\"Guangzhou, China\\", \\"date\\": \\"Late May\\", \\"R0 value\\": \\"3.60\\", \\"%CI values\\": \\"(95% confidence interval: 2.50-5.35)\\", \\"method\\": \\"-\\" } } ]","publish_time":"2022-01-18 00:00:00"},{"main_cord_uid":"z22ekgtv","cord_uid":"z22ekgtv","abstract":"BACKGROUND: Influenza A pandemics cause significant mortality and morbidity. H2N2 viruses have caused a prior pandemic, and are circulating in avian reservoirs. The age-related frequency of current population immunity to H2 viruses was evaluated. METHODS: Hemagglutinin inhibition (HAI) assays against historical human and recent avian influenza A(H2N2) viruses were performed across age groups in Rochester, New York, and Hong Kong, China. The impact of existing cross-reactive HAI immunity on the effective reproduction number was modeled. RESULTS: One hundred fifty individual sera from Rochester and 295 from Hong Kong were included. Eighty-five percent of patients born in Rochester and Hong Kong before 1968 had HAI titers \xc3\xa2\xe2\u20ac\xb0\xc2\xa51:40 against A/Singapore/1/57, and >50% had titers \xc3\xa2\xe2\u20ac\xb0\xc2\xa51:40 against A/Berkeley/1/68. The frequency of titers \xc3\xa2\xe2\u20ac\xb0\xc2\xa51:40 to avian H2N2 A/mallard/England/727/06 and A/mallard/Netherlands/14/07 in subjects born before 1957 was 62% and 24%, respectively. There were no H2 HAI titers >1:40 in individuals born after 1968. These levels of seroprevalence reduce the initial reproduction number of A/Singapore/1/1957 or A/Berkeley/1/68 by 15%\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u015320%. A basic reproduction number (R(0)) of the emerging transmissible virus <1.2 predicts a preventable pandemic. CONCLUSIONS: Population immunity to H2 viruses is insufficient to block epidemic spread of H2 virus. An H2N2 pandemic would have lower impact in those born before 1968.","title":"Population Serologic Immunity to Human and Avian H2N2 Viruses in the United States and Hong Kong for Pandemic Risk Assessment","annotator_investigating_R0":"1","text_response":"disease name: H2N2 viruses\\r\\nlocation: Rochester, New York\\r\\ndate: -\\r\\nR0 value: <1.2\\r\\n%CI values: -\\r\\nmethod: Hemagglutinin inhibition (HAI) assays against historical human and recent avian influenza A(H2N2) viruses\\r\\n|\\r\\ndisease name: H2N2 viruses\\r\\nlocation: Hong Kong, China\\r\\ndate: -\\r\\nR0 value: <1.2\\r\\n%CI values: -\\r\\nmethod: Hemagglutinin inhibition (HAI) assays against historical human and recent avian influenza A(H2N2) viruses","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"H2N2 viruses\\",\\r\\n\\"location\\": \\"Rochester, New York\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"<1.2\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Hemagglutinin inhibition (HAI) assays against historical human and recent avian influenza A(H2N2) viruses\\"}},{\\"contribution\\":{\\"disease name\\": \\"H2N2 viruses\\",\\r\\n\\"location\\": \\"Hong Kong, China\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"<1.2\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Hemagglutinin inhibition (HAI) assays against historical human and recent avian influenza A(H2N2) viruses\\"}}]","json_model_response":"unanswerable","publish_time":"2018-10-01 10:00:00","cluster_id":"1200"},{"main_cord_uid":"9blabiww","cord_uid":"9blabiww","abstract":"Background: Small studies have correlated hypertension with pneumonia risk; whether this is recapitulated in larger prospective studies, and represents a causal association, is unclear. Methods: We estimated the risk for prevalent hypertension with incident respiratory diseases over mean follow-up of 8 years among 377,143 British participants in the UK Biobank. Mendelian randomization of blood pressure on pneumonia was implemented using 75 independent, genome-wide significant variants associated with systolic and diastolic blood pressures among 299,024 individuals not in the UK Biobank. Secondary analyses with pulmonary function tests were performed. Findings: In total, 107,310 participants (30%) had hypertension at UK Biobank enrollment, and 9,969 (3%) developed pneumonia during follow-up. Prevalent hypertension was independently associated with increased risk for incident pneumonia (HR: 1.36; 95% CI: 1.29-1.43; p < 0.001), as well as other incident respiratory diseases. Genetic predisposition to a 5 mm Hg increase in blood pressure was associated with increased risk for incident pneumonia for systolic blood pressure (HR: 1.08; 95% CI: 1.04-1.13; p < 0.001) and diastolic blood pressure (HR: 1.11; 95% CI: 1.03-1.20; p = 0.005). Additionally, consistent with epidemiologic associations, increased blood pressure genetic risk was significantly associated with reduced performance on pulmonary function tests (p < 0.001). Conclusions: These results suggest that elevated blood pressure increases risk for pneumonia. Maintaining adequate blood pressure control, in addition to other measures, may reduce risk for pneumonia. Funding: S.M.Z. (1F30HL149180-01), M.H. (T32HL094301-07), and P.N. (R01HL1427, R01HL148565, and R01HL148050) are supported by the National Institutes of Health. J.P. is supported by the John S. LaDue Memorial Fellowship.","title":"Elevated Blood Pressure Increases Pneumonia Risk: Epidemiological Association and Mendelian Randomization in the UK Biobank","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"xpqi1rwp","cord_uid":"xpqi1rwp","abstract":"Background: Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) has entered our lives with the fear of outbreak, death, and recurrence. Our objective in this study is to evaluate the epidemiological features of Coronavirus Disease 2019 (COVID-19) infection and death in Fars province, Iran. Methods: A cross-sectional study was conducted from February 18th to September 30th, 2020, where age, history of underlying diseases, sex, community-wide quarantine, nationality, close contact, pregnancy, medical staff job, traveling, and residency were compared between alive and deceased groups. Data were analyzed using IBM SPSS software, version 22.0, and the significance level was set at 0.05. Results: Regarding 57958 new cases of COVID-19, the basic reproduction number (R0) was estimated as 2.8, requiring a minimum of 65% immunization to reach herd immunity. Moreover, an R0=0.36 was required to reach the endemic state in the region. The incidence, mortality, fatality, and recurrence rates of COVID-19 were estimated as 1347.9 per 100,000 dwellers, 209.5 per 1000,000 dwellers, 1.6 %, and 3.1 per 100,000 dwellers, respectively. Age, history of underlying diseases, urban residency, and the male sex were significantly higher in the deceased group (OR=1.09, 5.48, 1.24, and 1.32;All Ps<0.001, <0.001, 0.005, and <0.001, respectively). In addition, the recurrence rate among positive cases was estimated as 0.23% with a median\xc3\u201a\xc2\xb1inter-quartile range equal to 84\xc3\u201a\xc2\xb146.25 days. Community-wide quarantine was shown to be a protective factor for death due to COVID-19 (OR=0.58, P=0.005). Conclusion: Community-wide quarantine blocks the transmission of COVID-19 effectively. COVID-19 enjoys no solid immunity. History of underlying diseases, the male sex, urban residency, and age were among the most significant causes of death due to COVID-19. Further investigations are recommended on the genetic structure of SARS-CoV-2, treatments, and vaccination.","title":"Epidemiological Study of Infection and Death Due to COVID-19 in Fars Province, Iran, From February to September 2020","annotator_investigating_R0":"1","text_response":"disease name: Coronavirus Disease 2019 (COVID-19)\\r\\nlocation: Fars Province, Iran\\r\\ndate: February 18th to September 30th, 2020\\r\\nR0 value: 2.8\\r\\n%CI values: -\\r\\nmethod: Cross-sectional study","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\",\\r\\n\\"location\\": \\"Fars Province, Iran\\",\\r\\n\\"date\\": \\"February 18th to September 30th, 2020\\",\\r\\n\\"R0 value\\": \\"2.8\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Cross-sectional study\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Fars Province, Iran\\", \\"date\\": \\"February 18th to September 30th, 2020\\", \\"R0 value\\": \\"2.8\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"cross-sectional study\\" } } ]","publish_time":"2022"},{"main_cord_uid":"ldvhl5ik","cord_uid":"ldvhl5ik","abstract":"BACKGROUND: We recently showed that seasonal patterns of COVID-19 incidence and Influenza-Like Illnesses incidence are highly similar, in a country in the temperate climate zone, such as the Netherlands. We hypothesize that in The Netherlands the same environmental factors and mobility trends that are associated with the seasonality of flu-like illnesses are predictors of COVID-19 seasonality as well. METHODS: We used meteorological, pollen/hay fever and mobility data from the Netherlands. For the reproduction number of COVID-19 (R(t)), we used daily estimates from the Dutch State Institute for Public Health. For all datasets, we selected the overlapping period of COVID-19 and the first allergy season: from February 17, 2020 till September 21, 2020 (n = 218). Backward stepwise multiple linear regression was used to develop an environmental prediction model of the R(t) of COVID-19. Next, we studied whether adding mobility trends to an environmental model improved the predictive power. RESULTS: Through stepwise backward multiple linear regression four highly significant (p < 0.01) predictive factors are selected in our combined model: temperature, solar radiation, hay fever incidence, and mobility to indoor recreation locations. Our combined model explains 87.5% of the variance of R(t) of COVID-19 and has a good and highly significant fit: F(4, 213) = 374.2, p < 0.00001. This model had a better overall predictive performance than a solely environmental model, which explains 77.3% of the variance of R(t) (F(4, 213) = 181.3, p < 0.00001). CONCLUSIONS: We conclude that the combined mobility and environmental model can adequately predict the seasonality of COVID-19 in a country with a temperate climate like the Netherlands. In this model higher solar radiation, higher temperature and hay fever are related to lower COVID-19 reproduction, and higher mobility to indoor recreation locations is related to an increased COVID-19 spread.","title":"Environmental factors and mobility predict COVID-19 seasonality in the Netherlands","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2022-03-04 05:00:00","action":"keep","cluster_id":"154"},{"main_cord_uid":"l9x8c2dq","cord_uid":"l9x8c2dq","abstract":"To counter the second COVID-19 wave, the Italian government has adopted a scheme of three sets of restrictions (coded as yellow, orange, and red) imposed on a regional basis. We estimate that milder restrictions in regions at lower risk (yellow) resulted in a transmissibility reduction of about 18%, leading to a reproduction number Rt of about 0.99. Stricter measures (orange and red) led to reductions of 34% and 45% and Rt values of about 0.89 and 0.77 respectively.","title":"Effectiveness of regional restrictions in reducing SARS-CoV-2 transmission during the second wave of COVID-19, Italy.","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-01-11 05:00:00"},{"main_cord_uid":"byvxg8o1","cord_uid":"byvxg8o1","abstract":"Background: The SEIR model or a variation of it is commonly used to study epidemic spread and make predictions on how it evolves. It is used to guide officials in their response to an epidemic. This research demonstrates an effective and simple approach that estimates the parameters of any variations of the SEIR model. This new technique will be demonstrated on the spread of COVID-19 in Libya. Methods: A five compartmental epidemic model is used to model the COVID-19 pandemic in Libya. Two sets of data are needed to evaluate the model parameters, the cumulative number of symptomatic cases and the total number of active cases. This data along with the assumption that the cumulative number of symptomatic cases grows exponentially, to determine most of the model parameters. Results: Libya epidemic start-date was estimated as t_o=-18.5 days, corresponding to May 5th. We mathematically demonstrated that the number of active cases follows two competing exponential distributions: a positive exponential function, measuring how many new cases are added, and a negative exponential function, measuring how many cases recovered. From this distribution we showed that the average recovery time is 48 days, and the incubation period is 15.2 days. Finally, the productive number was estimated as R0 = 7.6. Conclusions: With only the cumulative number of cases and the total number of active cases of COVID19, several important SEIR model parameters can be measured effectively. This approach can be applied for any infectious disease epidemic anywhere in the world.","title":"A New Mathematical Approach for the Estimation of epidemic Model Parameters with Demonstration on COVID-19 Pandemic in Libya","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Libya\\r\\ndate: May 5th\\r\\nR0 value: 7.6\\r\\n%CI values: -\\r\\nmethod: SEIR model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Libya\\",\\r\\n\\"date\\": \\"May 5th\\",\\r\\n\\"R0 value\\": \\"7.6\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SEIR model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Libya\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"6.7\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SEIR model\\" } } ]","publish_time":"2020-07-21 00:00:00"},{"main_cord_uid":"rr7r7ef0","cord_uid":"rr7r7ef0","abstract":"The outbreak of the novel coronavirus disease, COVID-19, originating from Wuhan, China in early December, has infected more than 70,000 people in China and other countries and has caused more than 2,000 deaths. As the disease continues to spread, the biomedical society urgently began identifying effective approaches to prevent further outbreaks. Through rigorous epidemiological analysis, we characterized the fast transmission of COVID-19 with a basic reproductive number 5.6 and proved a sole zoonotic source to originate in Wuhan. No changes in transmission have been noted across generations. By evaluating different control strategies through predictive modeling and Monte carlo simulations, a comprehensive quarantine in hospitals and quarantine stations has been found to be the most effective approach. Government action to immediately enforce this quarantine is highly recommended.","title":"Characterizing the transmission and identifying the control strategy for COVID-19 through epidemiological modeling","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: -\\r\\ndate: -\\r\\nR0 value: 5.6\\r\\n%CI values: -\\r\\nmethod: rigorous epidemiological analysis","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"-\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"5.6\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"rigorous epidemiological analysis\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"China\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"5.6\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"rigorous epidemiological analysis\\" } } ]","publish_time":"2020-02-25 05:00:00"},{"main_cord_uid":"mqsudckd","cord_uid":"mqsudckd","abstract":"I describe SIR modeling of the COVID-19 pandemic in two U.S. urban environments, New York City (NYC) and Cook County, IL, from onset through the month of June, 2020. Since testing was not widespread early in the pandemic in the U.S., I do not use data on confirmed cases and rely solely on public fatality data to estimate model parameters. Fits to the first 20 days of data determine a degenerate combination of the basic reproduction number, R0, and the mean time to removal from the infectious population, 1/{gamma} with {gamma}(R0 - 1) = 0.25(0.21) inverse days for NYC (Cook County). Equivalently, the initial doubling time was td = 2.8(3.4) days for NYC (Cook). The early fatality data suggest that both locations had infections in early February. I model the mitigation measures implemented in mid-March in both locations (distancing, quarantine, isolation, etc) via a time-dependent reproduction number Rt that declines monotonically from R0 to a smaller asymptotic value, with a parameterized functional form. The timing (mid-March) and duration (several days) of the transitions in Rt appear well determined by the data. However, the fatality data determine only a degenerate combination of the parameters R0, the percentage reduction in social contact due to mitigation measures, X, and the infection fatality rate (IFR), f . With flat priors, based on simulations the NYC model parameters have 95.45% credible intervals of R0 = 3.0 - 5.4, X = 80 - 99.9% and f = 2 - 6%, with 5 - 13% of the population asymptotically infected. A strong external prior indicating a lower value of f or of 1/{gamma} would imply lower values of R0 and X and higher percentage infection of the population. For Cook County, the evolution was qualitatively different: after mitigation measures were implemented, the daily fatality counts reached a plateau for about a month before tailing off. This is consistent with an SIR model that exhibits \\"critical slowing-down\\", in which Rt plateaus at a value just above unity. For Cook County, the 95.45% credible intervals for the model parameters are much broader and shifted downward, R0 = 1.4 - 4.7, X = 26 - 54%, and f = 0.1 - 0.6% with 15 - 88% of the population asymptotically infected. Despite the apparently lower efficacy of its social contact reduction measures, Cook County has had significantly fewer fatalities per population than NYC, D{infty}/N = 100 vs. 270 per 100,000. In the model, this is attributed to the lower inferred IFR for Cook; an external prior pointing to similar values of the IFR for the two locations would instead chalk up the difference in D/N to differences in the relative growth rate of the disease. I derive a model-dependent threshold, Xcrit, for \\"safe\\" re-opening, that is, for easing of contact reduction that would not trigger a second wave; for NYC, the models predict that increasing social contact by more than 20% from post-mitigation levels will lead to renewed spread, while for Cook County the threshold value is very uncertain, given the parameter degeneracies. The timing of 2nd-wave growth will depend on the amplitude of contact increase relative to Xcrit and on the asymptotic growth rate, and the impact in terms of fatalities will depend on the parameter f .","title":"A \\"Tail\\" of Two Cities: Fatality-based Modeling of COVID-19 Evolution in New York City and Cook County, IL","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-08-12 10:00:00"},{"main_cord_uid":"ho27d3ob","cord_uid":"ho27d3ob","abstract":"BackgroundThe outbreak of Coronavirus disease, which originated in Wuhan, China in 2019, has affected the lives of billions of people globally. Throughout 2020, the reproduction number of COVID-19 was widely used by decision-makers to explain their strategies to control the pandemic. MethodsIn this work, we deduce and analyze both initial and effective reproduction numbers for 12 diverse world regions between February and December of 2020. We consider mobility reductions, mask wearing and compliance with masks, mask efficacy values alongside other non-pharmaceutical interventions (NPIs) in each region to get further insights in how each of the above factored into each regions SARS-COV-2 transmission dynamic. ResultsWe quantify in each region the following reductions in the observed effective reproduction numbers of the pandemic: i) reduction due to decrease in mobility (as captured in Google mobility reports); ii) reduction due to mask wearing and mask compliance; iii) reduction due to other NPIs, over and above the ones identified in i) and ii). ConclusionIn most cases mobility reduction coming from nationwide lockdown measures has helped stave off the initial wave in countries who took these types of measures. Beyond the first waves, mask mandates and compliance, together with social-distancing measures (which we refer to as other NPIs) have allowed some control of subsequent disease spread. The methodology we propose here is novel and can be applied to other respiratory diseases such as influenza or RSV.","title":"Human behaviour, NPI and mobility reduction effects on COVID-19 transmission in different countries of the world","annotator_investigating_R0":"0","text_response":"disease name: COVID-19\\r\\nlocation: 12 diverse world regions\\r\\ndate: February and December of 2020.\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: -","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"12 diverse world regions\\",\\r\\n\\"date\\": \\"February and December of 2020.\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"-\\"}}]","json_model_response":"unanswerable","publish_time":"2022"},{"main_cord_uid":"a89zj5mh","cord_uid":"a89zj5mh","abstract":"BACKGROUND: Mathematical modeling of virus dynamics has provided quantitative insights into viral infections such as influenza, the simian immunodeficiency virus/human immunodeficiency virus, hepatitis B, and hepatitis C. Through modeling, we can estimate the half-life of infected cells, the exponential growth rate, and the basic reproduction number (R(0)). To calculate R(0) from virus load data, the death rate of productively infected cells is required. This can be readily estimated from treatment data collected during the chronic phase, but is difficult to determine from acute infection data. Here, we propose two new models that can reliably estimate the average life span of infected cells from acute-phase data, and apply both methods to experimental data from humanized mice infected with HIV-1. METHODS: Both new models, called as the reduced quasi-steady state (RQS) model and the piece-wise regression (PWR) model, are derived by simplification of a standard model for the acute-phase dynamics of target cells, viruses and infected cells. By having only a limited number of parameters, both models allow us to reliably estimate the death rate of productively infected cells. Simulated datasets with plausible parameter values are generated with the standard model to compare the performance of the new models with that of the major previous model (i.e., the simple exponential model). Finally, we fit models to time course data from HIV-1 infected humanized mice to estimate the several important parameters characterizing their acute infection. RESULTS AND CONCLUSIONS: The new models provided much better estimates than the previous model because they more precisely capture the de novo infection process. Both models describe the acute phase of HIV-1 infected humanized mice reasonably well, and we estimated an average death rate of infected cells of 0.61 and 0.61, an average exponential growth rate of 0.69 and 0.76, and an average basic reproduction number of 2.30 and 2.38 in the RQS model and the PWR model, respectively. These estimates are fairly close to those obtained in humans.","title":"Improving the estimation of the death rate of infected cells from time course data during the acute phase of virus infections: application to acute HIV-1 infection in a humanized mouse model","annotator_investigating_R0":"1","text_response":"disease name: HIV-1\\r\\nlocation: -\\r\\ndate: -\\r\\nR0 value: 2.30\\r\\n%CI values: -\\r\\nmethod: Reduced quasi-steady state (RQS) model\\r\\n|\\r\\ndisease name: HIV-1\\r\\nlocation: -\\r\\ndate: -\\r\\nR0 value: 2.38\\r\\n%CI values: -\\r\\nmethod: the piece-wise regression (PWR) model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"HIV-1\\",\\r\\n\\"location\\": \\"-\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"2.30\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Reduced quasi-steady state (RQS) model\\"}},{\\"contribution\\":{\\"disease name\\": \\"HIV-1\\",\\r\\n\\"location\\": \\"-\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"2.38\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"the piece-wise regression (PWR) model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"HIV-1\\", \\"location\\": \\"-\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"2.30\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"reduce quasi-steady state (RQS) model and the piece-wise regression (PWR) model\\" } } ]","publish_time":"2014-05-21 10:00:00","cluster_id":"1234"},{"main_cord_uid":"vc29aif3","cord_uid":"vc29aif3","abstract":"Mass media reports can induce individual behaviour change during a disease outbreak, which has been found to be useful as it reduces the force of infection. We propose a compartmental model by including a new compartment of the intensity of the media reports, which extends existing models by considering a novel media function, which is dependent both on the number of infected individuals and on the intensity of mass media. The existence and stability of the equilibria are analyzed and an optimal control problem of minimizing the total number of cases and total cost is considered, using reduction or enhancement in the media reporting rate as the control. With the help of Pontryagin\xc3\xa2\xe2\u201a\xac\xe2\u201e\xa2s Maximum Principle, we obtain the optimal media reporting intensity. Through parameterization of the model with the 2009 A/H1N1 influenza outbreak data in the 8th Hospital of Xi\xc3\xa2\xe2\u201a\xac\xe2\u201e\xa2an in Shaanxi Province of China, we obtain the basic reproduction number for the formulated model with two particular media functions. The optimal media reporting intensity obtained here indicates that during the early stage of an epidemic we should quickly enhance media reporting intensity, and keep it at a maximum level until it can finally weaken when epidemic cases have decreased significantly. Numerical simulations show that media impact reduces the number of cases during an epidemic, but that the number of cases is further mitigated under the optimal reporting intensity. Sensitivity analysis implies that the outbreak severity is more sensitive to the weight \xc3\u017d\xc2\xb1(1) (weight of media effect sensitive to infected individuals) than weight \xc3\u017d\xc2\xb1(2) (weight of media effect sensitive to media items).","title":"Optimal media reporting intensity on mitigating spread of an emerging infectious disease","annotator_investigating_R0":"0","text_response":"disease name: 2009 A/H1N1 influenza\\r\\nlocation: Shaanxi Province of China\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: compartmental model by including a new compartment of the intensity of the media reports","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"2009 A/H1N1 influenza\\",\\r\\n\\"location\\": \\"Shaanxi Province of China\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"compartmental model by including a new compartment of the intensity of the media reports\\"}}]","json_model_response":"unanswerable","publish_time":"2019-03-21 05:00:00"},{"main_cord_uid":"ddyidt3n","cord_uid":"ddyidt3n","abstract":"Containment strategies to combat epidemics such as SARS-CoV-2/COVID-19 require the availability of epidemiological parameters, e.g., the effective reproduction number. Parametric models such as the commonly used susceptible-infected-removed (SIR) compartment models fitted to observed incidence time series have limitations due to the time-dependency of the parameters. Furthermore, fatalities are delayed with respect to the counts of new cases, and the reproduction cycle leads to periodic patterns in incidence time series. Therefore, based on comprehensible nonparametric methods including time-delay correlation analyses, estimates of crucial parameters that characterise the COVID-19 pandemic with a focus on the German epidemic are presented using publicly available time-series data on prevalence and fatalities. The estimates for Germany are compared with the results for seven other countries (France, Italy, the United States of America, the United Kingdom, Spain, Switzerland, and Brazil). The duration from diagnosis to death resulting from delay-time correlations turns out to be 13 days with high accuracy for Germany and Switzerland. For the other countries, the time-to-death durations have wider confidence intervals. With respect to the German data, the two time series of new cases and fatalities exhibit a strong coherence. Based on the time lag between diagnoses and deaths, properly delayed asymptotic as well as instantaneous fatality\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153case ratios are calculated. The temporal median of the instantaneous fatality\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153case ratio with time lag of 13 days between cases and deaths for Germany turns out to be 0.02. Time courses of asymptotic fatality\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153case ratios are presented for other countries, which substantially differ during the first half of the pandemic but converge to a narrow range with standard deviation 0.0057 and mean 0.024. Similar results are obtained from comparing time courses of instantaneous fatality\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153case ratios with optimal delay for the 8 exemplarily chosen countries. The basic reproduction number, R0, for Germany is estimated to be between 2.4 and 3.4 depending on the generation time, which is estimated based on a delay autocorrelation analysis. Resonances at about 4 days and 7 days are observed, partially attributable to weekly periodicity of sampling. The instantaneous (time-dependent) reproduction number is estimated from the incident (counts of new) cases, thus allowing us to infer the temporal behaviour of the reproduction number during the epidemic course. The time course of the reproduction number turns out to be consistent with the time-dependent per capita growth.","title":"Exploring COVID-19 daily records of diagnosed cases and fatalities based on simple nonparametric methods","annotator_investigating_R0":"1","text_response":"disease name: SARS-CoV-2/COVID-19\\r\\nlocation: Germany\\r\\ndate: -\\r\\nR0 value: 2.4 and 3.4\\r\\n%CI values: -\\r\\nmethod: comprehensible nonparametric methods including time-delay correlation analyses","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"SARS-CoV-2/COVID-19\\",\\r\\n\\"location\\": \\"Germany\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"2.4 and 3.4\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"comprehensible nonparametric methods including time-delay correlation analyses\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Germany\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"between 2.4 and 3.4\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"comprehensible nonparametric methods including time-delay correlation analyses\\" } } ]","publish_time":"2021"},{"main_cord_uid":"ecen7ke8","cord_uid":"ecen7ke8","abstract":"Objective: To understand the epidemiological characteristics of COVID-19 cases in different epidemic stages in Gansu province. Methods: Epidemiological investigation was conducted to collect the information of confirmed COVID-19 cases, including demographic, epidemiological and clinical information. Results: As of 25 February 2020, a total of 91 confirmed COVID-19 cases had been reported in Gansu. The epidemic of COVID-19 in Gansu can be divided as three different stages, i.e. imported case stage, imported-case plus indigenous case stage, and indigenous case stage. A total of 63 cases were clustered cases (69.23%), 3 cases were medical staff infected with non-occupational exposure. The initial symptoms included fever (54.95%, 50/91), cough (52.75%, 48/91), or fatigue (28.57%, 26/91), the proportion of each symptom showed a decreasing trend along with the three epidemic stages, but only the differences in proportions of fever (trend &#967;2=2.20, P<0.05) and fatigue (trend &#967;2=3.18, P<0.05) among the three epidemic stages were statistically significant. The cases with critical severe symptoms accounted for 42.85% (6/14), 23.73% (14/59) and 16.67% (3/18), respectively, in three epidemic stages, showed a decreasing trend (H=6.45, P<0.05). Also, the incubation period prolonged along with the epidemic stage (F=51.65, P<0.01), but the intervals between disease onset and hospital visit (F=5.32, P<0.01), disease onset and diagnosis (F=5.25, P<0.01) became shorter along with the epidemic stage. Additionally, the basic reproduction number (R0) had decreased from 2.61 in imported case stage to 0.66 in indigenous case stage. Conclusions: The COVID-19 epidemic in Gansu was caused by the imported cases, and about 2/3 cases were clustered ones. No medical worker was observed to be infected by occupational exposure. With the progression of COVID-19 epidemic in Gansu, the change in initial symptom and incubation period suggests, the early screening cannot only depend on body temperature monitoring.","title":"[Epidemiological characteristics of COVID-19 in Gansu province]","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Gansu province\\r\\ndate: As of 25 February 2020\\r\\nR0 value: decreased from 2.61 in imported case stage to 0.66 in indigenous case stage\\r\\n%CI values: -\\r\\nmethod: Epidemiological investigation","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Gansu province\\",\\r\\n\\"date\\": \\"As of 25 February 2020\\",\\r\\n\\"R0 value\\": \\"decreased from 2.61 in imported case stage to 0.66 in indigenous case stage\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Epidemiological investigation\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Gansu\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"2.61 in imported case stage to 0.66 in indigenous case stage\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Epidemiological investigation\\" } } ]","publish_time":"2020"},{"main_cord_uid":"crhs4ygw","cord_uid":"crhs4ygw","abstract":"BACKGROUND SARS-CoV-2 RNA quantities, measured by reverse transcription quantitative PCR (RT-qPCR), have been proposed to stratify clinical risk or determine analytical performance targets. We investigated reproducibility and how setting diagnostic cut-offs altered the clinical sensitivity of COVID-19 testing. METHODS Quantitative SARS-CoV-2 RNA distributions (Cq and copies/mL) from more than 6000 patients from three clinical laboratories in UK, Belgium and the Republic of Korea were analyzed. Impact of Cq cut-offs on clinical sensitivity was assessed. The June/July 2020 INSTAND EQA scheme SARS-CoV-2 materials were used to estimate laboratory reported copies/mL and to estimate the variation in copies/mL for a given Cq. RESULTS When the WHO suggested Cq cut-off of 25 was applied, the clinical sensitivity dropped to as little as about 16%. Clinical sensitivity also dropped to as little as about 27% when a simulated LOD of 106 copies/mL was applied. The inter-laboratory variation for a given Cq value was >1000 fold in copies/mL (99% CI). CONCLUSION While RT-qPCR has been instrumental in the response to COVID-19, we recommend Cq (Ct or Cp) values not be used to set clinical cut-offs, or diagnostic performance targets, due to poor inter-laboratory reproducibility; calibrated copy-based units (used elsewhere in virology) offer more reproducible alternatives. We also report a phenomenon where diagnostic performance may change relative to the effective reproduction number (R). Our findings indicate that the disparities between patient populations across time are an important consideration when evaluating or deploying diagnostic tests. This is especially relevant to the emergency situation of an evolving pandemic.","title":"The dangers of using Cq to quantify nucleic acid in biological samples; a lesson from COVID-19.","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-10-11 10:00:00"},{"main_cord_uid":"c4a7h4ab","cord_uid":"c4a7h4ab","abstract":"OBJECTIVE: While interest in elective robotic surgery is growing, use in emergency setting remains limited due to challenges posed by sicker patients, advanced pathology and logistical issues. During the COVID-19 pandemic, robotic surgery could provide the benefit of having the surgeon away from the bedside and reducing the number of directly exposed medical staff. The objective of this study was to report patient outcomes and initial learning experience of emergency robotic colorectal surgery during the COVID-19 pandemic. METHODS: A case series study was conducted, including patients undergoing emergency robotic colorectal surgery between February 2020 and February 2021 at Queen Alexandra Hospital in Portsmouth, UK. Patient data were collected from an ethics approved prospective database. Patient demographics, operative time, conversions and postoperative complications were recorded. In addition, readmissions, length of stay and short-term oncological outcomes were analyzed. RESULTS: Ten patients with median age 64 y (range, 36 \xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153 83 y) were included. Four patients had robotic complete mesocolic resection for obstructing cancers. Six had colorectal resections for benign disease in emergency setting. All were R0 with a mean lymph node harvest of 54 \xc3\u201a\xc2\xb113. Mean operative time was 249 \xc3\u201a\xc2\xb1 117 min, the median length of stay was 9.4 d (range, 5\xc3\xa2\xe2\u201a\xac\xe2\u20ac\x9d22 d). Only one patient was given a temporary diverting ileostomy. There were no grade III/V complications and no 30-day mortality. CONCLUSIONS: Provided an experienced team and peri-operative planning, emergency robotic colorectal surgery can achieve favorable outcomes with benefits of radical lymph node dissection in oncological cases and avoidance of diverting stoma.","title":"Emergency robotic colorectal surgery during COVID-19 pandemic: A retrospective case series study","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2022-03-22 05:00:00"},{"main_cord_uid":"prifbaqy","cord_uid":"prifbaqy","abstract":"The control of Covid 19 epidemics by public health policy in Italy during the first and the second epidemic waves has been driven by using reproductive number Rt(t) to identify the supercritical (percolative), the subcritical (arrested), separated by the critical regime. Here we show that to quantify the Covid-19 spreading rate with containment measures (CSRwCM) there is a need of a 3D expanded parameter space phase diagram built by the combination of Rt(t) and doubling time Td(t). In this space we identify the dynamics of the Covid-19 dynamics Italy and its administrative Regions. The supercritical regime is mathematically characterized by i) the power law of Td vs. [Rt(t)-1] and ii) the exponential behaviour of Td vs. time, either in the first and in the second wave. The novel 3D phase diagram shows clearly metastable states appearing before and after the second wave critical regime. for loosening quarantine and tracing of actives cases. The metastable states are precursors of the abrupt onset of a next nascent wave supercritical regime. This dynamic description allows epidemics predictions needed by policymakers to activate non-pharmaceutical interventions (NPIs), a key issue for avoiding economical losses, reduce fatalities and avoid new virus variant during vaccination campaign","title":"Metastable states in plateaus and multi-wave epidemic dynamics of Covid-19 spreading in Italy","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"4oyejow9","cord_uid":"4oyejow9","abstract":"How to avoid a second wave of COVID-19 after reopening the economy is a pressing question. The extremely high basic reproductive number $R_0$ (5.7 to 6.4, shown in new studies) of SARS-CoV-2 further complicates the challenge. Here we assess effects of Social distancing 2.0, i.e. proximity alert (to maintain inter-personal distance) plus privacy-preserving contact tracing. To solve the dual task, we developed an open source mobile app. The app uses a Bluetooth-based, decentralized contact tracing platform over which the anonymous user ID cannot be linked by the government or a third party. Modelling results show that a 50\\\\% adoption rate of Social distancing 2.0, with privacy-preserving contact tracing, would suffice to decrease the $R_0$ to less than 1 and prevent the resurgence of COVID-19 epidemic.","title":"Social Distancing 2.0 with Privacy-Preserving Contact Tracing to Avoid a Second Wave of COVID-19","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"f0ohxkjm","cord_uid":"f0ohxkjm","abstract":"The first case of Corona Virus Disease 2019 (COVID-19) was reported in Wuhan, China in December 2019. Since then, COVID-19 has quickly spread out to all provinces in China and over 150 countries or territories in the world. With the first level response to public health emergencies (FLRPHE) launched over the country, the outbreak of COVID-19 in China is achieving under control in China. We develop a mathematical model based on epidemiology of COVID-19, incorporating the isolation of healthy people, confirmed cases and close contacts. We calculate the basic reproduction numbers 2.5 in China (excluding Hubei province) and 2.9 in Hubei province with the initial time on January 30 which show the severe infectivity of COVID-19, and verify that the current isolation method effectively contains the transmission of COVID-19. Under the isolation of healthy people, confirmed cases and close contacts, we find a noteworthy phenomenon that is the potential second epidemic of COVID-19, and estimate the peak time and value and the cumulative number of cases. Simulations show that the isolation of close contacts tracked measure can efficiently contain the transmission of the potential second epidemic of COVID-19. With isolation of all susceptible people or all infected people or both, there is no potential second epidemic of COVID-19. Furthermore, resumption of work and study can increase the transmission risk of the potential second epidemic of COVID-19.","title":"The Impact of Isolation on the Transmission of COVID-19 and Estimation of Potential Second Epidemic in China","annotator_investigating_R0":"1","text_response":"disease name: Corona Virus Disease 2019 (COVID-19)\\r\\nlocation: China (excluding Hubei province)\\r\\ndate: January 30\\r\\nR0 value: 2.5\\r\\n%CI values: -\\r\\nmethod: mathematical model based on epidemiology of COVID-19, incorporating the isolation of healthy people, confirmed cases and close contacts\\r\\n|\\r\\ndisease name: Corona Virus Disease 2019 (COVID-19)\\r\\nlocation: Hubei province\\r\\ndate: January 30\\r\\nR0 value: 2.9\\r\\n%CI values: -\\r\\nmethod: mathematical model based on epidemiology of COVID-19, incorporating the isolation of healthy people, confirmed cases and close contacts","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Corona Virus Disease 2019 (COVID-19)\\",\\r\\n\\"location\\": \\"China (excluding Hubei province)\\",\\r\\n\\"date\\": \\"January 30\\",\\r\\n\\"R0 value\\": \\"2.5\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"mathematical model based on epidemiology of COVID-19, incorporating the isolation of healthy people, confirmed cases and close contacts\\"}},{\\"contribution\\":{\\"disease name\\": \\"Corona Virus Disease 2019 (COVID-19)\\",\\r\\n\\"location\\": \\"Hubei province\\",\\r\\n\\"date\\": \\"January 30\\",\\r\\n\\"R0 value\\": \\"2.9\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"mathematical model based on epidemiology of COVID-19, incorporating the isolation of healthy people, confirmed cases and close contacts\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"China (excluding Hubei province)\\", \\"date\\": \\"January 30\\", \\"R0 value\\": \\"2.5\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"mathematical model based on epidemiology of COVID-19\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Hubei province\\", \\"date\\": \\"January 30\\", \\"R0 value\\": \\"2.9\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"mathematical model based on epidemiology of COVID-19\\" } } ]","publish_time":"2020","cluster_id":"1551"},{"main_cord_uid":"mw8uliak","cord_uid":"mw8uliak","abstract":"In this work, we extend existing models of vector-borne diseases by including density-dependent rates and some existing control mechanisms to decrease the disease burden in the human population. We begin by analyzing the vector model dynamics and by determining the offspring reproductive number denoted by N as well as the trivial and nontrivial equilibria. Using theory of cooperative systems and the general theory of Lyapunov, we prove that, although there is a possibility that the trivial equilibrium coexists with a positive equilibrium, it remains globally asymptotically stable whenever N\xe2\u2030\xa41. The fact that the non-trivial equilibrium is globally asymptotically stable permits us to reduce the study of the full model to the study of a reduced model whenever N&gt;1. Thus, we analyze the reduced model by computing the basic reproduction number R0, equilibrium points as well as asymptotic stability of each equilibrium point. We also explore the nature of the bifurcation for the disease-free equilibrium from R0=1. By the application of the centre manifold theory, we prove that the backward bifurcation phenomenon can occur in our model, which means that the necessary condition R0&lt;1 is not sufficient to guarantee the final extinction of the disease in human populations. To calibrate our model, we estimate model parameters on clinical data from the last Chikungunya epidemic which occurred in Chad, using the non-linear least-square method. We find out that R0=1.8519, which means that we are in an endemic state since R0&gt;1. To determine model parameters that are responsible for disease spread in the human community, we perform sensitivity analysis (SA) using a global method. It follows that the density-dependent death rate of mosquitoes and the average number of mosquito bites are key parameters in the disease dynamics. Following this, we thus formulate an optimal control model by including in the autonomous model, four time-dependent control functions to fight the disease spread. Pontryagin\xe2\u20ac\u2122s maximum principle is used to characterize our optimal controls. Numerical simulations, using parameter values of Chikungunya transmission dynamics, and efficiency analysis, are conducted to determine the better control strategy which guaranteed the final extinction of the disease in human populations.","title":"Mathematical modeling and projections of a vector-borne disease with optimal control strategies: A case study of the Chikungunya in Chad","annotator_investigating_R0":"1","text_response":"disease name: Chikungunya\\r\\nlocation: Chad\\r\\ndate: -\\r\\nR0 value: 1.8519\\r\\n%CI values: -\\r\\nmethod: non-linear least-square method","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Chikungunya\\",\\r\\n\\"location\\": \\"Chad\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"1.8519\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"non-linear least-square method\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"Chinkungunya\\", \\"location\\": \\"Chad\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"1.8511\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Non-linear least-square method\\" } } ]","publish_time":"2021"},{"main_cord_uid":"58qmh46w","cord_uid":"58qmh46w","abstract":"Objective: To analyze of the transmission characteristics of a cluster of COVID-19 cases in Chongqing and evaluate the infectivity of COVID-19 in the incubation period. Methods: A retrospective survey was conducted by using unified questionnaire through field and telephone interviews among 129 close contacts of COVID-19 cases. The relationship of transmission was indicated by transmission chain, and the infectivity was analyzed by the contact history. Results: This cluster of COVID-19 cases occurred after a classmate party involving members in three families and work fellows in a factory (R(0)=3.8). The infection rate during the incubation period was 17.57%. On average, it was infectious three days before onset. There was significant difference in infection rate among different contact modes (\xc3\x8f\xe2\u20ac\xa1(2)=15.10, P<0.01),There was significant difference in infection rate among single exposureswith different time length ( \xc3\x8f\xe2\u20ac\xa1(2)=25.08, P<0.01). Conclusions: COVID-19 is highly infectious in the incubation period. The more confined the space is, the higher the risk is,and the longer the single exposure is, the higher the risk of transmission is. Indirect contact transmission still exists.","title":"[Investigation of transmission chain of a cluster COVID-19 cases].","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Chongqing\\r\\ndate: -\\r\\nR0 value: 3.8\\r\\n%CI values: -\\r\\nmethod: Field and telephone interviews","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Chongqing\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"3.8\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Field and telephone interviews\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Chongqing\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"3.8\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"retrospective survey\\" } } ]","publish_time":"2020-05-13 00:00:00"},{"main_cord_uid":"rslc829m","cord_uid":"rslc829m","abstract":"Background Some aspects of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) transmission in children and adults remain unclear. This report describes different SARS-CoV-2 transmission patterns by age group in Japan. Methods and findings This retrospective observational case series study analyzed transmission patterns of real-time polymerase chain reaction (RT-PCR)-confirmed SARS-CoV-2 infections found by local health authorities and commercial laboratories during January 14 through July 31, 2020 in Japan. After ascertaining the infection source for every symptomatic case as clusters at households, daycare facilities, schools, hospitals and workplaces etc., their associated transmission patterns were analyzed. Identified cases were divided into three groups: underage, < 20; adults, 20- 59; and elderly people 60 years old and older. The reproductive number (R)s of respective transmission directions found for the respective age groups were compared. Of 26,986 total cases, 23,746 unknown cases were found, leaving 3,240 ascertained sources of infection (12.0%) comprising 125 (3.9%) underage, 2350 (72.5%) adult, and 765 (23.6%) elderly people. The respective Rs of underage infection sources directed to underage, adult, and elderly people were estimated respectively as 0.0415 (95% CI, 0.0138- 0.0691), 1.11 (95% CI, 0.9171-1.3226), and 0.2811 (95% CI, 0.2074-0.3687). The respective Rs of adult infection source directed to underage, adult, and elderly people were estimated respectively as 0.0140 (95% CI, 0.0120-0.0162), 0.5392 (95% CI, 0.5236-0.5550), and 0.1135 (95% CI, 0.1074-0.1197). The respective Rs of elderly infection source directed to underage, adult, and elderly people were estimated as 0.065 (95% CI, 0.0039-0.0091), 0.3264 (95% CI, 0.3059-0.3474), and 0.3991 (95% CI, 0.3757-0.4229). Conclusions The main sources of SARS-CoV-2 infection were adults and elderly people. The R of underage people directed to adults was greater than 1 because of close familial contact but they were unlikely to become carriers transmitting SARS-CoV-2 because they accounted for a minority for transmissions. Apparently, SARS-CoV-2 was transmitted among adults and elderly people, suggesting that infection control of SARS-CoV-2 should be managed specifically by generation.","title":"SARS-CoV-2 infection control implementation based on sources of infection showing directions for three age groups in Japan","annotator_investigating_R0":"1","text_response":"disease name: SARS-CoV-2\\r\\nlocation: Japan\\r\\ndate: during January 14 through July 31, 2020\\r\\nR0 value: underage infection sources directed to underage, adult, and elderly people were estimated respectively as 0.0415 (95% CI, 0.0138- 0.0691), 1.11 (95% CI, 0.9171-1.3226), and 0.2811 (95% CI, 0.2074-0.3687)\\r\\n%CI values: -\\r\\nmethod: -\\r\\n|\\r\\ndisease name: SARS-CoV-2\\r\\nlocation: Japan\\r\\ndate: during January 14 through July 31, 2020\\r\\nR0 value: adult infection source directed to underage, adult, and elderly people were estimated respectively as 0.0140 (95% CI, 0.0120-0.0162), 0.5392 (95% CI, 0.5236-0.5550), and 0.1135 (95% CI, 0.1074-0.1197)\\r\\n%CI values: -\\r\\nmethod: -\\r\\n|\\r\\ndisease name: SARS-CoV-2\\r\\nlocation: Japan\\r\\ndate: during January 14 through July 31, 2020\\r\\nR0 value: elderly infection source directed to underage, adult, and elderly people were estimated as 0.065 (95% CI, 0.0039-0.0091), 0.3264 (95% CI, 0.3059-0.3474), and 0.3991 (95% CI, 0.3757-0.4229)\\r\\n%CI values: -\\r\\nmethod: -","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"SARS-CoV-2\\",\\r\\n\\"location\\": \\"Japan\\",\\r\\n\\"date\\": \\"during January 14 through July 31, 2020\\",\\r\\n\\"R0 value\\": \\"underage infection sources directed to underage, adult, and elderly people were estimated respectively as 0.0415 (95% CI, 0.0138- 0.0691), 1.11 (95% CI, 0.9171-1.3226), and 0.2811 (95% CI, 0.2074-0.3687)\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"-\\"}},{\\"contribution\\":{\\"disease name\\": \\"SARS-CoV-2\\",\\r\\n\\"location\\": \\"Japan\\",\\r\\n\\"date\\": \\"during January 14 through July 31, 2020\\",\\r\\n\\"R0 value\\": \\"adult infection source directed to underage, adult, and elderly people were estimated respectively as 0.0140 (95% CI, 0.0120-0.0162), 0.5392 (95% CI, 0.5236-0.5550), and 0.1135 (95% CI, 0.1074-0.1197)\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"-\\"}},{\\"contribution\\":{\\"disease name\\": \\"SARS-CoV-2\\",\\r\\n\\"location\\": \\"Japan\\",\\r\\n\\"date\\": \\"during January 14 through July 31, 2020\\",\\r\\n\\"R0 value\\": \\"elderly infection source directed to underage, adult, and elderly people were estimated as 0.065 (95% CI, 0.0039-0.0091), 0.3264 (95% CI, 0.3059-0.3474), and 0.3991 (95% CI, 0.3757-0.4229)\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"-\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"SARS-CoV-2\\", \\"location\\": \\"Japan\\", \\"date\\": \\"January 14 through July 31, 2020\\", \\"R0 value\\": \\"0.4415\\", \\"%CI values\\": \\"(95% CI, 0.0138- 0.0691)\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"SARS-CoV-2\\", \\"location\\": \\"Japan\\", \\"date\\": \\"January 14 through July 31, 2020\\", \\"R0 value\\": \\"1.11\\", \\"%CI values\\": \\"(95% CI, 0.9171-1.326)\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"SARS-CoV-2\\", \\"location\\": \\"Japan\\", \\"date\\": \\"January 14 through July 31, 2020\\", \\"R0 value\\": \\"0.492\\", \\"%CI values\\": \\"(95% CI, 0.5236-0.5550)\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"SARS-CoV-2\\", \\"location\\": \\"Japan\\", \\"date\\": \\"January 14 through July 31, 2020\\", \\"R0 value\\": \\"0.3264\\", \\"%CI values\\": \\"(95% CI, 0.3059-0.3474)\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"SARS-CoV-2\\", \\"location\\": \\"Japan\\", \\"date\\": \\"January 14 through July 31, 2020\\", \\"R0 value\\": \\"0.4391\\", \\"%CI values\\": \\"(95% CI, 0.3757-0.4229)\\", \\"method\\": \\"-\\" } } ]","publish_time":"2021-01-15 00:00:00","cluster_id":"1500"},{"main_cord_uid":"5deyoiq8","cord_uid":"5deyoiq8","abstract":"Finding medications or vaccines that may decrease the infectious period of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) could potentially reduce transmission in the broader population. We developed a computational model of the U.S. simulating the spread of SARS-CoV-2 and the potential clinical and economic impact of reducing the infectious period duration. Simulation experiments found that reducing the average infectious period duration could avert a median of 442,852 [treating 25% of symptomatic cases, reducing by 0.5 days, reproductive number (R(0)) 3.5, and starting treatment when 15% of the population has been exposed] to 44.4 million SARS-CoV-2 cases (treating 75% of all infected cases, reducing by 3.5 days, R(0) 2.0). With R(0) 2.5, reducing the average infectious period duration by 0.5 days for 25% of symptomatic cases averted 1.4 million cases and 99,398 hospitalizations; increasing to 75% of symptomatic cases averted 2.8 million cases. At $500/person, treating 25% of symptomatic cases saved $209.5 billion (societal perspective). Further reducing the average infectious period duration by 3.5 days averted 7.4 million cases (treating 25% of symptomatic cases). Expanding treatment to 75% of all infected cases, including asymptomatic infections (R(0) 2.5), averted 35.9 million cases and 4 million hospitalizations, saving $48.8 billion (societal perspective and starting treatment after 5% of the population has been exposed). Our study quantifies the potential effects of reducing the SARS-CoV-2 infectious period duration.","title":"The value of decreasing the duration of the infectious period of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection","annotator_investigating_R0":"1","text_response":"disease name: severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)\\r\\nlocation: U.S.\\r\\ndate: -\\r\\nR0 value: 2.5\\r\\n%CI values: -\\r\\nmethod: computational model of the U.S. simulating the spread of SARS-CoV-2 and the potential clinical and economic impact of reducing the infectious period duration","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)\\",\\r\\n\\"location\\": \\"U.S.\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"2.5\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"computational model of the U.S. simulating the spread of SARS-CoV-2 and the potential clinical and economic impact of reducing the infectious period duration\\"}}]","json_model_response":"unanswerable","publish_time":"2021-01-07 00:00:00"},{"main_cord_uid":"qz06ccmt","cord_uid":"qz06ccmt","abstract":"Background: The transmissibility of SARS-CoV-2 determines both the ability of the virus to invade a population and the strength of intervention that would be required to contain or eliminate the spread of infection. The basic reproduction number, R0, provides a quantitative measure of the transmission potential of a pathogen. Objective: Conduct a scoping review of the available literature providing estimates of R0 for SARS-CoV-2, provide an overview of the drivers of variation in R0 estimates and the considerations taken in the calculation of the parameter. Design: Scoping review of available literature between the 01 December 2019 and 07 May 2020. Data sources: Both peer-reviewed and pre-print articles were searched for on PubMed, Google Scholar, MedRxiv and BioRxiv. Selection criteria: Studies were selected for review if (i) the estimation of R0 represented either the initial stages of the outbreak or the initial stages of the outbreak prior to the onset of widespread population restriction (lockdown), (ii) the exact dates of the study period were provided and (iii) the study provided primary estimates of R0. Results: A total of 20 R0 estimates were extracted from 15 studies. There was substantial variation in the estimates reported. Estimates derived from mathematical models fell within a wider range of 1.94-6.94 than statistical models which fell between the range of 2.2 to 4.4. Several studies made assumptions about the length of the infectious period which ranged from 5.8-20 days and the serial interval which ranged from 4.41-14 days. For a given set of parameters a longer duration of infectiousness or a longer serial interval equates to a higher R0. Several studies took measures to minimise bias in early case reporting, to account for the potential occurrence of super-spreading events, and to account for early sub-exponential epidemic growth. Conclusions: The variation in reported estimates of R0 reflects the complex nature of the parameter itself, including the context (i.e. social/spatial structure), the methodology used to estimate the parameter, and model assumptions. R0 is a fundamental parameter in the study of infectious disease dynamics however it provides limited practical applicability outside of the context in which it was estimated, and should be calculated and interpreted with this in mind.","title":"The basic reproduction number of SARS-CoV-2: a scoping review of available evidence","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-07-30 10:00:00"},{"main_cord_uid":"u5o6fq24","cord_uid":"u5o6fq24","abstract":"Emerging and re-emerging infections such as SARS (2003) and pandemic H1N1 (2009) have caused concern for public health researchers and policy makers due to the increased burden of these diseases on health care systems. This concern has prompted the use of mathematical models to evaluate strategies to control disease spread, making these models invaluable tools to identify optimal intervention strategies. A particularly important quantity in infectious disease epidemiology is the basic reproduction number, R(0.) Estimation of this quantity is crucial for effective control responses in the early phase of an epidemic. In our previous study, an approach for estimating the basic reproduction number in real time was developed. This approach uses case notification data and the structure of potential transmission contacts to accurately estimate R(0) from the limited amount of information available at the early stage of an outbreak. Based on this approach, we extend the existing methodology; the most recent method features intra- and inter-age groups contact heterogeneity. Given the number of newly reported cases at the early stage of the outbreak, with parsimony assumptions on removal distribution and infectivity profile of the diseases, experiments to estimate real time R(0) under different levels of intra- and inter-group contact heterogeneity using two age groups are presented. We show that the new method converges more quickly to the actual value of R(0) than the previous one, in particular when there is high-level intra-group and inter-group contact heterogeneity. With the age specific contact patterns, number of newly reported cases, removal distribution, and information about the natural history of the 2009 pandemic influenza in Hong Kong, we also use the extended model to estimate R(0) and age-specific R(0).","title":"Early real-time estimation of the basic reproduction number of emerging or reemerging infectious diseases in a community with heterogeneous contact pattern: Using data from Hong Kong 2009 H1N1 Pandemic Influenza as an illustrative example","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2015-09-15 00:00:00"},{"main_cord_uid":"pytbdsq1","cord_uid":"pytbdsq1","abstract":"Background: The spread of the novel coronavirus seems mysterious enough to make us double-check the indices being used to predict its transmission. In this study, serological analysis was performed to assess some metric and epidemiological aspects of the infection and its transmissibility among people in contact with SARA-CoV-2 patients. Material and Methods: A total of 453 contacts of 40 COVID-19 patients entered this contact tracing prospective cohort study. Accordingly, SARS-CoV-2 patients were diagnosed by the real-time polymerase chain reaction testing of nasopharyngeal samples. The infectiousness history was detected by the serological testing of IgG and IgM. Trained expert team completed two questionnaires, and blood samples were taken by experts in a laboratory. Data were analyzed using SPSS V21.0 and R software. Results: The mean ages of the SARS-CoV-2 patients and the contacts were 53.0?\xb118.2 and 30.8?\xb119.3 years, respectively. The overall R0 of the infection was 2.58. Household and non-household secondary attack rates (SAR) were 20% (95%CI;12.7\xe2\u20ac\u201c27.3) and 11.3% (95%CI;6.1-16.5), respectively. The transmission probability of each contact was 0.0205, and the serial interval was 6.4?\xb14.6 (95% CI;5.2\xe2\u20ac\u201c7.6) days. The SAR was higher among the contacts who were exposed to asymptomatic primary cases (28%, 95%CI;10-46%) than (13.8%, 95%CI;9.4-18.2) among those exposed to symptomatic patients. Conclusions: It is concluded that the herd immunity of 60 to 65% is needed in human communities, based on the amount of R0 estimated in our survey. The findings demonstrated the amount of the reduction in infection R0, which is predicted based on both clinical and public health interventions. ?\xa9 The Author(s) 2021;All rights reserved.","title":"A contact tracing prospective cohort retrieving epidemiological facts on sars-cov-2 transmission aspects: A serological analysis in an iranian community","annotator_investigating_R0":"1","text_response":"disease name: novel coronavirus\\r\\nlocation: iranian community\\r\\ndate: -\\r\\nR0 value: 2.58\\r\\n%CI values: -\\r\\nmethod: SPSS V21.0 and R software","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"novel coronavirus\\",\\r\\n\\"location\\": \\"iranian community\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"2.58\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SPSS V21.0 and R software\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"SARS-CoV-2\\", \\"location\\": \\"Iran\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"2.58\\", \\"%CI values\\": \\"(95%CI;12.7-27.3)\\", \\"method\\": \\"SARS-CoV-2\\" } } ]","publish_time":"2021"},{"main_cord_uid":"tat7wuvc","cord_uid":"tat7wuvc","abstract":"COVTD-19 is an infectious disease which is spreading as a global pandemy to the whole world. This paper exlplores nonlinear compartemental dynamic models which is used to model the spread of Covid-19. The Susceptible-Infected-Removed (SIR) model is one of the compartmental dynamic models which can be used to simulate what happens when someone in the community catches a disease, like Covid-19. The classical SIR model assumes that the properties of individuals can be divided into three distinct compartments: S(t) is the total of susceptible persons, I(t) is the total of infected persons and R(t) is the total of recovered person from infection and are now immune against the disease. The model also includes the dedicated effort of the government, the decision makers, and the stakeholders. Theoretically, interventions such as social distancing, mass testing, and isolation of positive cases should slow the rate of the infection spreads. The analysis of equilibrium indicates that the model has two equilibriums. One of them isthe disease free equilibrium and the other one is the endemic equilibrium. If the effort level less than minimum level, than the spread of the virus becomes endemic and if the effort level more than minimum level, than the spread of the virus can be controlled. The basic reproduction number 91D, is used to be an indicator of the expected number of individuals directly infected by an infectious person in a population where all individuals are susceptible to infection. If 910 &lt; 1, then the disease free equilibrium point is stable, meaning that the virus spread can be controlled. If 9t0 &gt; 1, then the disease free equilibrium point is unstable, meaning that the virus spread will continue. By constructing suitable Lyapunov function for SIR covid-19 model, the stability of the disease free equilibrium state of the model is thereby established.","title":"Lyapunov Stability Analysis of Covid 19 SIR Modeling","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"zefl5ul8","cord_uid":"1sc17vgr","abstract":"Although many persons in the United States have acquired immunity to COVID-19, either through vaccination or infection with SARS-CoV-2, COVID-19 will pose an ongoing threat to non-immune persons so long as disease transmission continues. We can estimate when sustained disease transmission will end in a population by calculating the population-specific basic reproduction number [R]0, the expected number of secondary cases generated by an infected person in the absence of any interventions. The value of [R]0 relates to a herd immunity threshold (HIT), which is given by 1 - 1/[R]0. When the immune fraction of a population exceeds this threshold, sustained disease transmission becomes exponentially unlikely (barring mutations allowing SARS-CoV-2 to escape immunity). Here, we report state-level [R]0 estimates obtained using Bayesian inference. Maximum a posteriori estimates range from 7.1 for New Jersey to 2.3 for Wyoming, indicating that disease transmission varies considerably across states and that reaching herd immunity will be more difficult in some states than others. [R]0 estimates were obtained from compartmental models via the next-generation matrix approach after each model was parameterized using regional daily confirmed case reports of COVID-19 from 21-January-2020 to 21-June-2020. Our [R]0 estimates characterize infectiousness of ancestral strains, but they can be used to determine HITs for a distinct, currently dominant circulating strain, such as SARS-CoV-2 variant Delta (lineage B.1.617.2), if the relative infectiousness of the strain can be ascertained. On the basis of Delta-adjusted HITs, vaccination data, and seroprevalence survey data, we find that no state has achieved herd immunity as of 20-September-2021. Significance StatementCOVID-19 will continue to threaten non-immune persons in the presence of ongoing disease transmission. We can estimate when sustained disease transmission will end by calculating the population-specific basic reproduction number [R]0, which relates to a herd immunity threshold (HIT), given by 1 - 1/[R]0. When the immune fraction of a population exceeds this threshold, sustained disease transmission becomes exponentially unlikely. Here, we report state-level [R]0 estimates indicating that disease transmission varies considerably across states. Our [R]0 estimates can also be used to determine HITs for the Delta variant of COVID-19. On the basis of Delta-adjusted HITs, vaccination data, and serological survey results, we find that no state has yet achieved herd immunity.","title":"Bayesian Inference of State-Level COVID-19 Basic Reproduction Numbers across the United States","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: New Jersey\\r\\ndate: 21-January-2020 to 21-June-2020\\r\\nR0 value: 7.1\\r\\n%CI values: -\\r\\nmethod: Bayesian inference\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Wyoming\\r\\ndate: 21-January-2020 to 21-June-2020\\r\\nR0 value: 2.3\\r\\n%CI values: -\\r\\nmethod: Bayesian inference","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"New Jersey\\",\\r\\n\\"date\\": \\"21-January-2020 to 21-June-2020\\",\\r\\n\\"R0 value\\": \\"7.1\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Bayesian inference\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Wyoming\\",\\r\\n\\"date\\": \\"21-January-2020 to 21-June-2020\\",\\r\\n\\"R0 value\\": \\"2.3\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Bayesian inference\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"New Jersey\\", \\"date\\": \\"21-January-2020 to 21-June-2020\\", \\"R0 value\\": \\"7.1\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"compartmental models via the next-generation matrix\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Wyoming\\", \\"date\\": \\"21-January-2020 to 21-June-2020\\", \\"R0 value\\": \\"2.3\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"compartmental models via the next-generation matrix\\" } } ]","publish_time":"2021","action":"change_main_cord_id","cluster_id":"187"},{"main_cord_uid":"6xntkvki","cord_uid":"6xntkvki","abstract":"COVID-19 pandemic has rapidly spread worldwide. Spain has suffered one of the largest nationwide bursts, particularly in the highly populated areas of Madrid and Barcelona (two of the five largest conurbations in Europe). We used segmented regression analyses to identify shifts in the evolution of the effective reproduction number (Rt) reported for 16 Spanish administrative regions. We associate these breaking points with a timeline of key containment measures taken by national and regional governments, applying time lags for the time from contagion to case detection, with their associated errors. Results show an early decrease of Rt that preceded the nationwide lockdown; a generalized, sharp decrease in Rt associated with such lockdown; a low impact of the strengthened lockdown, with a flattening of Rt evolution in high-incidence regions, and even increases in Rt at low-incidence regions; and an increase in Rt associated to the relaxation of the lockdown measures in ten regions. These results evidence the importance of generalized lockdown measures to contain COVID-19 spread, and the limited effect of the subsequent application of a stricter lockdown (restrictions to all non-essential economic activities). Most importantly, they highlight the importance of maintaining strong social distancing measures and strengthening public health control during lockdown de-escalation.","title":"COVID-19 effective reproduction number dropped during Spain\'s nationwide dropdown, then spiked at lower-incidence regions","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-09-09 10:00:00"},{"main_cord_uid":"b2f0pn3l","cord_uid":"b2f0pn3l","abstract":"The role of asymptomatic carriers in transmission poses challenges for control of the COVID-19 pandemic. Study of asymptomatic transmission and implications for surveillance and disease burden are ongoing, but there has been little study of the implications of asymptomatic transmission on dynamics of disease. We use a mathematical framework to evaluate expected effects of asymptomatic transmission on the basic reproduction number R0 (i.e., the expected number of secondary cases generated by an average primary case in a fully susceptible population) and the fraction of new secondary cases attributable to asymptomatic individuals. If the generation-interval distribution of asymptomatic transmission differs from that of symptomatic transmission, then estimates of the basic reproduction number which do not explicitly account for asymptomatic cases may be systematically biased. Specifically, if asymptomatic cases have a shorter generation interval than symptomatic cases, R0 will be over-estimated, and if they have a longer generation interval, R0 will be under-estimated. Estimates of the realized proportion of asymptomatic transmission during the exponential phase also depend on asymptomatic generation intervals. Our analysis shows that understanding the temporal course of asymptomatic transmission can be important for assessing the importance of this route of transmission, and for disease dynamics. This provides an additional motivation for investigating both the importance and relative duration of asymptomatic transmission.","title":"The time scale of asymptomatic transmission affects estimates of epidemic potential in the COVID-19 outbreak","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"avjugdkq","cord_uid":"avjugdkq","abstract":"It is of great theoretical and application value to accurately forecast the spreading dynamics of COVID-19 epidemic. We first proposed and established a Bayesian model to predict the epidemic spreading behavior. In this model, the infection probability matrix is estimated according to the individual contact frequency in certain population group. This infection probability matrix is highly correlated with population geographic distribution, population age structure and so on. This model can effectively avoid the prediction malfunction by using the traditional ordinary differential equation methods such as SIR (susceptible, infectious and recovered) model and so on. Meanwhile, it would forecast the epidemic distribution and predict the epidemic hot spots geographically at different time. According to the results revealed by Bayesian model, the effect of population geographical distribution should be considered in the prediction of epidemic situation, and there is no simple derivation relationship between the threshold of group immunity and the virus reproduction numberR0. If we further consider the virus mutation effect and the antibody attenuation effect, with a large global population spatial distribution, it will be difficult for us to eliminate Covid-19 in a short time even with vaccination endeavor. Covid-19 may exist in human society for a long time, and the epidemic caused by re-infection is characterized by a wild-geometric && low- probability distribution with no epidemic hotspots.","title":"A Continuous Bayesian Model for the Stimulation COVID-19 Epidemic Dynamics","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-06-22 10:00:00"},{"main_cord_uid":"squ2ksbg","cord_uid":"squ2ksbg","abstract":"Studies of novel coronavirus disease 2019 (COVID-19), which is caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), have reported varying estimates of epidemiological parameters, including serial interval distributions-i.e., the time between illness onset in successive cases in a transmission chain-and reproduction numbers. By compiling a line-list database of transmission pairs in mainland China, we show that mean serial intervals of COVID-19 shortened substantially from 7.8 to 2.6 days within a month (9 January to 13 February 2020). This change was driven by enhanced nonpharmaceutical interventions, particularly case isolation. We also show that using real-time estimation of serial intervals allowing for variation over time provides more accurate estimates of reproduction numbers than using conventionally fixed serial interval distributions. These findings could improve our ability to assess transmission dynamics, forecast future incidence, and estimate the impact of control measures.","title":"Serial interval of SARS-CoV-2 was shortened over time by nonpharmaceutical interventions","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"o03j064x","cord_uid":"o03j064x","abstract":"An [Formula: see text] epidemiological model with suscptibles dispersal between two patches is addressed and discussed. The basic reproduction numbers [Formula: see text] and [Formula: see text] are defined as the threshold parameters. It shows that if both [Formula: see text] and [Formula: see text] are below unity, the disease-free equilibrium is shown to be globally asymptotically stable by using the comparison principle of the cooperative systems. If [Formula: see text] is above unity and [Formula: see text] is below unity, the disease persists in the first patch provided [Formula: see text]. If [Formula: see text] is above unity, [Formula: see text] is below unity, and [Formula: see text], the disease persists in the second patch. And if [Formula: see text] and [Formula: see text] are above unity, and further [Formula: see text] and [Formula: see text] are satisfied, the unique endemic equilibrium is globally asymptotically stable by constructing the Lyapunov function. Furthermore, it follows that the susceptibles dispersal in the population does not alter the qualitative behavior of the epidemiological model. ELECTRONIC SUPPLEMENTARY MATERIAL: The online version of this article (doi:10.1186/1687-1847-2012-131) contains supplementary material, which is available to authorized users.","title":"Global dynamics for an SIR patchy model with susceptibles dispersal","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2012-08-01 10:00:00"},{"main_cord_uid":"8dwq6bib","cord_uid":"8dwq6bib","abstract":"The aim of this study is the characterization and genomic tracing by phylogenetic analyses of 59 new SARS-CoV-2 Italian isolates obtained from patients attending clinical centres in North and Central Italy until the end of April 2020. All but one of the newly-characterized genomes belonged to the lineage B.1, the most frequently identified in European countries, including Italy. Only a single sequence was found to belong to lineage B. A mean of 6 nucleotide substitutions per viral genome was observed, without significant differences between synonymous and non-synonymous mutations, indicating genetic drift as a major source for virus evolution. tMRCA estimation confirmed the probable origin of the epidemic between the end of January and the beginning of February with a rapid increase in the number of infections between the end of February and mid-March. Since early February, an effective reproduction number (Re) greater than 1 was estimated, which then increased reaching the peak of 2.3 in early March, confirming the circulation of the virus before the first COVID-19 cases were documented. Continuous use of state-of-the-art methods for molecular surveillance is warranted to trace virus circulation and evolution and inform effective prevention and containment of future SARS-CoV-2 outbreaks.","title":"Molecular Tracing of SARS-CoV-2 in Italy in the First Three Months of the Epidemic","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"g0rfkk9b","cord_uid":"g0rfkk9b","abstract":"The COVID-19 pandemic has resulted in more 176 million cases and around 3.82 million deaths worldwide. Different drug interventions acting at multiple stages of the pathogenesis of COVID-19 can substantially reduce infection-induced mortality. The current within-host mathematical modeling studies deals with the optimal combined drug intervention strategy and its efficacy in reducing the burden of COVID-19. The drug interventions considered here include Hydroxychloroquine (HCQ), the first BCG vaccine dose, and a booster dose of BCG administered at a later stage. In this work, we consider two scenarios involving the administration of these interventions. The findings of these studies include the following: the average infected cell count and viral load decreased the most when both the HCQ and BCG interventions were applied together in both scenarios. On the other hand, the average susceptible cell count decreased the best when HCQ alone was administered in both these scenarios. From the comparative effectiveness study it was observed that the basic reproduction number and viral count decreased the best when HCQ and BCG booster interventions were applied together, reinstating the fact obtained earlier in the optimal control setting. These findings may help physicians with decision making in the treatment of life-threatening COVID-19 pneumonia. This study involving different drug interventions is first of its kind. \xc3\u201a\xc2\xa9 Research India Publications.","title":"Combined drug interventions and its efficacy in the reduction of COVID-19 burden: A within-host modeling study with reference to HCQ and BCG vaccination","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"9ymxgwj9","cord_uid":"9ymxgwj9","abstract":"Background Paediatric palliative care services in LMIC countries compete for resources with many other priorities. Their provision is desirable and includes advocacy, training health and community care workers, policy development and mentorship. Objectives The THET J&J start-up grants provided an ideal opportunity to establish a partnership with the Ministry of Health (MoH). The long term aim being to develop children\'s palliative care services in The Gambia. A needs assessment was carried out in early 2020. We hope reporting the results raises awareness of the gaps and possible solutions in LMIC. Methods The study took the form of a cross-sectional design with a focus on estimating the need for CPC and gaps at the country level. A mixed methods approach utilising both quantitative and qualitative data was used. Both primary and secondary data sources were used. The estimation of the need for CPC was based on estimation techniques using the prevalence and mortality of the specific diseases known to require palliative care. The response to the need and existing gaps were analysed using interviews and focus groups with key persons as well as survey data from service providers. Ethical approval for this study was given by the University of the Gambia, School of Medicine. Reference number R020 004 Results Five organisations completed a Capacity Self-Assessment Tool, 17 staff from 5 facilities were interviewed and 2 Focus Group Discussions were conducted (8 staff). The leading cause of death in children was heart disease, then lower respiratory infections and neonatal disorders, with HIV/AIDS being 5th, Tuberculosis 7th and cancer 9th. Under 5 mortality is 47.8 per 1,000 live births. It was not possible to estimate prevalence. Facility capacity assessment to provide CPC ranged from 23%-74%. Themes identified were a need to improve diagnostic ability;a desire for training;improve access and utilisation of medicines;and provide support for families. Training in Palliative care is on the nursing and medical students syllabus. Senior staff were keen for more training. Topics that staff felt anxious about were breaking bad news, anticipating palliative needs and use of medication. Conclusions The establishment of a training and mentoring service for staff in palliative care is required and desired. Paediatric diagnostic facilities need improved including equipment and access to specialist opinions eg an echocardiogram. in the main hospital in Banjul. The use of online Palliative training through lectures and modules, supported by scheduled in person visits is thought to be a good solution particularly in the current Covid-19 situation. 1 online lecture session has already taken place for 30 participants, supported by the MoH. This had good media coverage and promoted CPC awareness within the country. M.Sowe is currently undertaking a Palliative Care Diploma in Uganda partly funded by this grant. The World Bank has recently provided funding for specialist paediatrician secondment to The Gambia to improve paediatric services and a memorandum of understanding for patient pathways has been signed with the much larger neighbouring country of Senegal.","title":"Development of a partnership to improve palliative care services for children in the Gambia","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"qmrxje99","cord_uid":"qmrxje99","abstract":"There was a fury of the pandemic because of novel coronavirus (2019-nCoV/SARS-CoV-2) that happened in Wuhan, Hubei province, in China in December 2019. Since then, many model predictions on the COVID-19 pandemic in Wuhan and other parts of China have been reported. The first incident of coronavirus disease 2019 (COVID-19) in India was reported on 30 January 2020, which was a student from Wuhan. The number of reported cases has started to increase day by day after 30 February 2020. The purpose of this investigation is to provide a prediction of the epidemic peak for COVID-19 in India by utilizing real-time data from 30 February to 14 April 2020. We apply the well-known epidemic compartmental model \\"SEIR\\" to predict the epidemic peak of COVID-19, India. Since we do not have the complete detail of the infective population, using the available infected population data, we identify the R0 by using polynomial regression. By using the third-order polynomial equation, we estimate that the basic reproduction number for the epidemic in India is R0 = 3.3 (95%CI, 3.1 to 3.5), and the epidemic peak could be reached by September 2020.","title":"COVID-19 peak estimation and effect of nationwide lockdown in India","annotator_investigating_R0":"1","text_response":"disease name: coronavirus disease 2019 (COVID-19)\\r\\nlocation: India\\r\\ndate: from 30 February to 14 April 2020\\r\\nR0 value: 3.3\\r\\n%CI values: 95%CI, 3.1 to 3.5\\r\\nmethod: epidemic compartmental model SEIR","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"coronavirus disease 2019 (COVID-19)\\",\\r\\n\\"location\\": \\"India\\",\\r\\n\\"date\\": \\"from 30 February to 14 April 2020\\",\\r\\n\\"R0 value\\": \\"3.3\\",\\r\\n\\"%CI values\\": \\"95%CI, 3.1 to 3.5\\",\\r\\n\\"method\\": \\"epidemic compartmental model SEIR\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease 2019 (COVID-19)\\", \\"location\\": \\"India\\", \\"date\\": \\"30 February to 14 April 2020\\", \\"R0 value\\": \\"3.3\\", \\"%CI values\\": \\"(95%CI, 3.1 to 3.5)\\", \\"method\\": \\"polynomial regression\\" } } ]","publish_time":"2020-05-13 00:00:00"},{"main_cord_uid":"yp9kj5cv","cord_uid":"yp9kj5cv","abstract":"BACKGROUND: Since the coronavirus disease 2019 outbreak began in the Chinese city of Wuhan on Dec 31, 2019, 68 imported cases and 175 locally acquired infections have been reported in Singapore. We aimed to investigate options for early intervention in Singapore should local containment (eg, preventing disease spread through contact tracing efforts) be unsuccessful. METHODS: We adapted an influenza epidemic simulation model to estimate the likelihood of human-to-human transmission of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) in a simulated Singaporean population. Using this model, we estimated the cumulative number of SARS-CoV-2 infections at 80 days, after detection of 100 cases of community transmission, under three infectivity scenarios (basic reproduction number [R0] of 1\xc3\u201a\xc2\xb75, 2\xc3\u201a\xc2\xb70, or 2\xc3\u201a\xc2\xb75) and assuming 7\xc3\u201a\xc2\xb75% of infections are asymptomatic. We first ran the model assuming no intervention was in place (baseline scenario), and then assessed the effect of four intervention scenarios compared with a baseline scenario on the size and progression of the outbreak for each R0 value. These scenarios included isolation measures for infected individuals and quarantining of family members (hereafter referred to as quarantine); quarantine plus school closure; quarantine plus workplace distancing; and quarantine, school closure, and workplace distancing (hereafter referred to as the combined intervention). We also did sensitivity analyses by altering the asymptomatic fraction of infections (22\xc3\u201a\xc2\xb77%, 30\xc3\u201a\xc2\xb70%, 40\xc3\u201a\xc2\xb70%, and 50\xc3\u201a\xc2\xb70%) to compare outbreak sizes under the same control measures. FINDINGS: For the baseline scenario, when R0 was 1\xc3\u201a\xc2\xb75, the median cumulative number of infections at day 80 was 279\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020000 (IQR 245\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020000-320\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020000), corresponding to 7\xc3\u201a\xc2\xb74% (IQR 6\xc3\u201a\xc2\xb75-8\xc3\u201a\xc2\xb75) of the resident population of Singapore. The median number of infections increased with higher infectivity: 727\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020000 cases (670\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020000-776\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020000) when R0 was 2\xc3\u201a\xc2\xb70, corresponding to 19\xc3\u201a\xc2\xb73% (17\xc3\u201a\xc2\xb78-20\xc3\u201a\xc2\xb76) of the Singaporean population, and 1\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020207\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020000 cases (1\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020164\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020000-1\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020249\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020000) when R0 was 2\xc3\u201a\xc2\xb75, corresponding to 32% (30\xc3\u201a\xc2\xb79-33\xc3\u201a\xc2\xb71) of the Singaporean population. Compared with the baseline scenario, the combined intervention was the most effective, reducing the estimated median number of infections by 99\xc3\u201a\xc2\xb73% (IQR 92\xc3\u201a\xc2\xb76-99\xc3\u201a\xc2\xb79) when R0 was 1\xc3\u201a\xc2\xb75, by 93\xc3\u201a\xc2\xb70% (81\xc3\u201a\xc2\xb75-99\xc3\u201a\xc2\xb77) when R0 was 2\xc3\u201a\xc2\xb70, and by 78\xc3\u201a\xc2\xb72% (59\xc3\u201a\xc2\xb70 -94\xc3\u201a\xc2\xb74) when R0 was 2\xc3\u201a\xc2\xb75. Assuming increasing asymptomatic fractions up to 50\xc3\u201a\xc2\xb70%, up to 277 000 infections were estimated to occur at day 80 with the combined intervention relative to 1800 for the baseline at R0 of 1\xc3\u201a\xc2\xb75. INTERPRETATION: Implementing the combined intervention of quarantining infected individuals and their family members, workplace distancing, and school closure once community transmission has been detected could substantially reduce the number of SARS-CoV-2 infections. We therefore recommend immediate deployment of this strategy if local secondary transmission is confirmed within Singapore. However, quarantine and workplace distancing should be prioritised over school closure because at this early stage, symptomatic children have higher withdrawal rates from school than do symptomatic adults from work. At higher asymptomatic proportions, intervention effectiveness might be substantially reduced requiring the need for effective case management and treatments, and preventive measures such as vaccines. FUNDING: Singapore Ministry of Health, Singapore Population Health Improvement Centre.","title":"Interventions to mitigate early spread of SARS-CoV-2 in Singapore: a modelling study","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"aek3t5w6","cord_uid":"aek3t5w6","abstract":"Detection and isolation of infected people are believed to play an important role in the control of the COVID-19 pandemic. Some countries conduct large-scale screenings for testing, whereas others test mainly people with high prior probability of infection such as showing severe symptoms and/or having an epidemiological link with a known or suspected case or cluster of cases. However, what a good testing strategy is and whether the difference in testing strategy shows a meaningful, measurable impact on the COVID-19 epidemic remain unknown. Here, we showed that patterns of association between effective reproduction number (Rt) and test positivity rate can illuminate differences in testing situation among different areas, using global and local data from Japan. This association can also evaluate the adequacy of current testing systems and what information is captured in COVID-19 surveillance. The differences in testing systems alone cannot predict the results of epidemic containment efforts. Furthermore, monitoring test positivity rates and severe case proportions among the nonelderly can predict imminent case count increases. Monitoring test positivity rates in conjunction with the concurrent Rt could be useful to assess and strengthen public health management and testing systems and deepen understanding of COVID-19 epidemic dynamics.","title":"Relationship of Test Positivity Rates with COVID-19 Epidemic Dynamics","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"u5qt9es8","cord_uid":"u5qt9es8","abstract":"OBJECTIVES: The outbreak of Middle Eastern respiratory syndrome coronavirus (MERS-CoV) was one of the major events in South Korea in 2015. In particular, this study pays attention to formulating a mathematical model for MERS transmission dynamics and estimating transmission rates. METHODS: Incidence data of MERS-CoV from the government authority was analyzed for the first aim and a mathematical model was built and analyzed for the second aim of the study. A mathematical model for MERS-CoV transmission dynamics is used to estimate the transmission rates in two periods due to the implementation of intensive interventions. RESULTS: Using the estimates of the transmission rates, the basic reproduction number was estimated in two periods. Due to the superspreader, the basic reproduction number was very large in the first period; however, the basic reproduction number of the second period has reduced significantly after intensive interventions. CONCLUSION: It turned out to be the intensive isolation and quarantine interventions that were the most critical factors that prevented the spread of the MERS outbreak. The results are expected to be useful to devise more efficient intervention strategies in the future.","title":"The Characteristics of Middle Eastern Respiratory Syndrome Coronavirus Transmission Dynamics in South Korea","annotator_investigating_R0":"0","text_response":"disease name: MERS\\r\\nlocation: South Korea\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: mathematical mode","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"MERS\\",\\r\\n\\"location\\": \\"South Korea\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"mathematical mode\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"MERS-CoV\\", \\"location\\": \\"South Korea\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"mathematical model\\" } } ]","publish_time":"2016-01-18 05:00:00"},{"main_cord_uid":"926bl05q","cord_uid":"926bl05q","abstract":"Studies on the early introduction of SARS-CoV-2 in a naive population have important epidemic control implications. We report findings from the epidemiological investigation of the initial 135 COVID-19 cases in Brunei and describe the impact of control measures and travel restrictions. Epidemiological and clinical information was obtained for all confirmed COVID-19 cases, whose symptom onset was from March 9 to April 5, 2020. The basic reproduction number (R0), incubation period, and serial interval (SI) were calculated. Time-varying R was estimated to assess the effectiveness of control measures. Of the 135 cases detected, 53 (39.3%) were imported. The median age was 36 (range = 0.5-72) years. Forty-one (30.4%) and 13 (9.6%) were presymptomatic and asymptomatic cases, respectively. The median incubation period was 5 days (interquartile range [IQR] = 5, range = 1-11), and the mean SI was 5.4 days (SD = 4.5; 95% CI: 4.3, 6.5). The reproduction number was between 3.9 and 6.0, and the doubling time was 1.3 days. The time-varying reproduction number (Rt) was below one (Rt = 0.91; 95% credible interval: 0.62, 1.32) by the 13th day of the epidemic. Epidemic control was achieved through a combination of public health measures, with emphasis on a test-isolate-trace approach supplemented by travel restrictions and moderate physical distancing measures but no actual lockdown. Regular and ongoing testing of high-risk groups to supplement the existing surveillance program and a phased easing of physical distancing measures has helped maintain suppression of the COVID-19 outbreak in Brunei, as evidenced by the identification of only six additional cases from April 5 to August 5, 2020.","title":"Epidemiological Investigation of the First 135 COVID-19 Cases in Brunei: Implications for Surveillance, Control, and Travel Restrictions","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Brunei\\r\\ndate: from March 9 to April 5, 2020\\r\\nR0 value: between 3.9 and 6.0\\r\\n%CI values: -\\r\\nmethod: Time-varying R","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Brunei\\",\\r\\n\\"date\\": \\"from March 9 to April 5, 2020\\",\\r\\n\\"R0 value\\": \\"between 3.9 and 6.0\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Time-varying R\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Brunei\\", \\"date\\": \\"March 9 to April 5, 2020\\", \\"R0 value\\": \\"between 3.9 and 6.0\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Epidemiological and clinical information\\" } } ]","publish_time":"2020"},{"main_cord_uid":"5wn7l61e","cord_uid":"5wn7l61e","abstract":"BACKGROUND: The required efforts, feasibility and predicted success of an intervention strategy against an infectious disease are partially determined by its basic reproduction number, R(0). In its simplest form R(0) can be understood as the product of the infectious period, the number of infectious contacts and the per-contact transmission probability, which in the case of vector-transmitted diseases necessarily extend to the vector stages. As vectors do not usually recover from infection, they remain infectious for life, which places high significance on the vector\xc3\xa2\xe2\u201a\xac\xe2\u201e\xa2s life expectancy. Current methods for estimating the R(0) for a vector-borne disease are mostly derived from compartmental modelling frameworks assuming constant vector mortality rates. We hypothesised that some of the assumptions underlying these models can lead to unrealistic high vector life expectancies with important repercussions for R(0) estimates. METHODOLOGY AND PRINCIPAL FINDINGS: Here we used a stochastic, individual-based model which allowed us to directly measure the number of secondary infections arising from one index case under different assumptions about vector mortality. Our results confirm that formulas based on age-independent mortality rates can overestimate R(0) by nearly 100% compared to our own estimate derived from first principles. We further provide a correction factor that can be used with a standard R(0) formula and adjusts for the discrepancies due to erroneous vector age distributions. CONCLUSION: Vector mortality rates play a crucial role for the success and general epidemiology of vector-transmitted diseases. Many modelling efforts intrinsically assume these to be age-independent, which, as clearly demonstrated here, can lead to severe over-estimation of the disease\xc3\xa2\xe2\u201a\xac\xe2\u201e\xa2s reproduction number. Our results thus re-emphasise the importance of obtaining field-relevant and species-dependent vector mortality rates, which in turn would facilitate more realistic intervention impact predictions.","title":"Robustness of the reproductive number estimates in vector-borne disease systems","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2018-12-17 00:00:00"},{"main_cord_uid":"bu43gmpc","cord_uid":"bu43gmpc","abstract":"BACKGROUND: The role of demographic factors, climatic conditions, school cycles, and connectivity patterns in shaping the spatio-temporal dynamics of pandemic influenza is not clearly understood. Here we analyzed the spatial, age and temporal evolution of the 2009 A/H1N1 influenza pandemic in Chile, a southern hemisphere country covering a long and narrow strip comprising latitudes 17\xc3\u201a\xc2\xb0S to 56\xc3\u201a\xc2\xb0S. METHODS: We analyzed the dissemination patterns of the 2009 A/H1N1 pandemic across 15 regions of Chile based on daily hospitalizations for severe acute respiratory disease and laboratory confirmed A/H1N1 influenza infection from 01-May to 31-December, 2009. We explored the association between timing of pandemic onset and peak pandemic activity and several geographical and demographic indicators, school vacations, climatic factors, and international passengers. We also estimated the reproduction number (R) based on the growth rate of the exponential pandemic phase by date of symptoms onset, estimated using maximum likelihood methods. RESULTS: While earlier pandemic onset was associated with larger population size, there was no association with connectivity, demographic, school or climatic factors. In contrast, there was a latitudinal gradient in peak pandemic timing, representing a 16-39-day lag in disease activity from the southern regions relative to the northernmost region (P < 0.001). Geographical differences in latitude of Chilean regions, maximum temperature and specific humidity explained 68.5% of the variability in peak timing (P = 0.01). In addition, there was a decreasing gradient in reproduction number from south to north Chile (P < 0.0001). The regional mean R estimates were 1.6-2.0, 1.3-1.5, and 1.2-1.3 for southern, central and northern regions, respectively, which were not affected by the winter vacation period. CONCLUSIONS: There was a lag in the period of most intense 2009 pandemic influenza activity following a South to North traveling pattern across regions of Chile, significantly associated with geographical differences in minimum temperature and specific humidity. The latitudinal gradient in timing of pandemic activity was accompanied by a gradient in reproduction number (P < 0.0001). Intensified surveillance strategies in colder and drier southern regions could lead to earlier detection of pandemic influenza viruses and improved control outcomes.","title":"The influence of climatic conditions on the transmission dynamics of the 2009 A/H1N1 influenza pandemic in Chile","annotator_investigating_R0":"1","text_response":"disease name: A/H1N1 influenza\\r\\nlocation: Chile, southern region\\r\\ndate: 01-May to 31-December, 2009\\r\\nR0 value: 1.6-2.0\\r\\n%CI values: -\\r\\nmethod: growth rate of the exponential pandemic phase by date of symptoms onset\\r\\n|\\r\\ndisease name: A/H1N1 influenza\\r\\nlocation: Chile, central region\\r\\ndate: 01-May to 31-December, 2009\\r\\nR0 value: 1.3-1.5\\r\\n%CI values: -\\r\\nmethod: growth rate of the exponential pandemic phase by date of symptoms onset\\r\\n|\\r\\ndisease name: A/H1N1 influenza\\r\\nlocation: Chile, northern regions\\r\\ndate: 01-May to 31-December, 2009\\r\\nR0 value: 1.2-1.3\\r\\n%CI values: -\\r\\nmethod: growth rate of the exponential pandemic phase by date of symptoms onset","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"A/H1N1 influenza\\",\\r\\n\\"location\\": \\"Chile, southern region\\",\\r\\n\\"date\\": \\"01-May to 31-December, 2009\\",\\r\\n\\"R0 value\\": \\"1.6-2.0\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"growth rate of the exponential pandemic phase by date of symptoms onset\\"}},{\\"contribution\\":{\\"disease name\\": \\"A/H1N1 influenza\\",\\r\\n\\"location\\": \\"Chile, central region\\",\\r\\n\\"date\\": \\"01-May to 31-December, 2009\\",\\r\\n\\"R0 value\\": \\"1.3-1.5\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"growth rate of the exponential pandemic phase by date of symptoms onset\\"}},{\\"contribution\\":{\\"disease name\\": \\"A/H1N1 influenza\\",\\r\\n\\"location\\": \\"Chile, northern regions\\",\\r\\n\\"date\\": \\"01-May to 31-December, 2009\\",\\r\\n\\"R0 value\\": \\"1.2-1.3\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"growth rate of the exponential pandemic phase by date of symptoms onset\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"2009 A/H1N1 influenza\\", \\"location\\": \\"Chile\\", \\"date\\": \\"01-May to 31-December, 2009\\", \\"R0 value\\": \\"1.6-2.0\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"maximum likelihood methods\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 A/H1N1 influenza\\", \\"location\\": \\"Chile\\", \\"date\\": \\"01-May to 31-December, 2009\\", \\"R0 value\\": \\"1.3-1.5\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"maximum likelihood methods\\" } }, { \\"contribution\\": { \\"disease name\\": \\"2009 A/H1N1 influenza\\", \\"location\\": \\"Chile\\", \\"date\\": \\"01-May to 31-December, 2009\\", \\"R0 value\\": \\"1.2-1.3\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"maximum likelihood methods\\" } } ]","publish_time":"2012-11-13 05:00:00","cluster_id":"1177"},{"main_cord_uid":"fdwrrpnl","cord_uid":"fdwrrpnl","abstract":"BACKGROUND: Since the 2009 A/H1N1 pandemic, Public Health England have developed a suite of real-time statistical models utilising enhanced pandemic surveillance data to nowcast and forecast a future pandemic. Their ability to track seasonal influenza and predict heightened winter healthcare burden in the light of high activity in Australia in 2017 was untested. METHODS: Four transmission models were used in forecasting the 2017/2018 seasonal influenza epidemic in England: a stratified primary care model using daily, region-specific, counts and virological swab positivity of influenza-like illness consultations in general practice (GP); a strain-specific (SS) model using weekly, national GP ILI and virological data; an intensive care model (ICU) using reports of ICU influenza admissions; and a synthesis model that included all data sources. For the first 12 weeks of 2018, each model was applied to the latest data to provide estimates of epidemic parameters and short-term influenza forecasts. The added value of pre-season population susceptibility data was explored. RESULTS: The combined results provided valuable nowcasts of the state of the epidemic. Short-term predictions of burden on primary and secondary health services were initially highly variable before reaching consensus beyond the observed peaks in activity between weeks 3\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u01534 of 2018. Estimates for R(0) were consistent over time for three of the four models until week 12 of 2018, and there was consistency in the estimation of R(0) across the SPC and SS models, and in the ICU attack rates estimated by the ICU and the synthesis model. Estimation and predictions varied according to the assumed levels of pre-season immunity. CONCLUSIONS: This exercise successfully applied a range of pandemic models to seasonal influenza. Forecasting early in the season remains challenging but represents a crucially important activity to inform planning. Improved knowledge of pre-existing levels of immunity would be valuable.","title":"Forecasting the 2017/2018 seasonal influenza epidemic in England using multiple dynamic transmission models: a case study","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"seasonal influenza\\", \\"location\\": \\"England\\", \\"date\\": \\"For the first 12 weeks of 2018\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"strategized primary care model using daily, region-specific, counts and virological swab positivity of influenza-like illness consultations in general practice (GP), a strain-specific (SS) model using weekly, national GP ILI and virological data, an intensive care model (ICU) using reports of ICU influenza admissions; and a synthesis model\\" } } ]","publish_time":"2020-04-15 00:00:00"},{"main_cord_uid":"m9mrbf3l","cord_uid":"m9mrbf3l","abstract":"OBJECTIVES: Universities are exploring strategies to mitigate the spread of COVID-19 prior to reopening their campuses. National guidelines do not currently recommend testing students prior to campus arrival. However, the impact of presemester testing has not been studied. DESIGN: Dynamic SARS-CoV-2 transmission models are used to explore the effects of three presemester testing interventions. INTERVENTIONS: Testing of students 0, 1 and 2 times prior to campus arrival. PRIMARY OUTCOMES: Number of active infections and time until isolation bed capacity is reached. SETTING: We set on-campus and off-campus populations to 7500 and 17 500 students, respectively. We assumed 2% prevalence of active cases at the semester start, and that one-third of infected students will be detected and isolated throughout the semester. Isolation bed capacity was set at 500. We varied disease transmission rates (R(0)=1.5, 2, 3, 4) to represent the effectiveness of mitigation strategies throughout the semester. RESULTS: Without presemester screening, peak number of active infections ranged from 4114 under effective mitigation strategies (R(0)=1.5) to 10 481 under ineffective mitigation strategies (R(0)=4), and exhausted isolation bed capacity within 10 (R(0)=4) to 25 days (R(0)=1.5). Mandating at least one test prior to campus arrival delayed the timing and reduced the size of the peak, while delaying the time until isolation bed capacity was reached. Testing twice in conjunction with effective mitigation strategies (R(0)=1.5) was the only scenario that did not exhaust isolation bed capacity during the semester. CONCLUSIONS: Presemester screening is necessary to avert early and large surges of active COVID-19 infections. Therefore, we recommend testing within 1 week prior to and on campus return. While this strategy is sufficient for delaying the timing of the peak outbreak, presemester testing would need to be implemented in conjunction with effective mitigation strategies to significantly reduce outbreak size and preserve isolation bed capacity.","title":"Modelling the impact of presemester testing on COVID-19 outbreaks in university campuses","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-12-15 05:00:00"},{"main_cord_uid":"o5twfbsh","cord_uid":"o5twfbsh","abstract":"This study examined four countries Israel, United States, United Kingdom, and Serbia and present their possible vaccination trajectories into 2021. We found that populations in all the four countries are relaxing and taking the advantage of the benefit of an increasingly immunized community hence, experiencing a rising phase of Rc(t). The United States is of particular concern, due to its fast rising Rc(t) in comparison to other countries, potentially generating another wave of infection. Due to aggressive vaccination program, continued implementation of restrictive measures, or both, in all countries we analyzed, present a cautiously optimistic outlook at controlling the pandemic toward the latter part of 2021. We also found that despite a significant fraction of the population in selected countries being immunized, no countries other than Israel has its Rc(t) reached its intrinsic R0 value. Based on our proposed methodology for deriving R0, our prediction shows that Israel\'s indigenous COVID-19 daily R0 is approximately 2.2 based on its latest data.","title":"Estimation of the Reproduction Number for COVID-19 Based on Latest Vaccination Results and the Timing for Herd-Immunity: Prospect for 2021","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Israel\\r\\ndate: 2021\\r\\nR0 value: 2.2\\r\\n%CI values: -\\r\\nmethod: -","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Israel\\",\\r\\n\\"date\\": \\"2021\\",\\r\\n\\"R0 value\\": \\"2.2\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"-\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Israel\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"2.2\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Israel\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United States\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United Kingdom\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Serbia\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United Kingdom\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United Kingdom\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United Kingdom\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United Kingdom\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United Kingdom\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United Kingdom\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United Kingdom\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United Kingdom\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United Kingdom\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United Kingdom\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United Kingdom\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"} } ]","publish_time":"2021-03-26 00:00:00"},{"main_cord_uid":"qugxks5e","cord_uid":"qugxks5e","abstract":"The novel coronavirus disease 2019 (COVID-19) infection broke out in December 2019 in Wuhan, and rapidly overspread 31 provinces in mainland China on 31 January 2020. In the face of the increasing number of daily confirmed infected cases, it has become a common concern and worthy of pondering when the infection will appear the turning points, what is the final size and when the infection would be ultimately controlled. Based on the current control measures, we proposed a dynamical transmission model with contact trace and quarantine and predicted the peak time and final size for daily confirmed infected cases by employing Markov Chain Monte Carlo algorithm. We estimate the basic reproductive number of COVID-19 is 5.78 (95%CI: 5.71-5.89). Under the current intervention before 31 January, the number of daily confirmed infected cases is expected to peak on around 11 February 2020 with the size of 4066 (95%CI: 3898-4472). The infection of COVID-19 might be controlled approximately after 18 May 2020. Reducing contact and increasing trace about the risk population are likely to be the present effective measures.","title":"Current trends and future prediction of novel coronavirus disease (COVID-19) epidemic in China: a dynamical modeling analysis.","annotator_investigating_R0":"1","text_response":"disease name: novel coronavirus disease 2019 (COVID-19)\\r\\nlocation: Wuhan, China\\r\\ndate: -\\r\\nR0 value: 5.78\\r\\n%CI values: 95%CI: 5.71-5.89\\r\\nmethod: Markov Chain Monte Carlo algorithm","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"novel coronavirus disease 2019 (COVID-19)\\",\\r\\n\\"location\\": \\"Wuhan, China\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"5.78\\",\\r\\n\\"%CI values\\": \\"95%CI: 5.71-5.89\\",\\r\\n\\"method\\": \\"Markov Chain Monte Carlo algorithm\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"China\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"5.78\\", \\"%CI values\\": \\"(95%CI: 5.71-5.89)\\", \\"method\\": \\"Markov Chain Monte Carlo algorithm\\" } } ]","publish_time":"2020-04-08 00:00:00"},{"main_cord_uid":"l0750hal","cord_uid":"l0750hal","abstract":"In the night of February 20, 2020, the first case of novel coronavirus disease (COVID-19) was confirmed in the Lombardy Region, Italy. In the week that followed, Lombardy experienced a very rapid increase in the number of cases. We analyzed the first 5,830 laboratory-confirmed cases to provide the first epidemiological characterization of a COVID-19 outbreak in a Western Country. Epidemiological data were collected through standardized interviews of confirmed cases and their close contacts. We collected demographic backgrounds, dates of symptom onset, clinical features, respiratory tract specimen results, hospitalization, contact tracing. We provide estimates of the reproduction number and serial interval. The epidemic in Italy started much earlier than February 20, 2020. At the time of detection of the first COVID-19 case, the epidemic had already spread in most municipalities of Southern-Lombardy. The median age for of cases is 69 years (range, 1 month to 101 years). 47% of positive subjects were hospitalized. Among these, 18% required intensive care. The mean serial interval is estimated to be 6.6 days (95% CI, 0.7 to 19). We estimate the basic reproduction number at 3.1 (95% CI, 2.9 to 3.2). We estimated a decreasing trend in the net reproduction number starting around February 20, 2020. We did not observe significantly different viral loads in nasal swabs between symptomatic and asymptomatic. The transmission potential of COVID-19 is very high and the number of critical cases may become largely unsustainable for the healthcare system in a very short-time horizon. We observed a slight decrease of the reproduction number, possibly connected with an increased population awareness and early effect of interventions. Aggressive containment strategies are required to control COVID-19 spread and catastrophic outcomes for the healthcare system.","title":"The early phase of the COVID-19 outbreak in Lombardy, Italy","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Lombardy, Italy\\r\\ndate: -\\r\\nR0 value: 3.1\\r\\n%CI values: (95% CI, 2.9 to 3.2)\\r\\nmethod: -","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Lombardy, Italy\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"3.1\\",\\r\\n\\"%CI values\\": \\"(95% CI, 2.9 to 3.2)\\",\\r\\n\\"method\\": \\"-\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Lombardy Region, Italy\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"3.1\\", \\"%CI values\\": \\"(95% CI, 2.9 to 3.2)\\", \\"method\\": \\"-\\" } } ]","publish_time":"2020"},{"main_cord_uid":"3g8pwbcq","cord_uid":"3g8pwbcq","abstract":"OBJECTIVES: The novel coronavirus (SARS-CoV-2) originating from Wuhan spread rapidly throughout China. While its origin remains uncertain, accumulating evidence links a wet market with the early spread of SARS-CoV-2 in Wuhan. Similarly, the influence of the marketplace on the early transmission dynamics is yet to be investigated. METHODS: Using the daily series of COVID-19 incidence, stratified according to contact history with the market, we have conducted quantitative modeling analyses to estimate the reproduction numbers (R) for market-to-human and human-to-human transmission, the reporting probability, and the early effects of public health interventions. RESULTS: We estimated R at 0.24 (95% CrI: 0.01-1.38) for market-to-human transmission and 2.37 (95% CrI: 2.08-2.71) for human-to-human transmission during the early spread in China (2019-2020). Moreover, we estimated that the reporting rate for cases stemming from market-to-human transmission was 2-34 fold higher than that for cases stemming from human-to-human transmission, suggesting that contact history with the wet market played a key role in identifying COVID-19 cases. CONCLUSIONS: Our R estimate tied to market-to-human transmission had substantial uncertainty, but it was significantly lower compared with the reproduction number driving human-to-human transmission. Our results also suggest that asymptomatic and subclinical infections constitute a substantial component of the COVID-19 morbidity burden.","title":"Effect of a wet market on coronavirus disease (COVID-19) transmission dynamics in China, 2019-2020","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: China\\r\\ndate: 2019-2020\\r\\nR0 value: 0.24  for market-to-human transmission\\r\\n%CI values: (95% CrI: 0.01-1.38)\\r\\nmethod: quantitative modeling analyses\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: China\\r\\ndate: 2019-2020\\r\\nR0 value: 2.37  for human-to-human transmission\\r\\n%CI values: (95% CrI: 2.08-2.71)\\r\\nmethod: quantitative modeling analyses","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"China\\",\\r\\n\\"date\\": \\"2019-2020\\",\\r\\n\\"R0 value\\": \\"0.24  for market-to-human transmission\\",\\r\\n\\"%CI values\\": \\"(95% CrI: 0.01-1.38)\\",\\r\\n\\"method\\": \\"quantitative modeling analyses\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"China\\",\\r\\n\\"date\\": \\"2019-2020\\",\\r\\n\\"R0 value\\": \\"2.37  for human-to-human transmission\\",\\r\\n\\"%CI values\\": \\"(95% CrI: 2.08-2.71)\\",\\r\\n\\"method\\": \\"quantitative modeling analyses\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"China\\", \\"date\\": \\"2019-2020\\", \\"R0 value\\": \\"0.24\\", \\"%CI values\\": \\"(95% CrI: 0.01-1.38)\\", \\"method\\": \\"quantitative modeling analyses\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"China\\", \\"date\\": \\"2019-2020\\", \\"R0 value\\": \\"2.37\\", \\"%CI values\\": \\"(95% CrI: 2.08-2.71)\\", \\"method\\": \\"quantitative modeling analyses\\" } } ]","publish_time":"2020","cluster_id":"69"},{"main_cord_uid":"ixtq6e46","cord_uid":"ixtq6e46","abstract":"In epidemiology, the effective reproduction number $R_e$ is used to characterize the growth rate of an epidemic outbreak. In this paper, we investigate properties of $R_e$ for a modified SEIR model of COVID-19 in the city of Houston, TX USA, in which the population is divided into low-risk and high-risk subpopulations. The response of $R_e$ to two types of control measures (testing and distancing) applied to the two different subpopulations is characterized. A nonlinear cost model is used for control measures, to include the effects of diminishing returns. We propose three types of heuristic strategies for mitigating COVID-19 that are targeted at reducing $R_e$, and we exhibit the tradeoffs between strategy implementation costs and number of deaths. We also consider two variants of each type of strategy: basic strategies, which consider only the effects of controls on $R_e$, without regard to subpopulation; and high-risk prioritizing strategies, which maximize control of the high-risk subpopulation. Results showed that of the three heuristic strategy types, the most cost-effective involved setting a target value for $R_e$ and applying sufficient controls to attain that target value. This heuristic led to strategies that begin with strict distancing of the entire population, later followed by increased testing. Strategies that maximize control on high-risk individuals were less cost-effective than basic strategies that emphasize reduction of the rate of spreading of the disease. The model shows that delaying the start of control measures past a certain point greatly worsens strategy outcomes. We conclude that the effective reproduction can be a valuable real-time indicator in determining cost-effective control strategies.","title":"Cost Effective Reproduction Number Based Strategies for Reducing Deaths from COVID-19","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-04-19 00:00:00"},{"main_cord_uid":"jsr6b9pb","cord_uid":"jsr6b9pb","abstract":"The spread of COVID-19 within a region in South East Asia has been modelled using a compartment model called SEIR (Susceptible, Exposed, Infected, Recovered). Actual number of sick people needing treatments, or the number active case data was used to obtain realistic values of the model parameters such as the reproduction number (R0), incubation, and recovery periods. It is shown that at the beginning of the pandemic where most people were still not aware, the R0 was very high as seen by the steep increase of people got infected and admitted to the hospitals. Few weeks after the lockdown of the region was in place and people were obeying the regulation and observing safe distancing, the R0 values dropped significantly and converged to a steady value of about 3. Using the obtained model parameters, fitted on a daily basis, the maximum number of active cases converged to a certain value of about 2500 cases. It is expected that in the early June 2020 that the number of active cases will drop to a significantly low level.","title":"Application Of Seir Model In COVID-19 And The Effect Of Lockdown On Reducing The Number Of Active Cases","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: a region in South East Asia\\r\\ndate: -\\r\\nR0 value: 3\\r\\n%CI values: -\\r\\nmethod: compartment model (SEIR)","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"a region in South East Asia\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"3\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"compartment model (SEIR)\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"South East Asia\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"compartmental model called SEIR (Susceptible, Exposed, Infected, Recovered)\\" } } ]","publish_time":"2020"},{"main_cord_uid":"yxhn0sns","cord_uid":"yxhn0sns","abstract":"BackgroundGovernments around the world have implemented non-pharmaceutical interventions to limit the transmission of COVID-19. While lockdowns and physical distancing have proven effective for reducing COVID-19 transmission, there is still limited understanding of how NPI measures are reflected in indicators of human mobility. Further, there is a lack of understanding about how findings from high-income settings correspond to low and middle-income contexts. MethodsIn this study, we assess the relationship between indicators of human mobility, NPIs, and estimates of Rt, a real-time measure of the intensity of COVID-19 transmission. We construct a multilevel generalised linear mixed model, combining local disease surveillance data from subnational districts of Ghana with the timing of NPIs and indicators of human mobility from Google and Vodafone Ghana. FindingsWe observe a relationship between reductions in human mobility and decreases in Rt during the early stages of the COVID-19 epidemic in Ghana. We find that the strength of this relationship varies through time, decreasing after the most stringent period of interventions in the early epidemic. InterpretationOur findings demonstrate how the association of NPI and mobility indicators with COVID-19 transmission may vary through time. Further, we demonstrate the utility of combining local disease surveillance data with large scale human mobility data to augment existing surveillance capacity and monitor the impact of NPI policies. Research in ContextO_ST_ABSEvidence before this studyC_ST_ABSWe searched PubMed and preprint archives for articles published in English that contained information about the COVID-19 pandemic published up to Nov 1, 2021, using the search terms \\"coronavirus\\", \\"CoV\\", \\"COVID-19\\", \\"mobility\\", \\"movement\\", and \\"flow\\". The data thus far suggests that NPI measures including physical distancing, reduction of travel, and use of personal protective equipment have been demonstrated to reduce COVID-19 transmission. Much of the existing research focuses on comparisons of NPI stringency with COVID-19 transmission among different high-income countries, or on high-income countries, leaving critical questions about the applicability of these findings to low- and middle-income settings. Added value of this studyWe used a detailed COVID-19 surveillance dataset from Ghana, and unique high resolution spatial data on human mobility from Vodafone Ghana as well as Google smartphone GPS location data. We show how human mobility and NPI stringency were associated with changes in the effective reproduction number (Rt). We further demonstrate how this association was strongest in the early COVID-19 outbreak in Ghana, decreasing after the relaxation of national restrictions. Implications of all the available evidenceThe change in association between human mobility, NPI stringency, and Rt may reflect a \\"decoupling\\" of NPI stringency and human mobility from disease transmission in Ghana as the COVID-19 epidemic progressed. This finding provides public health decision makers with important insights for the understanding of the utility of mobility data for predicting the spread of COVID-19.","title":"Estimating the relationship between mobility, non-pharmaceutical interventions, and COVID-19 transmission in Ghana","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"9yi3rv38","cord_uid":"9yi3rv38","abstract":"Multiple safe and effective vaccines and antiviral drugs have been approved or authorized for use against the COVID-19 pandemic in the United States. The effectiveness of these and other intervention measures is threatened by the emergence of numerous SARS-CoV-2 variants of concern. We present a model for studying the transmission dynamics of two of these variants (Delta and Omicron) in the presence of vaccination, treatment of individuals with clinical symptoms of the disease and the use of face masks in the community. The model was fitted using daily case data for the COVID-19 pandemic in the United States corresponding to the period starting from when Omicron first emerged (end of November 2021) to date. It is shown, based on simulating the model with the current COVID-19 data, that the reproduction number of the Delta variant (denoted by Rvd) is much smaller than one (Rvd = 0.28), while that of Omicron (denoted by Rvo) is approximately equal to unity (Rvo = 0.96). This shows that the Delta variant has essentially died out, and that Omicron is currently the predominant variant of concern in the United States. Furthermore, if the current baseline levels of the control measures being implemented in the United States are maintained, the Omicron variant will also be on a rapid decline (towards elimination). The analysis and simulations of the calibrated model show that vaccine-derived immunity can be achieved in the United States if at least 68% of the population is fully-vaccinated with either the Pfizer or Moderna vaccine. It is shown that the COVID-19 pandemic can be eliminated in the United States by June of 2022 if the current baseline level of the proportion of individuals that is fully-vaccinated is increased by about 20%. The threshold vaccination coverage needed to achieve the vaccine-derived herd immunity decreases if the vaccination program is combined with a face mask use strategy, particularly one that emphasizes the use of moderate to high quality masks (e.g., surgical or N95 masks). Greater reduction in disease burden (in comparison to the baseline scenario) are recorded if the very high quality N95 masks are prioritized in the community, followed by the moderately-effective surgical masks and then the lowly-effective cloth masks. We also showed that having high percentage of the populace wearing the moderately-effective surgical mask is more beneficial to the community than having low percentage of the populace wearing the highly-effective N95 masks (this result does not hold for the case when cloth masks compliance is compared with that of N95 masks). However, if a certain (fixed) percentage is to give up masking, our study showed that it is more beneficial if they give up wearing surgical masks and not N95 masks (in other words, in a head-to-head comparison, N95 is always superior than surgical mask). This study showed that waning natural and vaccine-derived immunity (if considered individually) offer marginal impact on disease burden, except for the case when they wane at a much faster rate (e.g., within three months), in comparison to the baseline (estimated to be within 9 months to a year). Greater reduction or increase in disease burden is recorded if both the vaccine-derived and natural immunity wane at the same time (rather than the case when we considered only one of them varying, while the other is at baseline). For instance, if both vaccine-derived and natural immunity wane within three months, a 14% increase in the peak daily cases will be recorded, in comparison to the baseline. For this case, where immunity wanes within three months, our study predicts another (but milder) Omicron wave in the United States that peaks around July 2022 (with the peak 72% lower than the original Omicron peak). Under this (fast waning) scenario, our study suggests that a fourth dose of the two mRNA vaccines would need to be approved in the United States to aid and accelerate the prospect of SARS-CoV-2 elimination in 2022. It is shown that while the treatment of symptomatic individuals has marginal effect in reducing daily cases of SARS-CoV-2, in comparison to the baseline, it has significant impact in reducing daily hospitalizations. It is further shown that, while treatment significantly reduces hospitalization, the prospects of COVID-19 elimination in the United States is more significantly enhanced if investments in control resources are focused on mask usage and vaccination rather than on treatment.","title":"Dynamics of the Delta and Omicron variants of SARS-CoV-2 in the United States: the battle of supremacy in the presence of vaccination, mask usage and antiviral treatment","annotator_investigating_R0":"1","text_response":"disease name: COVID-19, Delta variant\\r\\nlocation: United States\\r\\ndate: End of November 2021 to date\\r\\nR0 value: 0.28\\r\\n%CI values: -\\r\\nmethod: Model fitted using daily case data for the COVID-19 pandemic in the United States\\r\\n|\\r\\ndisease name: COVID-19, Omicron\\r\\nlocation: United States\\r\\ndate: End of November 2021 to date\\r\\nR0 value: 0.96\\r\\n%CI values: -\\r\\nmethod: Model fitted using daily case data for the COVID-19 pandemic in the United States","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19, Delta variant\\",\\r\\n\\"location\\": \\"United States\\",\\r\\n\\"date\\": \\"End of November 2021 to date\\",\\r\\n\\"R0 value\\": \\"0.28\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Model fitted using daily case data for the COVID-19 pandemic in the United States\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19, Omicron\\",\\r\\n\\"location\\": \\"United States\\",\\r\\n\\"date\\": \\"End of November 2021 to date\\",\\r\\n\\"R0 value\\": \\"0.96\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Model fitted using daily case data for the COVID-19 pandemic in the United States\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United States\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"0.48\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"model for studying the transmission dynamics of two of these variants (Delta and Omicron) in the presence of vaccination, treatment of individuals with clinical symptoms of the disease and the use of face masks in the community\\" } } ]","publish_time":"2022-02-24 05:00:00","cluster_id":"145"},{"main_cord_uid":"kpc35qbs","cord_uid":"kpc35qbs","abstract":"BACKGROUND: The dynamics of the COVID-19 pandemic vary owing to local population density and policy measures. During decision-making, policymakers consider an estimate of the effective reproduction number Rt, which is the expected number of secondary infections spread by a single infected individual. OBJECTIVE: We propose a simple method for estimating the time-varying infection rate and the Rt. METHODS: We used a sliding window approach with a Susceptible-Infectious-Removed (SIR) model. We estimated the infection rate from the reported cases over a 7-day window to obtain a continuous estimation of Rt. A proposed adaptive SIR (aSIR) model was applied to analyze the data at the state and county levels. RESULTS: The aSIR model showed an excellent fit for the number of reported COVID-19 cases, and the 1-day forecast mean absolute prediction error was <2.6% across all states. However, the 7-day forecast mean absolute prediction error approached 16.2% and strongly overestimated the number of cases when the Rt was rapidly decreasing. The maximal Rt displayed a wide range of 2.0 to 4.5 across all states, with the highest values for New York (4.4) and Michigan (4.5). We found that the aSIR model can rapidly adapt to an increase in the number of tests and an associated increase in the reported cases of infection. Our results also suggest that intensive testing may be an effective method of reducing Rt. CONCLUSIONS: The aSIR model provides a simple and accurate computational tool for continuous Rt estimation and evaluation of the efficacy of mitigation measures.","title":"Adaptive Susceptible-Infectious-Removed Model for Continuous Estimation of the COVID-19 Infection Rate and Reproduction Number in the United States: Modeling Study","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"2yzgc9xb","cord_uid":"2yzgc9xb","abstract":"Analysis of genetic sequence data from the SARS-CoV-2 pandemic can provide insights into epidemic origins, worldwide dispersal, and epidemiological history. With few exceptions, genomic epidemiological analysis has focused on geographically distributed data sets with few isolates in any given location. Here, we report an analysis of 20 whole SARS- CoV-2 genomes from a single relatively small and geographically constrained outbreak in Weifang, People\xc3\xa2\xe2\u201a\xac\xe2\u201e\xa2s Republic of China. Using Bayesian model-based phylodynamic methods, we estimate a mean basic reproduction number (R(0)) of 3.4 (95% highest posterior density interval: 2.1\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u01535.2) in Weifang, and a mean effective reproduction number (R(t)) that falls below 1 on 4 February. We further estimate the number of infections through time and compare these estimates to confirmed diagnoses by the Weifang Centers for Disease Control. We find that these estimates are consistent with reported cases and there is unlikely to be a large undiagnosed burden of infection over the period we studied.","title":"Genomic epidemiology of a densely sampled COVID-19 outbreak in China","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Weifang, People\'s Republic of China\\r\\ndate: 4 February\\r\\nR0 value: 3.4\\r\\n%CI values: 95% highest posterior density interval: 2.1-5.2\\r\\nmethod: Bayesian model-based phylodynamic methods","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Weifang, People\'s Republic of China\\",\\r\\n\\"date\\": \\"4 February\\",\\r\\n\\"R0 value\\": \\"3.4\\",\\r\\n\\"%CI values\\": \\"95% highest posterior density interval: 2.1-5.2\\",\\r\\n\\"method\\": \\"Bayesian model-based phylodynamic methods\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Weifang, People\'s Republic of China\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"3.4\\", \\"%CI values\\": \\"(95% highest posterior density interval: 2.1-5.2)\\", \\"method\\": \\"Bayesian model-based phylodynamic methods\\" } } ]","publish_time":"2021-03-14 00:00:00"},{"main_cord_uid":"ditadt8l","cord_uid":"ditadt8l","abstract":"The coronavirus disease 2019 (COVID-19) has been damaging our daily life after declaration of pandemic. Therefore, we have started studying on the characteristics of Susceptible-Infectious-Recovered (SIR) model to know about the truth of infectious disease and our future. After detailed studies on the characteristics of the SIR model for the various parameter dependencies with respect to such as the outing restriction (lockdown) ratio and vaccination rate, we have finally noticed that the second term (isolation term) in the differential equation of the number of the infected is quite similar to the \\"helium ash particle loss term\\" in deuterium-tritium (D-T) nuclear fusion. Based on this analogy, we have found that isolation of the infected is not actively controlled in the SIR model. Then we introduce the isolation control time parameter q and have studied its effect on this pandemic. Required isolation time to terminate the COVID-19 can be estimated by this proposed method. To show this isolation control effect, we choose Tokyo for the model calculation because of high population density. We determine the reproduction number and the isolation ratio in the initial uncontrolled phase, and then the future number of the infected is estimated under various conditions. If the confirmed case can be isolated in 3~8 days by widely performed testing, this pandemic could be suppressed without awaiting vaccination. If the mild outing restriction and vaccination are taken together, the isolation control time can be longer. We consider this isolation time control might be the only solution to overcome the pandemic when vaccine is not available.","title":"Suppression of COVID-19 infection by isolation time control based on the SIR model and an analogy from nuclear fusion research","annotator_investigating_R0":"0","text_response":"disease name: coronavirus disease 2019 (COVID-19)\\r\\nlocation: Tokyo\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: Susceptible-Infectious-Recovered (SIR) model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"coronavirus disease 2019 (COVID-19)\\",\\r\\n\\"location\\": \\"Tokyo\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Susceptible-Infectious-Recovered (SIR) model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Tokyo\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Susceptible-Infectious-Recovered (SIR) model\\" } } ]","publish_time":"2020-09-20 10:00:00"},{"main_cord_uid":"w5dmgt13","cord_uid":"w5dmgt13","abstract":"Coronavirus disease 2019 (covid-19), with the fatality rate in elder (60 years old or more) being much higher than young (60 years old or less) patients, was declared a pandemic by the World Health Organization on March 11, 2020. Taking into account this age-dependent fatality rate, a mathematical model considering young and elder subpopulations was formulated based on the natural history of covid-19 to study the transmission of the SARS-CoV-2. This model can be applied to study the epidemiological scenario resulting from the adoption of isolation or lockdown in many countries to control the rapid propagation of covid-19. We chose as examples the isolation adopted in Sao Paulo State (Brazil) in the early phase but not at the beginning of the epidemic, and the lockdown implemented in Spain when the number of severe covid-19 cases was increasing rapidly. Based on the data collected from Sa o Paulo State and Spain, the model parameters were evaluated and we obtained higher estimation for the basic reproduction number R0 (9.24 for Sao Paulo State, and 8 for Spain) compared to the currently accepted estimation of R0 around 3. The model allowed to explain the flattening of the epidemic curves by isolation in Sao Paulo State and lockdown in Spain when associated with the protective measures (face mask and social distancing) adopted by the population. However, a simplified mathematical model providing lower estimation for R0 did not explain the flattening of the epidemic curves. The implementation of the isolation in Sa o Paulo State before the rapidly increasing phase of the epidemic enlarged the period of the first wave of the epidemic and delayed its peak, which are the desirable results of isolation to avoid the overloading in the health care system.","title":"Mathematical modeling of the transmission of SARS-CoV-2 \'\' Evaluating the impact of isolation in Sao Paulo State (Brazil) and lockdown in Spain associated with protective measures on the epidemic of covid-19","annotator_investigating_R0":"1","text_response":"disease name: covid-19\\r\\nlocation: Sao Paulo State (Brazil)\\r\\ndate: -\\r\\nR0 value: 9.24\\r\\n%CI values: -\\r\\nmethod: mathematical model considering young and elder subpopulation\\r\\n|\\r\\ndisease name: covid-19\\r\\nlocation: Spain\\r\\ndate: -\\r\\nR0 value: 8\\r\\n%CI values: -\\r\\nmethod: mathematical model considering young and elder subpopulation","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"covid-19\\",\\r\\n\\"location\\": \\"Sao Paulo State (Brazil)\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"9.24\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"mathematical model considering young and elder subpopulation\\"}},{\\"contribution\\":{\\"disease name\\": \\"covid-19\\",\\r\\n\\"location\\": \\"Spain\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"8\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"mathematical model considering young and elder subpopulation\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"Coronavirus disease 2019 (covid-19)\\", \\"location\\": \\"Sao Paulo State (Brazil)\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"9.24\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"mathematical model considering young and elder subpopulations\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus disease 2019 (covid-19)\\", \\"location\\": \\"Spain\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"8\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"mathematical model considering young and elder subpopulations\\" } } ]","publish_time":"2020-08-01 10:00:00","cluster_id":"598"},{"main_cord_uid":"0e0gnsb4","cord_uid":"0e0gnsb4","abstract":"A novel coronavirus strain, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), emerged in China. This study aims to characterize key attributes of SARS-CoV-2 epidemiology as the infection emerged in China. An age-stratified mathematical model was constructed to describe transmission dynamics and estimate age-specific differences in biological susceptibility to infection, age-assortativeness in transmission mixing, and transition in rate of infectious contacts (and reproduction number R 0) following introduction of mass interventions. The model estimated the infectious contact rate in early epidemic at 0.59 contacts/day (95% uncertainty interval-UI = 0.48-0.71). Relative to those 60-69 years, susceptibility was 0.06 in those &#8804;19 years, 0.34 in 20-29 years, 0.57 in 30-39 years, 0.69 in 40-49 years, 0.79 in 50-59 years, 0.94 in 70-79 years, and 0.88 in &#8805;80 years. Assortativeness in transmission mixing by age was limited at 0.004 (95% UI = 0.002-0.008). R 0 rapidly declined from 2.1 (95% UI = 1.8-2.4) to 0.06 (95% UI = 0.05-0.07) following interventions\' onset. Age appears to be a principal factor in explaining the transmission patterns in China. The biological susceptibility to infection seems limited among children but high among those >50 years. There was no evidence for differential contact mixing by age.","title":"Characterizing key attributes of COVID-19 transmission dynamics in China\'s original outbreak: Model-based estimations","annotator_investigating_R0":"1","text_response":"disease name: SARS-CoV-2\\r\\nlocation: China\\r\\ndate: -\\r\\nR0 value: 2.1\\r\\n%CI values: (95% UI = 1.8-2.4)\\r\\nmethod: age-stratified mathematical model\\r\\n|\\r\\ndisease name: SARS-CoV-2\\r\\nlocation: China\\r\\ndate: following interventions\' onset\\r\\nR0 value: 0.06\\r\\n%CI values: (95% UI = 0.05-0.07)\\r\\nmethod: age-stratified mathematical model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"SARS-CoV-2\\",\\r\\n\\"location\\": \\"China\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"2.1\\",\\r\\n\\"%CI values\\": \\"(95% UI = 1.8-2.4)\\",\\r\\n\\"method\\": \\"age-stratified mathematical model\\"}},{\\"contribution\\":{\\"disease name\\": \\"SARS-CoV-2\\",\\r\\n\\"location\\": \\"China\\",\\r\\n\\"date\\": \\"following interventions\' onset\\",\\r\\n\\"R0 value\\": \\"0.06\\",\\r\\n\\"%CI values\\": \\"(95% UI = 0.05-0.07)\\",\\r\\n\\"method\\": \\"age-stratified mathematical model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"China\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"2.1\\", \\"%CI values\\": \\"(95% UI = 1.8-2.4)\\", \\"method\\": \\"age-stratified mathematical model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"China\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"0.66\\", \\"%CI values\\": \\"(95% UI = 0.05-0.07)\\", \\"method\\": \\"age-stratified mathematical model\\" } } ]","publish_time":"2020","cluster_id":"25"},{"main_cord_uid":"at1jvlnn","cord_uid":"6n1jlpvc","abstract":"The role of mathematical models in controlling infectious diseases cannot be overemphasized. COVID-19 is a viral disease that is caused by Severe Acute Respiratory Syndrome coronavirus 2 (SARS-CoV-2) which has no approved vaccine. The available control measures are non-pharmacological interventions like wearing face masks, social distancing, and lockdown which are being advocated for by the WHO. This work assesses the impact of non-pharmaceutical control measures (social distancing and use of face-masks) and mass testing on the spread of COVID-19 in Nigeria. A community-based transmission model for COVID-19 in Nigeria is formulated with observing social distancing, wearing face masks in public and mass testing. The model is parameterized using Nigeria data on COVID-19 in Nigeria. The basic reproduction number is found to be less than unity( R_0<1) when the compliance with intervention measures is moderate (50%[\xe2\u2030\xa4]<70%) and the testing rate per day is moderate (0.5[\xe2\u2030\xa4]{sigma}_2<0.7) or when the compliance with intervention measures is strict ([\xe2\u2030\xa5]70%) and the testing rate per day is poor ({sigma}_2=0.3). This implies that Nigeria will be able to halt the spread of COVID-19 under these two conditions. However, it will be easier to enforce strict compliance with intervention measures in the presence of poor testing rate due to the limited availability of testing facilities and manpower in Nigeria. Hence, this study advocates that Nigerian governments (Federal and States) should aim at achieving a testing rate of at least 0.3 per day while ensuring that all the citizens strictly comply with wearing face masks and observing social distancing in public.","title":"The role of mathematical model in curbing COVID-19 in Nigeria","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Nigeria\\r\\ndate: -\\r\\nR0 value: R_0<1\\r\\n%CI values: -\\r\\nmethod: community-based transmission model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Nigeria\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"R_0<1\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"community-based transmission model\\"}}]","json_model_response":"unanswerable","publish_time":"2020-07-25 00:00:00","action":"change_main_cord_id","cluster_id":"546"},{"main_cord_uid":"4gr6i8rf","cord_uid":"4gr6i8rf","abstract":"As severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) spreads, the susceptible subpopulation declines causing the rate at which new infections occur to slow down. Variation in individual susceptibility or exposure to infection exacerbates this effect. Individuals that are more susceptible or more exposed tend to be infected and removed from the susceptible subpopulation earlier. This selective depletion of susceptibles intensifies the deceleration in incidence. Eventually, susceptible numbers become low enough to prevent epidemic growth or, in other words, the herd immunity threshold is reached. Here we fit epidemiological models with inbuilt distributions of susceptibility or exposure to SARS-CoV-2 outbreaks to estimate basic reproduction numbers (R_0) alongside coefficients of individual variation (CV) and the effects of containment strategies. Herd immunity thresholds are then calculated as 1-(1/R_0 )^(1/((1+CV^2 ) )) or 1-(1/R_0 )^(1/((1+2CV^2 ) )), depending on whether variation is on susceptibility or exposure. Our inferences result in herd immunity thresholds around 10-20%, considerably lower than the minimum coverage needed to interrupt transmission by random vaccination, which for R_0 higher than 2.5 is estimated above 60%. We emphasize that the classical formula, 1-1/R_0 , remains applicable to describe herd immunity thresholds for random vaccination, but not for immunity induced by infection which is naturally selective. These findings have profound consequences for the governance of the current pandemic given that some populations may be close to achieving herd immunity despite being under more or less strict social distancing measures.","title":"Herd immunity thresholds for SARS-CoV-2 estimated from unfolding epidemics","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-07-24 10:00:00"},{"main_cord_uid":"n4sc7g1u","cord_uid":"n4sc7g1u","abstract":"Mathematical modeling in epidemiology has a very important role in the study of the dynamics of an epidemic. The outbreak of COVID-19, which is currently being spread widely in the world requires in-depth study, starting from the search for sources, prediction of spread patterns, to strategies for handling this virus outbreak. Mathematical modeling can be applied to support various fields of the study. In this paper, we discuss mathematical modeling of the spread of COVID-19 by providing analysis and predictions based on data from the case of COVID-19 in South Kalimantan Province. This study was conducted by estimating parameters of the SIR Model, which is accommodates the death cases in the data, supported by several methods, namely Runge Kutta Method and Nonlinear Least Squares Method. Our analysis to the data and the model yields a Basic Reproduction Number , which means that one individual infected by COVID-19 can produce three new infected individuals. Whereas our prediction shows that infected cases can reach to 37.82% and cases of death can reach to 0.49% of the population who remained in normal activities during the PSBB. The peaks of this case are estimated to occur in the 2nd week of August to the 1st week of October 2020. The fewer people who have normal activities, then the spread of COVID-19 is predicted to pass faster with smaller cases of infection and death. Conversely, the more people who have normal activities, then the spread of COVID-19 in South Kalimantan can take longer and take a higher number of victims.","title":"Pemodelan Matematika Penyebaran COVID-19 Di Provinsi Kalimantan Selatan","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"South Kalimantan Province\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SIR Model\\" } } ]","publish_time":"2020"},{"main_cord_uid":"pxhott2p","cord_uid":"pxhott2p","abstract":"COVID-19 pandemic has become a major threat to the country. Till date, well tested medication or antidote is not available to cure this disease. According to WHO reports, COVID-19 is a severe acute respiratory syndrome which is transmitted through respiratory droplets and contact routes. Analysis of this disease requires major attention by the Government to take necessary steps in reducing the effect of this global pandemic. In this study, outbreak of this disease has been analysed for India till 30th March 2020 and predictions have been made for the number of cases for the next 2 weeks. SEIR model and Regression model have been used for predictions based on the data collected from John Hopkins University repository in the time period of 30th January 2020 to 30th March 2020. The performance of the models was evaluated using RMSLE and achieved 1.52 for SEIR model and 1.75 for the regression model. The RMSLE error rate between SEIR model and Regression model was found to be 2.01. Also, the value of R0 which is the spread of the disease was calculated to be 2.02. Expected cases may rise between 5000-6000 in the next two weeks of time. This study will help the Government and doctors in preparing their plans for the next two weeks. Based on the predictions for short-term interval, these models can be tuned for forecasting in long-term intervals.","title":"SEIR and Regression Model based COVID-19 outbreak predictions in India","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: India\\r\\ndate: 30th January 2020 to 30th March 2020\\r\\nR0 value: 2.02\\r\\n%CI values: -\\r\\nmethod: SEIR model and Regression model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"India\\",\\r\\n\\"date\\": \\"30th January 2020 to 30th March 2020\\",\\r\\n\\"R0 value\\": \\"2.02\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SEIR model and Regression model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"India\\", \\"date\\": \\"30th January 2020 to 30th March 2020\\", \\"R0 value\\": \\"2.02\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SEIR model and Regression model\\" } } ]","publish_time":"2020-04-01 10:00:00"},{"main_cord_uid":"mip0v988","cord_uid":"mip0v988","abstract":"As countries in the world review interventions for containing the pandemic of coronavirus disease 2019 (COVID-19), important lessons can be drawn from the study of the full transmission dynamics of its causative agent-severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)- in Wuhan (China), where vigorous non-pharmaceutical interventions have suppressed the local outbreak of this disease1. Here we use a modelling approach to reconstruct the full-spectrum dynamics of COVID-19 in Wuhan between 1 January and 8 March 2020 across 5 periods defined by events and interventions, on the basis of 32,583 laboratory-confirmed cases1. Accounting for presymptomatic infectiousness2, time-varying ascertainment rates, transmission rates and population movements3, we identify two key features of the outbreak: high covertness and high transmissibility. We estimate 87% (lower bound, 53%) of the infections before 8 March 2020 were unascertained (potentially including asymptomatic and mildly symptomatic individuals); and a basic reproduction number (R0) of 3.54 (95% credible interval 3.40-3.67) in the early outbreak, much higher than that of severe acute respiratory syndrome (SARS) and Middle East respiratory syndrome (MERS)4,5. We observe that multipronged interventions had considerable positive effects on controlling the outbreak, decreasing the reproduction number to 0.28 (95% credible interval 0.23-0.33) and-by projection-reducing the total infections in Wuhan by 96.0% as of 8 March 2020. We also explore the probability of resurgence following the lifting of all interventions after 14 consecutive days of no ascertained infections; we estimate this probability at 0.32 and 0.06 on the basis of models with 87% and 53% unascertained cases, respectively-highlighting the risk posed by substantial covert infections when changing control measures. These results have important implications when considering strategies of continuing surveillance and interventions to eventually contain outbreaks of COVID-19.","title":"Reconstruction of the full transmission dynamics of COVID-19 in Wuhan","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Wuhan (China)\\r\\ndate: 1 January and 8 March 2020\\r\\nR0 value: 3.54\\r\\n%CI values: (95% credible interval 3.40-3.67)\\r\\nmethod: modelling approach\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Wuhan (China)\\r\\ndate: as of 8 March 2022\\r\\nR0 value: 0.28\\r\\n%CI values: (95% credible interval 0.23-0.33)\\r\\nmethod: modelling approach","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Wuhan (China)\\",\\r\\n\\"date\\": \\"1 January and 8 March 2020\\",\\r\\n\\"R0 value\\": \\"3.54\\",\\r\\n\\"%CI values\\": \\"(95% credible interval 3.40-3.67)\\",\\r\\n\\"method\\": \\"modelling approach\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Wuhan (China)\\",\\r\\n\\"date\\": \\"as of 8 March 2022\\",\\r\\n\\"R0 value\\": \\"0.28\\",\\r\\n\\"%CI values\\": \\"(95% credible interval 0.23-0.33)\\",\\r\\n\\"method\\": \\"modelling approach\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease 2019 (COVID-19)\\", \\"location\\": \\"Wuhan (China)\\", \\"date\\": \\"between 1 January and 8 March 2020\\", \\"R0 value\\": \\"3.54\\", \\"%CI values\\": \\"(95% credible interval 3.40-3.67)\\", \\"method\\": \\"a modelling approach\\" } } ]","publish_time":"2020","cluster_id":"238"},{"main_cord_uid":"w63jlt4s","cord_uid":"w63jlt4s","abstract":"The transmission of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) becomes pandemic, but presents different patterns in the world. To characterize the epi- demic of coronavirus disease 2019 (covid-19) in each countries and regions, mathematical models were formulated aiming the estimation of the basic reproduction number R0. Simple mathematical model, the SIR model, provided lower estimation for R0, ranging from 1.5 to 3.0. However, more elaborate model presented here estimated higher value for R0, 9.24 and 8.0 respectively, for Sao Paulo State (Brazil) and Spain. Additionally, SIR model estimated R0 using the severe covid-19 cases, which are not participating in the SARS-CoV-2 transmission chain.","title":"The SIR model estimates incorrectly the basic reproduction number for the covid-19 epidemic","annotator_investigating_R0":"1","text_response":"disease name: Coronavirus Disease 2019 (COVID-19)\\r\\nlocation: Sao Paulo State (Brazil)\\r\\ndate: -\\r\\nR0 value: 9.24\\r\\n%CI values: -\\r\\nmethod: more elaborate model\\r\\n|\\r\\ndisease name: Coronavirus Disease 2019 (COVID-19)\\r\\nlocation: Spain\\r\\ndate: -\\r\\nR0 value: 8.0\\r\\n%CI values: -\\r\\nmethod: more elaborate model\\r\\n|\\r\\ndisease name: Coronavirus Disease 2019 (COVID-19)\\r\\nlocation: -\\r\\ndate: -\\r\\nR0 value: 1.5 to 3.0\\r\\n%CI values: -\\r\\nmethod: Simple mathematical model, the SIR model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\",\\r\\n\\"location\\": \\"Sao Paulo State (Brazil)\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"9.24\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"more elaborate model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\",\\r\\n\\"location\\": \\"Spain\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"8.0\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"more elaborate model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Coronavirus Disease 2019 (COVID-19)\\",\\r\\n\\"location\\": \\"-\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"1.5 to 3.0\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Simple mathematical model, the SIR model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (covid-19)\\", \\"location\\": \\"Sao Paulo State (Brazil)\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"1.5 to 3.0\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SIR model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (covid-19)\\", \\"location\\": \\"Spain\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"9.24\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SIR model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (covid-19)\\", \\"location\\": \\"Spain\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"8.0\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SIR model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Coronavirus Disease 2019 (covid-19)\\", \\"location\\": \\"Spain\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SIR model\\" } } ]","publish_time":"44117.41667","cluster_id":"1019"},{"main_cord_uid":"gz18sxzc","cord_uid":"gz18sxzc","abstract":"A better understanding of how the COVID-19 epidemic responds to social distancing efforts is required for the control of future outbreaks and to calibrate partial lock-downs. We present quantitative relationships between key parameters characterizing the COVID-19 epidemiology and social distancing efforts of nine selected European countries. Epidemiological parameters were extracted from the number of daily deaths data, while mitigation efforts are estimated from mobile phone tracking data. The decrease of the basic reproductive number (R0) as well as the duration of the initial exponential expansion phase of the epidemic strongly correlates with the magnitude of mobility reduction. Utilizing these relationships we decipher the relative impact of the timing and the extent of social distancing on the total death burden of the epidemic.","title":"Effects of social distancing on the spreading of COVID-19 inferred from mobile phone data","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-06-26 10:00:00"},{"main_cord_uid":"66ulqu11","cord_uid":"66ulqu11","abstract":"Background: As the COVID-19 epidemic is spreading, incoming data allows us to quantify values of key variables that determine the transmission and the effort required to control the epidemic. We determine the incubation period and serial interval distribution for transmission clusters in Singapore and in Tianjin. We infer the basic reproduction number and identify the extent of pre-symptomatic transmission. Methods: We collected outbreak information from Singapore and Tianjin, China, reported from Jan.19-Feb.26 and Jan.21-Feb.27, respectively. We estimated incubation periods and serial intervals in both populations. Results: The mean incubation period was 7.1 (6.13, 8.25) days for Singapore and 9 (7.92, 10.2)days for Tianjin. Both datasets had shorter incubation periods for earlier-occurring cases. The mean serial interval was 4.56 (2.69, 6.42) days for Singapore and 4.22 (3.43, 5.01) for Tianjin. We inferred that early in the outbreaks, infection was transmitted on average 2.55 and 2.89days before symptom onset (Singapore, Tianjin). The estimated basic reproduction number for Singapore was 1.97 (1.45, 2.48) secondary cases per infective; for Tianjin it was 1.87 (1.65,2.09) secondary cases per infective. Conclusions: Estimated serial intervals are shorter than incubation periods in both Singapore and Tianjin, suggesting that pre-symptomatic transmission is occurring. Shorter serial intervals lead to lower estimates of R0, which suggest that half of all secondary infections should be prevented to control spread.","title":"Transmission interval estimates suggest pre-symptomatic spread of COVID-19","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Singapore\\r\\ndate: Jan.19-Feb.26\\r\\nR0 value: 1.97 (1.45, 2.48)\\r\\n%CI values: -\\r\\nmethod: -\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Tianjin, China\\r\\ndate: Jan.21-Feb.27\\r\\nR0 value: 1.87 (1.65,2.09)\\r\\n%CI values: -\\r\\nmethod: -","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Singapore\\",\\r\\n\\"date\\": \\"Jan.19-Feb.26\\",\\r\\n\\"R0 value\\": \\"1.97 (1.45, 2.48)\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"-\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Tianjin, China\\",\\r\\n\\"date\\": \\"Jan.21-Feb.27\\",\\r\\n\\"R0 value\\": \\"1.87 (1.65,2.09)\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"-\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Singapore and Tianjin, China\\", \\"date\\": \\"Jan.19-Feb.26\\", \\"R0 value\\": \\"1.97\\", \\"%CI values\\": \\"1.45, 2.48)\\", \\"method\\": \\"-\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Tianjin, China\\", \\"date\\": \\"Jan.21-Feb.27\\", \\"R0 value\\": \\"1.87\\", \\"%CI values\\": \\"1.65, 2.09)\\", \\"method\\": \\"-\\" } } ]","publish_time":"2020-03-06 05:00:00","cluster_id":"943"},{"main_cord_uid":"8jad0bcg","cord_uid":"8jad0bcg","abstract":"In this paper, for an infectious disease such as Covid-19, we present a SIR model which examines the impact of waning immunity, vaccination rates, vaccine efficacy, and the proportion of the susceptible population who aspire to be vaccinated. Under an assumed constant control reproduction number, we provide simple conditions for the disease to be eliminated, and conversely for it to exhibit the more likely endemic behaviour. With regard to Covid-19, it is shown that if the control reproduction number is set to the basic reproduction number (say 6) of the dominant delta (B1.617.2) variant, vaccination alone, even under the most optimistic of assumptions about vaccine efficacy and high vaccine coverage, is very unlikely to lead to elimination of the disease. The model is not intended to be predictive but more an aid to understanding the relative importance of various biological and control parameters. For example, from a long-term perspective, it may be found that in the UK, through changes in societal behaviour (such as mask use, ventilation, and level of homeworking), without formal government interventions such as on-off lockdowns, the control reproduction number can still be maintained at a level significantly below the basic reproduction number. Even so, our simulations show that endemic behaviour ensues. The model obtains equilibrium values of the state variables such as the infection prevalence and mortality rate under various scenarios.","title":"A prototype vaccination model for endemic Covid-19 under waning immunity and imperfect vaccine take-up","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-11-11 00:00:00"},{"main_cord_uid":"ra1dy1i1","cord_uid":"ra1dy1i1","abstract":"Background: In late 2019, first cases of coronavirus disease 2019, or COVID-19, caused by the novel coronavirus SARS-CoV-2, were reported in Wuhan, China. Subsequently COVID-19 spread rapidly around the world. To contain the ensuing pandemic, numerous countries have implemented control measures related to international travel, including border closures, partial travel restrictions, entry or exit screening, and quarantine of travellers. Objectives: To assess the effectiveness of travel-related control measures during the COVID-19 pandemic on infectious disease and screening-related outcomes. Search methods: We searched MEDLINE, Embase and COVID-19-specific databases, including the WHO Global Database on COVID-19 Research, the Cochrane COVID-19 Study Register, and the CDC COVID-19 Research Database on 26 June 2020. We also conducted backward-citation searches with existing reviews. Selection criteria: We considered experimental, quasi-experimental, observational and modelling studies assessing the effects of travel-related control measures affecting human travel across national borders during the COVID-19 pandemic. We also included studies concerned with severe acute respiratory syndrome (SARS) and Middle East respiratory syndrome (MERS) as indirect evidence. Primary outcomes were cases avoided, cases detected and a shift in epidemic development due to the measures. Secondary outcomes were other infectious disease transmission outcomes, healthcare utilisation, resource requirements and adverse effects if identified in studies assessing at least one primary outcome. Data collection and analysis: One review author screened titles and abstracts; all excluded abstracts were screened in duplicate. Two review authors independently screened full texts. One review author extracted data, assessed risk of bias and appraised study quality. At least one additional review author checked for correctness of all data reported in the \'Risk of bias\' assessment, quality appraisal and data synthesis. For assessing the risk of bias and quality of included studies, we used the Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2) tool for observational studies concerned with screening, ROBINS-I for observational ecological studies and a bespoke tool for modelling studies. We synthesised findings narratively. One review author assessed certainty of evidence with GRADE, and the review author team discussed ratings. Main results: We included 40 records reporting on 36 unique studies. We found 17 modelling studies, 7 observational screening studies and one observational ecological study on COVID-19, four modelling and six observational studies on SARS, and one modelling study on SARS and MERS, covering a variety of settings and epidemic stages. Most studies compared travel-related control measures against a counterfactual scenario in which the intervention measure was not implemented. However, some modelling studies described additional comparator scenarios, such as different levels of travel restrictions, or a combination of measures. There were concerns with the quality of many modelling studies and the risk of bias of observational studies. Many modelling studies used potentially inappropriate assumptions about the structure and input parameters of models, and failed to adequately assess uncertainty. Concerns with observational screening studies commonly related to the reference test and the flow of the screening process. Studies on COVID-19. Travel restrictions reducing cross-border travel Eleven studies employed models to simulate a reduction in travel volume; one observational ecological study assessed travel restrictions in response to the COVID-19 pandemic. Very low-certainty evidence from modelling studies suggests that when implemented at the beginning of the outbreak, cross-border travel restrictions may lead to a reduction in the number of new cases of between 26% to 90% (4 studies), the number of deaths (1 study), the time to outbreak of between 2 and 26 days (2 studies), the risk of outbreak of between 1% to 37% (2 studies), and the effective reproduction number (1 modelling and 1 observational ecological study). Low-certainty evidence from modelling studies suggests a reduction in the number of imported or exported cases of between 70% to 81% (5 studies), and in the growth acceleration of epidemic progression (1 study). Screening at borders with or without quarantine Evidence from three modelling studies of entry and exit symptom screening without quarantine suggests delays in the time to outbreak of between 1 to 183 days (very low-certainty evidence) and a detection rate of infected travellers of between 10% to 53% (low-certainty evidence). Six observational studies of entry and exit screening were conducted in specific settings such as evacuation flights and cruise ship outbreaks. Screening approaches varied but followed a similar structure, involving symptom screening of all individuals at departure or upon arrival, followed by quarantine, and different procedures for observation and PCR testing over a period of at least 14 days. The proportion of cases detected ranged from 0% to 91% (depending on the screening approach), and the positive predictive value ranged from 0% to 100% (very low-certainty evidence). The outcomes, however, should be interpreted in relation to both the screening approach used and the prevalence of infection among the travellers screened; for example, symptom-based screening alone generally performed worse than a combination of symptom-based and PCR screening with subsequent observation during quarantine. Quarantine of travellers Evidence from one modelling study simulating a 14-day quarantine suggests a reduction in the number of cases seeded by imported cases; larger reductions were seen with increasing levels of quarantine compliance ranging from 277 to 19 cases with rates of compliance modelled between 70% to 100% (very low-certainty evidence). Authors\' conclusions: With much of the evidence deriving from modelling studies, notably for travel restrictions reducing cross-border travel and quarantine of travellers, there is a lack of \'real-life\' evidence for many of these measures. The certainty of the evidence for most travel-related control measures is very low and the true effects may be substantially different from those reported here. Nevertheless, some travel-related control measures during the COVID-19 pandemic may have a positive impact on infectious disease outcomes. Broadly, travel restrictions may limit the spread of disease across national borders. Entry and exit symptom screening measures on their own are not likely to be effective in detecting a meaningful proportion of cases to prevent seeding new cases within the protected region; combined with subsequent quarantine, observation and PCR testing, the effectiveness is likely to improve. There was insufficient evidence to draw firm conclusions about the effectiveness of travel-related quarantine on its own. Some of the included studies suggest that effects are likely to depend on factors such as the stage of the epidemic, the interconnectedness of countries, local measures undertaken to contain community transmission, and the extent of implementation and adherence.","title":"Travel-related control measures to contain the COVID-19 pandemic: a rapid review","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"66eqh79t","cord_uid":"66eqh79t","abstract":"Summary Epidemics of novel or re-emerging infectious diseases have quickly spread globally via air travel, as highlighted by pandemic H1N1 influenza in 2009 (pH1N1). Federal, state, and local public health responders must be able to plan for and respond to these events at aviation points of entry. The emergence of a novel influenza virus and its spread to the United States were simulated for February 2009 from 55 international metropolitan areas using three basic reproduction numbers (R 0): 1.53, 1.70, and 1.90. Empirical data from the pH1N1 virus were used to validate our SEIR model. Time to entry to the U.S. during the early stages of a prototypical novel communicable disease was predicted based on the aviation network patterns and the epidemiology of the disease. For example, approximately 96% of origins (R 0 of 1.53) propagated a disease into the U.S. in under 75 days, 90% of these origins propagated a disease in under 50 days. An R 0 of 1.53 reproduced the pH1NI observations. The ability to anticipate the rate and location of disease introduction into the U.S. provides greater opportunity to plan responses based on the scenario as it is unfolding. This simulation tool can aid public health officials to assess risk and leverage resources efficiently.","title":"A model-based tool to predict the propagation of infectious disease via airports","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"novel influenza\\", \\"location\\": \\"55 international metropolitan areas\\", \\"date\\": \\"February 2009\\", \\"R0 value\\": \\"1.53\\", \\"%CI values\\": \\"1.70\\", \\"method\\": \\"SEIR model\\" } }, { \\"contribution\\": { \\"disease name\\": \\"novel influenza\\", \\"location\\": \\"55 international metropolitan areas\\", \\"date\\": \\"February 2009\\", \\"R0 value\\": \\"1.90\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SEIR model\\" } } ]","publish_time":"2012-01-31 05:00:00"},{"main_cord_uid":"zd4c3nep","cord_uid":"zd4c3nep","abstract":"This paper deals with the mathematical modeling of the second wave of COVID-19 and verifies the current Omicron variant pandemic data in India. We also we discussed such as uniformly bounded of the system, Equilibrium analysis and basic reproduction number R0. We calculated the analytic solutions by HPM (homotopy perturbation method) and used Mathematica 12 software for numerical analysis up to 8th order approximation. It checked the error values of the approximation while the system has residual error, absolute error and h curve initial derivation of square error at up to 8th order approximation. The basic reproduction number ranges between 0.8454 and 2.0317 to form numerical simulation, it helps to identify the whole system fluctuations. Finally, our proposed model validated (from real life data) the highly affected five states of COVID-19 and the Omicron variant. The algorithm guidelines are used for international arrivals, with Omicron variant cases updated by the Union Health Ministry in January 2022. Right now, the third wave is underway in India, and we conclude that it may peak by the end of May 2022.","title":"Stability and Numerical Solutions of Second Wave Mathematical Modeling on COVID-19 and Omicron Outbreak Strategy of Pandemic: Analytical and Error Analysis of Approximate Series Solutions by Using HPM","annotator_investigating_R0":"1","text_response":"disease name: COVID-19 and Omicron Outbreak\\r\\nlocation: India\\r\\ndate: January 2022\\r\\nR0 value: 0.8454 - 2.0317\\r\\n%CI values: -\\r\\nmethod: HPM (homotopy perturbation method) and used Mathematica 12 software)","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19 and Omicron Outbreak\\",\\r\\n\\"location\\": \\"India\\",\\r\\n\\"date\\": \\"January 2022\\",\\r\\n\\"R0 value\\": \\"0.8454 - 2.0317\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"HPM (homotopy perturbation method) and used Mathematica 12 software)\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"India\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"0.8454 and 2.0317\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"HPM (homeotopy perturbation method)\\" } } ]","publish_time":"2022"},{"main_cord_uid":"bsfst41t","cord_uid":"bsfst41t","abstract":"Background: GC represents a worldwide problem;radical surgery remaining the gold standard of curative treatment. In the West, even with peri-operative chemotherapy, 5-year survival rate is approximately 40%. GC is a heterogeneous disease, well characterized by different molecular classifications, all having in common the role of the immune system and a T-cell inflamed phenotype across all subtypes. The anti-PD-L1 Av antibody has demonstrated efficacy in GC with response rates of around 10% in the refractory setting. The addition of other immune checkpoint inhibitors to chemotherapy have demonstrated efficacy in the metastatic setting. The combination of Av to perioperative chemotherapy may increase pathological responses by a synergistic effect, and then improving the survival (OS). Methods: The MONEO is an open-label, non-randomized, multicentric, phase II study that explores the combination of Av plus peri-operative FLOT (docetaxel, oxaliplatin, fluorouracil/leucovorin) in resectable GC pts. EudraCT 2019-000782-21;ClinicalTrials NCT03979131. Main inclusion criteria require pts with histologically proven GC, stage Ib (T1N1 only) - IIIC (7th AJCC Ed), available paraffin block from diagnosis and surgery, evaluable disease (RECIST 1.1) amenable to radical surgery. Significant comorbidities and active autoimmune diseases are excluded. Treatment consists of surgery with 4 peri-operatory cycles of FLOT + Av, followed by Av up to one year. The primary objective is the pathological complete response (pCR) rate, compared to historical data. Secondary objectives include OS, disease-free survival, R0 resection rate, tolerability and biomarker analysis. Key point is the comprehensive biomarker analysis from tissue and blood samples (pathological immune response, TCR clonality, immune contexture characterization, immunodynamic monitoring). Statistics for an estimated 33% pCR (historical 16%), 82% power, 0.1 one-side type I error. 37 pts will be recruited from 10 Spanish centers. The sponsor is Vall d\'Hebron Institute of Oncology (VHIO), principal investigators Dr. Melero and Dr. Alsina. In compliance with the Helsinki Declaration. At a data cut-off day of 5 of February 2021, 38 patients have been enrolled, 27 of them have had the surgery. Although the difficulties during the COVID19 pandemia, only two patients had been withdrawn from the study.","title":"MONEO: A phase II study of avelumab (Av) plus FLOT in the peri-operative treatment for patients (pts) with resectable gastric or gastroesophageal junction cancer (GC)","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"3s2g3o81","cord_uid":"3s2g3o81","abstract":"In this work, a researcher develop $SHEIQRD$ (Susceptible-Stay at home-Exposed-Infected-Quarantine-Recovery-Death) coronavirus pandemic spread model. The disease-free and endemic equilibrium points are calculated and analyzed. The basic reproductive number $R_0$ is derived and its sensitivity analysis is done. COVID-19 pandemic spread is die out when $R_0\\\\leq 1$ and its persist in the community whenever $R_0>1$. Efficient stay at home rate, high coverage of precise identification and isolation of expose and infected individuals, and redaction of transmission and stay at home return rate can be mitigate the pandemics. Finally, theoretical analysis and numerical results are consistent.","title":"Model the transmission dynamics of COVID-19 propagation with public health intervention","annotator_investigating_R0":"0","text_response":"disease name: COVID-19\\r\\nlocation: -\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: Susceptible-Stay at home-Exposed-Infected-Quarantine-Recovery-Death) coronavirus pandemic spread model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"-\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Susceptible-Stay at home-Exposed-Infected-Quarantine-Recovery-Death) coronavirus pandemic spread model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"-\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SHEIQRD (Susceptible-Stay at home-Exposed-Infected-Quarantine-Recovery-Death) coronavirus pandemic spread model\\" } } ]","publish_time":"2020-04-25 10:00:00"},{"main_cord_uid":"nhm24vmy","cord_uid":"nhm24vmy","abstract":"BACKGROUND: The novel coronavirus disease (COVID-19) culminated in a pandemic with many countries affected in varying stages. We aimed to develop a simulation environment for COVID-19 spread, taking environmental and social factors into account. METHODS: The program was written in R language. A stochastic point process simulation model for simulating epidemics, a maximum-likelihood estimation model, an exponential growth rate model for calculating the basic reproduction number (R0), and functions for generating graphical representations of the simulations were utilized. Geographical area definition, population size, the number of initial infected individuals, period of simulation, parameters accounting for the radius of spread like masks usage, mobility level, intrinsic viral virulence, average infectious period, fraction of population vaccinated, time of vaccination, the efficacy of the vaccine, presence or absence of quarantine centers, time of establishment of quarantine centers, the efficacy of case detection and average time to quarantine from the detection of the infection were considered. RESULTS: When the defined parameters were input, the model performed successfully producing the epidemic curve, R0 and an animation of infection spread. It was found that when parameters of known epidemics such as COVID-19 in California, Texas and, Florida were input, the epidemic curve generated was comparable to the epidemic curve in reality. CONCLUSION: This model can be utilized by many countries to visualize the effects of various mitigation strategies applied in their stage of disease and for policy makers to make informed decisions. It is applicable to many infectious diseases and hence can be used for research and educational purposes.","title":"A stochastic process based modular tool-box for simulating COVID-19 infection spread","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"California, Texas and, Florida\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"exponential growth rate model\\" } } ]","publish_time":"2022-03-05 00:00:00"},{"main_cord_uid":"fbl13xq7","cord_uid":"fbl13xq7","abstract":"This paper addresses the problem of describing the spread of COVID-19 by a mathematical model introducing all the possible control actions as prevention (informative campaign, use of masks, social distancing, vaccination) and medication. The model adopted is similar to SEIQR, with the infected patients split into groups of asymptomatic subjects and isolated ones. This distinction is particularly important in the current pandemic, due to the fundamental the role of asymptomatic subjects in the virus diffusion. The influence of the control actions is considered in analysing the model, from the calculus of the equilibrium points to the determination of the reproduction number. This choice is motivated by the fact that the available organised data have been collected since from the end of February 2020, and almost simultaneously containment measures, increasing in typology and effectiveness, have been applied. The characteristics of COVID-19, not fully understood yet, suggest an asymmetric diffusion among countries and among categories of subjects. Referring to the Italian situation, the containment measures, as applied by the population, have been identified, showing their relation with the government\xc3\xa2\xe2\u201a\xac\xe2\u201e\xa2s decisions;this allows the study of possible scenarios, comparing the impact of different possible choices.","title":"A Control Based Mathematical Model for the Evaluation of Intervention Lines in COVID-19 Epidemic Spread: The Italian Case Study","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"0yjlpzwp","cord_uid":"0yjlpzwp","abstract":"OBJECTIVES: In the current early phase of the coronavirus disease 2019 (COVID-19) outbreak, Bali needs to prepare to face the escalation of cases, with a particular focus on the readiness of healthcare services. We simulated the future trajectory of the epidemic under current conditions, projected the impact of policy interventions, and analyzed the implications for healthcare capacity. METHODS: Our study was based on the first month of publicly accessible data on new confirmed daily cases. A susceptible, exposed, infected, recovered (SEIR) model for COVID-19 was employed to compare the current dynamics of the disease with those predicted under various scenarios. RESULTS: The fitted model for the cumulative number of confirmed cases in Bali indicated an effective reproduction number of 1.4. Interventions have decreased the possible maximum number of cases from 71 125 on day 86 to 22 340 on day 119, and have prolonged the doubling time from about 9 days to 21 days. This corresponds to an approximately 30% reduction in transmissions from cases of mild infections. There will be 2780 available hospital beds, and at the peak (on day 132), the number of severe cases is estimated to be roughly 6105. Of these cases, 1831 will need intensive care unit (ICU) beds, whereas the number of currently available ICU beds is roughly 446. CONCLUSIONS: The healthcare system in Bali is in danger of collapse; thus, serious efforts are needed to improve COVID-19 interventions and to prepare the healthcare system in Bali to the greatest extent possible.","title":"Forecasting COVID-19 Transmission and Healthcare Capacity in Bali, Indonesia","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"0ax7ovzv","cord_uid":"0ax7ovzv","abstract":"As of March 13, 2020, Europe became the center of COVID-19 pandemic. In order to prevent further spread and slow down the increase in confirmed cases and deaths, many countries in European Union have taken some interventions since mid-March. In this study, a metapopulation model was used to model the outbreak of COVID-19 in Europe and the effectiveness of these interventions were also estimated. The findings suggested that many countries successfully kept the reproduction number R_t less than 1 (e.g., Belgium, Germany, Spain, and France) while other countries exhibited R_t greater than 1 (e.g., United Kingdom, Cyprus). Based on the assumed reopen strategy, this study also revealed that a 2-week delay in response predicted approximately 2,000 deaths and 200,000 cases (daily peak value), while a 3-week delay predicted approximately 5,000 deaths and 600,000 cases (daily peak value). Therefore, a quick response upon signs of a re-emerging pandemic in the world is highly imperative to mitigate potential loss of life and to keep transmission of Covid-19 under control.","title":"An Analysis of Outbreak Dynamics and Intervention Effects for COVID-19 Transmission in Europe","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-07-25 10:00:00"},{"main_cord_uid":"m6u0xf5j","cord_uid":"m6u0xf5j","abstract":"We study epidemiological characteristics of 25 early COVID-19 outbreak countries, which emphasizes on the reproduction of infection and effects of government control measures. The study is based on a vSIADR model which allows asymptomatic and pre-diagnosis infections to reflect COVID-19 clinical realities, and a linear mixed-effect model to analyse the association between each country\'s control measures and the effective reproduction number R-t. It finds significant effects of higher stringency measures in lowering the reproduction, and a significant shortening effect on the time to the epidemic turning point by applying stronger early counter measures. Epidemic projections under scenarios of the counter measures (China and Korea, the USA and the UK) show substantial reduction in the epidemic size and death by taking earlier and forceful actions. The governments\' response before and after the start of the second wave epidemics were alarmingly weak, which made the average duration of the second wave more than doubled that of the first wave. We identify countries which urgently need to restore to at least the maximum stringency measures implemented so far in the pandemic in order to avoid even higher infection size and death.","title":"Better strategies for containing COVID-19 pandemic: a study of 25 countries via a vSIADR model","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"idauypat","cord_uid":"idauypat","abstract":"Setting: Italy and especially Lombardy is experiencing a heavy burden of Covid-19 infection. The peak of the epidemics has not yet been reached and it is expected to be delayed in Central and Southern Italian regions compared to Northern ones. Objective: We have modeled the Covid-19 outbreak progression in Italian Regions vs. Lombardy to assess the epidemics. Primary and Secondary Measures: In our models, we have estimated the basic reproduction number (R0) which represents the average number of people that can be infected by a person who has already acquired the infection both by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations. We used the susceptible exposed infected removed (SEIR) compartment model to predict the spreading of the pandemic in Italy. Results. The two methods provide agreements of values, although the first method based on exponential fit should provide a better estimation, being computed on the entire time series. Taking into account the growth rate of the infection across a 1-month period, in Lombardy each infected person has involved other 5 people (4.94 based on data of March 22nd) compared to a value of R0=2.68 reported in the Chinese city of Whuan. According to our model and Piedmont, Veneto, Emilia Romagna, Tuscany and Marche reach an R0 value up to 4. The R0 is 3.7 for Lazio and 3.6 for Campania region, where this latter shows the highest value among the Southern Italian regions, followed by Apulia (3.5), Sicily (3.4), Abruzzo (3.4), Calabria (3.1), Basilicata (2.5) and Molise (2.4). The value of R0 is decreasing in Lombardy and Northern Regions, while it is increasing in Central and Southern Regions. Conclusion. The peak is expected by March 29th at national level.","title":"Covid-19 Outbreak Progression in Italian Regions: Approaching the Peak by March 29th","annotator_investigating_R0":"1","text_response":"disease name: Covid-19\\r\\nlocation: Lombardy, Italy\\r\\ndate: across a 1month period\\r\\nR0 value: 4.94\\r\\n%CI values: the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\r\\nmethod: (SEIR) compartment model\\r\\n|\\r\\ndisease name: Covid-19\\r\\nlocation: Tuscany, Italy\\r\\ndate: across a 1month period\\r\\nR0 value: 4\\r\\n%CI values: the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\r\\nmethod: (SEIR) compartment model\\r\\n|\\r\\ndisease name: Covid-19\\r\\nlocation: Marche, Italy\\r\\ndate: across a 1month period\\r\\nR0 value: 4\\r\\n%CI values: the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\r\\nmethod: (SEIR) compartment model\\r\\n|\\r\\ndisease name: Covid-19\\r\\nlocation: Lazio, Italy\\r\\ndate: across a 1month period\\r\\nR0 value: 3.7\\r\\n%CI values: the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\r\\nmethod: (SEIR) compartment model\\r\\n|\\r\\ndisease name: Covid-19\\r\\nlocation: Campania, Italy\\r\\ndate: across a 1month period\\r\\nR0 value: 3.6\\r\\n%CI values: the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\r\\nmethod: (SEIR) compartment model\\r\\n|\\r\\ndisease name: Covid-19\\r\\nlocation: Apulia, Italy\\r\\ndate: across a 1month period\\r\\nR0 value: 3.5\\r\\n%CI values: the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\r\\nmethod: (SEIR) compartment model\\r\\n|\\r\\ndisease name: Covid-19\\r\\nlocation: Sicily, Italy\\r\\ndate: across a 1month period\\r\\nR0 value: 3.4\\r\\n%CI values: the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\r\\nmethod: (SEIR) compartment model\\r\\n|\\r\\ndisease name: Covid-19\\r\\nlocation: Abruzzo, Italy\\r\\ndate: across a 1month period\\r\\nR0 value: 3.4\\r\\n%CI values: the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\r\\nmethod: (SEIR) compartment model\\r\\n|\\r\\ndisease name: Covid-19\\r\\nlocation: Calabria, Italy\\r\\ndate: across a 1month period\\r\\nR0 value: 3.1\\r\\n%CI values: the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\r\\nmethod: (SEIR) compartment model\\r\\n|\\r\\ndisease name: Covid-19\\r\\nlocation: Basilicata, Italy\\r\\ndate: across a 1month period\\r\\nR0 value: 2.5\\r\\n%CI values: the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\r\\nmethod: (SEIR) compartment model\\r\\n|\\r\\ndisease name: Covid-19\\r\\nlocation: Molise, Italy\\r\\ndate: across a 1month period\\r\\nR0 value: 2.4\\r\\n%CI values: the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\r\\nmethod: (SEIR) compartment model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"Lombardy, Italy\\",\\r\\n\\"date\\": \\"across a 1month period\\",\\r\\n\\"R0 value\\": \\"4.94\\",\\r\\n\\"%CI values\\": \\"the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\",\\r\\n\\"method\\": \\"(SEIR) compartment model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"Tuscany, Italy\\",\\r\\n\\"date\\": \\"across a 1month period\\",\\r\\n\\"R0 value\\": \\"4\\",\\r\\n\\"%CI values\\": \\"the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\",\\r\\n\\"method\\": \\"(SEIR) compartment model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"Marche, Italy\\",\\r\\n\\"date\\": \\"across a 1month period\\",\\r\\n\\"R0 value\\": \\"4\\",\\r\\n\\"%CI values\\": \\"the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\",\\r\\n\\"method\\": \\"(SEIR) compartment model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"Lazio, Italy\\",\\r\\n\\"date\\": \\"across a 1month period\\",\\r\\n\\"R0 value\\": \\"3.7\\",\\r\\n\\"%CI values\\": \\"the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\",\\r\\n\\"method\\": \\"(SEIR) compartment model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"Campania, Italy\\",\\r\\n\\"date\\": \\"across a 1month period\\",\\r\\n\\"R0 value\\": \\"3.6\\",\\r\\n\\"%CI values\\": \\"the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\",\\r\\n\\"method\\": \\"(SEIR) compartment model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"Apulia, Italy\\",\\r\\n\\"date\\": \\"across a 1month period\\",\\r\\n\\"R0 value\\": \\"3.5\\",\\r\\n\\"%CI values\\": \\"the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\",\\r\\n\\"method\\": \\"(SEIR) compartment model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"Sicily, Italy\\",\\r\\n\\"date\\": \\"across a 1month period\\",\\r\\n\\"R0 value\\": \\"3.4\\",\\r\\n\\"%CI values\\": \\"the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\",\\r\\n\\"method\\": \\"(SEIR) compartment model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"Abruzzo, Italy\\",\\r\\n\\"date\\": \\"across a 1month period\\",\\r\\n\\"R0 value\\": \\"3.4\\",\\r\\n\\"%CI values\\": \\"the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\",\\r\\n\\"method\\": \\"(SEIR) compartment model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"Calabria, Italy\\",\\r\\n\\"date\\": \\"across a 1month period\\",\\r\\n\\"R0 value\\": \\"3.1\\",\\r\\n\\"%CI values\\": \\"the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\",\\r\\n\\"method\\": \\"(SEIR) compartment model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"Basilicata, Italy\\",\\r\\n\\"date\\": \\"across a 1month period\\",\\r\\n\\"R0 value\\": \\"2.5\\",\\r\\n\\"%CI values\\": \\"the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\",\\r\\n\\"method\\": \\"(SEIR) compartment model\\"}},{\\"contribution\\":{\\"disease name\\": \\"Covid-19\\",\\r\\n\\"location\\": \\"Molise, Italy\\",\\r\\n\\"date\\": \\"across a 1month period\\",\\r\\n\\"R0 value\\": \\"2.4\\",\\r\\n\\"%CI values\\": \\"the susceptible exposed infected removed (SEIR) compartment model, by fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\",\\r\\n\\"method\\": \\"(SEIR) compartment model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"Covid-19\\", \\"location\\": \\"Lazio\\", \\"date\\": \\"March 22nd\\", \\"R0 value\\": \\"3.7\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Covid-19\\", \\"location\\": \\"Campania region\\", \\"date\\": \\"March 22nd\\", \\"R0 value\\": \\"3.6\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"day by day assessment, based on single observations\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Covid-19\\", \\"location\\": \\"Apulia (3.5), Sicily (3.4), Abruzzo (3.4), Calabria (3.1), Basilicata (2.5) and Molise (2.4)\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Covid-19\\", \\"location\\": \\"South Italian regions\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\" } }, { \\"contribution\\": { \\"disease name\\": \\"Covid-19\\", \\"location\\": \\"South Italian regions\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"fitting the exponential growth rate of the infection across a 1month period and also by using day by day assessment, based on single observations\\" } } ]","publish_time":"2020-04-02 10:00:00","cluster_id":"1031"},{"main_cord_uid":"n8vfx5xl","cord_uid":"n8vfx5xl","abstract":"This paper formulates and analyses a susceptible-exposed-infected-recovered (SEIR) type epidemic model with the effect of transport-related infection between two cities in the presence of treatment control. The dispersal of populations from one city to another city has an important impact on the dynamics of disease evolution. The basic reproduction number is calculated for all the different cases of the proposed model system. It is found out that the disease-free equilibrium is disease-free if the basic reproduction is less than unity, otherwise the disease may remain in the system. In addition, the optimal control problem is constructed and solved analytically and numerically by considering the treatment control as a control variable. Further, we present a numerical simulation to confirm the analytical results. Finally, we show a comparison of the result of our predicted model with the real data of severe acute respiratory syndrome (SARS) outbreak in 2003 in Hong Kong. \xc3\u201a\xc2\xa9 2020 Inderscience Enterprises Ltd.. All rights reserved.","title":"Population dispersal and optimal control of an SEIR epidemic model","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"SARS\\", \\"location\\": \\"Hong Kong\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"susceptible-exposed-infected-recovered (SEIR) type epidemic model\\" } } ]","publish_time":"2020"},{"main_cord_uid":"pndu87bp","cord_uid":"pndu87bp","abstract":"We present a compartmental SEIAR model of epidemic spread as a generalization of the SEIR model. We believe that the asymptomatic infectious cohort is an omitted part of the understanding of the epidemic dynamics of disease COVID-19. We introduce and derive the basic reproduction number as the weighted arithmetic mean of the basic reproduction numbers of the symptomatic and asymptomatic cohorts. Since the asymptomatic subjects people are not detected, they can spread the disease much longer, and this increases the COVID-19 $R_0$ up to around 9. We show that European epidemic outbreaks in various European countries correspond to the simulations with commonly used parameters based on clinical characteristics of the disease COVID-19, but $R_0$ is around three times bigger if the asymptomatic cohort is taken into account. Many voices in the academic world are drawing attention to the asymptomatic group of infectious subjects at present. We are convinced that the asymptomatic cohort plays a crucial role in the spread of the COVID-19 disease, and it has to be understood during government measures.","title":"SEIAR model with asymptomatic cohort and consequences to efficiency of quarantine government measures in COVID-19 epidemic","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: European countries\\r\\ndate: -\\r\\nR0 value: up to around 9\\r\\n%CI values: -\\r\\nmethod: compartmental SEIAR model of epidemic spread as a generalization of the SEIR model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"European countries\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"up to around 9\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"compartmental SEIAR model of epidemic spread as a generalization of the SEIR model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Europe\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"9\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"compartmental SEIAR model of epidemic spread as a generalization of the SEIR model\\" } } ]","publish_time":"2020-04-06 00:00:00"},{"main_cord_uid":"355guih4","cord_uid":"355guih4","abstract":"SIMPLE SUMMARY: Year-long, every human race is fighting against SARS-CoV-2 with their all resources. Since 2017, the Bangladeshi government is providing shelter to a huge number of Rohingya refugees, and now in this COVID-19 pandemic, the government is to provide all necessities and medical supports to this population, while the country hardly can fulfill all rights of her own population. This study analyzes the SARS-CoV-2 situation in the Rohingya refugee camps at Cox\xe2\u20ac\u2122s Bazar and found that the authority has done a great job taking control over the murrain compared to the host and over-all the worldwide situation. Although taken precautions are good enough till now, more detailed and pragmatic preparedness should be adopted for the worst scenario in case. Last but not least, this success would not be possible without the help of other non-governmental and international voluntary and professional organizations. ABSTRACT: Background: Bangladesh hosts more than 800,000 Rohingya refugees from Myanmar. The low health immunity, lifestyle, access to good healthcare services, and social-security cause this population to be at risk of far more direct effects of COVID-19 than the host population. Therefore, evidence-based forecasting of the COVID-19 burden is vital in this regard. In this study, we aimed to forecast the COVID-19 obligation among the Rohingya refugees of Bangladesh to keep up with the disease outbreak\xe2\u20ac\u2122s pace, health needs, and disaster preparedness. Methodology and Findings: To estimate the possible consequences of COVID-19 in the Rohingya camps of Bangladesh, we used a modified Susceptible-Exposed-Infectious-Recovered (SEIR) transmission model. All of the values of different parameters used in this model were from the Bangladesh Government\xe2\u20ac\u2122s database and the relevant emerging literature. We addressed two different scenarios, i.e., the best-fitting model and the good-fitting model with unique consequences of COVID-19. Our best fitting model suggests that there will be reasonable control over the transmission of the COVID-19 disease. At the end of December 2020, there will be only 169 confirmed COVID-19 cases in the Rohingya refugee camps. The average basic reproduction number ([Formula: see text]) has been estimated to be 0.7563. Conclusions: Our analysis suggests that, due to the extensive precautions from the Bangladesh government and other humanitarian organizations, the coronavirus disease will be under control if the maintenance continues like this. However, detailed and pragmatic preparedness should be adopted for the worst scenario.","title":"SARS-CoV-2 and Rohingya Refugee Camp, Bangladesh: Uncertainty and How the Government Took Over the Situation","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Rohingya Refugee Camp, Bangladesh\\r\\ndate: end of December 2020\\r\\nR0 value: 0.7563\\r\\n%CI values: -\\r\\nmethod: modified Susceptible-Exposed-Infectious-Recovered (SEIR) transmission model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Rohingya Refugee Camp, Bangladesh\\",\\r\\n\\"date\\": \\"end of December 2020\\",\\r\\n\\"R0 value\\": \\"0.7563\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"modified Susceptible-Exposed-Infectious-Recovered (SEIR) transmission model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Rohingya refugee camps of Bangladesh\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"modified Susceptible-Exposed-Infectious-Recovered (SEIR) transmission model\\" } } ]","publish_time":"2021-02-05 00:00:00","cluster_id":"1506"},{"main_cord_uid":"sy1eztce","cord_uid":"sy1eztce","abstract":"Global efforts to prevent the spread of the SARS-COV-2 pandemic in early 2020 focused on non-pharmaceutical interventions like social distancing; policies that aim to reduce transmission by changing mixing patterns between people. As countries have implemented these interventions, aggregated location data from mobile phones have become an important source of real-time information about human mobility and behavioral changes on a population level. Human activity measured using mobile phones reflects the aggregate behavior of a subset of people, and although metrics of mobility are related to contact patterns between people that spread the coronavirus, they do not provide a direct measure. In this study, we use results from a nowcasting approach from 1,396 counties across the US between January 22nd, 2020 and July 9th, 2020 to determine the effective reproductive number (R(t)) along an urban/rural gradient. For each county, we compare the time series of R(t) values with mobility proxies from mobile phone data from Camber Systems, an aggregator of mobility data from various providers in the United States. We show that the reproduction number is most strongly associated with mobility proxies for change in the travel into counties compared to baseline, but that the relationship weakens considerably after the initial 15 weeks of the epidemic, consistent with the emergence of a more complex ecosystem of local policies and behaviors including masking. Importantly, we highlight potential issues in the data generation process, representativeness and equity of access which must be addressed to allow for general use of these data in public health.","title":"The relationship between human mobility measures and SAR-Cov-2 transmission varies by epidemic phase and urbanicity: results from the United States","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-04-20 10:00:00"},{"main_cord_uid":"61o5f82j","cord_uid":"61o5f82j","abstract":"BackgroundMonitoring the time-varying reproduction number (Rt) of the disease is useful in determining whether there is sustained transmission in a population. In this study, we examined Rt of COVID-19 and compared its transmissibility between different intervention periods in Hangzhou and Shenzhen. MethodsDaily aggregated counts of confirmed imported and local cases between January 1, 2020 and March 13, 2020 were analysed. A likelihood function was constructed to estimate Rt, accounting for imported cases. ResultsAlthough Hangzhou had fewer number of cases than Shenzhen, Shenzhen had higher proportion of imported cases than Hangzhou (83% vs 29%). Since the epidemic of COVID-19 in Shenzhen was dominated by imported cases, Rt was kept below unity through time. On the contrary, Rt was greater than unity in Hangzhou from 16 January to 7 February due to the surge in local cases. Credits to the Wuhan lockdown and outbreak response measures following the local lockdown, Rt decreased steadily and dropped below unity in mid-February. ConclusionThe lockdown measures and local outbreak responses helped reduce the potential of local transmission in Hangzhou and Shenzhen. Meanwhile, cities with similar epidemic trend could have different transmission dynamics given the variation in imported cases.","title":"Transmissibility of coronavirus disease 2019 (COVID-19) in Chinese cities with different transmission dynamics of imported cases","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-03-18 05:00:00"},{"main_cord_uid":"ikv0xwwp","cord_uid":"ikv0xwwp","abstract":"The Covid-19 outbreak has led countries to implement unprecedented measures to limit virus spread within the population, impacting in particular the organization of workplaces, universities, schools. Yet, the power and limitations of such strategies remain unquantified. Here, we develop a simulation study to analyze Covid-19 transmission on three real-life contact networks from a workplace, a primary school and a high school in France, gathered by SocioPatterns, and assess the impact of organization strategies. Investigated strategies include rotations, which consist in partitioning the individuals into two groups, with a presence switch between groups on a weekly or daily frequency ; and On-Off, which consist in keeping everybody together but alternating presence and telecommuting periods. Assuming baseline non pharmaceutical interventions and reactive isolation of symptomatic cases, all strategies where assessed based on a selection of criteria (outbreak probability, outbreak size, and delay before outbreak) and for reproduction numbers ranging 0.5-2. Our results are clear: whatever the network used, the ranking of the strategies based on their ability to mitigate epidemic propagation in the network from a first index case is always the same, namely, from best to worst: Rotation week-by-week, Rotation day-by-day, On-Off week-by-week, and On-Off day-by-day. The advantage of a weekly alternation over a daily alternation, despite significant, is very slight: for the attack rate when there is an outbreak in a high school for example, the numbers for On-Off are 16.8 vs. 18.4 (out of 327 individuals), a 9% improvement. Our results suggest that when the effective reproduction number R within the network is less than 1.34, therefore assuming concurrent implementation of social distancing and other non pharmaceutical interventions, all four strategies efficiently control the outbreak by decreasing effective R to less than 1; the choice between them should therefore be guided by considerations of practical feasibility.","title":"Analysis of mitigation of Covid-19 outbreaks in workplaces and schools by hybrid telecommuting","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-11-12 05:00:00"},{"main_cord_uid":"ajtq33sh","cord_uid":"ajtq33sh","abstract":"AIM: Comprehensive case investigation and contact tracing are crucial to prevent community spread of COVID-19. We demonstrated a utility of using traditional contact tracing measures supplemented with symptom tracking and contact management system to assist public health workers with high efficiency. METHODS: A centralized contact tracing system was developed to support data linkage, cross-jurisdictional coordination, and follow-up of contacts\' health status. We illustrated the process of how digital tools support contact tracing and management of COVID-19 cases and measured the timeliness from case detection to contact monitoring to evaluate system performance. RESULTS: Among the 8051 close contacts of the 487 confirmed cases (16.5 close contacts/case, 95% CI [13.9-19.1]), the median elapsed time from last exposure to quarantine was three days (IQR 1-5). By implementing the approach of self-reporting using automatic text-messages and web-app, the percentage of health status updates from self-reporting increased from 22.5% to 61.5%. The high proportion of secondary cases detected via contact tracing (88%) might reduce the R0 to under one and minimize the impact of local transmission in the community. CONCLUSION: Comprehensive contact tracing and management with complementary technology would still be a pillar of strategies for containing outbreaks during de-escalation or early in the next wave of COVID-19 pandemic.","title":"Contact tracing with digital assistance in Taiwan\'s COVID-19 outbreak response","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"edpxab9w","cord_uid":"edpxab9w","abstract":"Intestinal microbiota can indirectly modulate airway physiology and immunity through the gut-lung axis. Recent microbiome studies indicate that patients with coronavirus disease 2019 (COVID-19) exhibit a specific intestinal dysbiosis that is closely associated with the disease pathophysiology. Therefore, rebalancing the intestinal microbiome using probiotics may be effective for controlling COVID-19. However, the rationale for using probiotics in COVID-19 remains unclear. In the present study, an in vitro cytokine response assay was conducted, followed by a single-arm, double-blind, prospective trial to evaluate the immunological efficacy of probiotic lactic acid bacteria against COVID-19. The present study focused on Lactobacillus plantarum (L. plantarum), Bifidobacterium longum and Lactococcus lactis ssp. lactis, which exhibit robust protective effects against infection with respiratory RNA viruses. Considering the feasibility of long-term daily intake for prophylactic purposes, healthy uninfected individuals were enrolled as subjects. Our previous pilot trial demonstrated that oral Qingfei Paidu decoction (QFPD), a Chinese herbal medicine formulated specifically against COVID-19, upregulates plasma TNF-\xc3\u017d\xc2\xb1, IL-1\xc3\u017d\xc2\xb2, IL-18 and IL-8. Therefore, the present study utilized the cytokine changes induced by QFPD to define the innate cytokine index QICI [=(TNF-\xc3\u017d\xc2\xb1) x (IL-1\xc3\u017d\xc2\xb2) x (IL-18) x (IL-8)/(IL-6)] as an indicator of the anti-COVID-19 immunomodulatory potential of the lactic acid bacteria. A total of 20 eligible volunteers were enrolled, 18 of whom completed the intervention. L. plantarum demonstrated a strikingly high innate cytokine index in all subjects in the in vitro cytokine response assay. In the subsequent trial, oral intake of L. plantarum significantly increased the innate cytokine index (mean fold change, 17-fold; P=0.0138) and decreased the plasma level of IL-6 (P=0.0128), a key driver of complex immune dysregulation in COVID-19, as compared with the baseline. The cytokine index increased in 16 of 18 subjects (88.9%) with considerable individual differences in the fold change (1- to 128-fold). In line with these innate cytokine changes, L. plantarum ingestion significantly enhanced the activity of natural killer cells. By contrast, oral B. longum failed to induce a significant increase in the innate cytokine index (mean fold change, 2-fold; P=0.474) as compared with the baseline. In conclusion, L. plantarum demonstrated superior QFPD-like immunomodulatory ability and mimicked the blood cytokine environment produced by early immune responses to viral infection. Daily consumption of L. plantarum as an anti-COVID-19 probiotic may be a possible option for preventing COVID-19 during the pandemic. The present study was prospectively registered in the University Hospital Medical Information Network-Clinical Trials Registry under the trial number UMIN000040479 on 22 May 2020 (https://upload.umin.ac.jp/cgi-open-bin/ctr_e/ctr_view.cgi?recptno=R000046202).","title":"Lactobacillus plantarum induces innate cytokine responses that potentially provide a protective benefit against COVID-19: A single-arm, double-blind, prospective trial combined with an in vitro cytokine response assay","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-11-02 05:00:00"},{"main_cord_uid":"efbt2xx0","cord_uid":"efbt2xx0","abstract":"Estimates of the reproductive number for novel pathogens such as severe acute respiratory syndrome coronavirus 2 are essential for understanding the potential trajectory of the epidemic and the level of intervention that is needed to bring the epidemic under control. However, most methods for estimating the basic reproductive number (R0) and time-varying effective reproductive number (Rt) assume that the fraction of cases detected and reported is constant through time. We explore the impact of secular changes in diagnostic testing and reporting on estimates of R0 and Rt using simulated data. We then compare these patterns to data on reported cases of coronavirus disease and testing practices from different states in the United States from March 4 to August 30, 2020. We find that changes in testing practices and delays in reporting can result in biased estimates of R0 and Rt. Examination of changes in the daily number of tests conducted and the percent of patients testing positive may be helpful for identifying the potential direction of bias. Changes in diagnostic testing and reporting processes should be monitored and taken into consideration when interpreting estimates of the reproductive number of coronavirus disease.","title":"The Impact of Changes in Diagnostic Testing Practices on Estimates of COVID-19 Transmission in the United States","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"6sqgqttc","cord_uid":"6sqgqttc","abstract":"The outbreak of COVID-19, caused by the SARS-CoV-2 coronavirus, has been declared a pandemic by the World Health Organization (WHO) in March, 2020 and rapidly spread to over 210 countries and territories around the world. By December 24, there are over 77M cumulative confirmed cases with more than 1.72M deaths worldwide. To mathematically describe the dynamic of the COVID-19 pandemic, we propose a time-dependent SEIR model considering the incubation period. Furthermore, we take immunity, reinfection, and vaccination into account and propose the SEVIS model. Unlike the classic SIR based models with constant parameters, our dynamic models not only predicts the number of cases, but also monitors the trajectories of changing parameters, such as transmission rate, recovery rate, and the basic reproduction number. Tracking these parameters, we observe the significant decrease in the transmission rate in the U.S. after the authority announced a series of orders aiming to prevent the spread of the virus, such as closing non-essential businesses and lockdown restrictions. Months later, as restrictions being gradually lifted, we notice a new surge of infection emerges as the transmission rates show increasing trends in some states. Using our epidemiology models, people can track, timely monitor, and predict the COVID-19 pandemic with precision. To illustrate and validate our model, we use the national level data (the U.S.) and the state level data (New York and North Dakota), and the resulting relative prediction errors for the infected group and recovered group are mostly lower than 0.5%. We also simulate the long-term development of the pandemic based on our proposed models to explore when the crisis will end under certain conditions.","title":"Toward the Impact of Non-pharmaceutical Interventions and Vaccination on the COVID-19 Pandemic With Time-Dependent SEIR Model","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-03-18 05:00:00"},{"main_cord_uid":"q4jbqsh1","cord_uid":"q4jbqsh1","abstract":"World Health Organization (WHO) has declared COVID-19 a pandemic on March 11, 2020. As of May 23, 2020, according to WHO, there are 213 countries, areas or territories with COVID-19 positive cases. To effectively address this situation, it is imperative to have a clear understanding of the COVID-19 transmission dynamics and to concoct efficient control measures to mitigate/contain the spread. In this work, the COVID-19 dynamics is modelled using susceptible\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153exposed\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153infectious\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u0153removed model with a nonlinear incidence rate. In order to control the transmission, the coefficient of nonlinear incidence function is adopted as the Governmental control input. To adequately understand the COVID-19 dynamics, bifurcation analysis is performed and the effect of varying reproduction number on the COVID-19 transmission is studied. The inadequacy of an open-loop approach in controlling the disease spread is validated via numerical simulations and a robust closed-loop control methodology using sliding mode control is also presented. The proposed SMC strategy could bring the basic reproduction number closer to 1 from an initial value of 2.5, thus limiting the exposed and infected individuals to a controllable threshold value. The model and the proposed control strategy are then compared with real-time data in order to verify its efficacy.","title":"Dynamics and control of COVID-19 pandemic with nonlinear incidence rates","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"-\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"closer to 1\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"susceptible-exposed-infectious-removed model with a nonlinear incidence rate\\" } } ]","publish_time":"2020-06-25 10:00:00"},{"main_cord_uid":"9xmsu5m9","cord_uid":"9xmsu5m9","abstract":"The current worldwide pandemic produced by coronavirus disease 2019 (COVID-19) has changed the paradigm of mathematical epidemiology due to the high number of unknowns of this new disease. Thus, the empirical approach has emerged as a robust tool to analyze the actual situation carried by the countries and also allows us to predict the incoming scenarios. In this paper, we propose three empirical indexes to estimate the state of the pandemic. These indexes quantify both the propagation and the number of estimated cases, allowing us to accurately determine the real risk of a country. We have calculated these indexes\' evolution for several European countries. Risk diagrams are introduced as a tool to visualize the evolution of a country and evaluate its current risk as a function of the number of contagious individuals and the empiric reproduction number. Risk diagrams at the regional level are useful to observe heterogeneity on COVID-19 penetration and spreading in some countries, which is essential during deconfinement processes. During the pandemic, there have been significant differences seen in countries reporting case criterion and detection capacity. Therefore, we have introduced estimations about the real number of infectious cases that allows us to have a broader view and to better estimate the risk. These diagrams and indexes have been successfully used for the monitoring of European countries and regions during the COVID-19 pandemic.","title":"Monitoring and Analysis of COVID-19 Pandemic: The Need for an Empirical Approach","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-07-08 10:00:00"},{"main_cord_uid":"jikjwrdj","cord_uid":"jikjwrdj","abstract":"India has been the latest global epicenter for COVID-19, a novel coronavirus disease that emerged in China in late 2019. We present a base mathematical model for the transmission dynamics of COVID-19 in India and its neighbour, Pakistan. The base model, which takes the form of a deterministic system of nonlinear differential equations, is parameterized using cumulative COVID-19 mortality data from each of the two countries. The model was used to assess the population-level impact of the control and mitigation strategies implemented in the two countries (notably community lockdowns, use of face masks, and social-distancing). Numerical simulations of the basic model indicate that, based on the current baseline levels of the control and mitigation strategies implemented, the pandemic trajectory in India is on a downward trend (as characterized by the reproduction number of the disease dynamics in India below, but close to, unity). This downward trend will be reversed, and India will be recording mild outbreaks (i.e., pandemic waves), if the control and mitigation strategies are relaxed from their current levels (e.g., relaxed to the extent that the associated community transmission parameters are increased by 20% or 40% from their current baseline values). Our simulations suggest that India could record up to 460,000 cumulative deaths by early September 2021 under the baseline levels of the control strategies implemented (up to 25,000 of the projected deaths could be averted if the control and mitigation measures are strengthened to the extent that the associated community transmission parameters are reduced by 20% from their baseline values). Our simulations show that the pandemic in Pakistan is much milder, with an estimated projected cumulative mortality of about 24,000 by early September 2021 under the baseline scenario. The basic model was extended to assess the impact of back-and-forth mobility between the two countries. Simulations of the resulting metapopulation model show that the burden of the COVID-19 pandemic in Pakistan increases with increasing values of the average time residents of India spend in Pakistan. In particular, it is shown that the India- to-Pakistan mobility pattern may trigger a fourth wave of the pandemic in Pakistan (under certain mobility scenarios), with daily mortality peaking in mid-August to mid-September of 2021. Under the respective baseline control scenarios, our simulations show that the back-and-forth mobility between India and Pakistan could delay the time-to-elimination of the COVID-19 pandemic in the two countries by three to five months (specifically, under the respective baseline scenarios, elimination could be delayed in India and Pakistan to November 2022 and July 2022, respectively).","title":"Dynamics of COVID-19 pandemic in India and Pakistan: A metapopulation modelling approach","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"utng9v48","cord_uid":"utng9v48","abstract":"BACKGROUND: The isolation of symptomatic cases and tracing of contacts has been used as an early COVID-19 containment measure in many countries, with additional physical distancing measures also introduced as outbreaks have grown. To maintain control of infection while also reducing disruption to populations, there is a need to understand what combination of measures-including novel digital tracing approaches and less intensive physical distancing-might be required to reduce transmission. We aimed to estimate the reduction in transmission under different control measures across settings and how many contacts would be quarantined per day in different strategies for a given level of symptomatic case incidence. METHODS: For this mathematical modelling study, we used a model of individual-level transmission stratified by setting (household, work, school, or other) based on BBC Pandemic data from 40\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020162 UK participants. We simulated the effect of a range of different testing, isolation, tracing, and physical distancing scenarios. Under optimistic but plausible assumptions, we estimated reduction in the effective reproduction number and the number of contacts that would be newly quarantined each day under different strategies. RESULTS: We estimated that combined isolation and tracing strategies would reduce transmission more than mass testing or self-isolation alone: mean transmission reduction of 2% for mass random testing of 5% of the population each week, 29% for self-isolation alone of symptomatic cases within the household, 35% for self-isolation alone outside the household, 37% for self-isolation plus household quarantine, 64% for self-isolation and household quarantine with the addition of manual contact tracing of all contacts, 57% with the addition of manual tracing of acquaintances only, and 47% with the addition of app-based tracing only. If limits were placed on gatherings outside of home, school, or work, then manual contact tracing of acquaintances alone could have an effect on transmission reduction similar to that of detailed contact tracing. In a scenario where 1000 new symptomatic cases that met the definition to trigger contact tracing occurred per day, we estimated that, in most contact tracing strategies, 15\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020000-41\xc3\u0192\xc2\xa2\xc3\u201a\xe2\u201a\xac\xc3\u201a\xcb\u2020000 contacts would be newly quarantined each day. INTERPRETATION: Consistent with previous modelling studies and country-specific COVID-19 responses to date, our analysis estimated that a high proportion of cases would need to self-isolate and a high proportion of their contacts to be successfully traced to ensure an effective reproduction number lower than 1 in the absence of other measures. If combined with moderate physical distancing measures, self-isolation and contact tracing would be more likely to achieve control of severe acute respiratory syndrome coronavirus 2 transmission. FUNDING: Wellcome Trust, UK Engineering and Physical Sciences Research Council, European Commission, Royal Society, Medical Research Council.","title":"Effectiveness of isolation, testing, contact tracing, and physical distancing on reducing transmission of SARS-CoV-2 in different settings: a mathematical modelling study","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"amynknk5","cord_uid":"amynknk5","abstract":"We develop a mathematical model to estimate the effect of New Zealand\xc3\xa2\xe2\u201a\xac\xe2\u201e\xa2s vaccine rollout on the potential spread and health impacts of COVID-19. The main purpose of this study is to provide a basis for policy advice on border restrictions and control measures in response to outbreaks that may occur during the vaccination roll-out. The model can be used to estimate the theoretical population immunity threshold, which represents a point in the vaccine rollout at which border restrictions and other controls could be removed and only small, occasional outbreaks would take place. We find that, with a basic reproduction number of 6, approximately representing the Delta variant of SARS-CoV-2, and under baseline vaccine effectiveness assumptions, reaching the population immunity threshold would require close to 100% of the total population to be vaccinated. Since this coverage is not likely to be achievable in practice, relaxing controls completely would risk serious health impacts. However, the higher vaccine coverage is, the more collective protection the population has against adverse health outcomes from COVID-19, and the easier it will become to control outbreaks. There remains considerable uncertainty in model outputs, in part because of the potential for the evolution of new variants. If new variants arise that are more transmissible or vaccine resistant, an increase in vaccine coverage will be needed to provide the same level of protection.","title":"A COVID-19 vaccination model for Aotearoa New Zealand","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2022-02-17 05:00:00"},{"main_cord_uid":"4izymiy4","cord_uid":"4izymiy4","abstract":"Population density, behaviour and cultural habits strongly influence the spread of pathogens. Consequently, key epidemiological parameters may vary from country to country. Confirmed COVID-19 cases in in China have been used to estimate those parameters, that vary largely (reviewed in 1). The estimates also depend on testing frequency and case definitions that are prone to change during ongoing epidemics, providing additional uncertainties. The rise in fatal cases due to SARS-CoV2 could be a more reliable parameter, since missing of deaths is less likely. In the absence of changes in the management of severe COVID-19 cases, the rise in death cases should be proportional to the rise in virus infections. Although the fluctuating low numbers of fatal cases very early in the epidemic may lead to some uncertainty, more than 100 deaths per day are reported since 10.03.2020 in Italy and since 21.03.2020 in the US. Therefore, the dynamics of deaths were analysed to estimate the daily reproduction numbers (Rt) and the effectiveness of control measures. Thus, our analysis provides evidence that basic epidemiological parameters differ between countries to an extent compromising epidemiological predictions of the pandemic. It also suggests that suppression of spread in Italy and the US may be more difficult to achieve. Although we assume that variations in social behaviour are responsible for the different estimates of R0, selection of more rapidly spreading variants of SARS-CoV-2 cannot be excluded. Despite uncertainty in the reliability of the data used and lack of information on possible changes in the effectiveness of registration of COVID-19 deaths during the observation period, our findings should be considered as a working hypothesis demanding further investigations. As the number of deaths rapidly increases worldwide, we encourage more sophisticated modelling of the epidemic based on the dynamics of death cases by experts in the field.","title":"Determination of daily reproduction numbers of SARS-CoV2 based on death cases suggests more rapid initial spread in Italy and the United States","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-03-31 10:00:00"},{"main_cord_uid":"v4mbry22","cord_uid":"v4mbry22","abstract":"As reported by the World Health Organization, a novel coronavirus (2019-nCoV) was identified as the causative virus of Wuhan pneumonia of unknown etiology by Chinese authorities on 7 January, 2020. In this study, we developed a Bats-Hosts-Reservoir-People transmission network model for simulating the potential transmission from the infection source (probable be bats) to the human infection. Since the Bats-Hosts-Reservoir network was hard to explore clearly and public concerns were focusing on the transmission from a seafood market (reservoir) to people, we simplified the model as Reservoir-People transmission network model. The basic reproduction number (R0) was calculated from the RP model to assess the transmissibility of the 2019-nCoV.","title":"A mathematical model for simulating the transmission of Wuhan novel Coronavirus","annotator_investigating_R0":"0","text_response":"disease name: 2019-nCoV\\r\\nlocation: -\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: Reservoir-People transmission network model.","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"2019-nCoV\\",\\r\\n\\"location\\": \\"-\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"Reservoir-People transmission network model.\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"2019-nCoV\\", \\"location\\": \\"Wuhan\\", \\"date\\": \\"7 January, 2020\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"Reservoir-People transmission network model\\" } } ]","publish_time":"2020-01-19 05:00:00"},{"main_cord_uid":"nomcp6no","cord_uid":"nomcp6no","abstract":"The tempo-spatial patterns of Covid-19 infections are a result of nested personal, societal, and political decisions that involve complicated epidemiological dynamics across overlapping spatial scales. High infection \\"hotspots\\" interspersed within regions where infections remained sporadic were ubiquitous early in the outbreak, but the spatial signature of the infection evolved to affect most regions equally, albeit with distinct temporal patterns. The sparseness of Covid-19 infections in the United States was analyzed at scales spanning from 10 to 2,600 km (county to continental scale). Spatial evolution of Covid-19 cases in the United States followed multifractal scaling. A rapid increase in the spatial correlation was identified early in the outbreak (March to April). Then, the increase continued at a slower rate and approached the spatial correlation of human population. Instead of adopting agent-based models that require tracking of individuals, a kernel-modulated approach is developed to characterize the dynamic spreading of disease in a multifractal distributed susceptible population. Multiphase Covid-19 epidemics were reasonably reproduced by the proposed kernel-modulated susceptible-infectious-recovered (SIR) model. The work explained the fact that while the reproduction number was reduced due to nonpharmaceutical interventions (e.g., masks, social distancing, etc.), subsequent multiple epidemic waves still occurred; this was due to an increase in susceptible population flow following a relaxation of travel restrictions and corollary stay-at-home orders. This study provides an original interpretation of Covid-19 spread together with a pragmatic approach that can be imminently used to capture the spatial intermittency at all epidemiologically relevant scales while preserving the \\"disordered\\" spatial pattern of infectious cases.","title":"A kernel-modulated SIR model for Covid-19 contagious spread from county to continent","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021"},{"main_cord_uid":"yk89gmcl","cord_uid":"yk89gmcl","abstract":"34,354,966 active cases and 460,787 deaths because of COVID-19 pandemic were recorded on November 06, 2021, in India. To end this ongoing global COVID-19 pandemic, there is an urgent need to implement multiple population-wide policies like social distancing, testing more people and contact tracing. To predict the course of the pandemic and come up with a strategy to control it effectively, a compartmental model has been established. The following six stages of infection are taken into consideration: susceptible (S), asymptomatic infected (A), clinically ill or symptomatic infected (I), quarantine (Q), isolation (J) and recovered (R), collectively termed as SAIQJR. The qualitative behavior of the model and the stability of biologically realistic equilibrium points are investigated in terms of the basic reproduction number. We performed sensitivity analysis with respect to the basic reproduction number and obtained that the disease transmission rate has an impact in mitigating the spread of diseases. Moreover, considering the non-pharmaceutical and pharmaceutical intervention strategies as control functions, an optimal control problem is implemented to mitigate the disease fatality. To reduce the infected individuals and to minimize the cost of the controls, an objective functional has been constructed and solved with the aid of Pontryagin\xc3\xa2\xe2\u201a\xac\xe2\u201e\xa2s maximum principle. The implementation of optimal control strategy at the start of a pandemic tends to decrease the intensity of epidemic peaks, spreading the maximal impact of an epidemic over an extended time period. Extensive numerical simulations show that the implementation of intervention strategy has an impact in controlling the transmission dynamics of COVID-19 epidemic. Further, our numerical solutions exhibit that the combination of three controls are more influential when compared with the combination of two controls as well as single control. Therefore, the implementation of all the three control strategies may help to mitigate novel coronavirus disease transmission at this present epidemic scenario. SUPPLEMENTARY INFORMATION: The online version supplementary material available at 10.1007/s11071-022-07235-7.","title":"Mathematical modeling and optimal intervention strategies of the COVID-19 outbreak","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"India\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"compartmental model\\" } } ]","publish_time":"2022-01-30 05:00:00"},{"main_cord_uid":"vvn7sthi","cord_uid":"vvn7sthi","abstract":"BACKGROUND: TG01 is the first cancer immunotherapy targeting KRAS oncogenic mutations. This study assessed the safety and efficacy of TG01/GM-CSF in patients with resected pancreatic adenocarcinoma. METHODS: Patients with stage I or II pancreatic adenocarcinoma who had undergone surgical resection (R0 or R1) received adjuvant gemcitabine with TG01/GM-CSF using two schedules of vaccination. Immune response was defined as a positive delayed-type hypersensitivity (DTH) response and/or positive T-cell proliferation assay. RESULTS: Thirty-two patients were enrolled between February 2013 and May 2016. Nineteen were treated with the high antigen burden, with four serious adverse reactions considered possibly related to TG01 treatment, including three allergic reactions. On this basis, a further 13 patients received a modified vaccination schedule with reduced antigen burden, with no serious adverse events related to TG01. Ninety-five percent patients in the main cohort and 92% in the modified cohort had a positive immune response. Median overall survival (OS) was 33.1 months, and median disease-free survival (DFS) was 13.9 months for the main cohort. For the modified cohort, the median OS was 34.3 months and median DFS was 19.5 months. CONCLUSIONS: TG01/GM-CSF with gemcitabine was well tolerated, with high levels of immune activation. OS and DFS compare favourably with published data for adjuvant gemcitabine. CLINICAL TRIAL REGISTRATION: This clinical trial was registered at ClinicalTrials.gov (NCT02261714).","title":"TG01/GM-CSF and adjuvant gemcitabine in patients with resected RAS-mutant adenocarcinoma of the pancreas (CT TG01-01): a single-arm, phase 1/2 trial","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-02-17 00:00:00"},{"main_cord_uid":"i2mafyzi","cord_uid":"i2mafyzi","abstract":"Abstract Introduction: The COVID-19 has emerged as a global concern for public health due to large scale outbreak. The number of confirmed cases has also been increased in India in the past few weeks. The predictions for the COVID-19 can provide insights into the epidemiology of the disease, which helps policymakers to check health system capacities. Methods: We obtained data on daily confirmed, recovered and death cases for a period of 21 days and have implemented the exponential growth model to predict future cases for all the three components. The mathematical model was used to calculate the average reproduction number and herd immunity. We estimated the number of active cases till the 30th of April. We have also tried to analyze the public health capacity to combat COVID-19 in India. Results: If the exponential growth in the number of cases continues then the total number of active cases will be 2,49,635 until the end of April. The reproduction number for COVID-19 in India was found to be 2.56 and herd immunity as 61%. The cumulative cases predicted by the mathematical model was 1,20,203. Discussion: This prediction provides an alarming situation for India in terms of public health preparedness. The number of tests is needed to increase to detect all the cases of COVID-19 in India. Though some serious preventive measures have been implemented, but India should be ready to face any sudden community outbreak. Keywords: COVID-19, India, predictions, reproduction number, public health capacity","title":"COVID-19 in India: Predictions, Reproduction Number and Public Health Preparedness","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: India\\r\\ndate: until the end of April\\r\\nR0 value: 2.56\\r\\n%CI values: -\\r\\nmethod: mathematical model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"India\\",\\r\\n\\"date\\": \\"until the end of April\\",\\r\\n\\"R0 value\\": \\"2.56\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"mathematical model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"India\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"2.56\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"exponential growth model\\" } } ]","publish_time":"2020-04-14 10:00:00"},{"main_cord_uid":"w502ylcu","cord_uid":"w502ylcu","abstract":"BACKGROUND: Atopic dermatitis is a chronic, inflammatory condition causing a substantial burden to patients and caregivers. SHR0302 is an oral, highly selective, Janus kinase 1 inhibitor under investigation for inflammatory skin diseases. OBJECTIVE: The aim of this study was to investigate the efficacy and safety of SHR0302 in Chinese patients with moderate to severe atopic dermatitis. DESIGN AND SETTING: A randomized, double-blind, placebo-controlled, multicenter, phase II trial was conducted in China between October 2019 and August 2020. PARTICIPANTS: Patients (n = 105) aged 18\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u015375 years with moderate to severe dermatitis and nonresponsive or intolerant to topical or conventional systemic treatments were included. INTERVENTIONS: Patients were randomly assigned in a ratio of 1:1:1 to receive SHR0302 4 mg once daily, SHR0302 8 mg once daily, or placebo for 12 weeks. MAIN OUTCOME MEASURES: The primary efficacy endpoint was the proportion of patients achieving Investigator\xc3\xa2\xe2\u201a\xac\xe2\u201e\xa2s Global Assessment (IGA) response (IGA of 0 [clear] or 1 [almost clear] with improvement of \xc3\xa2\xe2\u20ac\xb0\xc2\xa52 grades) at week 12. Secondary efficacy assessments included Eczema Area and Severity Index (EASI) and pruritus Numerical Rating Scale (NRS) scores. RESULTS: At week 12, IGA response was achieved in nine patients (25.7%; 90% confidence interval [CI] 13.6\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u015337.9%; p = 0.022) in the SHR0302 4 mg group, 19 patients (54.3%; 90% CI 40.4\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u015368.1%; p < 0.001) in the SHR0302 8 mg group, and two patients (5.7%; 90% CI 0.0\xc3\xa2\xe2\u201a\xac\xe2\u20ac\u015312.2%) in the placebo group. EASI75 was achieved in 51.4% (p = 0.013), 74.3% (p < 0.001), and 22.9% of patients in the SHR0302 4 mg, SHR0302 8 mg, and placebo groups, respectively, while an NRS \xc3\xa2\xe2\u20ac\xb0\xc2\xa53-point improvement occurred in 65.7% (p < 0.001), 74.3% (p < 0.001), and 22.9% of patients, respectively. Treatment-emergent adverse events were reported in 60.0%, 68.6%, and 51.4% of patients in the SHR0302 4 mg, SHR0302 8 mg, and placebo groups, respectively. The adverse events were mild in most cases. Three serious adverse events were reported, all being worsening of atopic dermatitis. No serious infection was reported. CONCLUSIONS AND RELEVANCE: Oral SHR0302 was effective and well tolerated in Chinese adult patients with moderate to severe atopic dermatitis. TRIAL REGISTRATION: ClinicalTrials.gov identifier: NCT04162899; URL: https://clinicaltrials.gov/. Date first registered: 14 November 2019. SUPPLEMENTARY INFORMATION: The online version contains supplementary material available at 10.1007/s40257-021-00627-2.","title":"Efficacy and Safety of SHR0302, a Highly Selective Janus Kinase 1 Inhibitor, in Patients with Moderate to Severe Atopic Dermatitis: A Phase II Randomized Clinical Trial","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2021-08-09 10:00:00"},{"main_cord_uid":"75sy3fiz","cord_uid":"75sy3fiz","abstract":"BACKGROUND: With the sensitivity of the polymerase chain reaction test used to detect the presence of the virus in the human host, the worldwide health community has been able to record a large number of the recovered population. OBJECTIVE: The aim of this study was to evaluate the probability of reinfection in the recovered class and the model equations, which exhibits the disease-free equilibrium state for the coronavirus disease. METHODS: The model differential equation was evaluated for the disease-free equilibrium for the case of reinfection as well as the existence and stability criteria for the disease, using the model proportions. This evaluation shows that the criteria for a local or worldwide asymptotic stability with a basic reproductive number (R0=0) were satisfied. Hence, there is a chance of no secondary reinfections from the recovered population, as the rate of incidence of the recovered population vanishes (ie, B=0). RESULTS: With a total of about 900,000 infected cases worldwide, numerical simulations for this study were carried out to complement the analytical results and investigate the effect that the implementation of quarantine and observation procedures has on the projection of further virus spread. CONCLUSIONS: As shown by the results, the proportion of the infected population, in the absence of a curative vaccination, will continue to grow worldwide; meanwhile, the recovery rate will continue slowly, which means that the ratio of infection rate to recovery rate will determine the death rate that is recorded. Most significant for this study is the rate of reinfection by the recovered population, which will decline to zero over time as the virus is cleared clinically from the system of the recovered class.","title":"Estimation of the Probability of Reinfection With COVID-19 by the Susceptible-Exposed-Infectious-Removed-Undetectable-Susceptible Model","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020","cluster_id":"354"},{"main_cord_uid":"jwb9n00x","cord_uid":"jwb9n00x","abstract":"Humoral responses in COVID-19 disease are often of limited durability, as seen with other human coronavirus epidemics. To address the underlying etiology, we examined postmortem thoracic lymph nodes and spleens in acute SARS-CoV-2 infection and observed the absence of germinal centers, a striking reduction in Bcl-6+ germinal center B cells but preservation of AID+ B cells. Absence of germinal centers correlated with an early specific block in Bcl-6+TFH cell differentiation together with an increase in T-bet+TH1 cells and aberrant extra-follicular TNF-a accumulation. Parallel peripheral blood studies revealed loss of transitional and follicular B cells in severe disease and accumulation of SARS-CoV-2-specific \\"disease-related\\" B cell populations. These data identify defective Bcl-6+TFH cell generation and dysregulated humoral immune induction early in COVID-19 disease, providing a mechanistic explanation for the limited durability of antibody responses in coronavirus infections and suggest that achieving herd immunity through natural infection may be difficult. Funding: This work was supported by NIH U19 AI110495 to SP, NIH R01 AI146779 to AGS, NIH R01AI137057 and DP2DA042422 to DL, BMH was supported by NIGMS T32 GM007753, TMC was supported by T32 AI007245. Funding for these studies from the Massachusetts Consortium of Pathogen Readiness, the Mark and Lisa Schwartz Foundation and Enid Schwartz is also acknowledged. Conflict of Interest: None. Ethical Approval: This study was performed with the approval of the Institutional Review Boards at the Massachusetts General Hospital and the Brigham and Women\'s Hospital.","title":"The Loss of Bcl-6 Expressing T Follicular Helper Cells and the Absence of Germinal Centers in COVID-19","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"1nkoogxn","cord_uid":"1nkoogxn","abstract":"As the novel coronavirus (SARS-CoV-2) continues to spread rapidly across the globe, we aimed to identify and summarize the existing evidence on epidemiological characteristics of SARS-CoV-2 and the effectiveness of control measures to inform policymakers and leaders in formulating management guidelines, and to provide directions for future research. We conducted a systematic review of the published literature and preprints on the coronavirus disease (COVID-19) outbreak following predefined eligibility criteria. Of 317 research articles generated from our initial search on PubMed and preprint archives on 21 February 2020, 41 met our inclusion criteria and were included in the review. Current evidence suggests that it takes about 3-7 days for the epidemic to double in size. Of 21 estimates for the basic reproduction number ranging from 1.9 to 6.5, 13 were between 2.0 and 3.0. The incubation period was estimated to be 4-6 days, whereas the serial interval was estimated to be 4-8 days. Though the true case fatality risk is yet unknown, current model-based estimates ranged from 0.3% to 1.4% for outside China. There is an urgent need for rigorous research focusing on the mitigation efforts to minimize the impact on society.","title":"A Systematic Review of COVID-19 Epidemiology Based on Current Evidence","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020"},{"main_cord_uid":"mddbbge4","cord_uid":"mddbbge4","abstract":"The outbreak of COVID-19 was first reported from China, and on 19 February 2020, the first case was confirmed in Qom, Iran. The basic reproduction number (R0 ) of infection is variable in different populations and periods. This study aimed to estimate the R0 of COVID-19 in Qom, Iran, and compare it with that in other countries. For estimation of the serial interval, we used data of the 51 confirmed cases of COVID-19 and their 318 close contacts in Qom, Iran. The number of confirmed cases daily in the early phase of the outbreak and estimated serial interval were used for R0 estimation. We used the time-varying method as a method with the least bias to estimate R0 in Qom, Iran, and in China, Italy and South Korea. The serial interval was estimated with a gamma distribution, a mean of 4.55 days and a standard deviation of 3.30 days for the COVID-19 epidemic based on Qom data. The R0 in this study was estimated to be between 2 and 3 in Qom. Of the four countries studied, the lowest R0 was estimated in South Korea (1.5-2) and the highest in Iran (4-5). Sensitivity analyses demonstrated that R0 is sensitive to the applied mean generation time. To the best of the authors\' knowledge, this study is the first to estimate R0 in Qom. To control the epidemic, the reproduction number should be reduced by decreasing the contact rate, decreasing the transmission probability and decreasing the duration of the infectious period.","title":"Estimation of the serial interval and basic reproduction number of COVID-19 in Qom, Iran, and three other countries: A data-driven analysis in the early phase of the outbreak","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Qom, Iran\\r\\ndate: early phase of the outbreak\\r\\nR0 value: 2 and 3\\r\\n%CI values: -\\r\\nmethod: time-varying method\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: South Korea\\r\\ndate: early phase of the outbreak\\r\\nR0 value: 1.5-2\\r\\n%CI values: -\\r\\nmethod: time-varying method\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Iran\\r\\ndate: early phase of the outbreak\\r\\nR0 value: 4-5\\r\\n%CI values: -\\r\\nmethod: time-varying method\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: China\\r\\ndate: early phase of the outbreak\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: time-varying method\\r\\n|\\r\\ndisease name: COVID-19\\r\\nlocation: Italy\\r\\ndate: early phase of the outbreak\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: time-varying method","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Qom, Iran\\",\\r\\n\\"date\\": \\"early phase of the outbreak\\",\\r\\n\\"R0 value\\": \\"2 and 3\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"time-varying method\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"South Korea\\",\\r\\n\\"date\\": \\"early phase of the outbreak\\",\\r\\n\\"R0 value\\": \\"1.5-2\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"time-varying method\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Iran\\",\\r\\n\\"date\\": \\"early phase of the outbreak\\",\\r\\n\\"R0 value\\": \\"4-5\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"time-varying method\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"China\\",\\r\\n\\"date\\": \\"early phase of the outbreak\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"time-varying method\\"}},{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Italy\\",\\r\\n\\"date\\": \\"early phase of the outbreak\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"time-varying method\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Qom, Iran\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"between 2 and 3\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"time-varying method\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"China, Italy and South Korea\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"time-varying method\\" } }, { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"China, Italy and South Korea\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"time-varying method\\" } } ]","publish_time":"2020","cluster_id":"7"},{"main_cord_uid":"ktjbgcnw","cord_uid":"ktjbgcnw","abstract":"Since COVID-19 was first identified in December 2019, various public health interventions have been implemented across the world. As different measures are implemented at different countries at different times, we conduct an assessment of the relative effectiveness of the measures implemented in 18 countries and regions using data from 22/01/2020 to 02/04/2020. We compute the top one and two measures that are most effective for the countries and regions studied during the period. Two Explainable AI techniques, SHAP and ECPI, are used in our study; such that we construct (machine learning) models for predicting the instantaneous reproduction number ($R_t$) and use the models as surrogates to the real world and inputs that the greatest influence to our models are seen as measures that are most effective. Across-the-board, city lockdown and contact tracing are the two most effective measures. For ensuring $R_t<1$, public wearing face masks is also important. Mass testing alone is not the most effective measure although when paired with other measures, it can be effective. Warm temperature helps for reducing the transmission.","title":"An Investigation of COVID-19 Spreading Factors with Explainable AI Techniques","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"unanswerable","publish_time":"2020-05-05 10:00:00"},{"main_cord_uid":"qpcqj2it","cord_uid":"qpcqj2it","abstract":"An outbreak of coronavirus disease began in a large penitentiary complex in Brazil on April 1, 2020. By June 12, there were 1,057 confirmed cases among inmates and staff. Nine patients were hospitalized, and 3 died. Mean serial interval was &#8776;2.5 days; reproduction number range was 1.0-2.3.","title":"COVID-19 Outbreak in a Large Penitentiary Complex, April-June 2020, Brazil","annotator_investigating_R0":"1","text_response":"disease name: coronavirus disease\\r\\nlocation: large penitentiary complex in Brazil\\r\\ndate: on April 1, 2020. By June 12\\r\\nR0 value: 1.0-2.3\\r\\n%CI values: -\\r\\nmethod: -","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"coronavirus disease\\",\\r\\n\\"location\\": \\"large penitentiary complex in Brazil\\",\\r\\n\\"date\\": \\"on April 1, 2020. By June 12\\",\\r\\n\\"R0 value\\": \\"1.0-2.3\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"-\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"Large Penitentiary Complex, Brazil\\", \\"date\\": \\"April-June 2020\\", \\"R0 value\\": \\"1.0-2.3\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } } ]","publish_time":"2021"},{"main_cord_uid":"tm60ejkc","cord_uid":"tm60ejkc","abstract":"OBJECTIVE: The aim of this study was to systematically review and meta-analyze all literature reporting the basic reproductive number (R0), effective reproductive number (Re or Rt), and the serial interval (SI) values of severe acute respiratory syndrome-coronavirus-2 (SARS-CoV-2) infection. SUMMARY BACKGROUND DATA: To assess the rate at which an infectious disease can spread in a population, the 2 measures, R0 and Re or Rt, are widely used. One of the parameters which influence the calculations is the SI, the period between symptom onset in an infector and an infectee. METHODS: Web of Science, PubMed, Scopus, and Science Direct searching up to May 10, 2020, was performed. A continuous random-effect model was applied using the DerSimonian-Laird (inverse variance) method. Heterogeneity and publication bias were assessed. RESULTS: A total of 39 articles met the eligibility criteria. Our results demonstrated the mean SI was 5.45 days, with the 95% confidence interval (CI) of 4.23 to 6.66. Pooled estimates for reproduction rates was 3.14 (95% CI: 2.69-3.59) for R0 and 3.18 (95% CI: 2.89-3.47) for Rt. Subgroup analysis by geographical region and date of publication revealed variations over both time and geography in calculated R0 and Rt values. As time has progressed, predicted R0 and Rt values had decreased globally. CONCLUSIONS: The study findings indicate that one SARS-CoV-2-infected person is likely to infect 3 persons, supporting that COVID-19 is a highly contagious disease. As an essential objective metrics implied in risk assessment for this emerging pandemic, monitoring R0 and Re is necessary to indicate the effectiveness or failures of mitigation efforts.","title":"Meta-Analysis on Serial Intervals and Reproductive Rates for SARS-CoV-2","annotator_investigating_R0":"-1","text_response":"unanswerable","json_response":"unanswerable","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"-\\", \\"date\\": \\"up to May 10, 2020\\", \\"R0 value\\": \\"3.14\\", \\"%CI values\\": \\"(95% CI: 2.69-3.59)\\", \\"method\\": \\"DerSimonian-Laird (inverse variance) method\\" } } ]","publish_time":"2020"},{"main_cord_uid":"ozsm5r0m","cord_uid":"ozsm5r0m","abstract":"This study aimed to estimate the basic reproduction number and the time-varying estimate of effective reproductive number of COVID-19 in American countries as they implemented non-pharmacological strategies for the containment of the SARS-CoV-2 virus. Data sources included COVID-19 epidemic data from Johns Hopkins University\xe2\u20ac\u2122 data repository and official websites of countries with a relatively high incidence of COVID-19. The maximum likelihood method was used to estimate the and . The results showed that El Salvador, the Dominican Republic, Panama, and Peru have the lowest, while the USA and Canada have the highest. Other American countries have an around 1.4. Countries could be divided into three groups based on the varied behavior of over time. The first group (Mexico, USA, Colombia and Brazil) started with a high, which decreased post-intervention. In the second group, the intervention was performed at the moment when the, is high and it decreased slowly post-intervention (Canada, Argentina, Chile Peru, Panama and Dominican Republic). In the third group (Bolivia, Peru and Guatemala), the, was erratic and could not be attributable to the intervention. There is a close relationship between and non-pharmacological interventions decreed by governments of countries for the control of the COVID-19 pandemic. There are also immediate changes in the behavior of the indicator, and therefore the progression of the outbreak, when the interventions were implemented closer to the index case for each country.","title":"Estimation of time-varying reproduction numbers of COVID-19 in American countries with regards to non-pharmacological interventions","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: American countries\\r\\ndate: -\\r\\nR0 value: -\\r\\n%CI values: -\\r\\nmethod: maximum likelihood method","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"American countries\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"-\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"maximum likelihood method\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"American countries\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"-\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"maximum likelihood method\\" } } ]","publish_time":"2020"},{"main_cord_uid":"m1vtzt07","cord_uid":"m1vtzt07","abstract":"BACKGROUND: Uncertainties surrounding the 2019 novel coronavirus (COVID-19) remain a major global health challenge and requires attention. Researchers and medical experts have made remarkable efforts to reduce the number of cases and prevent future outbreaks through vaccines and other measures. However, there is little evidence on how severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection entropy can be applied in predicting the possible number of infections and deaths. In addition, more studies on how the COVID-19 infection density contributes to the rise in infections are needed. This study demonstrates how the SARS-COV-2 daily infection entropy can be applied in predicting the number of infections within a given period. In addition, the infection density within a given population attributes to an increase in the number of COVID-19 cases and, consequently, the new variants. RESULTS: Using the COVID-19 initial data reported by Johns Hopkins University, World Health Organization (WHO) and Global Initiative on Sharing All Influenza Data (GISAID), the result shows that the original SAR-COV-2 strain has R(0)<1 with an initial infection growth rate entropy of 9.11 bits for the United States (U.S.). At close proximity, the average infection time for an infected individual to infect others within a susceptible population is approximately 7 minutes. Assuming no vaccines were available, in the U.S., the number of infections could range between 41,220,199 and 82,440,398 in late March 2022 with approximately, 1,211,036 deaths. However, with the available vaccines, nearly 48 Million COVID-19 cases and 706, 437 deaths have been prevented. CONCLUSION: The proposed technique will contribute to the ongoing investigation of the COVID-19 pandemic and a blueprint to address the uncertainties surrounding the pandemic.","title":"Predicting the number of COVID-19 infections and deaths in USA","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: USA\\r\\ndate: -\\r\\nR0 value: <1\\r\\n%CI values: -\\r\\nmethod: -","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"USA\\",\\r\\n\\"date\\": \\"-\\",\\r\\n\\"R0 value\\": \\"<1\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"-\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"COVID-19\\", \\"location\\": \\"United States (U.S.)\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"R(0)1\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"-\\" } } ]","publish_time":"2022-03-28 10:00:00"},{"main_cord_uid":"v2loylpa","cord_uid":"v2loylpa","abstract":"Background: Amid a critical and emergent situation like the coronavirus disease (COVID-19) pandemic related to extreme health and economic repercussions, we used and presented the mathematical modeling like susceptible-infectious-recovered (SIR) to have a numerical demonstration that can shed light to decide the fate of the scourge in Bangladesh. To describe the idea about the factors influencing the outbreak data, we presented the current situation of the COVID-19 outbreak with graphical trends. Methods: Primary data were collected and analyzed by using a pre-created Google Survey form having a pre-set questionnaire on the social distancing status of different districts. Secondary data on the total and the daily number of laboratory tests, confirmed positive cases, and death cases were extracted from the publicly available sources to make predictions. We estimated the basic reproduction number (R \xc3\u0192\xc2\xa2\xc3\u201a\xe2\u20ac\u201d\xc3\u201a\xc2\xa6) based on the SIR mathematical model and predicted the probable fate of this pandemic in Bangladesh. Results: Quarantine situations in different regions of Bangladesh were evaluated and presented. We also provided tentative forecasts until 31 May 2020 and found that the predicted curve followed the actual curve approximately. Estimated R \xc3\u0192\xc2\xa2\xc3\u201a\xe2\u20ac\u201d\xc3\u201a\xc2\xa6-values (6.924) indicated that infection rate would be greater than the recovery rate. Furthermore, by calibrating the parameters of the SIR model to fit the reported data, we assume the ultimate ending of the pandemic in Bangladesh by December 2022. Conclusion: We hope that the results of our analysis could contribute to the elucidation of critical aspects of this outbreak and help the concerned authority toward decision making.","title":"Prediction of Epidemics Trend of COVID-19 in Bangladesh","annotator_investigating_R0":"1","text_response":"disease name: COVID-19\\r\\nlocation: Bangladesh\\r\\ndate: until 31 May 2020\\r\\nR0 value: 6.924\\r\\n%CI values: -\\r\\nmethod: SIR mathematical model","json_response":"[{\\"contribution\\":{\\"disease name\\": \\"COVID-19\\",\\r\\n\\"location\\": \\"Bangladesh\\",\\r\\n\\"date\\": \\"until 31 May 2020\\",\\r\\n\\"R0 value\\": \\"6.924\\",\\r\\n\\"%CI values\\": \\"-\\",\\r\\n\\"method\\": \\"SIR mathematical model\\"}}]","json_model_response":"[ { \\"contribution\\": { \\"disease name\\": \\"coronavirus disease (COVID-19)\\", \\"location\\": \\"Bangladesh\\", \\"date\\": \\"-\\", \\"R0 value\\": \\"6.924\\", \\"%CI values\\": \\"-\\", \\"method\\": \\"SIR mathematical model\\" } } ]","publish_time":"2020"}]}'),pa=function(e){d(a,e);var t=p(a);function a(e){var i;n(this,a),(i=t.call(this,e)).onRefresh=function(){var e=ma.h[Math.floor(300*Math.random())+1];i.setState({title:e.title,abstract:e.abstract,label:e.json_response,prediction:e.json_model_response})};var o=ma.h[Math.floor(300*Math.random())+1];return i.label_heading="Human Annotation",i.prediction_heading="LLM Prediction",i.state={title:o.title,abstract:o.abstract,label:o.json_response,prediction:o.json_model_response},i}return c(a,[{key:"render",value:function(){return(0,Ut.jsxs)("div",{children:[(0,Ut.jsx)(ha,{}),(0,Ut.jsx)(sa,{title:this.state.title,abstract:this.state.abstract,onClick:this.onRefresh}),(0,Ut.jsx)(da,{label:this.state.label,prediction:this.state.prediction,label_heading:this.label_heading,prediction_heading:this.prediction_heading})]})}}]),a}(e.Component),fa=function(e){d(a,e);var t=p(a);function a(){return n(this,a),t.apply(this,arguments)}return c(a,[{key:"render",value:function(){return(0,Ut.jsxs)("div",{className:"description-div",children:[(0,Ut.jsx)("h5",{children:"Leaderboards for Empirical AI Research"}),(0,Ut.jsx)("p",{children:"The Information Extraction (IE) task addressed focuses on empirical AI research leaderboards, where AI models, introduced and described in research papers, are succinctly characterized by four key attributes: the task (T), dataset (D), evaluation metric (M), and score (S) achieved. A single annotation unit comprises a single related (T, D, M, S) tuple, and a paper that reports a leaderboard can have more than one (T, D, M, S) tuple. The annotations on the left show the crowdsourced annotations obtained from paperswithcode, while the annotations on the right are exactly as output by the FLAN-T5-Large (780M) Large Language Model (LLM) and entries were not seen during training."})]})}}]),a}(e.Component),ga=fa,ba=JSON.parse('[{"Context":"Geometric and Combinatorial Properties of Well-Centered Triangulations in Three and Higher Dimensions An n-simplex is said to be n-well-centered if its circumcenter lies in its interior. We introduce several other geometric conditions and an algebraic condition that can be used to determine whether a simplex is n-well-centered. These conditions, together with some other observations, are used to describe restrictions on the local combinatorial structure of simplicial meshes in which every simplex is well-centered. In particular, it is shown that in a 3-well-centered (2well-centered) tetrahedral mesh there are at least 7 (9) edges incident to each interior vertex, and these bounds are sharp. Moreover, it is shown that, in stark contrast to the 2-dimensional analog, where there are exactly two vertex links that prevent a well-centered triangle mesh in R 2 , there are infinitely many vertex links that prohibit a well-centered tetrahedral mesh in R 3 .","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"The Smallville Effect: Social Ties Make Mobile Networks More Secure Against the Node Capture Attack Mobile Ad Hoc networks, due to the unattended nature of the network itself and the dispersed location of nodes, are subject to several unique security issues. One of the most vexed security threat is node capture. A few solutions have already been proposed to address this problem; however, those solutions are either centralized or focused on theoretical mobility models alone. In the former case the solution does not fit well the distributed nature of the network while, in the latter case, the quality of the solutions obtained for realistic mobility models severely differs from the results obtained for theoretical models. The rationale of this paper is inspired by the observation that re-encounters of mobile nodes do elicit a form of social ties. Leveraging these ties, it is possible to design efficient and distributed algorithms that, with a moderated degree of node cooperation, enforce the emergent property of node capture detection. In particular, in this paper we provide a proof of concept proposing a set of algorithms that leverage, to different extent, node mobility and node cooperation-that is, identifying social ties-to thwart node capture attack. In particular, we test these algorithms on a realistic mobility scenario. Extensive simulations show the quality of the proposed solutions and, more important, the viability of the proposed approach.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"GeneSyst: a Tool to Reason about Behavioral Aspects of B Event Specifications. Application to Security Properties \u22c6 In this paper, we present a method and a tool to build symbolic labelled transition systems from B specifications. The tool, called GeneSyst, can take into account refinement levels and can visualize the decomposition of abstract states in concrete hierarchical states. The resulting symbolic transition system represents all the behaviors of the initial B event system. So, it can be used to reason about them. We illustrate the use of GeneSyst to check security properties on a model of electronic purse.The events have the form \\"e = G =\u21d2 T \\" where G is a predicate, T is a generalized substitution such that I \u2227 G \u21d2 fis(T ). Predicate G is called the guard of e and T is its action. They are respectively denoted by Guard (e) and Action(e). If the syntactic definition of an event e = S does not fulfill this form, it can be built by computing e = fis(S) =\u21d2 S. Following the so-called event-based approach [10], the semantics of event-B systems can be chosen to be the set of all the valid sequences of event executions.Definition 1 (Traces of Event-B systems) A finite sequence of event occurrences e 0 .e 1 .e 2 . . . en is a trace of system S if and only if e 0 is the initialisation of S, {e 1 , e 2 , . . . , en } \u2286 Interface(S) and fis(e 0 ; e 1 ; e 2 ; . . . ; en ) \u21d4 true.The set of all the finite traces of a system S is called Traces(S). For the initialisation, one can notice that prd x (Init ) does not depend on the initial values of the variables and that Guard (Init ) \u21d4 true. The following property characterizes traces by the existence of intermediary states xi in which the guard of e i holds and where the pair (x i , x i+1 ) is in the before-after predicate of event e i : Abstract. In this paper, we present a method and a tool to build symbolic labelled transition systems from B specifications. The tool, called GeneSyst, can take into account refinement levels and can visualize the decomposition of abstract states in concrete hierarchical states. The resulting symbolic transition system represents all the behaviors of the initial B event system. So, it can be used to reason about them. We illustrate the use of GeneSyst to check security properties on a model of electronic purse.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"MeTRAbs: Metric-Scale Truncation-Robust Heatmaps for Absolute 3D Human Pose Estimation Heatmap representations have formed the basis of human pose estimation systems for many years, and their extension to 3D has been a fruitful line of recent research. This includes 2.5D volumetric heatmaps, whose X and Y axes correspond to image space and Z to metric depth around the subject. To obtain metric-scale predictions, 2.5D methods need a separate post-processing step to resolve scale ambiguity. Further, they cannot localize body joints outside the image boundaries, leading to incomplete estimates for truncated images. To address these limitations, we propose metric-scale truncation-robust (MeTRo) volumetric heatmaps, whose dimensions are all defined in metric 3D space, instead of being aligned with image space. This reinterpretation of heatmap dimensions allows us to directly estimate complete, metric-scale poses without test-time knowledge of distance or relying on anthropometric heuristics, such as bone lengths. To further demonstrate the utility our representation, we present a differentiable combination of our 3D metric-scale heatmaps with 2D image-space ones to estimate absolute 3D pose (our MeTRAbs architecture). We find that supervision via absolute pose loss is crucial for accurate non-root-relative localization. Using a ResNet-50 backbone without further learned layers, we obtain state-of-the-art results on Human3.6M, MPI-INF-3DHP and MuPoTS-3D. Our code is publicly available. 1 Index Terms-3D human pose estimation, absolute human pose, scale estimation, truncation ! \u2022 I. S\xe1r\xe1ndi and B. Leibe are with RWTH 4 is evaluated in a multi-person context by training on MuCo-3DHP (MuCo) and testing on MuPoTS-3D (MuPoTS) Two evaluation protocols are in wide use In Protocol 2, subjects 1, 5, 6, 7, 8, 9 are used in training and 11 in evaluation, with Procrustes alignment between prediction and ground truth Every 64 th frame is evaluated MPII is a 2D-labeled dataset with 25k training images We use this dataset for weak supervision, following the idea of Zhou et al. Only arm and leg joints are used from MPII, as we found these to be the most consistently labeled across datasets In this dataset, the hips are labeled closer to the legs than in MPII We evaluate on both MuCo is a synthetically composited multi-person dataset, derived from 3DHP by pasting persons over each other based on their root joint depth order For single-person datasets, synthetic occlusion is added with 70% probability, Methods using no ground truth scale or depth information at test time 50 . 2\xb10 . 3 Methods using ground - truth scale or depth information at test time Walk SitD Pur . WD Avg \u2193 Sm . Pht . Dis . Dir . Gre . Pose Eat Phn . Wait WT Sit Comparison of MPJPE with prior work on H3 . 6M under Protocol 2 ( test subject 11 with Procrustes alignment to the ground truth ) . Universal , height - normalized skeletons ( simplified scale recovery task ) Metric - scale skeletons ( full scale recovery task ) - door Exer - reach screen 89 . 9\xb10 . 2 Sport cise floor Sit on 88 . 7\xb10 . 6 90 . 6\xb10 . 4 No Stand / chair Cro . / gr . sc . Out - Total Misc . MPJPE\u2193 PCK\u2191 AUC\u2191 walk Green On PCK\u2191 AUC\u2191","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3D Poses in the Wild Challenge\\", \\"Metric\\": \\"MPJPE\\", \\"Score\\": \\"68.83\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"Human3.6M\\", \\"Metric\\": \\"Average MPJPE (mm)\\", \\"Score\\": \\"38.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"Human3.6M\\", \\"Metric\\": \\"Multi-View or Monocular\\", \\"Score\\": \\"Multi-View\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"Human3.6M\\", \\"Metric\\": \\"Using 2D ground-truth joints\\", \\"Score\\": \\"No\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"Human3.6M\\", \\"Metric\\": \\"Average MPJPE (mm)\\", \\"Score\\": \\"48.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"Human3.6M\\", \\"Metric\\": \\"Frames Needed\\", \\"Score\\": \\"1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"Human3.6M\\", \\"Metric\\": \\"Need Ground Truth 2D Pose\\", \\"Score\\": \\"No\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\","},{"Context":"Grafit: Learning fine-grained image representations with coarse labels  We consider evaluation scenarios where it is beneficial to learn at a finer granularity than that provided by the training labels The third protocol is vanilla transfer learning, where we transfer from Imagenet to a fine-grained dataset We carryout our evaluations on public benchmarks, which statistics are detailed in shows that Grafit not only provides a better on-the-fly classification (as evaluated by the kNN metric), but that the ranked list is more relevant to the query (results for mAP) In SSL, the standard way to evaluate the quality of a feature extractor f is to measure the accuracy of the network after learning a linear classifier l for the target classes on top off The Rademacher complexity measures how a class of: Separability experiment on CIFAR-100 Ina second stage, we train a linear classifer l on the Resnet-18 trunk with fine class supervision, and evaluate its accuracy on the test set Table 1: Datasets used for our different tasks. The four top datasets offer two or more levels of granularity, we use them for all coarse-to-fine tasks. The bottom three are fine-grained datasets employed to evaluate transfer learning. 20 / 100 127 / 1000 6 / . . . / 1 , 010 #classes 6 / . . . / 8 , 142 Table 2: Coarse-to-fine: comparison with the state of the art for category-level retrieval (mAP, %) and kNN classification (top-1, %), with the ResNet50 architec- ture. We compare Grafit with the state of the art Method ImageNet - 1k kNN CIFAR - 100 mAP for details . Table 3: kNN evaluation on iNaturalist-2018 with dif- ferent semantic levels. The symbol \u2205 refers to the un- supervised case (a unique class). We compare with the best competing method according to Table 2. low Goyal et al . \' s [ 24","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"79.6%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"Flowers-102\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"99.1%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"iNaturalist 2018\\", \\"Metric\\": \\"Top-1 Accuracy\\", \\"Score\\": \\"81.2%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"iNaturalist 2018\\", \\"Metric\\": \\"Top-1 Accuracy\\", \\"Score\\": \\"69.8%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"83.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"iNaturalist 2019\\", \\"Metric\\": \\"Top-1 Accuracy\\", \\"Score\\": \\"84.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Oxford 102 Flowers\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"99.1%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Food-101\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"93.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Stanford Cars\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"94.7%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"iNaturalist 2018\\", \\"Metric\\": \\"Top-1 Accuracy\\", \\"Score\\": \\"69.05%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"iNaturalist 2018\\", \\"Metric\\": \\"Top-1 Accuracy\\", \\"Score\\": \\"67.98%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"iNaturalist 2018\\", \\"Metric\\": \\"Top-1 Accuracy\\", \\"Score\\": \\"64.16%\\"}} ]"},{"Context":"Sliced Recurrent Neural Networks Recurrent neural networks have achieved great success in many NLP tasks. However, they have difficulty in parallelization because of the recurrent structure, so it takes much time to train RNNs. In this paper, we introduce sliced recurrent neural networks (SRNNs), which could be parallelized by slicing the sequences into many subsequences. SRNNs have the ability to obtain high-level information through multiple layers with few extra parameters. We prove that the standard RNN is a special case of the SRNN when we use linear activation functions. Without changing the recurrent units, SRNNs are 136 times as fast as standard RNNs and could be even faster when we train longer sequences. Experiments on six largescale sentiment analysis datasets show that SRNNs achieve better performance than standard RNNs. We evaluate SRNNs on six large-scale sentiment analysis datasets shows the information of the datasets Yelp reviews: The Yelp reviews datasets are obtained from the Yelp Dataset Challenge, which has 5 sentiment labels (the higher, the better) This dataset consists of 4,736,892 documents, and we extract three subsets Yelp 2013, 2014, 2015 containing 468,608, 670,440 and 897,835 documents separately created the polarity dataset including 598,000 documents with two sentiment labels, and we obtain the polarity dataset from them Amazon reviews: The Amazon reviews dataset is a commentary dataset containing 34,686,770 reviews on 2,441,053 products from 6,643,669 users The dataset is also constructed into a full dataset with 3,650,000 documents and a polarity dataset with 4,000,000 documents, which is also obtained from When we focus on the results of SRNN (2,8) on Yelp datasets and SRNN (2,7) on Amazon datasets, we could find that even if they did not achieve the best Table 1: Dataset information. Max words denotes the max sequence length, and Average words denotes the average length of the sentences in each dataset. 308 , 028 228 , 715 210 , 353 202 , 058 1 , 274 , 916 Max words Dataset Average words Table 2. We choose different n and k values and get different SRNNs. For example, SRNN (16,1) means n=16 and k=1, which could get a 32-length minimum subsequence when T is 512 or a 16-length minimum subsequence when T is 256. We compare four SRNNs with the standard RNN. For each dataset, we use bold words to label the highest-performing model and the fastest model. 67s 284s 164s 145s 201s 388s 204s 4142s 238s 3172s 270s Validation Parameters Test Table 2: The accuracy and training time on validation and test sets of the models on each dataset. Four different structures of SRNNs are constructed. DCCNN","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"Yelp Binary classification\\", \\"Metric\\": \\"Error\\", \\"Score\\": \\"3.96\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"Amazon Review Full\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"61.65\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"Amazon Review Polarity\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.26\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"User and product information\\", \\"Metric\\": \\"IMDB (Acc)\\", \\"Score\\": \\"56.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"User and product information\\", \\"Metric\\": \\"Yelp 2013 (Acc)\\", \\"Score\\": \\"67.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"User and product information\\", \\"Metric\\": \\"Yelp 2014 (Acc)\\", \\"Score\\": \\"69.2\\"}} ]"},{"Context":"Distilling Visual Priors from Self-Supervised Learning Convolutional Neural Networks (CNNs) are prone to overfit small training datasets. We present a novel two-phase pipeline that leverages self-supervised learning and knowledge distillation to improve the generalization ability of CNN models for image classification under the data-deficient setting. The first phase is to learn a teacher model which possesses rich and generalizable visual representations via self-supervised learning, and the second phase is to distill the representations into a student model in a self-distillation manner, and meanwhile fine-tune the student model for the image classification task. We also propose a novel margin loss for the self-supervised contrastive learning proxy task to better learn the representation under the data-deficient scenario. Together with other tricks, we achieve competitive performance in the VIPriors image classification challenge. The self-supervised trained checkpoint from phase-1 is then used to initialize the teacher and student for fine-tuning on the whole dataset with labels The distillation process can be seen as a regulation to prevent the student from overfitting the small train dataset and give the student a more diversed representation for classification Along with a cross-entropy loss for classification: the final loss function for the student model is: The student model is then used for evaluation Dataset Only the subset of the ImageNet dataset given by the VIPrior challenge is used for our experiments, no external data or pre-trained checkpoint is used The VIPrior challenge dataset contains 1,000 classes which is the same with the original ImageNet, and is split into train, val and test splits, each of the splits has 50 images for each class, resulting in a total of 150,000 images Table 1: Training and Pre-training the model on the train split and evaluate the performance on the validation split on the given dataset. \'finetune fc\' stands for train a linear classifier on top of the pretrained representation, \'finetune\' stands for train the weight of the whole model. Our proposed pipeline (Phase-1 + Phase-2) can have 16.7 performance gain in top-1 validation accuracy. #Neg Margin Val Acc #Pretrain Epoch #Finetune Epoch Val Acc Table 2: The Val Acc means the linear classification accuracy obtained by fine- tune a linear classifier on top of the learned representation. The original MoCo v2 is sensitive to the number of negative, the performance drops drastically when number negatives is small. Our modified margin loss is less sensitive to the number negatives, as shown in the table, even has 16x less negatives the performance only drops 0.9. #Neg Margin Val Acc Table 3: The tricks used in","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Object Classification\\", \\"Dataset\\": \\"ImageNet VIPriors subset\\", \\"Metric\\": \\"Top-1\\", \\"Score\\": \\"68.8\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 1% labeled data\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"64.03%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 1% labeled data\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"84.88%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of Params\\", \\"Score\\": \\"53.3M\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"73.8%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"92.2%\\"}} ]"},{"Context":"Graph Structured Network for Image-Text Matching Image-text matching has received growing interest since it bridges vision and language. The key challenge lies in how to learn correspondence between image and text. Existing works learn coarse correspondence based on object co-occurrence statistics, while failing to learn finegrained phrase correspondence. In this paper, we present a novel Graph Structured Matching Network (GSMN) to learn fine-grained correspondence. The GSMN explicitly models object, relation and attribute as a structured phrase, which not only allows to learn correspondence of object, relation and attribute separately, but also benefits to learn fine-grained correspondence of structured phrase. This is achieved by node-level matching and structure-level matching. The node-level matching associates each node with its relevant nodes from another modality, where the node can be object, relation or attribute. The associated nodes then jointly infer fine-grained correspondence by fusing neighborhood associations at structure-level matching. Comprehensive experiments show that GSMN outperforms state-of-the-art methods on benchmarks, with relative Re-call@1 improvements of nearly 7% and 2% on Flickr30K and MSCOCO, respectively. Code will be released at: https://github.com/CrossmodalGroup/GSMN . To validate the effectiveness of our proposed method, we evaluate it on two most widely used benchmarks, Flickr30K and MSCOCO The evaluation result is calculated on 5-folds of testing images The commonly used evaluation metrics for image-text matching are Recall@K (K=1,5,10), denoted as R@1, R@5, and R@10, which depict the percentage of ground truth being retrieved at top 1, 5, 10 results, respectively Table 1: Image-text matching results on Flickr30K, \u2032 f t \u2032 and \u2032 f ixed \u2032 are fine-tuning and no fine-tuning. The bests are in bold. R@1 R@5 R@10 rSum Image - to - Text Text - to - Image Table 2: Image-text matching results on MSCOCO, \u2032 f t \u2032 and \u2032 f ixed \u2032 are fine-tuning and no fine-tuning. The bests are in bold. R@1 R@5 R@10 rSum Image - to - Text Text - to - Image Table 3: The ablation study on Flickr30K to investigate the effect of different network structures. R@1 R@10 Image - to - Text Text - to - Image","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-Modal Retrieval\\", \\"Dataset\\": \\"Flickr30k\\", \\"Metric\\": \\"Image-to-text R@1\\", \\"Score\\": \\"76.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-Modal Retrieval\\", \\"Dataset\\": \\"Flickr30k\\", \\"Metric\\": \\"Image-to-text R@10\\", \\"Score\\": \\"97.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-Modal Retrieval\\", \\"Dataset\\": \\"Flickr30k\\", \\"Metric\\": \\"Image-to-text R@5\\", \\"Score\\": \\"94.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-Modal Retrieval\\", \\"Dataset\\": \\"Flickr30k\\", \\"Metric\\": \\"Text-to-image R@1\\", \\"Score\\": \\"57.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-Modal Retrieval\\", \\"Dataset\\": \\"Flickr30k\\", \\"Metric\\": \\"Text-to-image R@10\\", \\"Score\\": \\"89.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-Modal Retrieval\\", \\"Dataset\\": \\"Flickr30k\\", \\"Metric\\": \\"Text-to-image R@5\\", \\"Score\\": \\"82.3\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"Flickr30K 1K test\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"29.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"Flickr30K 1K test\\", \\"Metric\\": \\"R@10\\", \\"Score\\": \\"72.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"Flickr30K 1K test\\", \\"Metric\\": \\"R@5\\", \\"Score\\": \\"60.1\\"}} ]"},{"Context":"Nystr\xf6mformer: A Nystr\xf6m-based Algorithm for Approximating Self-Attention Transformers have emerged as a powerful tool fora broad range of natural language processing tasks. A key component that drives the impressive performance of Transformers is the self-attention mechanism that encodes the influence or dependence of other tokens on each specific token. While beneficial, the quadratic complexity of self-attention on the input sequence length has limited its application to longer sequences -a topic being actively studied in the community. To address this limitation, we propose Nystr\xf6mformer -a model that exhibits favorable scalability as a function of sequence length. Our idea is based on adapting the Nystr\xf6m method to approximate standard self-attention with O(n) complexity. The scalability of Nystr\xf6mformer enables application to longer sequences with thousands of tokens. We perform evaluations on multiple downstream tasks on the GLUE benchmark and IMDB reviews with standard sequence length, and find that our Nystr\xf6mformer performs comparably, or in a few cases, even slightly better, than standard self-attention. On longer sequence tasks in the Long Range Arena (LRA) benchmark, Nystr\xf6mformer performs favorably relative to other efficient self-attention methods. Our code is available at https://github.com/mlpen/Nystromformer. In the first stage, we train Nystr\xf6mformer on a largescale text corpus, and report the language modeling performance of our model on a hold-out validation set In the second stage, we fine-tune the pre-trained Nystr\xf6mformer across several different NLP tasks in GLUE benchmarks) and IMDB reviews, and report the performance on individual dataset for each task Table 1: Memory consumption and running time results on various input sequence length. We report the average memory consump- input sequence length n 4096 time ( ms ) 2048 512 1024 8192 memory ( MB ) Table 2: Results on natural language understanding tasks. We re- IMDB QQP SST - 2 MRPC QNLI Table 3: Results on Long Range Arena (LRA) benchmark using our PyTorch implementation. We report classification accuracy for each Pathfinder ( 1K ) Retrieval ( 4K ) Avg Text ( 4K ) ListOps ( 2K ) Image ( 1K )","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Natural Language Inference\\", \\"Dataset\\": \\"QNLI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"88.7%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Textual Similarity\\", \\"Dataset\\": \\"MRPC\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"88.1%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"93.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"SST-2 Binary classification\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"91.4\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Natural Language Inference\\", \\"Dataset\\": \\"MultiNLI\\", \\"Metric\\": \\"Matched\\", \\"Score\\": \\"91.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Natural Language Inference\\", \\"Dataset\\": \\"MultiNLI\\", \\"Metric\\": \\"Mismatched\\", \\"Score\\": \\"90.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Natural Language Inference\\", \\"Dataset\\": \\"SNLI\\", \\"Metric\\": \\"% Test Accuracy\\", \\"Score\\": \\"93.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Natural Language Inference\\", \\"Dataset\\": \\"SciTail\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"91.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Natural Language Inference\\", \\"Dataset\\": \\"WNLI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"91.89%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Natural Language Inference\\", \\"Dataset\\": \\"QNLI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.4%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Textual Similarity\\", \\"Dataset\\": \\"STS Benchmark\\", \\"Metric\\": \\"Pearson Correlation\\", \\"Score\\": \\"0.9"},{"Context":"NP Datalog: a Logic Language for Expressing NPSearch and Optimization Problems This paper presents a logic language for expressing NP search and optimization problems. Specifically, first a language obtained by extending (positive) DATALOG with intuitive and efficient constructs (namely, stratified negation, constraints and exclusive disjunction) is introduced. Next, a further restricted language only using a restricted form of disjunction to define (non-deterministically) subsets (or partitions) of relations is investigated. This language, called NP Datalog , captures the power of DATALOG \xac in expressing search and optimization problems. A system prototype implementing NP Datalog is presented. The system translates NP Datalog queries into OPL programs which are executed by the ILOG OPL Development Studio. Our proposal combines easy formulation of problems, expressed by means of a declarative logic language, with the efficiency of the ILOG System. Several experiments show the effectiveness of this approach. The performances of the systems have been evaluated by measuring the time necessary to find one solution of the following problems: 3-Coloring, Hamiltonian Cycle, Transitive Closure, Min Coloring, N-Queens and Latin Squares The Hamiltonian Cycle problem has been evaluated over benchmark graphs used to test other systems (HC Instances) and random graphs generated by means of Culberson\\"s graph generator (HC Program Archive)","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"SEE: Towards Semi-Supervised End-to-End Scene Text Recognition Detecting and recognizing text in natural scene images is a challenging, yet not completely solved task. In recent years several new systems that try to solve at least one of the two sub-tasks (text detection and text recognition) have been proposed. In this paper we present SEE, a step towards semi-supervised neural networks for scene text detection and recognition, that can be optimized end-to-end. Most existing works consist of multiple deep neural networks and several pre-processing steps. In contrast to this, we propose to use a single deep neural network, that learns to detect and recognize text from natural images, in a semi-supervised way. SEE is a network that integrates and jointly learns a spatial transformer network, which can learn to detect text regions in an image, and a text recognition network that takes the identified text regions and recognizes their textual content. We introduce the idea behind our novel approach and show its feasibility, by performing a range of experiments on standard benchmark datasets, where we achieve competitive results. In this section we evaluate our presented network architecture on standard scene text detection/recognition benchmark datasets While performing our experiments we tried to answer the following questions: (1) Is the concept of letting the network automatically learn to detect text feasible? (2) Can we apply the method on areal world dataset? (3) Can we get any insights on what kind of features the network is trying: Operation method of grid generator and image sampler to extract? In order to answer these questions, we used different datasets On the one hand we used standard benchmark datasets for scene text recognition On the other hand we generated some datasets on our own First, we performed experiments on the SVHN dataset), that we used to prove that our concept as such is feasible Second, we generated more complex datasets based on SVHN images, to see how our system performs on images that contain several","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Optical Character Recognition\\", \\"Dataset\\": \\"FSNS - Test\\", \\"Metric\\": \\"Sequence error\\", \\"Score\\": \\"22\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Scene Text Detection\\", \\"Dataset\\": \\"ICDAR 2013\\", \\"Metric\\": \\"F-Measure\\", \\"Score\\": \\"90.1%\\"}} ]"},{"Context":"stdchk: A Checkpoint Storage System for Desktop Grid Computing Checkpointing is an indispensable technique to provide fault tolerance for long-running high-throughput applications like those running on desktop grids. This paper argues that a dedicated checkpoint storage system, optimized to operate in these environments, can offer multiple benefits: reduce the load on a traditional file system, offer high-performance through specialization, and, finally, optimize data management by taking into account checkpoint application semantics. Such a storage system can present a unifying abstraction to checkpoint operations, while hiding the fact that there are no dedicated resources to store the checkpoint data.We prototype stdchk, a checkpoint storage system that uses scavenged disk space from participating desktops to build a low-cost storage system, offering a traditional file system interface for easy integration with applications. This paper presents the stdchk architecture, key performance optimizations, support for incremental checkpointing, and increased data availability. Our evaluation confirms that the stdchk approach is viable in a desktop grid setting and offers a low-cost storage system with desirable performance characteristics: high write throughput and reduced storage space and network effort to save checkpoint images. We evaluate our prototype under a range of micro-and macro-benchmarks Table 1 Time to write a 1 GB file. Local I/O FUSE to local I/O /stdchk/null Average Time (s) 11.80 12.00 1.04 Standard deviation 0.16 0.24 0.03 Local I / O FUSE to local I / O / stdchk / null Table 1 Time to write a 1 GB file . Table 2: Characteristics of the collected checkpoints. Applica tion ( BLCR ) checkpoint s # of Average size ( MB ) Table 2 : Characteristics of the collected checkpoints . Table 4: The effect of m and k on CbCH no-overlap performance. The table presents the ratio of detected similarity (in percentage), the heuristic\'s throughput in MB/s, the average resulted checkpoint size in KB, and the average minimum and maximum chunk sizes (Values for m in bytes and for k in bits) k m 20 32 64 128 256 1544 and for k in bits ) checkpoint KB , heuristic","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Accurate 3D Object Detection using Energy-Based Models Accurate 3D object detection (3DOD) is crucial for safe navigation of complex environments by autonomous robots. Regressing accurate 3D bounding boxes in cluttered environments based on sparse LiDAR data is however a highly challenging problem. We address this task by exploring recent advances in conditional energy-based models (EBMs) for probabilistic regression. While methods employing EBMs for regression have demonstrated impressive performance on 2D object detection in images, these techniques are not directly applicable to 3D bounding boxes. In this work, we therefore design a differentiable pooling operator for 3D bounding boxes, serving as the core module of our EBM network. We further integrate this general approach into the state-of-the-art 3D object detector SA-SSD. On the KITTI dataset, our proposed approach consistently outperforms the SA-SSD baseline across all 3DOD metrics, demonstrating the potential of EBM-based regression for highly accurate 3DOD. Code is available at https://github.com/fregu856/ebms_3dod. We evaluate our EBM-based 3DOD approach on the KITTI 3DOD dataset and compare it with the SA-SSD baseline and other state-of-the-art methods KITTI is the most commonly used dataset for automotive 3DOD On the KITTI benchmark server, models are evaluated in terms of average precision (AP) in both 3D and BEV","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Hard\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"72.78%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Moderate val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"86.83\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Easy val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"95.45\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Easy\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"91.05%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Hard val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"82.23\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Moderate\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"80.12%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Moderate val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"75.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Moderate val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"59.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Easy val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"54.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Easy\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"53.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Moderate val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"56.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Moderate val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"67.9%\\"}} ]"},{"Context":"Fi-GNN: Modeling Feature Interactions via Graph Neural Networks for CTR Prediction Click-through rate (CTR) prediction is an essential task in web applications such as online advertising and recommender systems, whose features are usually in multi-field form. The key of this task is to model feature interactions among different feature fields. Recently proposed deep learning based models follow a general paradigm: raw sparse input multi-filed features are first mapped into dense field embedding vectors, and then simply concatenated together to feed into deep neural networks (DNN) or other specifically designed networks to learn high-order feature interactions. However, the simple unstructured combination of feature fields will inevitably limit the capability to model sophisticated interactions among different fields in a sufficiently flexible and explicit fashion.In this work, we propose to represent the multi-field features in a graph structure intuitively, where each node corresponds to a feature field and different fields can interact through edges. The task of modeling feature interactions can be thus converted to modeling node interactions on the corresponding graph. To this end, we design a novel model Feature Interaction Graph Neural Networks (Fi-GNN). Taking advantage of the strong representative power of graphs, our proposed model cannot only model sophisticated feature interactions in a flexible and explicit fashion, but also provide good model explanations for CTR prediction. Experimental results on two real-world datasets show its superiority over the state-of-the-arts. 4.1.1 Datasets We evaluate our proposed models on the following two datasets, whose statistics are summarized in This is a famous industry benchmark dataset for CTR prediction, which has 45 million users\' click records in 39 anonymous feature fields on displayed ads This dataset contains users\' click behaviors on displayed mobile ads For the two datasets, we remove the infrequent features appearing in less than 10, 5 times respectively and treat them as a single feature \\"<unknown>\\" We use the following two metrics for model evaluation: AUC (Area Under the ROC curve) and Logloss (cross entropy) Table 1: Statistics of evaluation datasets. 998 , 960 #Fields Table 2: Performance Comparison of Different methods. The best performance on each dataset and metric are highlighted. Further analysis is provided in Section 4.2. Second - order RI - Logloss Logloss Criteo Model Avazu AUC RI - AUC","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Click-Through Rate Prediction\\", \\"Dataset\\": \\"Avazu\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.812\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Click-Through Rate Prediction\\", \\"Dataset\\": \\"Avazu\\", \\"Metric\\": \\"LogLoss\\", \\"Score\\": \\"0.3817\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Click-Through Rate Prediction\\", \\"Dataset\\": \\"Criteo\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.8062\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Click-Through Rate Prediction\\", \\"Dataset\\": \\"Criteo\\", \\"Metric\\": \\"Log Loss\\", \\"Score\\": \\"0.4453\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Click-Through Rate Prediction\\", \\"Dataset\\": \\"34.4\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.8104\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Click-Through Rate Prediction\\", \\"Dataset\\": \\"34.4\\", \\"Metric\\": \\"Log Loss\\", \\"Score\\": \\"0.4416\\"}} ]"},{"Context":"BoxSup: Exploiting Bounding Boxes to Supervise Convolutional Networks for Semantic Segmentation Recent leading approaches to semantic segmentation rely on deep convolutional networks trained with humanannotated, pixel-level segmentation masks. Such pixelaccurate supervision demands expensive labeling effort and limits the performance of deep networks that usually benefit from more training data. In this paper, we propose a method that achieves competitive accuracy but only requires easily obtained bounding box annotations. The basic idea is to iterate between automatically generating region proposals and training convolutional networks. These two steps gradually recover segmentation masks for improving the networks, and vise versa. Our method, called \\"BoxSup\\", produces competitive results (e.g., 62.0% mAP for validation) supervised by boxes only, on par with strong baselines (e.g., 63.8% mAP) fully supervised by masks under the same setting. By leveraging a large amount of bounding boxes, BoxSup further unleashes the power of deep convolutional networks and yields state-of-the-art results on PAS-CAL VOC 2012 and PASCAL-CONTEXT [24]. The VGG model is also used by all competitors We first evaluate our method on the PASCAL VOC 2012 semantic segmentation benchmark This dataset involves 20 semantic categories of objects We use the \\"comp6\\" evaluation protocol The accuracy is evaluated by mean IoU scores We further perform experiments on the recently labeled PASCAL-CONTEXT dataset This dataset provides ground-truth semantic labels for the whole scene, including object and stuff (e.g., grass, sky, water) The training and evaluation are performed on the training and validation sets that have 4,998 and 5,105 images respectively To train a BoxSup model for this dataset, we first use the box annotations from all 80 object categories in the COCO dataset to train the FCN (using VGG-16) Table 1: Comparisons of supervision in PASCAL VOC 2012 validation. 10 , 582 VOC train + COCO 133 , 869 9 , 118 123 , 287 1 , 464 box semi VOC train - mask Table 2: Comparisons of estimated masks for supervision in PASCAL VOC 2012 validation. All methods only use 10,582 bounding boxes as annotations, with no ground- truth segmentation mask used. mean IoU Table 3: Comparisons of the effects of region proposal methods on our method in PASCAL VOC 2012 validation. All methods only use 10,582 bounding boxes as annota- tions, with no ground-truth segmentation mask used. SS MCG GOP","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL Context\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"40.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL VOC 2012 test\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"64.6%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL Context\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"60.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL VOC 2012 test\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"69.8%\\"}} ]"},{"Context":"ESPRESSO: A FAST END-TO-END NEURAL SPEECH RECOGNITION TOOLKIT We present ESPRESSO, an open-source, modular, extensible endto-end neural automatic speech recognition (ASR) toolkit based on the deep learning library PyTorch and the popular neural machine translation toolkit FAIRSEQ. ESPRESSO supports distributed training across GPUs and computing nodes, and features various decoding approaches commonly employed in ASR, including look-ahead word-based language model fusion, for which a fast, parallelized decoder is implemented. ESPRESSO achieves state-of-the-art ASR performance on the WSJ, LibriSpeech, and Switchboard data sets among other end-to-end systems without data augmentation, and is 4-11\xd7 faster for decoding than similar systems (e.g. ESPNET).  Table 2. Hyper-parameters for the three recipes. Hyper - parameter SWBD LM 48 18M 65k 113M 1 , 733 70M 80M 5k 435 1k 50 52 ASR 35 1 , 200 1 , 024 174M 1 , 783 25M WSJ 320 1 , 800 640 800 LibriSpeech 60 Table 3. WERs (%) on the WSJ dev93 and eval92 set. eval92 dev93 Table 4. Breakdown of the WERs (%) on WSJ. Sub eval92 Del dev93 Ins Table 5. WERs (%) on the LibriSpeech dev and test sets. other dev test clean Table 6. WERs (%) on the SWBD Hub5\'00 evaluation set. CallHome Switchboard Table 7. Training (per epoch) and decoding wall time on WSJ. ASR LM 1min 27s 46min 36min 29min 16s ASR Decoding ( eval92 ) Training w / o LM w / look - ahead LM 31min 56min 5min 21s 2min 44s","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"Hub5\'00 SwitchBoard\\", \\"Metric\\": \\"Eval2000\\", \\"Score\\": \\"9.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"WSJ eval92\\", \\"Metric\\": \\"Word Error Rate (WER)\\", \\"Score\\": \\"3.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"LibriSpeech test-clean\\", \\"Metric\\": \\"Word Error Rate (WER)\\", \\"Score\\": \\"2.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"LibriSpeech test-other\\", \\"Metric\\": \\"Word Error Rate (WER)\\", \\"Score\\": \\"8.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"Hub5\'00 CallHome\\", \\"Metric\\": \\"Word Error Rate (WER)\\", \\"Score\\": \\"19.1\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"LibriSpeech test-clean\\", \\"Metric\\": \\"Word Error Rate (WER)\\", \\"Score\\": \\"2.10\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"LibriSpeech test-other\\", \\"Metric\\": \\"Word Error Rate (WER)\\", \\"Score\\": \\"3.83\\"}} ]"},{"Context":"Classification of Shoulder X-Ray Images with Deep Learning Ensemble Models Fractures occur in the shoulder area, which has a wider range of motion than other joints in the body, for various reasons. To diagnose these fractures, data gathered from X-radiation (Xray), magnetic resonance imaging (MRI), or computed tomography (CT) are used. This study aims to help physicians by classifying shoulder images taken from X-ray devices as fracture / non-fracture with artificial intelligence. For this purpose, the performances of 26 deep learning-based pre-trained models in the detection of shoulder fractures were evaluated on the musculoskeletal radiographs (MURA) dataset, and two ensemble learning models (EL1 and EL2) were developed. The pretrained models used are ResNet, ResNeXt, DenseNet, VGG, Inception, MobileNet, and their spinal fully connected (Spinal FC) versions. In the EL1 and EL2 models developed using pre-trained models with the best performance, test accuracy was 0.8455,0.8472, Cohen\'s kappa was 0.6907, 0.6942 and the area that was related with fracture class under the receiver operating characteristic (ROC) curve (AUC) was 0.8862,0.8695. As a result of 28 different classifications in total, the highest test accuracy and Cohen\'s kappa values were obtained in the EL2 model, and the highest AUC value was obtained in the EL1 model. The MURA dataset was first introduced to the literature in a paper published in the OpenReview platform, announced in the conference on \\"Medical Imaging with Deep Learning\\" held in Amsterdam in 2018 Following this publication, this dataset was made publicly available for academic studies in a competition called \\"Bone X-Ray Deep Learning Competition\\" by the Machine Learning group of the Stanford University Being one of the largest public radiographic image datasets, MURA contains a total of 40,561 X-ray images in png format for the following parts of the body, labeled as either normal or abnormal (fracture): elbow, finger, forearm, hand, humerus, shoulder, and wrist using DenseNet-169 on this dataset, the AUC score representing the area under the overall Receiver Operator Characteristics (ROC) curve was 0.929, and the overall Cohen\'s kappa score was 0.705 Following this first study in which this dataset was introduced to the literature, there have been various studies Table 1. Layer with values of Spinal FCs used in classification models. Width Spinal FC Layer Width Spinal FC Layer Models 20 ResNeXt50 Table 2. Details of the shoulder bone X-ray images used in the study png , Bone X - ray Images New Image Test Dataset Size Table 7. Training accuracy results of classification models. Spinal DenseNet - 169 Standart Models VGG - 19 ResNet - 101 Net Standart FC FC ResNext - 101 MobileNet - v2 Spinal FC Table 8. Test accuracy results of classification models. Spinal Standart Models Net FC Table 9. Precision results of classification models. 75% Spinal 85% Standart Models VGG - 19 Net Standart FC FC ResNext - 101 MobileNet - v2 Spinal FC Table 10. Recall results of classification models. Spinal DenseNet - 169 Standart Models VGG - 19 ResNet - 101 Net Standart FC FC ResNext - 101 MobileNet - v2 Spinal FC","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"Fracture/Normal Shoulder Bone X-ray Images on MURA\\", \\"Metric\\": \\"Cohen\u2019s Kappa score\\", \\"Score\\": \\"0.6942\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"Fracture/Normal Shoulder Bone X-ray Images on MURA\\", \\"Metric\\": \\"Test Accuracy\\", \\"Score\\": \\"84.72%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"Fracture/Normal Shoulder Bone X-ray Images on MURA\\", \\"Metric\\": \\"AUC score\\", \\"Score\\": \\"0.8862\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Sarcasm Detection\\", \\"Dataset\\": \\"Automatic Misogynistic Identification\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.83\\"}} ]"},{"Context":"batchboost: REGULARIZATION FOR STABILIZING TRAINING WITH RESISTANCE TO UNDERFITTING & OVERFITTING DRAFT Overfitting & underfitting and stable training are an important challenges in machine learning. Current approaches for these issues are mixup[1], SamplePairing[2] and BC learning [3]. In our work, we state the hypothesis that mixing many images together can be more effective than just two. batchboost pipeline has three stages: (a) pairing: method of selecting two samples. (b) mixing: how to create anew one from two samples. (c) feeding: combining mixed samples with new ones from dataset into batch (with ratio \u03b3). Note that sample that appears in our batch propagates with subsequent iterations with less and less importance until the end of training. Pairing stage calculates the error per sample, sorts the samples and pairs with strategy: hardest with easiest one, than mixing stage merges two samples using mixup, x 1 + (1 \u2212 \u03bb)x 2 . Finally, feeding stage combines new samples with mixed by ratio 1:1. batchboost has 0.5-3% better accuracy than the current state-of-the-art mixup regularization on CIFAR-10[4] & Fashion-MNIST[5]. Our method is slightly better than SamplePairing technique on small datasets (up to 5%). batchboost provides stable training on not tuned parameters (like weight decay), thus its a good method to test performance of different architectures. Source code is at: https://github.com/maciejczyzewski/batchboost","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"97.54\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"Kuzushiji-MNIST\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"98.13\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"Kuzushiji-MNIST\\", \\"Metric\\": \\"Error\\", \\"Score\\": \\"8.25\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"Kuzushiji-MNIST\\", \\"Metric\\": \\"Error\\", \\"Score\\": \\"8.59\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"Kuzushiji-MNIST\\", \\"Metric\\": \\"Error\\", \\"Score\\": \\"2.77\\"}} ]"},{"Context":"TransReID: Transformer-based Object Re-Identification Extracting robust feature representation is one of the key challenges in object re-identification (ReID). Although convolution neural network (CNN)-based methods have achieved great success, they only process one local neighborhood at a time and suffer from information loss on details caused by convolution and downsampling operators (e.g. pooling and strided convolution). To overcome these limitations, we propose a pure transformer-based object ReID framework named TransReID. Specifically, we first encode an image as a sequence of patches and build a transformer-based strong baseline with a few critical improvements, which achieves competitive results on several ReID benchmarks with CNN-based methods. To further enhance the robust feature learning in the context of transformers, two novel modules are carefully designed. (i) The jigsaw patch module (JPM) is proposed to rearrange the patch embeddings via shift and patch shuffle operations which generates robust features with improved discrimination ability and more diversified coverage. (ii) The side information embeddings (SIE) is introduced to mitigate feature bias towards camera/view variations by plugging in learnable embeddings to incorporate these non-visual clues. To the best of our knowledge, this is the first work to adopt a pure transformer for ReID research. Experimental results of TransReID are superior promising, which achieve stateof-the-art performance on both person and vehicle ReID benchmarks. Code is available at https://github. com/heshuting555/TransReID. We evaluate our proposed method on four person ReID datasets, Market-1501, DukeMTMC-reID, MSMT17, Occluded-Duke, and two vehicle ReID datasets, VeRi-776 and VehicleID It is noted that, unlike other datasets, images in Occluded-Duke are selected from DukeMTMC-reID and the training/query/gallery set contains 9%/ 100%/ 10% occluded images respectively All datasets except VehicleID provide camera ID for each image, while only VeRi-776 and VehicleID dataset provide viewpoint labels for each image The details of these datasets are summarized in Table 1: Statistics of datasets used in the paper. - 15 #view #cam - . Table 2: Comparison of different backbones. Inference time is represented by comparing each model to ResNet50 as only relative comparison is necessary. All the experiments were carried out on the same machine for fair comparison. ViT-B/16 is regarded as the baseline model and abbreviated as Baseline in the rest of this paper. VeRi - 776 MSMT17 Inference Time mAP R1 Table 4: Ablation study of SIE. Since the person ReID datasets do not provide viewpoint annotations, viewpoint information can only be encoded in VeRi-776. Pairwise Distance ( w / o SIE ) intra_viewpoint \u221a inter_camera VeRi - 776 Viewpoint \u221a Method Camera inter_viewpoint mAP R1 Table 5. For the Baseline, JPM and SIE improve the performance by +2.6%/+1.0% mAP and +1.4%/+1.4% mAP on MSMT17/VeRi-776, respectively. With these two modules used together, TransReID achieves 64.9% (+3.9%) mAP","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"MSMT17\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"86.20\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"MSMT17\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"69.40\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"Market-1501\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"89.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"Market-1501\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"95.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"DukeMTMC-reID\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"82.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"DukeMTMC-reID\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"91.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Vehicle Re-Identification\\", \\"Dataset\\": \\"VeRi-776\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"97.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Vehicle Re-Identification\\", \\"Dataset\\": \\"VeRi-776\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"82.3\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"MSMT17\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"78.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"MSMT17\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"52.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"Market-1501\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"67.07\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"Market-1501\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"74.16\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"DukeMTMC-reID\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"78.59\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"DukeMTMC-reID\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"88.2\\"}} ]"},{"Context":"A BERT-based Distractor Generation Scheme with Multi-tasking and Negative Answer Training Strategies In this paper, we investigate the following two limitations for the existing distractor generation (DG) methods. First, the quality of the existing DG methods are still far from practical use. There are still room for DG quality improvement. Second, the existing DG designs are mainly for single distractor generation. However, for practical MCQ preparation, multiple distractors are desired. Aiming at these goals, in this paper, we present anew distractor generation scheme with multi-tasking and negative answer training strategies for effectively generating multiple distractors. The experimental results show that (1) our model advances the state-of-the-art result from 28.65 to 39.81 (BLEU 1 score) and (2) the generated multiple distractors are diverse and shows strong distracting power for multiple choice question. Datasets We follow the setting to evaluate our framework with the RACE dataset Table 2: A Running Example for the BDG scheme Iter . [ C ] Table 3: Answer Copying Problem on P.M. Gold 12 57 P . M . Table 4: Training Data Statistics 12284 96501 Table 5: Performance Comparison on Token Scores BLEU 4 BLEU 3 BLEU 2 BLEU 1 ROUGE L Table 6: The Effect on Mitigating Answer Copying Problem 0 121 0 Gold AN+PM BDG 115 109 GPT Table 5 : Performance Comparison on Token Scores Table 7: Comparison by MCQ Accuracy Accuracy Table 6 : The Effect on Mitigating Answer Copying Problem Table 9: Performance Comparison on Token Scores with Different \u03b3 Settings BLEU 4 BLEU 3 BLEU 2 BLEU 1 ROUGE L","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Distractor Generation\\", \\"Dataset\\": \\"RACE\\", \\"Metric\\": \\"BLEU-1\\", \\"Score\\": \\"39.81\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Distractor Generation\\", \\"Dataset\\": \\"RACE\\", \\"Metric\\": \\"BLEU-2\\", \\"Score\\": \\"24.81\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Distractor Generation\\", \\"Dataset\\": \\"RACE\\", \\"Metric\\": \\"BLEU-3\\", \\"Score\\": \\"17.66\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Distractor Generation\\", \\"Dataset\\": \\"RACE\\", \\"Metric\\": \\"BLEU-4\\", \\"Score\\": \\"13.56\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Distractor Generation\\", \\"Dataset\\": \\"RACE\\", \\"Metric\\": \\"ROUGE-L\\", \\"Score\\": \\"34.01\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Reading Comprehension\\", \\"Dataset\\": \\"RACE\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"89.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Reading Comprehension\\", \\"Dataset\\": \\"RACE\\", \\"Metric\\": \\"Accuracy (High)\\", \\"Score\\": \\"92.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Reading Comprehension\\", \\"Dataset\\": \\"RACE\\", \\"Metric\\": \\"Accuracy (Middle)\\", \\"Score\\": \\"88.7\\"}} ]"},{"Context":"A Style-Based Generator Architecture for Generative Adversarial Networks We propose an alternative generator architecture for generative adversarial networks, borrowing from style transfer literature. The new architecture leads to an automatically learned, unsupervised separation of high-level attributes (e.g., pose and identity when trained on human faces) and stochastic variation in the generated images (e.g., freckles, hair), and it enables intuitive, scale-specific control of the synthesis. The new generator improves the state-of-the-art in terms of traditional distribution quality metrics, leads to demonstrably better interpolation properties, and also better disentangles the latent factors of variation. To quantify interpolation quality and disentanglement, we propose two new, automated methods that are applicable to any generator architecture. Finally, we introduce anew, highly varied and high-quality dataset of human faces. We have collected anew dataset of human faces, Flickr-Faces-HQ (FFHQ), consisting of 70,000 high-quality images at 1024 2 resolution The dataset includes vastly more variation than CELEBA-HQ in terms of age, ethnicity and image background, and also has much better coverage of accessories such as eyeglasses, sunglasses, hats, etc We have made the dataset publicly available at https://github.com/NVlabs/ffhq-dataset BEDROOM the coarse styles basically control the viewpoint of the camera, middle styles select the particular furniture, and fine styles deal with colors and smaller details of materials These datasets were trained using the same setup as FFHQ for the duration of 70M images for BEDROOM and CATS, and 46M for CARS CARS has much higher quality training data that also allows higher spatial resolution (512 \xd7 384 instead of 256 2 ), and CATS continues to be a difficult dataset due to the high intrinsic variation in poses, zoom levels, and backgrounds Table 1. Fr\xe9chet inception distance (FID) for various generator de- signs (lower is better). In this paper we calculate the FIDs using 50,000 images drawn randomly from the training set, and report the lowest distance encountered over the course of training. FFHQ CelebA - HQ Table 2. FIDs in FFHQ for networks trained by enabling the mix- ing regularization for different percentage of training examples. Here we stress test the trained networks by randomizing 1 . . . 4 latents and the crossover points between them. Mixing regular- ization improves the tolerance to these adverse operations signifi- cantly. Labels E and F refer to the configurations in Table 1. 1 2 3 4 Number of latents during testing Table 3. Perceptual path lengths and separability scores for various generator architectures in FFHQ (lower is better). We perform the measurements in Z for the traditional network, and in W for style- based","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"LSUN Bedroom 256 x 256\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"2.65\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CelebA-HQ 1024x1024\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"5.06\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"FFHQ\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"4.43\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"LSUN Bedroom\\", \\"Metric\\": \\"FID-50k\\", \\"Score\\": \\"2.65\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CelebA-HQ 128x128\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"5.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"LSUN Bedroom 256 x 256\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"6.95\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"ImageNet 128x128\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"4.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"FFHQ 256 x 256\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"41.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"FFHQ 256 x 256\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"41.9\\"}} ]"},{"Context":"Scale-aware Fast R-CNN for Pedestrian Detection In this work, we consider the problem of pedestrian detection in natural scenes. Intuitively, instances of pedestrians with different spatial scales may exhibit dramatically different features. Thus, large variance in instance scales, which results in undesirable large intra-category variance in features, may severely hurt the performance of modern object instance detection methods. We argue that this issue can be substantially alleviated by the divide-and-conquer philosophy. Taking pedestrian detection as an example, we illustrate how we can leverage this philosophy to develop a Scale-Aware Fast R-CNN (SAF R-CNN) framework. The model introduces multiple built-in subnetworks which detect pedestrians with scales from disjoint ranges. Outputs from all the sub-networks are then adaptively combined to generate the final detection results that are shown to be robust to large variance in instance scales, via agate function defined over the sizes of object proposals. Extensive evaluations on several challenging pedestrian detection datasets well demonstrate the effectiveness of the proposed SAF R-CNN. Particularly, our method achieves state-of-the-art performance on Caltech [8], INRIA [5], and ETH [9], and obtains competitive results on KITTI [11]. We evaluate the effectiveness of the proposed SAF R-CNN on several popular pedestrian detection datasets including Caltech, INRIA, ETH, and KITTI More experimental analyses on the effectiveness of each component in our network are further given on the challenging Caltech dataset Datasets 1) Caltech: The Caltech dataset and its associated benchmark are among the most popular pedestrian detection datasets Every frame in the raw Caltech dataset has been densely annotated with the bounding boxes of pedestrian instances In the reasonable evaluation setting, the performance is evaluated on pedestrians over 50 pixels tall with no or partial occlusion 2) INRIA and ETH: The INRIA pedestrian dataset is split into a training and a testing set Following the training setting commonly adopted by the best performing approaches [10], we train our SAF R-CNN model using the INRIA training set and test it on both the INRIA and the ETH testing sets, in order","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Pedestrian Detection\\", \\"Dataset\\": \\"Caltech\\", \\"Metric\\": \\"Reasonable Miss Rate\\", \\"Score\\": \\"9.68\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Pedestrian Detection\\", \\"Dataset\\": \\"Caltech\\", \\"Metric\\": \\"Reasonable Miss Rate\\", \\"Score\\": \\"12.4\\"}} ]"},{"Context":"Learning One Class Representations for Face Presentation Attack Detection using Multi-channel Convolutional Neural Networks Face recognition has evolved as a widely used biometric modality. However, its vulnerability against presentation attacks poses a significant security threat. Though presentation attack detection (PAD) methods try to address this issue, they often fail in generalizing to unseen attacks. In this work, we propose anew framework for PAD using a one-class classifier, where the representation used is learned with a Multi-Channel Convolutional Neural Network (MCCNN). A novel loss function is introduced, which forces the network to learn a compact embedding for bonafide class while being far from the representation of attacks. A one-class Gaussian Mixture Model is used on top of these embeddings for the PAD task. The proposed framework introduces a novel approach to learn a robust PAD system from bonafide and available (known) attack classes. This is particularly important as collecting bonafide data and simpler attacks are much easier than collecting a wide variety of expensive attacks. The proposed system is evaluated on the publicly available WMCA multi-channel face PAD database, which contains a wide variety of 2D and 3D attacks. Further, we have performed experiments with MLFP and SiW-M datasets using RGB channels only. Superior performance in unseen attack protocols shows the effectiveness of the proposed approach. Software, data, and protocols to reproduce the results are made available publicly. In order to evaluate the effectiveness of the proposed approach, we have performed experiments in three publicly available databases, namely WMCA, MLFP, and SiW-M datasets We have made challenging protocols in the WMCA dataset to perform an extensive set of evaluations emulating real-world unseen attack scenarios 1) Protocols in SiW-M: To emulate unseen attack scenarios, we use the leave-one-out (LOO) testing protocols available with the SiW-M dataset The evaluation set consists of 20% of bonafide data and the attack which was left out in the training phase The subjects in bonafide sets are disjoint in train and evaluation sets For the MLFP dataset, we report only EER in the evaluation set since only two sets are available \u2022 MCCNN(BCE+OCCL)-GMM: Here, the bonafide embeddings from the MCCNN trained using both the losses are used to train a GMM, and in the evaluation stage, the score from the one class GMM is used","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Face Anti-Spoofing\\", \\"Dataset\\": \\"MLFP\\", \\"Metric\\": \\"HTER\\", \\"Score\\": \\"3.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Presentation Attack Detection\\", \\"Dataset\\": \\"WMCA\\", \\"Metric\\": \\"ACER\\", \\"Score\\": \\"0.097\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Face Presentation Attack Detection\\", \\"Dataset\\": \\"WMCA\\", \\"Metric\\": \\"ACER\\", \\"Score\\": \\"0.3\\"}} ]"},{"Context":"Temporal Dynamic Graph LSTM for Action-driven Video Object Detection In this paper, we investigate a weakly-supervised object detection framework. Most existing frameworks focus on using static images to learn object detectors. However, these detectors often fail to generalize to videos because of the existing domain shift. Therefore, we investigate learning these detectors directly from boring videos of daily activities. Instead of using bounding boxes, we explore the use of action descriptions as supervision since they are relatively easy to gather. A common issue, however, is that objects of interest that are not involved inhuman actions are often absent in global action descriptions known as \\"missing label\\". To tackle this problem, we propose a novel temporal dynamic graph Long Short-Term Memory network (TD-Graph LSTM). TD-Graph LSTM enables global temporal reasoning by constructing a dynamic graph that is based on temporal correlations of object proposals and spans the entire video. The missing label issue for each individual frame can thus be significantly alleviated by transferring knowledge across correlated objects proposals in the whole video. Extensive evaluations on a large-scale daily-life action dataset (i.e., Charades) demonstrates the superiority of our proposed method. We also release object bounding-box annotations for more than 5,000 frames in Charades. We believe this annotated data can also benefit other research on video-based object recognition in the future. Dataset Analysis We evaluate the action-drive weaklysupervised object detection performance on the Charades dataset The Charades video dataset is composed of daily indoor activities collected through Amazon Mechanical Turk In order to evaluate the video object detection performance over 17 daily object classes, we collect the bounding box annotations for 5,000 test frames from 200 videos in the Charades test set This poses more challenges for the object detection model compared to an image-based object detection dataset, such as the most popular PASCAL VOC that is widely used in existing weakly-based object detection methods further shows example frames with action labels on the Charades dataset Moreover, the video frames often appear with a very cluttered background, blurry objects and diverse viewpoints, which are more challenging and realistic compared to existing image datasets (e.g., MS COCO and ImageNet) and video datasets (e.g., UCF101) Evaluation Measures We evaluate the performance of both object Table 1. Per-class performance comparison of our proposed models with two state-of-the-art weakly-supervised learning methods when evaluating on the Charades dataset[32], test classification average precision (%). bounding box numbers in each image of the test set . bed tv towel vacuum window mAP 2500 table 10 12 sofa Percentage 18 ( 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 2000 ) 0 door laptop mirror pillow refri shelf 1 1500 3 ( % ) dish 5 6 broom chair Objects 8 cup Table 2. Per-class performance comparison of our proposed models with two state-of-the-art weakly-supervised learning methods when evaluating on the Charades dataset[32], test detection average precision (%). bed door laptop mirror pillow refri shelf sofa tv bed broom chair cup dish door laptop mirror pillow refri shelf sofa table dish broom chair towel vacuum window mAP table cup Table 3. Performance comparison of","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Weakly Supervised Object Detection\\", \\"Dataset\\": \\"Charades\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"1.98\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Action Detection\\", \\"Dataset\\": \\"Charades\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"45.1\\"}} ]"},{"Context":"Correspondence Networks with Adaptive Neighbourhood Consensus In this paper, we tackle the task of establishing dense visual correspondences between images containing objects of the same category. This is a challenging task due to large intra-class variations and alack of dense pixel level annotations. We propose a convolutional neural network architecture, called adaptive neighbourhood consensus network (ANC-Net), that can be trained end-to-end with sparse keypoint annotations, to handle this challenge. At the core of ANC-Net is our proposed non-isotropic 4D convolution kernel, which forms the building block for the adaptive neighbourhood consensus module for robust matching. We also introduce a simple and efficient multi-scale self-similarity module in ANC-Net to make the learned feature robust to intra-class variations. Furthermore, we propose a novel orthogonal loss that can enforce the one-to-one matching constraint. We thoroughly evaluate the effectiveness of our method on various benchmarks, where it substantially outperforms state-of-the-art methods. Datasets We evaluate our method on four public datasets, namely, PF-PASCAL, Spair-71k, and CUB Spair-71k dataset is much more challenging than the others as it contains both large viewpoint differences and scale differences Spair-71k is only used to evaluate the transferrability of the models trained on the PF-PASCAL training split The CUB dataset contains 11,788 images of various species of birds with large variation of appearance, shape and pose Evaluation metric Following common practice, we use the percentage of correct key-points (PCK@\u03b1) as our evaluation metric Table 1: Comparison with state-of-the-art methods. Spair - 71k CUB PF - PASCAL - Table 2. Our method consistently outperforms NC-Net and DCCNet. w / o 302 w / o 95 Original Table 2: Unbiased evaluation on PF-PASCAL. w / o 302 w / o 95 Original Table 3: Ablation study experimental results. 82 . 6 / 83 . 7 PCK@0 . 1 78 . 9 / 81 . 9","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic correspondence\\", \\"Dataset\\": \\"PF-PASCAL\\", \\"Metric\\": \\"PCK\\", \\"Score\\": \\"88.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic correspondence\\", \\"Dataset\\": \\"SPair-71k\\", \\"Metric\\": \\"PCK\\", \\"Score\\": \\"30.1\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic correspondence\\", \\"Dataset\\": \\"N3-weighted\\", \\"Metric\\": \\"PCK@0.5\\", \\"Score\\": \\"88.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic correspondence\\", \\"Dataset\\": \\"N3-weighted\\", \\"Metric\\": \\"PCK@0.5\\", \\"Score\\": \\"43.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic correspondence\\", \\"Dataset\\": \\"N3-test\\", \\"Metric\\": \\"PCK@0.2\\", \\"Score\\": \\"42.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic correspondence\\", \\"Dataset\\": \\"N3-test\\", \\"Metric\\": \\"PCK@0.3\\", \\"Score\\": \\"42.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic correspondence\\", \\"Dataset\\": \\"N3-test\\", \\"Metric\\": \\"PCK@0.4\\", \\"Score\\": \\"32.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic correspondence\\", \\"Dataset\\": \\"N3-test\\", \\"Metric\\": \\"PCK@0.5\\", \\"Score\\": \\"41.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic correspondence\\", \\"Dataset\\": \\"N3-test\\", \\"Metric\\": \\"PCK@0.2\\", \\"Score\\": \\"37.3\\""},{"Context":"Invariant Information Clustering for Unsupervised Image Classification and Segmentation We present a novel clustering objective that learns a neural network classifier from scratch, given only unlabelled data samples. The model discovers clusters that accurately match semantic classes, achieving state-of-the-art results in eight unsupervised clustering benchmarks spanning image classification and segmentation. These include STL10, an unsupervised variant of ImageNet, and CIFAR10, where we significantly beat the accuracy of our closest competitors by 6.6 and 9.5 absolute percentage points respectively. The method is not specialised to computer vision and operates on any paired dataset samples; in our experiments we use random transforms to obtain a pair from each image. The trained network directly outputs semantic labels, rather than high dimensional representations that need external processing to be usable for semantic clustering. The objective is simply to maximise mutual information between the class assignments of each pair. It is easy to implement and rigorously grounded in information theory, meaning we effortlessly avoid degenerate solutions that other clustering methods are susceptible to. In addition to the fully unsupervised mode, we also test two semi-supervised settings. The first achieves 88.8% accuracy on STL10 classification, setting anew global state-of-the-art overall existing methods (whether supervised, semi-supervised or unsupervised). The second shows robustness to 90% reductions in label coverage, of relevance to applications that wish to make use of small amounts of labels. github.com/xu-ji/IIC arXiv:1807.06653v4 [cs.CV]  Table 1: Unsupervised image clustering. Legend: \u2020Method based on k-means. \u2021Method that does not directly learn a clustering function and requires further application of k-means to be used for image clustering. Results obtained using our experiments with authors\' original code. STL10 CIFAR10 CFR100 - 20 MNIST Table 2: Ablations of IIC (unsupervised setting). Each row shows a single change from the full setting. The full setting has auxiliary overclus- tering, 5 initialisation heads, 5 sample repeats, and uses the unlabelled data subset of STL10. STL10 Table 3: Fully and semi-supervised clas- sification. Legend: *Fully supervised method. Our experiments with authors\' code. \u2020Multi-fold evaluation. STL10 Figure 5 : Unsupervised image clustering ( IIC ) results on STL10 . Dog Table 4: Unsupervised segmentation. IIC experiments use a single sub- head. Legend: \u2020Method based on k-means. \u2021Method that does not directly learn a clustering function and requires further application of k-means to be","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Semantic Segmentation\\", \\"Dataset\\": \\"Potsdam-3\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"45.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Semantic Segmentation\\", \\"Dataset\\": \\"Potsdam\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"65.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Semantic Segmentation\\", \\"Dataset\\": \\"COCO-Stuff-3\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"72.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Semantic Segmentation\\", \\"Dataset\\": \\"COCO-Stuff-15\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"27.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"ARI\\", \\"Score\\": \\"0.411\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.617\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Backbone\\", \\"Score\\": \\"ResNet-34\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"0.511\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Train set\\", \\"Score\\": \\"Train+Test\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised MNIST\\", \\"Dataset\\": \\"MNIST\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"99.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"STL-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"88.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"STL-10\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"88.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Image Classification\\", \\"Dataset\\": \\"CIFAR-20\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"25.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"61.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Image Classification\\", \\"Dataset\\": \\"STL-10\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"61.00\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Image Classification\\", \\"Dataset\\": \\"MNIST\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"99.3\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"STL-10\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"88.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"STL-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"88.8\\"}} ]"},{"Context":"Interpretable 3D Human Action Analysis with Temporal Convolutional Networks The discriminative power of modern deep learning models for 3D human action recognition is growing ever so potent. In conjunction with the recent resurgence of 3D human action representation with 3D skeletons, the quality and the pace of recent progress have been significant. However, the inner workings of state-of-the-art learning based methods in 3D human action recognition still remain mostly black-box. In this work, we propose to use anew class of models known as Temporal Convolutional Neural Networks (TCN) for 3D human action recognition. Compared to popular LSTM-based Recurrent Neural Network models, given interpretable input such as 3D skeletons, TCN provides us away to explicitly learn readily interpretable spatio-temporal representations for 3D human action recognition. We provide our strategy in re-designing the TCN with interpretability in mind and how such characteristics of the model is leveraged to construct a powerful 3D activity recognition method. Through this work, we wish to take a step towards a spatio-temporal model that is easier to understand, explain and interpret. The resulting model, Res-TCN, achieves state-of-the-art results on the largest 3D human action recognition dataset, NTU-RGBD. We evaluate Res-TCN on 3D skeleton based human activity recognition dataset of NTU NTU RGB+D dataset is currently the largest human activity recognition dataset with full 3D skeleton annotations The dataset provides two train/test split paradigms: Cross-Subject (CS) and Cross-View (CV) settings The dataset covers 40 distinct subjects with varying physical traits Table 1. Comparison to other learning based methods on NTURGB+D skeleton dataset with Cross-Subject (CS) and Cross- View (CV) settings in accuracy (%). CS CV","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"Varying-view RGB-D Action-Skeleton\\", \\"Metric\\": \\"Accuracy (AV I)\\", \\"Score\\": \\"48%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"Varying-view RGB-D Action-Skeleton\\", \\"Metric\\": \\"Accuracy (AV II)\\", \\"Score\\": \\"68%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"Varying-view RGB-D Action-Skeleton\\", \\"Metric\\": \\"Accuracy (CS)\\", \\"Score\\": \\"63%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"Varying-view RGB-D Action-Skeleton\\", \\"Metric\\": \\"Accuracy (CV I)\\", \\"Score\\": \\"14%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"Varying-view RGB-D Action-Skeleton\\", \\"Metric\\": \\"Accuracy (CV II)\\", \\"Score\\": \\"48%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"Kinetics-Skeleton dataset\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"20.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (CS)\\", \\"Score\\": \\"74.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (CV)\\", \\"Score\\": \\"83.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Activity Recognition\\", \\"Dataset\\": \\"EV-Action\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"80.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Activity Recognition\\", \\"Dataset\\": \\"EV-Action\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"64.1\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (CS)\\", \\"Score\\": \\"71.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (CV)\\", \\"Score\\": \\"84.9\\"}} ]"},{"Context":"DP-LSTM: Differential Privacy-inspired LSTM for Stock Prediction Using Financial News Stock price prediction is important for value investments in the stock market. In particular, short-term prediction that exploits financial news articles is promising in recent years. In this paper, we propose a novel deep neural network DP-LSTM for stock price prediction, which incorporates the news articles as hidden information and integrates difference news sources through the differential privacy mechanism. First, based on the autoregressive moving average model (ARMA), a sentiment-ARMA is formulated by taking into consideration the information of financial news articles in the model. Then, an LSTM-based deep neural network is designed, which consists of three components: LSTM, VADER model and differential privacy (DP) mechanism. The proposed DP-LSTM scheme can reduce prediction errors and increase the robustness. Extensive experiments on S&P 500 stocks show that (i) the proposed DP-LSTM achieves 0.32% improvement in mean MPA of prediction result, and (ii) for the prediction of the market index S&P 500, we achieve up to 65.79% improvement in MSE. We calculate the mean prediction accuracy (MPA) to evaluate the proposed methods, which is defined as where X t, is the real stock price of the -th stock on the t-th day, L is the number of stocks andX t, is the corresponding prediction result Table 1: Predicted Mean MPA results. Mean MPA Table 2: S&P 500 predicted results. DP - LSTM LSTM without news LSTM with news","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Stock Price Prediction\\", \\"Dataset\\": \\"2019_test set\\", \\"Metric\\": \\"10 fold Cross validation\\", \\"Score\\": \\"22\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"SYelp Binary classification\\", \\"Metric\\": \\"Error\\", \\"Score\\": \\"4.16\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"SYelp Binary classification\\", \\"Metric\\": \\"Error\\", \\"Score\\": \\"11.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"SYelp Binary classification\\", \\"Metric\\": \\"Error\\", \\"Score\\": \\"41.87\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"SYelp Binary classification\\", \\"Metric\\": \\"Error\\", \\"Score\\": \\"71.47\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"SYelp Fine-grained classification\\", \\"Metric\\": \\"Error\\", \\"Score\\": \\"29.62\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"SYelp Fine-grained classification\\", \\"Metric\\": \\"Error\\", \\"Score\\": \\"29.42\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"SYelp Fine-grained classification\\", "},{"Context":"Multi-Fiber Networks for Video Recognition In this paper, we aim to reduce the computational cost of spatio-temporal deep neural networks, making them run as fast as their 2D counterparts while preserving state-of-the-art accuracy on video recognition benchmarks. To this end, we present the novel Multi-Fiber architecture that slices a complex neural network into an ensemble of lightweight networks or fibers that run through the network. To facilitate information flow between fibers we further incorporate multiplexer modules and end up with an architecture that reduces the computational cost of 3D networks by an order of magnitude, while increasing recognition performance at the same time. Extensive experimental results show that our multi-fiber architecture significantly boosts the efficiency of existing convolution networks for both image and video recognition tasks, achieving state-of-the-art performance on UCF-101, HMDB-51 and Kinetics datasets. Our proposed model requires over 9\xd7 and 13\xd7 less computations than the I3D [1] and R(2+1)D [2] models, respectively, yet providing higher accuracy. We evaluate the proposed multi-fiber network on three benchmark datasets, Kinetics, UCF-101 and HMDB51, and compare the results with other state-of-the-art models Note, the complexity is evaluated with FLOPs, i.e Table 2. Multi-fiber Network architecture. The \\"2D MF-Net\\" takes images as input, while the \\"3D MF-Net\\" takes frames, i.e. video clips, as input. Note, the complexity is evaluated with FLOPs, i.e. floating-point multiplication-adds. The stride of \\"3D MF- Net\\" is denoted by \\"(temporal stride, height stride, width stride)\\", and the stride of \\"2D MF-Net\\" is denoted by \\"(height stride, width stride)\\". ( 1 , 2 , 2 ) 3D MF - Net ( 1 , 1 ) Stride ( 2 , 2 ) ( 1 , 2 , 2 ) 1000 ( 2 , 1 , 1 ) #Channel ( 1 , 1 , 1 ) 400 1 \xd7 1 \xd7 1 8 \xd7 7 \xd7 7 7 \xd7 7 1 \xd7 1 Output Size 2D MF - Net Table 3. Comparison on action recognition accuracy with state-of-the-arts on Kinetics. The complexity is measured using FLOPs, i.e. floating-point multiplication-adds. All results","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"72.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@5\\", \\"Score\\": \\"90.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"UCF101\\", \\"Metric\\": \\"3-fold Accuracy\\", \\"Score\\": \\"96.0\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"73.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"71.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"UCF101\\", \\"Metric\\": \\"3-fold Accuracy\\", \\"Score\\": \\"96.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"HMDB-51\\", \\"Metric\\": \\"Average accuracy of 3 splits\\", \\"Score\\": \\"74.9\\"}} ]"},{"Context":"Time-aware Large Kernel Convolutions To date, most state-of-the-art sequence modeling architectures use attention to build generative models for language based tasks. Some of these models use all the available sequence tokens to generate an attention distribution which results in time complexity of O(n 2 ). Alternatively, they utilize depthwise convolutions with softmax normalized kernels of size k acting as a limited-window self-attention, resulting in time complexity of O(k\xb7n). In this paper, we introduce Time-aware Large Kernel (TaLK) Convolutions, a novel adaptive convolution operation that learns to predict the size of a summation kernel instead of using a fixed-sized kernel matrix. This method yields a time complexity of O(n), effectively making the sequence encoding process linear to the number of tokens. We evaluate the proposed method on large-scale standard machine translation, abstractive summarization and language modeling datasets and show that TaLK Convolutions constitute an efficient improvement over other attention/convolution based approaches. We evaluated our proposed encoding technique on machine translation, abstractive summarization and language mod- eling Machine Translation On the machine translation task, we report results on three mainstream benchmark datasets: WMT English to German (En-De), WMT English to French (En-Fr) and IWSLT German to English (De-En) For all datasets, we replicated the pre-processing steps mentioned in We validated on newstest2012+2013 and tested on newstest2014 evaluation datasets For all datasets, we measured case-sensitive tokenized BLEU scores using multi-bleu 1 For all datasets, we used beam search with beam width 5 Abstractive Summarization For the abstractive summarization task, we decided to experiment with the CNN-DailyMail dataset The dataset is composed by approximately 280K news articles with associated multi-sentence summaries Language Modeling We experimented on the WikiText-103 benchmark dataset Specifically, we follow for WMT En-De and WMT En-Fr datasets the model hidden size d was set to 1024, the feed-forward hidden size d ff Table 2. Machine translation accuracy in terms of BLEU for WMT En-De and WMT En-Fr on newstest2014. - WMT En - Fr WMT En - De Table 3. Machine translation accuracy in terms of BLEU on IWSLT De-En. - WMT En - Fr WMT En - De Table 4. Results on CNN-DailyMail abstractive summarization. Rouge - L Rouge - 1 Rouge - 2 Table 5. Test perplexity on WikiText-103. We used adaptive inputs similar to Baevski & Auli (2019) and show that our method yields better perplexity than dynamic convolutions and comparative per- formance with self-attention. Rouge - L Rouge - 1 Rouge - 2 Table 6. Throughput and memory consumption decrease measured for different sequence lengths (n) on a batch of size 10 with each token being represented with d = 1024 and H = 16. Throughput is calculated across 100K iterations of a single input encoding execution for each","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-French\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"43.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"IWSLT2014 German-English\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"35.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-German\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"29.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-103\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"240M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-103\\", \\"Metric\\": \\"Test perplexity\\", \\"Score\\": \\"23.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Document Summarization\\", \\"Dataset\\": \\"CNN / Daily Mail\\", \\"Metric\\": \\"ROUGE-1\\", \\"Score\\": \\"40.59\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Document Summarization\\", \\"Dataset\\": \\"CNN / Daily Mail\\", \\"Metric\\": \\"ROUGE-2\\", \\"Score\\": \\"18.97\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Document Summarization\\", \\"Dataset\\": \\"CNN / Daily Mail\\", \\"Metric\\": \\"ROUGE-L\\", \\"Score\\": \\"36.81\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Document Summarization\\", \\"Dataset\\": \\"CNN / Daily Mail\\", \\"Metric\\": \\"ROUGE-1\\", \\"Score\\": \\"40.03\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Document Summarization\\", \\"Dataset\\": \\"CNN / Daily Mail\\", \\"Metric\\": \\"ROUGE-2\\", \\"Score\\": \\"18.45\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Document Summarization\\", \\"Dataset\\": \\"CNN / Daily Mail\\", \\"Metric\\": \\"ROUGE-L\\", \\"Score\\": \\"36.13\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-French\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"43.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-French\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"44.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2016 English-Romanian\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"27.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-German\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"21.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-German\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"14.54\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"IWSLT2015 English-German\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"37.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"IWSLT2015 German-English\\", \\"Metric\\": \\"BLEU score\\", \'Score\'"},{"Context":"A light-based device for solving the Hamiltonian path problem In this paper we suggest the use of light for performing useful computations. Namely, we propose a special device which uses light rays for solving the Hamiltonian path problem on a directed graph. The device has a graph-like representation and the light is traversing it following the routes given by the connections between nodes. In each node the rays are uniquely marked so that they can be easily identified. At the destination node we will search only for particular rays that have passed only once through each node. We show that the proposed device can solve small and medium instances of the problem in reasonable time.  Table 1. The labeling system generated by our backtracking procedure. First column contains the number of nodes of the graph. The second column represents the labels applied to nodes. 8 , 12 , 14 , 15 16 , 24 , 28 , 30 , 31 Labels ( delays ) n","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"ON THE EXPECTED MAXIMUM DEGREE OF GABRIEL AND YAO GRAPHS Motivated by applications of Gabriel graphs and Yao graphs in wireless ad-hoc networks, we show that the maximal degree of a random Gabriel graph or Yao graph defined on n points drawn uniformly at random from a unit square grows as \u0398(log n/ log log n) in probability.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"ProtTrans: Towards Cracking the Language of Life\'s Code Through Self-Supervised Learning Computational biology and bioinformatics provide vast data gold-mines from protein sequences, ideal for Language Models taken from NLP. These LMs reach for new prediction frontiers at low inference costs. Here, we trained two auto-regressive models (Transformer-XL, XLNet) and four auto-encoder models (BERT, Albert, Electra, T5) on data from UniRef and BFD containing up to 393 billion amino acids. The LMs were trained on the Summit supercomputer using 5616 GPUs and TPU Pod up-to 1024 cores. Dimensionality reduction revealed that the raw protein LM-embeddings from unlabeled data captured some biophysical features of protein sequences. We validated the advantage of using the embeddings as exclusive input for several subsequent tasks. The first was a per-residue prediction of protein secondary structure (3-state accuracy Q3=81%-87%); the second were per-protein predictions of protein sub-cellular localization (ten-state accuracy: Q10=81%) and membrane vs. water-soluble (2-state accuracy Q2=91%). For the per-residue predictions the transfer of the most informative embeddings (ProtT5) for the first time outperformed the state-of-the-art without using evolutionary information thereby bypassing expensive database searches. Taken together, the results implied that protein LMs learned some of the grammar of the language of life. To facilitate future work, we released our models at https://github.com/agemagician/ProtTrans. Language model corpora Here, we show more details on the differences between the different corpora used for protein LM pre-training Such an analysis could allow fora cheap and fast analysis of single proteins without a) needing large labeled datasets for supervised training and b) being less influenced by the experimental bias in today\'s labeled databases which focus mostly on model organisms with applications to biotechnology 2 , 122 BFD UniRef100 Fp32 Master Weight 15% 4096 25% 420M 32768 / 6144 15360 / 2560 40K / 5K 44928 Summit 18 / 7 10K 20K Lamb 343K 224M 32 / 6 TPU Pod 2048 140K / 20K 40K / 40K 40K / 0K 11B 9216 / 3584 AdaFactor 409M 22464 - 920K 3B Adam 2 21 / 2 4 5 1024 8 10752 / 1024 30 / 5 None Table 9), the other because it is larger and less redundant (dubbed NEW364 introduced here). Standard errors were computed using bootstrapping: CASP12=\xb11.6%, NEW364=\xb10.5%. Highest values in each column marked in bold-face. 78 , 1 CASP12 73 , 9 NEW364 0 100 t Q10 : Localization Q2 : Membrane / other Table 8. TS115 CASP12 CB513 NEW364 TS115 CASP12 CB513 NEW364 SeqVec Time ProtAlbert ProtT5 - XL Mean 89 59 Max ProtT5 - XXL ProtTXL ProtBert / ProtElectra Concat Min","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"TS115\\", \\"Metric\\": \\"Q3\\", \\"Score\\": \\"0.87\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"TS115\\", \\"Metric\\": \\"Q8\\", \\"Score\\": \\"0.77\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"TS115\\", \\"Metric\\": \\"Q3\\", \\"Score\\": \\"0.85\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"TS115\\", \\"Metric\\": \\"Q8\\", \\"Score\\": \\"0.74\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"TS115\\", \\"Metric\\": \\"Q3\\", \\"Score\\": \\"0.84\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"TS115\\", \\"Metric\\": \\"Q8\\", \\"Score\\": \\"0.73\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"CB513\\", \\"Metric\\": \\"Q3\\", \\"Score\\": \\"0.86\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"CB513\\", \\"Metric\\": \\"Q8\\", \\"Score\\": \\"0.74\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"CB513\\", \\"Metric\\": \\"Q3\\", \\"Score\\": \\"0.84\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"CB513\\", \\"Metric\\": \\"Q8\\", \\"Score\\": \\"0.71\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"CB513\\", \\"Metric\\": \\"Q3\\", \\"Score\\": \\"0.83\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"CB513\\", \\"Metric\\": \\"Q8\\", \\"Score\\": \\"0.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"CASP12\\", \\"Metric\\": \\"Q3\\", \\"Score\\": \\"0.81\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"CASP12\\", \\"Metric\\": \\"Q8\\", \\"Score\\": \\"0.70\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"CASP12\\", \\"Metric\\": \\"Q3\\", \\"Score\\": \\"0.77\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"CASP12\\", \\"Metric\\": \\"Q8\\", \\"Score\\": \\"0.66\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"CASP12\\", \\"Metric\\": \\"Q3\\", \\"Score\\": \\"0.76\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Protein Secondary Structure Prediction\\", \\"Dataset\\": \\"CASP12\\", \\"Metric\\": \\"Q8\\", \\"Score\\": \\"0.65\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"78.0%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Drug Discovery\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"65.3%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Drug Discovery\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"62.5%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Drug Discovery\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"38.14\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Drug Discovery\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"73.21\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Drug Discovery\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"75.9%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Drug Discovery\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"75.3%\\"}}, { \\"LEADERBOARD\\": { "},{"Context":"Unifying Graph Convolutional Neural Networks and Label Propagation Label Propagation (LPA) and Graph Convolutional Neural Networks (GCN) are both message passing algorithms on graphs. Both solve the task of node classification but LPA propagates node label information across the edges of the graph, while GCN propagates and transforms node feature information. However, while conceptually similar, theoretical relation between LPA and GCN has not yet been investigated. Here we study the relationship between LPA and GCN in terms of two aspects: (1) feature/label smoothing where we analyze how the feature/label of one node is spread over its neighbors; And, (2) feature/label influence of how much the initial feature/label of one node influences the final feature/label of another node. Based on our theoretical analysis, we propose an end-to-end model that unifies GCN and LPA for node classification. In our unified model, edge weights are learnable, and the LPA serves as regularization to assist the GCN in learning proper edge weights that lead to improved classification performance. Our model can also be seen as learning attention weights based on node labels, which is more task-oriented than existing feature-based attention models. Ina number of experiments on real-world graphs, our model shows superiority over state-of-the-art GCN-based methods in terms of node classification accuracy. We evaluate our model and present its performance on five datasets including citation networks and coauthor networks We use the following five datasets in our experiments: datasets: Cora, Citeseer, and Pubmed In these datasets, nodes correspond to documents, edges correspond to citation links, and each node has a sparse bag-of-words feature vector as well as a class label Statistics of the five datasets are shown in Table 1: Dataset statistics after removing self-loops and duplicate edges. 19 , 717 8 , 415 81 , 894 2 , 708 1 , 433 Coauthor - CS Cora Citeseer 3 , 327 15 4 , 552 18 , 333 3 , 703 Pubmed 34 , 493 3 5 , 278 500 5 6 44 , 324 Coauthor - Phy 7 6 , 805 247 , 962 Table 2: Mean and the 95% confidence intervals of test set accuracy for all methods and datasets. Citeseer Coauthor - CS Coauthor - Phy Cora Pubmed Table 3: Result of GCN-LPA on Citeseer dataset with differet ratio of labeled nodes in LPA. 100% 0% 20% 40% 60% 80% Table 4: Hyper-parameter settings for all datasets. Citeseer 16 Coauthor - CS Coauthor - Phy Cora Pubmed 32","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Citeseer\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"78.7%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Pubmed\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"87.8%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Cora\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"88.5%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Coauthor Phy\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"96.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Coauthor CS\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"94.8%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Citeseer\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"71.8%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Pubmed\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"76.80%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Cora\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"84.8%\\"}} ]"},{"Context":"Proposition of a full deterministic medium access method for wireless network in a robotic application Today, many network applications require shorter react time. Robotic field is an excellent example of these needs: robot react time has a direct effect on its task\'s complexity. Here, we propose a full deterministic medium access method fora wireless robotic application. This contribution is based on some low-power wireless personal area networks, like ZigBee standard. Indeed, ZigBee has identified limits with Quality of Service due to non-determinist medium access and probable collisions during medium reservation requests. In this paper, two major improvements are proposed: an efficient polling of the star nodes and a temporal deterministic distribution of peer-to-peer messages. This new MAC protocol with no collision offers some QoS faculties.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Effect of different substrates on Compact stacked square Microstrip Antenna Selection of the most suitable substrate fora Microstrip antenna is a matter of prime importance. This is because many limitations of the microstrip antenna such as high return loss, low gain and low efficiency can be overcome by selecting an appropriate substrate for fabrication of the antenna, without shifting the resonant frequency significantly. The substate properties such as its dielectric constant, loss tangent have a pronounced effect on the antenna characteristics. Some of the critical properties that are to betaken care of while selecting a dielectric are homogeneity, moisture absorption and adhesion of metal-foil cladding. In this paper a comprehensive study of the effect of variation of substrate material on the antenna properties has been presented.  buten 4350 SIMULATION RESULTS TABLE 1 Return Loss ( S11 ) Loss ( dBi ) Tangent Resonant ( \u03b5r ) frequency Direc - ( % ) ( GHz ) Efficiency Electrical tivity Gain Antenna Table 1. buten 4350 SIMULATION RESULTS TABLE 1 Return Loss ( S11 ) Loss ( dBi ) Tangent Resonant ( \u03b5r ) frequency Direc - ( % ) ( GHz ) Efficiency Electrical tivity Gain Antenna","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Dependent Randomized Rounding for Matroid Polytopes and Applications Motivated by several applications, we consider the problem of randomly rounding a fractional solution in a matroid (base) polytope to an integral one. We consider the pipage rounding technique [5,6,36] and also present anew technique, randomized swap rounding. Our main technical results are concentration bounds for functions of random variables arising from these rounding techniques. We prove Chernofftype concentration bounds for linear functions of random variables arising from both techniques, and also a lower-tail exponential bound for monotone submodular functions of variables arising from randomized swap rounding.The following are examples of our applications.\u2022 We give a (1 \u2212 1/e \u2212 \u03b5)-approximation algorithm for the problem of maximizing a monotone submodular function subject to 1 matroid and k linear constraints, for any constant k \u2265 1 and \u03b5 > 0. We also give the same result fora super-constant number k of \\"loose\\" linear constraints, where the right-hand side dominates the matrix entries by an \u2126(\u03b5 \u22122 log k) factor.\u2022 We present a result on minimax packing problems that involve a matroid base constraint. We give an O(log m/ log log m)-approximation for the general problem min{\u03bb : \u2203x \u2208 {0, 1} N , x \u2208 B(M), Ax \u2264 \u03bbb} where m is the number of packing constraints. Examples include the low-congestion multi-path routing problem [34] and spanning-tree problems with capacity constraints on cuts [4,16].\u2022 We generalize the continuous greedy algorithm [35,6] to problems involving multiple submodular functions, and use it to find a (1 \u2212 1/e \u2212 \u03b5)-approximate pareto set for the problem of maximizing a constant number of monotone submodular functions subject to a matroid constraint. An example is the Submodular Welfare Problem where we are looking for an approximate pareto set with respect to individual players\' utilities.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"\xc3 \xdd \xdb\xd3\xd6 \xd7 \xd0 \xd2 \xd3\xd2\xda\xd3\xd0\xd9\xd8 \xd3\xd2\xb8 \xd6\xd2\xd3\xd9\xd0\xd0 \xb9 \xd9\xd7\xd7 \xd2 \xd1\xd3 \xd0\xb8\xc5 \xd6 \xd3\xda \xd2 \xc5\xd3\xd2\xd8 \xd6\xd0\xd3 \xd1 \xd8 \xd3 \xd7 * \xd3\xd6\xd6 \xd7\xd4\xd3\xd2 \xd2 \xd9\xd8 \xd3\xd6\xba \xcc \xd0\xba \xb7\xbf\xbf \xbe \xbc \xbf \xbe \xdc \xb7\xbf\xbf \xbe \xbc \xbf \xbf\xbc \xd1 \xd0 \xd6 \xd7\xd7 \xd7 \xba \xd6\xdd\xd2\xba \xb9\xd2 \xd2\xd8 \xd7\xba \xd6\xb4 \xba \xb5\xb8\xc2 \xd6\xd3\xd1 \xba\xc1 \xd6 \xd6\xdd\xd2\xba \xb9\xd2 \xd2\xd8 \xd7\xba \xd6\xb4\xc2\xba \xc1 \xd6\xb5\xb8 \xd6 \xba\xc4 \xb9 \xd6\xd4 \xd2\xd8 \xd6 \xd6\xdd\xd2\xba \xb9\xd2 \xd2\xd8 \xd7\xba \xd6\xb4 \xba \xc4 \xd6\xd4 \xd2\xd8 \xd6\xb5\xba \xc8\xd6 \xd4\xd6 \xd2\xd8 \xd7\xd9 \xd1 \xd8\xd8 \xd8\xd3 \xd0\xd7 \xda \xd6 \xbe\xbc AE\xd3\xda \xd1 \xd6 \xbe\xbc\xbd \xbd\xba \xc1\xd2\xd8\xd6\xd3 \xd9\xd8 \xd3\xd2","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"DAG-Net: Double Attentive Graph Neural Network for Trajectory Forecasting Understanding human motion behaviour is a critical task for several possible applications like self-driving cars or social robots, and in general for all those settings where an autonomous agent has to navigate inside a human-centric environment. This is non-trivial because human motion is inherently multi-modal: given a history of human motion paths, there are many plausible ways by which people could move in the future. Additionally, people activities are often driven by goals, e.g. reaching particular locations or interacting with the environment. We address the aforementioned aspects by proposing anew recurrent generative model that considers both single agents\' future goals and interactions between different agents. The model exploits a double attention-based graph neural network to collect information about the mutual influences among different agents and to integrate it with data about agents\' possible future objectives. Our proposal is general enough to be applied to different scenarios: the model achieves state-of-the-art results in both urban environments and also in sports applications.","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Trajectory Prediction\\", \\"Dataset\\": \\"Stanford Drone\\", \\"Metric\\": \\"ADE (in world coordinates)\\", \\"Score\\": \\"0.54\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Trajectory Prediction\\", \\"Dataset\\": \\"Stanford Drone\\", \\"Metric\\": \\"FDE (in world coordinates)\\", \\"Score\\": \\"1.05\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Trajectory Prediction\\", \\"Dataset\\": \\"STATS SportVu NBA [ATK]\\", \\"Metric\\": \\"ADE\\", \\"Score\\": \\"9.18\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Trajectory Prediction\\", \\"Dataset\\": \\"STATS SportVu NBA [ATK]\\", \\"Metric\\": \\"FDE\\", \\"Score\\": \\"13.54\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Trajectory Prediction\\", \\"Dataset\\": \\"STATS SportVu NBA [DEF]\\", \\"Metric\\": \\"ADE\\", \\"Score\\": \\"7.01\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Trajectory Prediction\\", \\"Dataset\\": \\"STATS SportVu NBA [DEF]\\", \\"Metric\\": \\"FDE\\", \\"Score\\": \\"9.76\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Trajectory Prediction\\", \\"Dataset\\": \\"Drug-auto-auto-text\\", \\"Metric\\": \\"E\\", \\"Score\\": \\"0.67\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Trajectory Prediction\\", \\"Dataset\\": \\"Drug-to-text\\", \\"Metric\\": \\"E\\", \\"Score\\": \\"0.54\\"}} ]"},{"Context":"Low Power Oriented CMOS Circuit Optimization Protocol Low power oriented circuit optimization consists in selecting the best alternative between gate sizing, buffer insertion and logic structure transformation, for satisfying a delay constraint at minimum area cost. In this paper we used a closed form model of delay in CMOS structures to define metrics fora deterministic selection of the optimization alternative. The target is delay constraint satisfaction with minimum area cost. We validate the design space exploration method, defining maximum and minimum delay bounds on logical paths. Then we adapt this method to a \\"constant sensitivity method\\" allowing to size a circuit at minimum area under a delay constraint. An optimisation protocol is finally defined to manage the trade-off performance constraintcircuit structure. These methods are implemented in an optimization tool (POPS) and validated by comparing on a 0.25\xb5m process, the optimization efficiency obtained on various benchmarks (ISCAS\'85) to that resulting from an industrial tool.  Table 1. CPU time comparison in satisfying path delay constraint. 6120 9850 15890 9950 19400 9050 11760 different benchmarks . 11400 POPS ( ms ) W ( \xb5m ) in methods POPS 2000 c1355 210 Comparison 159 116 of Gate nb c1908 under on","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"A BRANCHING AND MERGING CONVOLUTIONAL NETWORK WITH HOMOGENEOUS FILTER CAPSULES We present a convolutional neural network design that, rather than using a single stem of convolutional layers, uses multiple stems, each having branched off of a prior stem. This leads to a different effective receptive field and level of abstraction for each branch moving onto a unique classification stage. The classification stages are then merged together, each effectively voting their level of confidence in the classification. A further novelty to our design is that we do not use any fully connected layers at all, but rather each of the final filters in each branch is transformed into a pair of homogeneous vector capsules. As the capsules are formed from entire filters, we refer to them as filter capsules. This design, in combination with a domain-specific set of randomly applied augmentation techniques, establishes anew state of the art for the MNIST dataset with an accuracy of 99.84% for an ensemble of these models, as well as establishing anew state of the art fora single model (99.79% accurate). These accuracies were achieved with a 75% reduction in both the number of parameters and the number of epochs of training relative to the previously best performing capsule network on MNIST. All training was performed using the Adam optimizer and experienced no overfitting. Additionally, since CIFAR-10 and CIFAR-100 images are 32 \xd7 32 pixels, are full color, and are comprised of more complex features, we ran an additional pair of experiments for each of these datasets that used additional convolutions For all four datasets, a model that included the branching and merging and HFCs achieved the highest mean accuracy with statistical significance Given that both of these datasets are monochromatic images with a size of 28 \xd7 28 and our network was designed with those properties in mind, this is not especially surprising The fact that the accuracy for Fashion-MNIST was not competitive with current state of the art for that dataset is also not surprising as our network design was optimized for accuracy on classification of the Arabic numerals in the MNIST dataset Table 2. Mean SD Table 2 : Individual Models Min Max Table 2: Individual Models Experiment Min Max Mean SD Mean SD Table 2 : Individual Models Min Max Table 3. Shown here are the number of ensembles that were generated that either 0 1 Table 3 : Ensembles Table 3: Ensembles Accuracy: 99.84% 99.83% 99.82% Shown here are the number of ensembles that were generated that either 0 1 Table 3 : Ensembles Table 4: Current and Previous MNIST State of the Art Results Paper Year Accuracy architectures [ 24 ] Single Models Ensembles Table 4 : Current and Previous MNIST State of the Art Results Accuracy Table 5. architectures [ 24 ] Single Models Ensembles Table 4 : Current and Previous MNIST State of the Art Results Accuracy Table 7: Experiments With and Without Branching and Merging and Homogeneous Filter Capsules Accuracy Min Max Mean SD MNIST Fashion -","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"MNIST\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"99.84\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"MNIST\\", \\"Metric\\": \\"Percentage error\\", \\"Score\\": \\"0.16\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"MNIST\\", \\"Metric\\": \\"Trainable Parameters\\", \\"Score\\": \\"1,514,187\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"Fashion-MNIST\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"99.13\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"MNIST\\", \\"Metric\\": \\"Percentage error\\", \\"Score\\": \\"0.17\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Comp3D\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.94\\"}} ]"},{"Context":"Multiple Instance-Based Video Anomaly Detection using Deep Temporal Encoding-Decoding In this paper, we propose a weakly supervised deep temporal encoding-decoding solution for anomaly detection in surveillance videos using multiple instance learning. The proposed approach uses both abnormal and normal video clips during the training phase which is developed in the multiple instance framework where we treat the video as a bag and video clips as instances in the bag. Our main contribution lies in the proposed novel approach to consider temporal relations between video instances. We deal with video instances (clips) as sequential visual data rather than a set of independent instances. We employ a deep temporal encoding-decoding network that is designed to capture spatio-temporal evolution of video instances overtime. We also propose anew loss function that maximizes the mean distance between normal and abnormal instance predictions. The new loss function ensures a low false alarm rate which is very crucial in practical surveillance application.The proposed temporal encoding-decoding approach with modified loss is benchmarked against the state of the art in simulation studies. The results show that the proposed method performs similar to or better than the state-of-the-art solutions for anomaly detection in video surveillance applications and achieve state of the art false alarm rate on UCF-crime dataset. , where he has worked, since 2010, and is currently a Professor, and a Research Development Lead, as well as the Discipline Leader (Manufacturing and Mechatronics) with the School of Engineering. His main research interests include statistical information fusion, random Finite sets, multi-object tracking, deep learning, and robust multi-structure data ftting in computer vision. In this section, we test our proposed temporal encodingdecoding network with the proposed loss function using two public datasets which are UCF-cirme dataset and Shang-haiTech In this paper, we have conducted experiment on two public datasets which are the UCF-crime dataset and the Shang-haiTech 1) UCF-Crime: is a large scale dataset of long videos with different scenes that represent real-life situations The dataset consists of 1900 videos divided into training sets and testing sets The total dataset duration is 128 hours In this dataset, no temporal (frame-level) annotation is available except for the testing videos The UCF-crime dataset is the biggest video anomaly dataset and the only one that has multiple scenes with real surveillance videos 2) ShanghaiTech: is a medium-scale dataset that contains 437 different videos captured at a university campus ShanghaiTech dataset is commonly used for unsupervised anomaly detection, thus, there is no abnormal videos for training To accommodate","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Anomaly Detection In Surveillance Videos\\", \\"Dataset\\": \\"UCF-Crime\\", \\"Metric\\": \\"Decidability\\", \\"Score\\": \\"-\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Anomaly Detection In Surveillance Videos\\", \\"Dataset\\": \\"UCF-Crime\\", \\"Metric\\": \\"EER\\", \\"Score\\": \\"-\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Anomaly Detection In Surveillance Videos\\", \\"Dataset\\": \\"UCF-Crime\\", \\"Metric\\": \\"ROC AUC\\", \\"Score\\": \\"80.10\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Anomaly Detection In Surveillance Videos\\", \\"Dataset\\": \\"ShanghaiTech Weakly Supervised\\", \\"Metric\\": \\"AUC-ROC\\", \\"Score\\": \\"89.14\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Anomaly Detection In Surveillance Videos\\", \\"Dataset\\": \\"UCF-Crime\\", \\"Metric\\": \\"Decidability\\", \\"Score\\": \\"87.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Anomaly Detection In Surveillance Videos\\", \\"Dataset\\": \\"UCF-Crime\\", \\"Metric\\": \\"EER\\", \\"Score\\": \\"11. Sur\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Anomaly Detection In Surveillance Videos\\", \\"Dataset\\": \\"UCF-Crime\\", \\"Metric\\": \\"ROC AUC\\", \\"Score\\": \\"75.41\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Anomaly Detection In Surveillance Videos\\", \\"Dataset\\": \\"UCF-Crime\\", \\"Metric\\": \\"Decidability\\", \\"Score\\": \\"0.861\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Anomaly Detection In Surveillance Videos\\", \\"Dataset\\": \\"UCF-Crime\\", \\"Metric\\": \\"EER\\", \\"Score\\": \\"0.087\\"}} ]"},{"Context":"From source to target and back: Symmetric Bi-Directional Adaptive GAN The effectiveness of GANs in producing images according to a specific visual domain has shown potential in unsupervised domain adaptation. Source labeled images have been modified to mimic target samples for training classifiers in the target domain, and inverse mappings from the target to the source domain have also been evaluated, without new image generation.In this paper we aim at getting the best of both worlds by introducing asymmetric mapping among domains. We jointly optimize bi-directional image transformations combining them with target self-labeling. We define anew class consistency loss that aligns the generators in the two directions, imposing to preserve the class identity of an image passing through both domain mappings. A detailed analysis of the reconstructed images, a thorough ablation study and extensive experiments on six different settings confirm the power of our approach. We evaluate SBADA-GAN on several unsupervised adaptation scenarios 1 , considering the following widely used digits datasets and settings: MNIST \u2192 MNIST-M: MNIST contains centered, 28 \xd7 28 pixel, grayscale images of single digit numbers on a black background, while MNIST-M is a variant where the background is substituted by a randomly extracted patch obtained from color photos of BSDS500 We follow the evaluation protocol of MNIST \u2194 USPS: USPS [9] is a digit dataset automatically scanned from envelopes by the U.S We follow the evaluation protocol of SVHN \u2194 MNIST: SVHN is the challenging realworld Street View House Number dataset, much larger in scale than the other considered datasets Besides presenting a great variety of styles (in shape and texture), images from this dataset often contain extraneous numbers in addition to the labeled, centered one Table 1: Comparison against previous work. SBADA-GAN C t reports the accuracies produced by the classifier trained in the target domain space. Similarly, SBADA-GAN C s reports the results produced by the classifier trained in the source domain space and tested on the target images mapped to this space. SBADA-GAN reports the results obtained by a weighted combination of the softmax outputs of these two classifiers. Note that all competitors convert SVHN to grayscale, while we deal with the more complex original RGB version. The last three rows report results from online available pre-print papers. - Synth Signs\u2192GTSRB not conv . MNIST\u2192SVHN MNIST\u2192MNIST - M SVHN\u2192MNIST MNIST\u2192 USPS - USPS\u2192MNIST Table 2: Dataset mean SSIM: this measure of data vari- ability suggests that our method successfully generates images with not only the same style of a chosen domain, but also similar perceptual variability. S map to T S T T map","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Domain Adaptation\\", \\"Dataset\\": \\"SVHN-to-MNIST\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"76.1\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Domain Adaptation\\", \\"Dataset\\": \\"SYNSIG-to-GTSRB\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"76.3\\"}} ]"},{"Context":"KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation Pre-trained language representation models (PLMs) cannot well capture factual knowledge from text. In contrast, knowledge embedding (KE) methods can effectively represent the relational facts in knowledge graphs (KGs) with informative entity embeddings, but conventional KE models cannot take full advantage of the abundant textual information. In this paper, we propose a unified model for Knowledge Embedding and Pre-trained LanguagE Representation (KEPLER), which cannot only better integrate factual knowledge into PLMs but also produce effective text-enhanced KE with the strong PLMs. In KEPLER, we encode textual entity descriptions with a PLM as their embeddings, and then jointly optimize the KE and language modeling objectives. Experimental results show that KE-PLER achieves state-of-the-art performances on various NLP tasks, and also works remarkably well as an inductive KE model on KG link prediction. Furthermore, for pretraining and evaluating KEPLER, we construct Wikidata5M 1 , a large-scale KG dataset with aligned entity descriptions, and benchmark state-of-the-art KE methods on it. It shall serve as anew KE benchmark and facilitate the research on large KG, inductive KE, and KG with text. The source code can be obtained from https://github.com/ THU-KEG/KEPLER. Recent pre-trained language representation models (PLMs) such as BERT (Devlin et al., 2019) and * Correspondence to: Z. Liu and J. Tang 1 https://deepgraphlearning.github. io/project/wikidata5m As we cannot afford the full RoBERTa corpora (126 GB, and we only use 13 GB) in KEPLER pre-training, we implement Our RoBERTa for direct comparisons to KEPLER It is initialized by RoBERTa BASE and is further trained with the MLM objective on the same corpora as KEPLER We also evaluate recent knowledge-enhanced PLMs, including ERNIE BERT and KnowBert BERT The evaluation method is described in Section 3.3 The \\"m/mm\\" stands for matched/mismatched evaluation sets for MNLI Hence we also evaluate the models on LAMA-UHN, which filters out the questionable templates from the Google-RE and T-REx corpora of LAMA The evaluation results are shown in, from which we have the following observations: (1) KEPLER consistently outperforms the vanilla PLM baseline Our RoBERTa in almost all the settings except ConceptNet, which focuses on commonsense knowledge rather than factual knowledge Table 1: Statistics of Wikidata5M (transductive setting) compared with existing KE benchmarks. #relation #entity Percentage #training #test #validation Occurrence Table 2: Top-5 entity categories in Wikidata5M. Percentage Occurrence Table 3: Statistics of Wikidata5M inductive setting. #relation #entity #triplet Table 4: Performances of different KE models on Wikidata5M (% except MR). HITS@10 HITS@1 HITS@3 MRR Table 5: Precision, recall and F-1 on TACRED (%). KnowBert results are different from the original paper since different task settings are used. RoBERTa BERT P R F - 1 Table 6: Accuracies (%) on the FewRel dataset. N -K indicates the N -way K-shot setting. MTB uses the LARGE size and all the other models use the BASE size. \u2020 indicates oracle models which may have seen facts in the FewRel 1.0 test set during pre-training. \u2212 Table 7: Entity typing results on OpenEntity (%). RoBERTa BERT P R F - 1 Table 8: GLUE results","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"TACRED\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"71.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Inductive knowledge graph completion\\", \\"Dataset\\": \\"Wikidata5m-ind\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.222\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Inductive knowledge graph completion\\", \\"Dataset\\": \\"Wikidata5m-ind\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.73\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Inductive knowledge graph completion\\", \\"Dataset\\": \\"Wikidata5m-ind\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.514\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Inductive knowledge graph completion\\", \\"Dataset\\": \\"Wikidata5m-ind\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.402\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"Wikidata5M\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.6954\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"Wikidata5M\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.895\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"Wikidata5M\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.6954\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"Wikidata5M\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.5893\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"Wikidata5M\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.412\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"Wikidata5M\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.8883\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"Wikidata5M\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.6908\\"}}, { \'"},{"Context":"A Balanced and Uncertainty-aware Approach for Partial Domain Adaptation 0000\u22120003\u22123890\u22121894] , Yunbo Wang 2[0000\u22120002\u22126215\u22128888] , Dapeng Hu 1 , Ran He 3[0000\u22120002\u22123807\u2212991X] , and Jiashi Feng 1[0000\u22120001\u22126843\u22120064]Abstract. This work addresses the unsupervised domain adaptation problem, especially in the case of class labels in the target domain being only a subset of those in the source domain. Such a partial transfer setting is realistic but challenging and existing methods always suffer from two key problems, negative transfer and uncertainty propagation. In this paper, we build on domain adversarial learning and propose a novel domain adaptation method BA 3 US with two new techniques termed Balanced Adversarial Alignment (BAA) and Adaptive Uncertainty Suppression (AUS), respectively. On one hand, negative transfer results in misclassification of target samples to the classes only present in the source domain. To address this issue, BAA pursues the balance between label distributions across domains in a fairly simple manner. Specifically, it randomly leverages a few source samples to augment the smaller target domain during domain alignment so that classes in different domains are symmetric. On the other hand, a source sample would be denoted as uncertain if there is an incorrect class that has a relatively high prediction score, and such uncertainty easily propagates to unlabeled target data around it during alignment, which severely deteriorates adaptation performance. Thus we present AUS that emphasizes uncertain samples and exploits an adaptive weighted complement entropy objective to encourage incorrect classes to have uniform and low prediction scores. Experimental results on multiple benchmarks demonstrate our BA 3 US surpasses state-of-the-arts for partial domain adaptation tasks. Code is available at https://github.com/tim-learn/BA3US.  Table 1. Accuracy (%) on Office-Home dataset for partial domain adaptation via ResNet-50 E - DANN Ours ( w / BAA ) SAFN [ 46 ] Table 2. Accuracy (%) on Office31 and ImageNet-Caltech for partial domain adap- tation via ResNet-50 - Table 3. Accuracy (%) on Office31 for partial domain adaptation via VGG-16 Avg . Table 4. Accuracy (%) on Office-Home dataset for vanilla unsupervised domain adaptation via ResNet-50 3 Table 5. Sensitivity of parameter \u03be. weights . Yellow bins denote ground - truth classes . Best viewed in color . 0 ( a ) Accuracy of Ar\u2192Cl weight number of classes in the target domain ( b ) estimated weight of Ar\u2192Cl class index Table 6. Sensitivity of parameter \u03b2. weights . Yellow bins denote ground - truth classes . Best viewed in color . 0 weight ( c ) estimated weight of A\u2192D ( b ) estimated weight","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Partial Domain Adaptation\\", \\"Dataset\\": \\"Office-31\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"97.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Partial Domain Adaptation\\", \\"Dataset\\": \\"Office-Home\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"76.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Partial Domain Adaptation\\", \\"Dataset\\": \\"ImageNet-Caltech\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"83.7\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Partial Domain Adaptation\\", \\"Dataset\\": \\"Office-31\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"86.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Partial Domain Adaptation\\", \\"Dataset\\": \\"Office-Home\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"70.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Partial Domain Adaptation\\", \\"Dataset\\": \\"ImageNet-Caltech\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"87.0\\"}} ]"},{"Context":"Polynomial kernels for 3-leaf power graph modification problems * A graph G = (V, E) is a 3-leaf power iff there exists a tree T whose leaves are V and such that (u, v) \u2208 E iff u and v are at distance at most 3 in T . The 3-leaf power graph edge modification problems, i.e. edition (also known as the closest 3-leaf power), completion and edge-deletion, are FTP when parameterized by the size of the edge set modification. However polynomial kernel was known for none of these three problems. For each of them, we provide cubic kernels that can be computed in linear time for each of these problems. We thereby answer an open problem first mentioned by Dom, Guo, H\xfcffner and Niedermeier [6].","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Escaping the Big Data Paradigm with Compact Transformers With the rise of Transformers as the standard for language processing, and their advancements in computer vision, along with their unprecedented size and amounts of training data, many have come to believe that they are not suitable for small sets of data. This trend leads to great concerns, including but not limited to: limited availability of data in certain scientific domains and the exclusion of those with limited resource from research in the field. In this paper, we dispel the myth that transformers are \\"data hungry\\" and therefore can only be applied to large sets of data. We show for the first time that with the rightsize and tokenization, transformers can perform head-to-head with state-of-the-art CNNs on small datasets. Our model eliminates the requirement for class token and positional embeddings through a novel sequence pooling strategy and the use of convolutions. We show that compared to CNNs, our compact transformers have fewer parameters and MACs, while obtaining similar accuracies. Our method is flexible in terms of model size, and can have as little as 0.28 M parameters and achieve reasonable results. It can reach an accuracy of 94.72% when training from scratch on CIFAR-10, which is comparable with modern CNN based approaches, and a significant improvement over previous Transformer based models. Our simple and compact design democratizes transformers by making them accessible to those equipped with basic computing resources and/or dealing with important small datasets. We conducted image classification experiments using our method on the following datasets: CIFAR-10, CIFAR-100, MNIST, and Fashion-MNIST These four datasets not only have a small number of training samples, but they are also small in resolution In this experiment we reduce the size of CIFAR-10 to determine the relationship between our model\'s performance and the number of samples within a dataset This experiment disassociates the dimensionality of the data from the size of the dataset, measuring which metric is the \\"data hungry\\" aspect of transformers This allows us to conclude that our model is not data hungry and can still effectively learn on very small datasets, obtaining over 84% accuracy with a dataset that has only 10k samples and a total of 10 classes Table 1. MobileNetV2 CCT ViT - Lite ResNet18 ResNet1001 ResNet164 Table 1: Top-1 validation accuracy comparisons. The numbers reported are best out of 4 runs. Hyperparamters are mentioned in Appendix A. Variants with \u2020 used a batch size of 64 instead of the default 128. Compact Convolutional Transformers Compact Vision Transformers Convolutional Networks ( Designed for CIFAR ) Vision Transformers Convolutional Networks ( Designed for ImageNet ) # Params MACs MNIST CIFAR - 10 Fashion - MNIST CIFAR - 100 Table 2: Top-1 validation accuracy of CIFAR-10 and CIFAR-100 when transforming ViT into CCT step by step. The numbers reported are best out of 4 runs. Hyperparamters are mentioned in Appendix A. # Params MACs CIFAR - 10 CIFAR - 100 Table 5: ViT and CCT hyperparamters. 0 Tuned Not Tuned Table 6: Difference between tuned and not tuned runs. 0 Tuned Not Tuned","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"76.67\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"94.72\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"73.8M\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"70.91%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"74.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"93.7\\"}} ]"},{"Context":"Matryoshka Networks: Predicting 3D Geometry via Nested Shape Layers . Exemplary shape reconstructions from a single image by our Matryoshka network based on nested shape layers.In this paper, we develop novel, efficient 2D encodings for 3D geometry, which enable reconstructing full 3D shapes from a single image at high resolution. The key idea is to pose 3D shape reconstruction as a 2D prediction problem. To that end, we first develop a simple baseline network that predicts entire voxel tubes at each pixel of a reference view. By leveraging well-proven architectures for 2D pixelprediction tasks, we attain state-of-the-art results, clearly outperforming purely voxel-based approaches. We scale this baseline to higher resolutions by proposing a memoryefficient shape encoding, which recursively decomposes a 3D shape into nested shape layers, similar to the pieces of a Matryoshka doll. This allows reconstructing highly detailed shapes with complex topology, as demonstrated in extensive experiments; we clearly outperform previous octreebased approaches despite having a much simpler architecture using standard network components. Our Matryoshka networks further enable reconstructing shapes from IDs or shape similarity, as well as shape sampling.  Table 2. Single image 3D shape reconstruction on ShapeNet-core at 32 3 resolution. We report the mean IoU (%) per category, and the average IoU over all categories. Our networks outperform all voxel decoder baselines and are competitive with the more complex PSGN. Figure 5 . Shapes reconstructed from a single image by our Matryoshka network at different resolutions . all bench chair couch watercraft lamp monitor Ground truth 3 256 car airplane 128 speaker firearm cellphone cabinet 64 table Table 3. Single image 3D shape reconstruction for high resolu- tions. We report IoU (in %) between predictions at several res- olutions and ground truth shapes at 256 3 . Predictions at lower resolution are up-sampled to 256 3 . 3 256 128 64 32 Table 4. Evaluation of base architectures. Across all categories, the ResNet-inspired architecture outperforms all other networks with a significant margin. with a significant margin . car","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"3D Object Reconstruction\\", \\"Dataset\\": \\"Data3D\u2212R2N2\\", \\"Metric\\": \\"3DIoU\\", \\"Score\\": \\"0.640\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Reconstruction\\", \\"Dataset\\": \\"Data3DR2N2\\", \\"Metric\\": \\"3DIoU\\", \\"Score\\": \\"0.57\\"}} ]"},{"Context":"Edge-Informed Single Image Super-Resolution The recent increase in the extensive use of digital imaging technologies has brought with it a simultaneous demand for higher-resolution images. We develop a novel \\"edge-informed\\" approach to single image superresolution (SISR). The SISR problem is reformulated as an image inpainting task. We use a two-stage inpainting model as a baseline for super-resolution and show its effectiveness for different scale factors (\xd72, \xd74, \xd78) compared to basic interpolation schemes. This model is trained using a joint optimization of image contents (texture and color) and structures (edges). Quantitative and qualitative comparisons are included and the proposed model is compared with current state-of-the-art techniques. We show that our method of decoupling structure and texture reconstruction improves the quality of the final reconstructed high-resolution image. Our proposed models are evaluated on the following publicly available datasets High-quality version of the CelebA dataset with 30K images We evaluate our model using PSNR and SSIM for \xd72, \xd74 and \xd78 SISR scale factors Table 1: Comparison of PSNR and SSIM for \xd72, \xd74, and \xd78 factor SISR over Set5, Set14, BSD100, and Celeb-HQ datasets with bicubic interpolation, ENet \xd78 0752 \xd72 \xd74 Bicubic Ours ENet Baseline EDSR Table 2: Quantitative performance of edge enhancer for Single Image Super-Resolution trained on Canny edges with \u03c3 = 2 for 512 \xd7 512 images. Statistics are calculated over the standard test sets of each dataset. interpolation , \xd74 SISR , \xd74 predicted edge - map SISR . Precision LR Recall Ground Truth","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"BSD100 - 4x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"24.25\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"BSD100 - 4x upscaling\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.851\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Celeb-HQ 4x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"28.23\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Celeb-HQ 4x upscaling\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.912\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Set5 - 4x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"28.59\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Set5 - 4x upscaling\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.965\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Set14 - 4x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"25.19\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Set14 - 4x upscaling\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.894\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"CelebA 64x64\\", \\"Metric\\": \\"FID\\", \\"Score\\":\\"4x upscaling\\", \\"Dataset\\": \\"CelebA 128x128\\", \\"Metric\\": \\"FID\\", \\"Score\\":\\"4x upscaling\\", \\"Metric\\": \\"MS-SSIM\\", \\"Score\\": \\"0.18\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"CelebA 128x128\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"38.46\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"CelebA 128x128\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.96\\"}} ]"},{"Context":"SIGN: Scalable Inception Graph Neural Networks Graph representation learning has recently been applied to abroad spectrum of problems ranging from computer graphics and chemistry to high energy physics and social media. The popularity of graph neural networks has sparked interest, both in academia and in industry, in developing methods that scale to very large graphs such as Facebook or Twitter social networks. In most of these approaches, the computational cost is alleviated by a sampling strategy retaining a subset of node neighbors or subgraphs at training time. In this paper we propose anew, efficient and scalable graph deep learning architecture which sidesteps the need for graph sampling by using graph convolutional filters of different size that are amenable to efficient precomputation, allowing extremely fast training and inference. Our architecture allows using different local graph operators (e.g. motifinduced adjacency matrices or Personalized Page Rank diffusion matrix) to best suit the task at hand. We conduct extensive experimental evaluation on various open benchmarks and show that our approach is competitive with other state-ofthe-art architectures, while requiring a fraction of the training and inference time. Moreover, we obtain state-of-the-art results on ogbn-papers100M, the largest public graph dataset, with over 110 million nodes and 1.5 billion edges. * Equal contribution Preprint. Under review. Datasets We evaluated the proposed method on node-wise classification tasks, both in transductive and inductive settings Inductive experiments are performed using four datasets: Reddit, Flickr, Yelp, and PPI Transductive experiments were performed on the new ogbn-products and ogbn-papers100M datasets Overall, this dataset is orders-of-magnitude larger than any existing node classification dataset and is therefore the most important testbed for the scalability of SIGN and related methods Statistics for all the datasets are reported in PPR-based operators are computed from a symmetrically normalized adjacency transition matrix in an approximated form, with a restart probability of \u03b1 = 0.01 for inductive datasets and \u03b1 = 0.05 in the transductive case Architectural and optimization hyperparameters were estimated using Bayesian optimization with a tree Parzen estimator surrogate function overall inductive datasets Given that this dataset represents a directed network, we experimented with operators built via asymmetric normalization of the original directed adjacency matrix and its Table 3: Summary of (s)ingle and (m)ulti-label dataset statistics. Wikipedia is used, with random features, for timing purposes only. 100% / - / 100% Train / Val / Test Table 4: Mean and standard deviation of preprocessing, training (one epoch) and inference times, in seconds, on ogbn-products and Wikipedia datasets, computed over 10 runs. SIGN-r denotes architecture with r precomputed operators. Preprocessing and training times for ClusterGCN on Wikipedia are not reported due to the clustering algorithm failing to complete. Training Preprocessing ogbn - products Inference Wikipedia Table 5: Micro-averaged F1 scores. For SIGN, we show the best performing configurations. The top three performance scores are highlighted as: First, Second, Third. Table 6: Performance on ogbn-products. SIGN(p,s,t) refers to a configuration using p, s, and t powers of simple, PPR-based, and triangle-based adjacency matrices. The top three performance scores are highlighted as: First, Second, Third. Training Validation Test MLP 84.03\xb10.93 75.54\xb10.14","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"AMZ Photo\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"91.72%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Reddit\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"96.60%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Coauthor CS\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"91.98\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"PPI\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"96.50\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"AMZ Comp\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"85.93%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"NCI1\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"80.7%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Pubmed\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"76.6%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Cora\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"82.3%\\"}} ]"},{"Context":"Attention-based Dropout Layer for Weakly Supervised Object Localization Weakly Supervised Object Localization (WSOL) techniques learn the object location only using image-level labels, without location annotations. A common limitation for these techniques is that they cover only the most discriminative part of the object, not the entire object. To address this problem, we propose an Attention-based Dropout Layer (ADL), which utilizes the self-attention mechanism to process the feature maps of the model. The proposed method is composed of two key components: 1) hiding the most discriminative part from the model for capturing the integral extent of object, and 2) highlighting the informative region for improving the recognition power of the model. Based on extensive experiments, we demonstrate that the proposed method is effective to improve the accuracy of WSOL, achieving anew state-of-the-art localization accuracy in CUB-200-2011 dataset. We also show that the proposed method is much more efficient in terms of both parameter and computation overheads than existing techniques. Dataset We evaluate the performance of the proposed method in CUB-200-2011 and ImageNet-1k, respectively The ImageNet-1k is a large-scale dataset with 1,000 different classes, consisting of approximately 1.3 million training images and 50,000 validation images For this dataset, we train the model with the training set and evaluate the performance with the validation set For this dataset, we train the model with the training set and evaluate the performance with the testing set The intraclass variation of CUB-200-2011 is smaller than that of ImageNet-1k, because all classes of this dataset belong to birds Consequently, although CUB-200-2011 is not a large-scale dataset such as ImageNet-1k, this is a particularly challenging dataset to conduct WSOL We use a pre-trained model which is trained with ImageNet-1k dataset, and then fine-tune the network We use three evaluation metrics as: Top-1 classification accuracy (Top-1 Clas), Localization accuracy with known ground-truth class (GT-known Loc), and Top-1 localization Table 1. Upper: Accuracy according to drop rate. Middle: Base- line accuracy. Lower: Accuracy when each component has been deactivated. Bold text refers the best localization accuracy, while italic text refers the best classification accuracy. N/A indicates that ADL outputs the raw input feature map instead of applying drop mask or importance map. Clas ( % ) Acc ( % ) Loc ( % ) Top - 1 GT - known Table 2. Effects in accuracy upon the choice of the feature maps to employ ADL. Bold text refers the best localization accuracy, while italic text refers the best classification accuracy. Clas ( % ) Acc ( % ) Loc ( % ) GT - Known Top - 1 Table 3. Quantitative evaluation results on CUB-200-2011 and ImageNet-1k. Bold text refers the best localization accuracy for each backbone network. We also underline the best score in each dataset. Overheads are computed","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Weakly-Supervised Object Localization\\", \\"Dataset\\": \\"CUB-200-2011\\", \\"Metric\\": \\"Top-1 Error Rate\\", \\"Score\\": \\"37.71\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Weakly-Supervised Object Localization\\", \\"Dataset\\": \\"ILSVHN\\", \\"Metric\\": \\"Top-1 Localization Accuracy\\", \\"Score\\": \\"60.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Weakly-Supervised Object Localization\\", \\"Dataset\\": \\"CUB-200-2011\\", \\"Metric\\": \\"Top-1 Error Rate\\", \\"Score\\": \\"64.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Weakly-Supervised Object Localization\\", \\"Dataset\\": \\"CUB-200-2011\\", \\"Metric\\": \\"Top-1 Localization Accuracy\\", \\"Score\\": \\"69.3\\"}} ]"},{"Context":"NVAE: A Deep Hierarchical Variational Autoencoder Normalizing flows, autoregressive models, variational autoencoders (VAEs), and deep energy-based models are among competing likelihood-based frameworks for deep generative learning. Among them, VAEs have the advantage of fast and tractable sampling and easy-to-access encoding networks. However, they are currently outperformed by other models such as normalizing flows and autoregressive models. While the majority of the research in VAEs is focused on the statistical challenges, we explore the orthogonal direction of carefully designing neural architectures for hierarchical VAEs. We propose Nouveau VAE (NVAE), a deep hierarchical VAE built for image generation using depth-wise separable convolutions and batch normalization. NVAE is equipped with a residual parameterization of Normal distributions and its training is stabilized by spectral regularization. We show that NVAE achieves state-of-the-art results among non-autoregressive likelihood-based models on the MNIST, CIFAR-10, CelebA 64, and CelebA HQ datasets and it provides a strong baseline on FFHQ. For example, on CIFAR-10, NVAE pushes the state-of-the-art from 2.98 to 2.91 bits per dimension, and it produces high-quality images on CelebA HQ as shown in Fig. 1. To the best of our knowledge, NVAE is the first successful VAE applied to natural images as large as 256\xd7256 pixels. The source code is available at https://github.com/NVlabs/NVAE. In this section, we examine NVAE on several image datasets The performance is measured in bits/dimension (bpd) for all the datasets but MNIST in which negative log-likelihood in nats is reported (lower is better in all cases) NVAE outperforms previous non-autoregressive models on most datasets and reduces the gap with autoregressive models For all the datasets but FFHQ, we follow Glow for the train and test splits Hyperparameters: Given a large number of datasets and the heavy compute requirements, we do not exhaustively optimize the hyperparameters Table 1: Comparison against the state-of-the-art likelihood-based generative models. The performance is measured in bits/dimension (bpd) for all the datasets but MNIST in which negative log-likelihood in nats is reported (lower is better in all cases). NVAE outperforms previous non-autoregressive models on most datasets and reduces the gap with autoregressive models. VAE Models with an Unconditional Decoder Flow Models without any Autoregressive Components in the Generative Model VAE and Flow Models with Autoregressive Components in the Generative Model Autoregressive Models - CelebA HQ 64\xd764 MNIST CIFAR - 10 FFHQ 28\xd728 CelebA 256\xd7256 - 32\xd732 ImageNet Table 2: Normalization & activation Table 3 : Residual cells in NVAE Bottom - up Top - down Test L = 10 L = 20 L = 40 Table 2 : Normalization & activation ( bpd ) time ( h ) ( GB ) Train Mem . Table 3: Residual cells in NVAE Table 3 :","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"bits/dimension\\", \\"Score\\": \\"2.91\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CelebA 256x256\\", \\"Metric\\": \\"bpd\\", \\"Score\\": \\"0.70\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"ImageNet 32x32\\", \\"Metric\\": \\"bpd\\", \\"Score\\": \\"3.92\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"FFHQ 256 x 256\\", \\"Metric\\": \\"bits/dimension\\", \\"Score\\": \\"0.69\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"bits/dimension\\", \\"Score\\": \\"2.38\\"}} ]"},{"Context":"The privacy implications of Bluetooth A substantial amount of research, as well as media hype, has surrounded RFID technology and its privacy implications. Currently, researchers and the media focus on the privacy threats posed by RFID, while consumer groups choose to boycott products bearing RFID tags. At the same, however, a very similar technology has quietly become part of our everyday lives: Bluetooth. In this paper we highlight the fact that Bluetooth is a widespread technology that has real privacy implications. Furthermore, we explore the applicability of RFID-based solutions to address these privacy implications.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Sequence Level Semantics Aggregation for Video Object Detection Video objection detection (VID) has been a rising research direction in recent years. A central issue of VID is the appearance degradation of video frames caused by fast motion. This problem is essentially ill-posed fora single frame. Therefore, aggregating features from other frames becomes a natural choice. Existing methods rely heavily on optical flow or recurrent neural networks for feature aggregation. However, these methods emphasize more on the temporally nearby frames. In this work, we argue that aggregating features in the full-sequence level will lead to more discriminative and robust features for video object detection. To achieve this goal, we devise a novel Sequence Level Semantics Aggregation (SELSA) module. We further demonstrate the close relationship between the proposed method and the classic spectral clustering method, providing a novel view for understanding the VID problem. We test the proposed method on the ImageNet VID and the EPIC KITCHENS dataset and achieve new state-of-theart results. Our method does not need complicated postprocessing methods such as Seq-NMS or Tubelet rescoring, which keeps the pipeline simple and clean. In this section, we first introduce the datasets and evaluation metrics used for VID in Sec EPIC KITCHENS is a large scale egocentric dataset, capturing daily activities happened in the kitchens In EPIC KITCHENS dataset, each frame contains avg/max 1.7/9 ob- jects, which is far more complex and challenging 106 sequences collected in the same 28 kitchens (S1) and 54 sequences collected in other 4 unseen kitchens (S2) are used for evaluation ImageNet VID dataset falls short in the density and diversity of objects Here we evaluate SELSA on the EPIC KITCHENS dataset Table 1. Detection results on the ImageNet VID validation set. For sequence-level methods, 21 frames are used when testing. No post-processing techniques are used. The absolute gains compared with the baseline are shown in the subscript. Sequence - level Info ( b ) ( a ) ( c ) Table 2. The effects of post-processing on our method. The abso- lute gains compared with the method without Seq-NMS are shown in the subscript. mAP ) which are both built on flow - based feature aggrega - tively . It also outperforms D ( & T loss ) [ 6 ] by a large margin With no video - level post - processing techniques , com - ResNet - 101 mAP ( % ) Methods Table 4. Performance comparison on EPIC KITCHENS test set. S1 and S2 indicate Seen and Unseen splits. S2 mAP@ . 05 mAP@ . 5 mAP@ . 75","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Video Object Detection\\", \\"Dataset\\": \\"ImageNet VID\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"84.3%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Video Object Detection\\", \\"Dataset\\": \\"ImageNet VID\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"85.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Object Detection\\", \\"Dataset\\": \\"ImageNet VID\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"48.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Object Detection\\", \\"Dataset\\": \\"ImageNet VID\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"85.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Object Detection\\", \\"Dataset\\": \\"ImageNet VID\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"40.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Multi-Object Tracking\\", \\"Dataset\\": \\"PASCAL VOC 2007\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"82.6%\\"}} ]"},{"Context":"FastFCN: Rethinking Dilated Convolution in the Backbone for Semantic Segmentation Modern approaches for semantic segmentation usually employ dilated convolutions in the backbone to extract highresolution feature maps, which brings heavy computation complexity and memory footprint. To replace the time and memory consuming dilated convolutions, we propose a novel joint upsampling module named Joint Pyramid Upsampling (JPU) by formulating the task of extracting highresolution feature maps into a joint upsampling problem. With the proposed JPU, our method reduces the computation complexity by more than three times without performance loss. Experiments show that JPU is superior to other upsampling modules, which can be plugged into many existing approaches to reduce computation complexity and improve performance. By replacing dilated convolutions with the proposed JPU module, our method achieves the state-of-the-art performance in Pascal Context dataset (mIoU of 53.13%) and ADE20K dataset (final score of 0.5584) while running 3 times faster. Code is available in https://github.com/wuhuikai/FastFCN . In this section, we first introduce the datasets used in our experiments as well as the implementation details Finally, to compare with the stateof-the-art methods, we report the performance on two segmentation datasets, Pascal Context and ADE20K, which are widely used as the segmentation benchmarks Dataset Pascal Context dataset is based on the PAS-CAL VOC 2010 detection challenge, which provides additional pixel-wise semantic annotations Table 1: Performance on the val set of Pascal Context dataset with the ResNet-50 as the backbone. mIoU% pixAcc% Table 2: Comparison of Computation Complexity. The FPS is measured on a Titan-Xp GPU with a 512\xd7512 image as input, which is averaged among 100 runs. FPS Table 3: The state-of-the-art methods on the val set of the Pascal Context dataset. PSPNet [ 38 ] EncNet [ 36 ] Backbone mIoU% pixAcc% Table 4: Results on the val set of ADE20K dataset. PSPNet [ 38 ] EncNet [ 36 ] mIoU% pixAcc% Table 5: Results on ADE20K test set. The first two entries ranked 1st and 2nd place in COCO-Place challenge 2017. Final Score","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K\\", \\"Metric\\": \\"Test Score\\", \\"Score\\": \\"55.84\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"44.34\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL Context\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"53.1\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K val\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"42.99\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K\\", \\"Metric\\": \\"Test Score\\", \\"Score\\": \\"56.32\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"43.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K\\", \\"Metric\\": \\"Test Score\\", \\"Score\\": \\"52.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"41.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL Context\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"53.9\\"}} ]"},{"Context":"Web-enabling Cache Daemon for Complex Data One of the most common basic techniques for improving the performance of web applications is caching frequently accessed data in fast data stores, colloquially known as cache daemons. In this paper we present a cache daemon suitable for storing complex data while maintaining fine-grained control over data storage, retrieval and expiry. Data manipulation in this cache daemon is performed via standard SQL statements so we call it SQLcached. It is a practical, usable solution already implemented in several large web sites.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"LADDERNET: MULTI-PATH NETWORKS BASED ON U-NET FOR MEDICAL IMAGE SEGMENTATION U-Net has been providing state-of-the-art performance in many medical image segmentation problems. Many modifications have been proposed for U-Net, such as attention U-Net, recurrent residual convolutional U-Net (R2-UNet), and U-Net with residual blocks or blocks with dense connections. However, all these modifications have an encoderdecoder structure with skip connections, and the number of paths for information flow is limited. We propose Lad-derNet in this paper, which can be viewed as a chain of multiple U-Nets. Instead of only one pair of encoder branch and decoder branch in U-Net, a LadderNet has multiple pairs of encoder-decoder branches, and has skip connections between every pair of adjacent decoder and decoder branches in each level. Inspired by the success of ResNet and R2-UNet, we use modified residual blocks where two convolutional layers in one block share the same weights. A LadderNet has more paths for information flow because of skip connections and residual blocks, and can be viewed as an ensemble of Fully Convolutional Networks (FCN). The equivalence to an ensemble of FCNs improves segmentation accuracy, while the shared weights within each residual block reduce parameter number. Semantic segmentation is essential for retinal disease detection. We tested LadderNet on two benchmark datasets for blood vessel segmentation in retinal images, and achieved superior performance over methods in the literature. The implementation is provided https: //github.com/juntang-zhuang/LadderNet We evaluated the proposed LadderNet on two popular datasets for retina blood vessel segmentation: the DRIVE dataset and the CHASE DB1 dataset The DRIVE dataset consists of 40 color images of the retina, 20 of which were used for training and the remaining 20 images for testing The CHASE DB1 dataset was collected from both left and right eyes of 14 schoolchildren Field of view (FOV) is provided for the DRIVE dataset but not the CHASE DB1 dataset We used several metrics to evaluate the performance of Lad-derNet, including accuracy (AC), sensitivity (SE), specificity (SP) and F1-score Different metrics are calculated as follows: The F1-score is calculated as follows: To further evaluate the performance of different neural networks, we calculated the receiver operating characteristics (ROC) curve and the are under curve (AUC) SE and SP focus more on one category than the other, while other metrics such as AC, AUC and","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Retinal Vessel Segmentation\\", \\"Dataset\\": \\"DRIVE\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.9793\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Retinal Vessel Segmentation\\", \\"Dataset\\": \\"DRIVE\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"0.8202\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Retinal Vessel Segmentation\\", \\"Dataset\\": \\"CHASE_DB1\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.9839\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Retinal Vessel Segmentation\\", \\"Dataset\\": \\"CHASE_DB1\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"0.8031\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Retinal Vessel Segmentation\\", \\"Dataset\\": \\"DRIVE\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.9864\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Retinal Vessel Segmentation\\", \\"Dataset\\": \\"DRIVE\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.9698\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Retinal Vessel Segmentation\\", \\"Dataset\\": \\"DRIVE\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"0.8237\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Retinal Vessel Segmentation\\", \\"Dataset\\": \\"CHASE_DB1\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.9905\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Retinal Vessel Segmentation\\", \\"Dataset\\": \\"CHASE_DB1\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"0.8153\\"}} ]"},{"Context":"Public-key cryptography in functional programming context Cryptography is the science of information and communication security. Up to now, for efficiency reasons cryptographic algorithm has been written in an imperative language. But to get acquaintance with a functional programming language a question arises: functional programming offers some new for secure communication or not? This article investigates this question giving an overview on some cryptography algorithms and presents how the RSA encryption in the functional language Clean can be implemented and how can be measured the efficiency of a certain application.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"A Flexible and Secure Remote Systems Authentication Scheme Using Smart Cards The paper presents an authentication scheme for remote systems using smart card. The scheme prevents the scenario of many logged in users with the same login identity, and does not require password/verifier table to validate the users\' login request. The scheme provides a user-friendly password change option, and withstands the replay, impersonation, stolen-verifier, guessing, and denial-of-service attacks 1 .","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"PolyLaneNet: Lane Estimation via Deep Polynomial Regression One of the main factors that contributed to the large advances in autonomous driving is the advent of deep learning. For safer self-driving vehicles, one of the problems that has yet to be solved completely is lane detection. Since methods for this task have to work in real-time (+30 FPS), they not only have to be effective (i.e., have high accuracy) but they also have to be efficient (i.e., fast). In this work, we present a novel method for lane detection that uses as input an image from a forwardlooking camera mounted in the vehicle and outputs polynomials representing each lane marking in the image, via deep polynomial regression. The proposed method is shown to be competitive with existing state-of-the-art methods in the TuSimple dataset while maintaining its efficiency (115 FPS). Additionally, extensive qualitative results on two additional public datasets are presented, alongside with limitations in the evaluation metrics used by recent works for lane detection. Finally, we provide source code and trained models that allow others to replicate all the results shown in this paper, which is surprisingly rare in state-of-the-art lane detection methods. The full source code and pretrained models are available at https://github.com/lucastabelini/PolyLaneNet. PolyLaneNet was evaluated on publicly available which are introduced in this section Three datasets were used to evaluate PolyLaneNet: TuSimple, LLAMAS and ELAS The dataset has a total of 6,408 annotated images with a resolution of 1280\xd7720 pixels, and it is originally split in 3,268 for training, 358 for validation, and 2,782 for testing For qualitative results, two other datasets were used: LLAMAS and ELAS The first is a large dataset, split into 58,269 images for training, 20,844 for validation, and 20,929 for test, with a resolution of 1280\xd7717 pixels Both TuSimple and LLAMAS are datasets from the USA ELAS is a dataset with 16,993 images from various cities in Brazil, with a resolution of 640\xd7480 pixels Since the dataset was originally proposed fora non-learning based method, it does not provide training/testing splits The main difference between ELAS and the other two datasets is that in ELAS only the ego-lane is","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Lane Detection\\", \\"Dataset\\": \\"TuSimple\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"93.36%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Lane Detection\\", \\"Dataset\\": \\"TuSimple\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"90.62\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Lane Detection\\", \\"Dataset\\": \\"TuSimple\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.24%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Lane Detection\\", \\"Dataset\\": \\"TuSimple\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"95.31\\"}} ]"},{"Context":"Milking CowMask for Semi-Supervised Image Classification Consistency regularization is a technique for semi-supervised learning that underlies a number of strong results for classification with few labeled data. It works by encouraging a learned model to be robust to perturbations on unlabeled data. Here, we present a novel mask-based augmentation method called CowMask. Using it to provide perturbations for semi-supervised consistency regularization, we achieve a state-of-the-art result on ImageNet with 10% labeled data, with a top-5 error of 8.76% and top-1 error of 26.06%. Moreover, we do so with a method that is much simpler than many alternatives. We further investigate the behavior of CowMask for semi-supervised learning by running many smaller scale experiments on the SVHN, CIFAR-10 and CIFAR-100 data sets, where we achieve results competitive with the state of the art, indicating that CowMask is widely applicable. We open source our code at https://github.com/google-research/google-research/tree/ master/milking_cowmask. We first evaluate CowMix for semi-supervised consistency regularization on the challenging ImageNet dataset, where we match the state of the art Next, we examine CowOut and CowMix further and compare with previously proposed methods by trying multiple versions of our approach combined with multiple models on three small image datasets: CIFAR-10, CIFAR-100 and SVHN The training regimes used for both ImageNet and the small image datasets are sufficiently similar that we used the same codebase for all of our experiments Our results are obtained by using the teacher network for evaluation Supervised sets are consistent for all experiments fora given dataset and number of supervised samples Alongside CowOut and CowMix we implemented and evaluated Mean Teacher, CutOut/RandErase and CutMix, and we compare our method against these using the CIFAR-10, CIFAR-100, and SVHN datasets Table 1: Results on ImageNet with 10% labels. Note that S 4 L involves three steps with different training procedures, while CowMix involves a single training run. SimCLR is able to beat CowMix, but only when using a very large model. 4 Our results - Other work Our baselines Table 2: Results on CIFAR-10 test set, error rates as mean \xb1 std \u2212 dev of 5 independent runs. Other work : uses 26M parameter models Augmentation / erasure based regularization Our results : uses 27M parameter Wide ResNet 28 - 96x2d with shake - shake Mix based regularization 100 ALL 4000 500 1000 2000 50 40 250 Table 3: Results on SVHN test set, error rates as mean \xb1 stdev of 5 independent runs. Other work : uses 26M parameter models Augmentation / erasure based regularization Our results : uses 27M parameter Wide ResNet 28 - 96x2d with shake - shake","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 10% labeled data\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"73.94%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 10% labeled data\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"91.24%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 1% labeled data\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"89.9%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 1% labeled data\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"89.5%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 10% labeled data\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"83.9%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 1% labeled data\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"96.7%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 1% labeled data\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"83.1%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 1% labeled data\\", \\"Metric\\": \\"Top 5 Accuracy\\", \'Score\'}]"},{"Context":"An End-to-End Neighborhood-based Interaction Model for Knowledge-enhanced Recommendation This paper studies graph-based recommendation, where an interaction graph is constructed from historical records and is leveraged to alleviate data sparsity and cold start problems. We reveal an early summarization problem in existing graph-based models, and propose Neighborhood Interaction (NI) model to capture each neighbor pair (between user-side and item-side) distinctively. NI model is more expressive and can capture more complicated structural patterns behind user-item interactions. To further enrich node connectivity and utilize high-order structural information, we incorporate extra knowledge graphs (KGs) and adopt graph neural networks (GNNs) in NI, called Knowledge-enhanced Neighborhood Interaction (KNI). Compared with the state-of-the-art recommendation methods, e.g., feature-based, meta path-based, and KG-based models, our KNI achieves superior performance in click-through rate prediction (1.1%-8.4% absolute AUC improvements) and outperforms by a wide margin in top-N recommendation on 4 real world datasets. We combine 4 recommendation datasets with 2 public knowledge graphs in our experiments The datasets and experiment code are publicly available 3 for reproducibility and further study The first two smaller datasets are released by We follow the procedures of to process the other two larger datasets, which are then linked to Freebase Note that another dataset LFM in KB4Rec is not included in our experiments, because it follows a quite different scheme from the others and does not contain any rating or click information After the datasets are processed, we split each dataset into training/validation/test sets at 6:2:2 For each dataset, we use the linked items as initial queries to find related non-item entities We repeat this process 4 times to ensure sufficient knowledge is included in the final dataset The basic statistics of the 4 datasets are presented in We evaluate these models on 2 tasks, click-through rate (CTR) Table 1: Statistics for the expanded datasets. Note: \\"entities\\" contain both items and non-item entities. 11 , 895 17 , 860 64 , 067 59 , 296 1 , 181 , 684 182 , 011 Movie - 20M 265 , 478 77 , 881 9 , 104 , 038 139 , 746 Movie - 1M 6 , 036 753 , 772 32 , 389 78 , 809 C - Book A - Book 14 , 967 2 , 445 Table 2: The results of CTR prediction. Note: \\"*\\" indicates the statistically significant improvements over the best baseline, with p-value smaller than 10 \u22126 in two-sided t-test. Model ACC Movie - 1M C - Book A - Book Movie - 20M AUC Table 3: Data sparsity statistics and AUC improvements. Note: The n-hop columns represent the number of n-hop neighbors. The sparsity is calculated as # missing edges / # node pairs.","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Click-Through Rate Prediction\\", \\"Dataset\\": \\"MovieLens 20M\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.9704\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Click-Through Rate Prediction\\", \\"Dataset\\": \\"MovieLens 1M\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.9449\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Citeseer\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"74.4%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Pubmed\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"74.4%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Cora\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"82.3%\\"}} ]"},{"Context":"A Fast and Accurate Unconstrained Face Detector We propose a method to address challenges in unconstrained face detection, such as arbitrary pose variations and occlusions. First, anew image feature called Normalized Pixel Difference (NPD) is proposed. NPD feature is computed as the difference to sum ratio between two pixel values, inspired by the Weber Fraction in experimental psychology. The new feature is scale invariant, bounded, and is able to reconstruct the original image. Second, we propose a deep quadratic tree to learn the optimal subset of NPD features and their combinations, so that complex face manifolds can be partitioned by the learned rules. This way, only a single soft-cascade classifier is needed to handle unconstrained face detection. Furthermore, we show that the NPD features can be efficiently obtained from a lookup table, and the detection template can be easily scaled, making the proposed face detector very fast. Experimental results on three public face datasets (FDDB, GENKI, and CMU-MIT) show that the proposed method achieves state-of-the-art performance in detecting unconstrained faces with arbitrary pose variations and occlusions in cluttered scenes. We evaluate the performance of the NPD face detector on three public-domain databases, FDDB, GENKI, and CMU-MIT The FDDB dataset covers challenging scenarios for face detection Images in FDDB comes from the Faces in the Wild dataset, which is a large collection of Internet images collected from the Yahoo News For benchmark evaluation, Jain and Learned-Miller provided an evaluation code fora comparison of different face detection algorithms There are two metrics for performance evaluation based on ROC: discrete score metric and continuous score metric, which correspond to coarse match (similar to previous evaluations in the face detection literature) and precise match, respectively, between the detection and the ground truth The database is divided into 10 subsets for performance evaluation, and the obtained detection results are accumulated to generate the ROC curve According to, ten ROC curves should be obtained and averaged for the final performance report, however, what is actually done and continuous metrics on the FDDB database [ 3 ] * FP = 100 TABLE 1 Continuous Metric Discrete Metric FP = 0 FP = 10 NPD POF DQT Haar 150 140 176 276 DQT - Soft 1 , 597 108 LBP 72 Stump CART n / a SURF [ 13 ] * NPD OpenCV Resolution i5@3 . 1GHz i7@3 . 9GHz Yan - DPM [ 46 ] X5650@2 . 66GHz JCascade [ 48 ] NPD @2 . 93GHz ACF [ 49 ]","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Face Detection\\", \\"Dataset\\": \\"FDDB\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"0.864\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Detection\\", \\"Dataset\\": \\"PASCAL Face\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"0.9029\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Detection\\", \\"Dataset\\": \\"Annotated Faces in the Wild\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"0.9721\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Face Detection\\", \\"Dataset\\": \\"FDDB\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"0.990\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Detection\\", \\"Dataset\\": \\"CMU-PIE\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"0.985\\"}} ]"},{"Context":"A Sim2Real Deep Learning Approach for the Transformation of Images from Multiple Vehicle-Mounted Cameras to a Semantically Segmented Image in Bird\'s Eye View* Accurate environment perception is essential for automated driving. When using monocular cameras, the distance estimation of elements in the environment poses a major challenge. Distances can be more easily estimated when the camera perspective is transformed to a bird\'s eye view (BEV). For flat surfaces, Inverse Perspective Mapping (IPM) can accurately transform images to a BEV. Three-dimensional objects such as vehicles and vulnerable road users are distorted by this transformation making it difficult to estimate their position relative to the sensor. This paper describes a methodology to obtain a corrected 360 \u2022 BEV image given images from multiple vehicle-mounted cameras. The corrected BEV image is segmented into semantic classes and includes a prediction of occluded areas. The neural network approach does not rely on manually labeled data, but is trained on a synthetic dataset in such away that it generalizes well to real-world data. By using semantically segmented images as input, we reduce the reality gap between simulated and real-world data and are able to show that our method can be successfully applied in the real world. Extensive experiments conducted on the synthetic data demonstrate the superiority of our approach compared to IPM. Source code and datasets are available at https://github.com/ika-rwth-aachen/Cam2BEV. In order to evaluate the methodology presented before, we train the neural networks entirely on simulated data In the following, we present the synthetic dataset and the training setup","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-View Image-to-Image Translation\\", \\"Dataset\\": \\"Cam2BEV\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"71.92\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cam2BEV\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"71.92\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Semantic Segmentation\\", \\"Dataset\\": \\"TuSimple\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"75.70%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Semantic Segmentation\\", \\"Dataset\\": \\"TuSimple\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"94.31\\"}} ]"},{"Context":"Control and Optimization Meet the Smart Power Grid: Scheduling of Power Demands for Optimal Energy Management The smart power grid aims at harnessing information and communication technologies to enhance reliability and enforce sensible use of energy. Its realization is geared by the fundamental goal of effective management of demand load. In this work, we envision a scenario with real-time communication between the operator and consumers. The grid operator controller receives requests for power demands from consumers, each with different power requirement, duration, and a deadline by which it is to be completed. The objective of the operator is to devise a power demand task scheduling policy that minimizes the grid operational cost over a time horizon. The operational cost is a convex function of instantaneous total power consumption and reflects the fact that each additional unit of power needed to serve demands is more expensive as the demand load increases.First, we study the off-line demand scheduling problem, where parameters are fixed and known a priori. If demands maybe scheduled preemptively, the problem is a load balancing one, and we present an iterative algorithm that optimally solves it. If demands need to be scheduled non-preemptively, the problem is a bin packing one. Next, we devise a stochastic model for the case when demands are generated continually and scheduling decisions are taken online and focus on long-term average cost. We present two instances of power consumption control based on observing current consumption. In the first one, the controller may choose to serve anew demand request upon arrival or to postpone it to the end of its deadline. The second one has the additional option to activate one of the postponed demands when an active demand terminates. For both instances, the optimal policies are thresholdbased. We derive a lower performance bound overall policies, which is asymptotically tight as deadlines increase. We propose the Controlled Release threshold policy and prove it is asymptotically optimal. The policy activates anew demand request if the current power consumption is less than a threshold, otherwise it is queued. Queued demands are scheduled when their deadline expires or when the consumption drops below the threshold.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Properties of polynomial bases used in a line-surface intersection algorithm * In [5], Srijuntongsiri and Vavasis propose the Kantorovich-Test Subdivision algorithm, or KTS, which is an algorithm for finding all zeros of a polynomial system in a bounded region of the plane. This algorithm can be used to find the intersections between a line and a surface. The main features of KTS are that it can operate on polynomials represented in any basis that satisfies certain conditions and that its efficiency has an upper bound that depends only on the conditioning of the problem and the choice of the basis representing the polynomial system. This article explores in detail the dependence of the efficiency of the KTS algorithm on the choice of basis. Three bases are considered: the power, the Bernstein, and the Chebyshev bases. These three bases satisfy the basis properties required by KTS. Theoretically, Chebyshev case has the smallest upper bound on its running time. The computational results, however, do not show that Chebyshev case performs better than the other two. * Supported in part by NSF DMS 0434338 and NSF CCF 0085969.  Table 1: Comparison of the efficiency of KTS algorithm operating on the power, the Bernstein, and the Chebyshev bases. The number of patches examined during the course of the algorithm and the width of the smallest patch examined are shown for each version of KTS. Bernstein basis patches of width Power basis cond ( f ) Chebyshev basis Smallest Table 2: The numbers of test polynomials out of 1000 that bounding intervals associated with the Bernstein basis is tighter than the those associated with the Chebyshev basis, and vice versa. 37 40 that Chebyshev is tighter that Bernstein is tighter Table 3: The numbers of test polynomials out of 1000 that bounding intervals associated with the Bernstein basis and those associated with the Chebyshev basis having at least one endpoint exactly at the boundary of the ranges of the polynomials. 0 2 13 Bernstein with Chebyshev with exact endpoint","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Improving Semantic Segmentation via Video Propagation and Label Relaxation Semantic segmentation requires large amounts of pixelwise annotations to learn accurate models. In this paper, we present a video prediction-based methodology to scale up training sets by synthesizing new training samples in order to improve the accuracy of semantic segmentation networks. We exploit video prediction models\' ability to predict future frames in order to also predict future labels. A joint propagation strategy is also proposed to alleviate mis-alignments in synthesized samples. We demonstrate that training segmentation models on datasets augmented by the synthesized samples leads to significant improvements inaccuracy. Furthermore, we introduce a novel boundary label relaxation technique that makes training robust to annotation noise and propagation artifacts along object boundaries. Our proposed methods achieve state-of-the-art mIoUs of 83.5% on Cityscapes and 82.9% on CamVid. Our single model, without model ensembles, achieves 72.8% mIoU on the KITTI semantic segmentation test set, which surpasses the winning entry of the ROB challenge 2018. Our code and videos can be found at https://nv-adlr.github. io/publication/2018-Segmentation. In this section, we evaluate our proposed method on three widely adopted semantic segmentation datasets, including Cityscapes, CamVid and KITTI For all three datasets, we use the standard mean Intersection over Union (mIoU) metric to report segmentation accuracy Table 1: Effectiveness of Mapillary pre-training and class uniform sampling on both fine and coarse annotations. mIoU ( % ) Table 2: Comparison between (1) label propagation (LP) and joint propagation (JP); (2) video prediction (VPred) and video recon- struction (VRec). Using the proposed video reconstruction and joint propagation techniques, we improve over the baseline by 1.08% mIoU (79.46% 80.54%). joint propagation techniques , we improve over the baseline by 80 . 54% ) . 0 \xb11 \xb12 \xb13 \xb14 Table 2 : Comparison between ( 1 ) label propagation ( LP ) and joint \xb15 struction ( VRec ) . Using the proposed video reconstruction and Table 3: Per-class mIoU results on Cityscapes. Top: our ablation improvements on the validation set. Bottom: comparison with top- performing models on the test set. sky bus bicycle truck veg . tsign pole rider swalk mIoU mcycle road car person tlight wall fence terrain","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"CamVid\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"81.7%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"KITTI Semantic Segmentation\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"72.8%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"83.5%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"CamVid\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"82.78\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"82.7%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"82.0%\\"}} ]"},{"Context":"Shape-Aware Human Pose and Shape Reconstruction Using Multi-View Images We propose a scalable neural network framework to reconstruct the 3D mesh of a human body from multi-view images, in the subspace of the SMPL model [23]. Use of multi-view images can significantly reduce the projection ambiguity of the problem, increasing the reconstruction accuracy of the 3D human body underclothing. Our experiments show that this method benefits from the synthetic dataset generated from our pipeline since it has good flexibility of variable control and can provide ground-truth for validation. Our method outperforms existing methods on real-world images, especially on shape estimations. Since it is often time-and labor-intensive to gather a dataset large enough for training a deep neural network, an increasing amount of attention is drawn to synthetic dataset generation Recent studies have shown that using a synthetic dataset, if sufficiently close to the real-world data, is helpful in training neural networks for real tasks built up a dataset (SURREAL) which contains human motion sequences with clothing using the SMPL model and CMU MoCap data While the SURREAL dataset is large enough and is very close to our needs, it is still insufficient in that (a) the clothing of the human is only a set of texture points on the body mesh, meaning that it is a tight clothing, (b) the body shape is drawn from the CAESAR dataset, where the uneven distribution of the shape parameters can serve as a \\"prior bias\\" to the neural network, and (c) the data only Table 1: Comparison results on Human3.6M using MPJPE. Smaller errors implies higher accuracy. Method w / syn . training Ours ( multi ) MPJPE / HD HMR Ours ( single ) w / o syn . training MPJPE Table 2: Comparison results on MPI INF 3DHP in PCK/AUC/ MPJPE. Better results have higher PCK/AUC and lower MPJPE. Table 4: Comparison on Human3.6M with other multi-view methods. Our method has comparable performance with previous work even without the assistance of camera calibration or temporal information. PA stands for Procrustes Aligned results for ours. Sitting Standing Table 5: Comparison results on tape-measured data using average relative errors (lower the better). Sitting Standing Table 6: Results on MPI INF 3DHP, validation set, before Pro- crustes aligment. also be drawn from these data . Hu - The same conclusion about over - Table 7: Results on MPI INF 3DHP, test set. The results of [19]","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"Human3.6M\\", \\"Metric\\": \\"Average MPJPE (mm)\\", \\"Score\\": \\"44.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"Human3.6M\\", \\"Metric\\": \\"Multi-View or Monocular\\", \\"Score\\": \\"Multi-View\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"Human3.6M\\", \\"Metric\\": \\"Using 2D ground-truth joints\\", \\"Score\\": \\"No\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"Human3.6M\\", \\"Metric\\": \\"Average MPJPE (mm)\\", \\"Score\\": \\"48.0\\"}} ]"},{"Context":"Optimal Gradient Clock Synchronization in Dynamic Networks We study the problem of clock synchronization in highly dynamic networks, where communication links can appear or disappear at anytime. The nodes in the network are equipped with hardware clocks, but the rate of the hardware clocks can vary arbitrarily within specific bounds, and the estimates that nodes can obtain about the clock values of other nodes are inherently inaccurate. Our goal in this setting is to output a logical clock at each node such that the logical clocks of any two nodes are not too far apart, and nodes that remain close to each other in the network fora longtime are better synchronized than distant nodes. This property is called gradient clock synchronization.Gradient clock synchronization has been widely studied in the static setting, where the network topology does not change. We show that the asymptotically optimal bounds obtained for the static case also apply to our highly dynamic setting: if two nodes remain at distance d from each other for sufficiently long, it is possible to upper bound the difference between their clock values by O(d log(D/d)), where Dis the diameter of the network. This is known to be optimal even for static networks. Furthermore, we show that our algorithm has optimal stabilization time: when a path of length d appears between two nodes, the time required until the clock skew between the two nodes is reduced to O(d log(D/d)) is O(D), which we prove to be optimal. Finally, the techniques employed for the more intricate analysis of the algorithm for dynamic graphs provide additional insights that are also of interest for the static setting. In particular, we establish self-stabilization of the gradient property within O(D) time.A distributed clock synchronization algorithm computes at each node a logical clock, and the goal is to synchronize these clocks as tightly as possible. Traditionally, distributed clock synchronization algorithms focus on minimizing the clock skew between the logical clocks of any two nodes in the network. The clock skew between two clocks is simply the difference between the two clock values. The maximum clock skew that may occur in the worst case between any two nodes at anytime is called the global skew of a clock synchronization algorithm. A well-known result states that no algorithm can guarantee a global skew better than \u2126(D), where D denotes the diameter of the network [1]. However, in many cases it is more important to tightly synchronize the logical clocks of nearby nodes in the network than it is to minimize the global skew. For example, if a time division multiple access (TDMA) protocol is used to coordinate access to a shared communication medium in a wireless sensor network, it suffices to synchronize the clocks of nodes that interfere with each other when transmitting. The problem of providing better guarantees on the synchronization quality between nodes that are closer is called gradient clock synchronization. The problem was introduced in a seminal paper by Fan and Lynch [7], where the authors show that a clock skew of \u2126(log D/ log log D) cannot be prevented between immediate neighbors in the network. The largest possible clock skew that may occur between the logical clocks of any two adjacent nodes at anytime is called the local skew of a clock synchronization algorithm. For static networks, it has been proved that the best possible local skew that an algorithm can achieve is bounded by \u0398(log D) [15,16].While tight bounds have been shown for the static model, the dynamic case has not been as well understood. A dynamic network arises in many natural contexts: for example, when nodes are mobile, or when communication links are unreliable and may fail and recover. The dynamic network model we consider in this article is general: it allows communication links to appear and disappear arbitrarily, subject only to a global connectivity constraint (which is required to maintain a bounded global skew). Hence the model is suitable for modeling various types of dynamic networks which remain connected overtime.Ina dynamic network the distances between nodes changeover time as communication links appear and disappear. Consequently, we divide the synchronization guarantee into two parts: a global skew guarantee bounds the skew between any two nodes in the network at anytime, and a dynamic gradient skew guarantee that bounds the skew between two nodes as a function of the distance between them and how long they remain at that distance.In [11], three of the authors showed that a clock synchronization algorithm cannot react immediately to the formation of new links, and that a certain stabilization time is required before the clocks of newly-adjacent nodes can be brought into synch. The stabilization time is inversely related to the synchronization guarantee: the tighter the synchronization required in stable state, the longer the time to reach that state. Intuitively, this is because when strict synchronization guarantees are imposed, the algorithm cannot change clock values quickly without violating the guarantee, and hence it takes longer to react. The algorithm given in [11] achieves the optimal trade-off between skew bound and stabilization time; however, its local skew bound is O( \u221a D), which is far from optimal.In this article, we propose an algorithm, referred to as A OPT , that achieves the same asymptotically optimal skew bounds as in the static model: if two nodes remain at distance d for sufficiently long, the skew between them is reduced to O(d log(D/d)), where Dis the dynamic diameter of the network (corresponding roughly to the time it takes for information to propagate from one end of the network to the other). The stabilization time of the algorithm, that is, the time to reach this guarantee, is O(D).In the sequel, we refer to estimate edges of the sort described above simply as edges; similarly, when we say \\"the graph\\" we mean the estimate graph. We do not reason explicitly about the communication graph, as the salient aspects of communication are encapsulated by the estimate layer.Dynamic networks. We consider dynamic networks over a fixed set of nodes V of size n := |V |. Edge insertions and removals are modeled as discrete events controlled by a worst-case adversary. In keeping with the abstract representation from [12], we say that there is an estimate edge {u, v} between two nodes u, v \u2208 V at time t \u2265 0 iff u and v have a means of obtaining clock value estimates about each other at time t. As explained above, this does not necessarily mean that there is a direct communication link between u and vat time t.We do not assume that nodes detect the formation or failure of a communication link between them at the same time, which introduces some asymmetry into the model. Hence, we model the network as a directed dynamic graph G = (V, E), where E : R + 0 \u2192 2 (V \xd7V ) maps non-negative times t to a set of directed estimate edges E(t) that exist at time t. If (u, v) \u2208 E(t), then at time t node u has an estimate for node v\'s logical clock, but not necessarily vice-versa. Formally, the set of node u\'s neighbors at time t is defined as N u (t) := {v | (u, v) \u2208 E(t)}. We assume that any asymmetry in the graph corresponds to the delay in nodes finding out about link status changes and is only temporary; this is explained below.In the following, we frequently refer to undirected edges {u, v}; when we write {u, v} \u2208 E(t), we mean that both (u, v) \u2208 E(t) and (v, u) \u2208 E(t). We say that edge {u, v} exists throughout a time interval [t 1 , t 2 ] if for all t \u2208 [t 1 , t 2 ] we have {u, v} \u2208 E(t). By extension, a path p is said to exist throughout [t 1 , t 2 ] if all its edges exist throughout the interval.Each undirected estimate edge {u, v} is associated with three parameters:\u2022 The estimate uncertainty \u01eb {u,v} , as explained above.\u2022 The detection delay \u03c4 {u,v} . We assume that u and v detect if the edge disappears \\"at\\" the respective other node within \u03c4 {u,v} \u2208 R + time. Formally, (a) if (u, v) / \u2208 E(t), then there is sometime t \u2032 \u2208 [t \u2212 \u03c4 {u,v} , t + \u03c4 {u,v} ] so that (v, u) / \u2208 E(t \u2032 ); and, symmetrically, (b) if (v, u) / \u2208 E(t), then there is sometime t \u2032 \u2208 [t \u2212 \u03c4 {u,v} , t + \u03c4 {u,v} ] so that (u, v) / \u2208 E(t \u2032 ).\u2022 We assume that u and v can exchange messages with message delay T {u,v} . More precisely, nodes that share an estimate edge can actively exchange information if required (possibly","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Polylogarithmic Approximation for Edit Distance and the Asymmetric Query Complexity We present a near-linear time algorithm that approximates the edit distance between two strings within a polylogarithmic factor; specifically, for strings of length n and every fixed \u03b5 > 0, it can compute a (log n) O(1/\u03b5) approximation inn 1+\u03b5 time. This is an exponential improvement over the previously known factor, 2\xd5 ( \u221a log n) , with a comparable running time [OR07, AO09]. Previously, no efficient polylogarithmic approximation algorithm was known for any computational task involving edit distance (e.g., nearest neighbor search or sketching).This result arises naturally in the study of anew asymmetric query model. In this model, the input consists of two strings x and y, and an algorithm can access yin an unrestricted manner, while being charged for querying every symbol of x. Indeed, we obtain our main result by designing an algorithm that makes a small number of queries in this model. We then provide a nearly-matching lower bound on the number of queries.Our lower bound is the first to expose hardness of edit distance stemming from the input strings being \\"repetitive\\", which means that many of their substrings are approximately identical. Consequently, our lower bound provides the first rigorous separation between edit distance and Ulam distance, which is edit distance on non-repetitive strings, such as permutations. \u221a log n) approximation with constant communication via [OR07, KOR00]. The only known lower bound says that approximation \u03b1 requires \u2126( log n / log log n \u03b1 ) communication [AK10, AJP10].The asymmetric model is \\"harder\\", in the sense that the query complexity is at least the communication complexity, up to a factor of log |\u03a3| in the complexity, since Alice and Bob can simulate the asymmetric query algorithm. In fact, our upper bound implies a communication protocol for the same DTEP \u03b2 problem with the same complexity, and it is a one-way communication protocol. Specifically, Alice can just send the O(\u03b2n \u03b5 ) characters queried by the query algorithm in the asymmetric query model. This is the first communication protocol achieving polylogarithmic approximation for DTEP \u03b2 under edit distance with o(n) communication.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Structure-Aware Human-Action Generation Generating long-range skeleton-based human actions has been a challenging problem since small deviations of one frame can cause a malformed action sequence. Most existing methods borrow ideas from video generation, which naively treat skeleton nodes/joints as pixels of images without considering the rich inter-frame and intra-frame structure information, leading to potential distorted actions. Graph convolutional networks (GCNs) is a promising way to leverage structure information to learn structure representations. However, directly adopting GCNs to tackle such continuous action sequences both in spatial and temporal spaces is challenging as the action graph could be huge. To overcome this issue, we propose a variant of GCNs (SA-GCNs) to leverage the powerful self-attention mechanism to adaptively sparsify a complete action graph in the temporal space. Our method could dynamically attend to important past frames and construct a sparse graph to apply in the GCN framework, wellcapturing the structure information inaction sequences. Extensive experimental results demonstrate the superiority of our method on two standard human action datasets compared with existing methods. The code to reproduce our analysis is available at https://github.com/PingYuiris/SA-GCN. We perform experiments to evaluate the proposed method on two standard skeleton-based human-action benchmarks, the Human-3.6m dataset and the NTU RGB+D dataset We also conduct human evaluation on the Amazon Mechanical Turk (AMT) to access the perceptual quality of generated sequences To examine the functionality of each component of the proposed model, we also perform detailed ablation studies on the Human-3.6m dataset NTU RGB+D This dataset contains 56,000 video clips on 60 classes performed by 40 subjects and recorded with 3 different camera views We then apply two commonly used benchmarks fora further evaluation in the ten classes: (i)cross-view : the training set contains actions captured by two cameras and remaining data are left for testing The metric has also been applied to evaluate the similarity between generated actions and the ground truth in, which has been proved consistent with human evaluation Recognition Accuracy Apart from using MMD to evaluate the Table 1: Model comparisons in terms of MMD on Human-3.6m. Pretrain MMDavg \u2193 MMDseq \u2193 Table 2: Action recognition accuracy on the generated actions on the Direct Discuss Eat Greet Phone Pose Sit SitD Smoke Walk Average Table 3: Model comparisons in terms of MMD on NTU RGB+D. MMDavg \u2193 MMDseq \u2193 MMDavg \u2193 MMDseq \u2193 cross - subject cross - view Table 4: Ablation study results. Baselines MMDavg \u2193 MMDseq \u2193 Table 5: AMT Evaluations Evaluation Score\u2191 Table 5 : AMT Evaluations","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Human action generation\\", \\"Dataset\\": \\"Human3.6M\\", \\"Metric\\": \\"MMD\\", \\"Score\\": \\"0.134\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Human action generation\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"MMD\\", \\"Score\\": \\"0.285\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Human action generation\\", \\"Dataset\\": \\"Human3.6M\\", \\"Metric\\": \\"MMD\\", \\"Score\\": \\"0.195\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Human action generation\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"MMD\\", \\"Score\\": \\"0.338\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Human action generation\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"MMD\\", \\"Score\\": \\"0.133\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Human action generation\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"MMD\\", \\"Score\\": \\"0.44\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Human action generation\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"MMD\\", \\"Score\\": \\"0.535\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Human action generation\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"METEOR\\", \\"Score\\": \\"21.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Human action generation\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"86.5\\"}}, { \'LEADERBOARD\'}]"},{"Context":"Covering of ordinals The paper focuses on the structure of fundamental sequences of ordinals smaller than \u03b50. A first result is the construction of a monadic second-order formula identifying a given structure, whereas such a formula cannot exist for ordinals themselves. The structures are precisely classified in the pushdown hierarchy. Ordinals are also located in the hierarchy, and a direct presentation is given.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Peer to Peer Optimistic Collaborative Editing on XML-like Trees Collaborative editing consists in editing a common document shared by several independent sites. Conflicts occurs when different users perform simultaneous uncompatible operations. Centralized systems solve this problem by using locks that prevent some modifications to occur and leave the resolution of conflicts to users. Optimistic peer to peer (P2P) editing doesn\'t allow locks and uses a Integration Transformation IT that reconciliates conflicting operations and ensures convergence (all copies are identical on each site). Two properties TP1 and TP2, relating the set of allowed operations Op and the transformation IT, have been shown to ensure convergence. The choice of the set Op is crucial to define an integration operation that satisfies TP1 and TP2. Many existing algorithms don\'t satisfy these properties and are incorrect. No algorithm enjoying both properties is known for strings and little work has been done for XML trees in a pure P2P framework. We focus on editing XML-like trees, i.e. unranked-unordered labeled trees also considered in the Harmony project. We show that no transformation satisfying TP1 and TP2 exists fora first set of operations but that TP1 and TP2 hold fora richer set of operations, provided that some decoration is added to the tree. We show how to combine our approach with any convergent editing process on strings to get a convergent process. We have implemented our transformation using a P2P algorithm inspired by Ressel et al. whose correctness relies on underlying partial order structure generated by the dependence relation on operations.45EmileCaplantStreet P hone 0491... Add(Henri, P hone)(t \u2032 ) = t \u2032 since Henri.P hone already exists. -Nop() : Do nothing. Nop()(t) = t -Del 1 (p, n): Replace a edge labeled n at end of path p by the set of its successors.Del 1 (n \u2032 .p, n)(t) = t, if n \u2208 Dom(t) Del 1 (n i .p, n)({n 1 (t 1 ), ..., n i (t i ), ..., n q (t q )}) = {n 1 (t 1 ), ..., n i (Del 1 (p, n)(t i )), ..., n q (t q )} Del 1 (\u01eb, n)(t) = t, if n \u2208 Dom(t) Del 1 (\u01eb, n i )({n 1 (t 1 ), ..., n i (t i ), ..., n q (t q )}) = {n 1 (t 1 ), ..., n q (t q )} \u2295 ti","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Published as a conference paper at ICLR 2018 LEARNING LATENT REPRESENTATIONS IN NEURAL NETWORKS FOR CLUSTERING THROUGH PSEUDO SUPERVISION AND GRAPH-BASED ACTIVITY REGULARIZATION In this paper, we propose a novel unsupervised clustering approach exploiting the hidden information that is indirectly introduced through a pseudo classification objective. Specifically, we randomly assign a pseudo parent-class label to each observation which is then modified by applying the domain specific transformation associated with the assigned label. Generated pseudo observation-label pairs are subsequently used to train a neural network with Auto-clustering Output Layer (ACOL) that introduces multiple softmax nodes for each pseudo parent-class. Due to the unsupervised objective based on Graph-based Activity Regularization (GAR) terms, softmax duplicates of each parent-class are specialized as the hidden information captured through the help of domain specific transformations is propagated during training. Ultimately we obtain a k-means friendly latent representation. Furthermore, we demonstrate how the chosen transformation type impacts performance and helps propagate the latent information that is useful in revealing unknown clusters. Our results show state-of-the-art performance for unsupervised clustering tasks on MNIST, SVHN and USPS datasets, with the highest accuracies reported to date in the literature.Published as a conference paper at ICLR 2018 auxiliary target distribution derived from the soft cluster assignments. Similarly, Joint Unsupervised Learning (JULE) (Yang et al., 2016) combines agglomerative clustering with convolutional neural networks (CNN) and formulates them as a recurrent process. Although JULE proposes an end-to-end learning framework, it suffers scalability issues due to its agglomerative clustering. Open source code is available at http://github.com/ozcell/LALNets that can be used to reproduce the experimental results obtained on three benchmark image datasets,, SVHN and USPS Specifications of these datasets are presented in To ensure that the representation obtained through the proposed approach is well-generalized for never-seen-before data, we train the neural network parameters using only the training set examples of each dataset and obtain the clustering performances using k-means with k = 10 on the latent space representation F of the untransformed test set examples (through T 1 )., we evaluate the test performances using unsupervised clustering accuracy given as where t * i is the ground-truth label, y i is the assigned cluster, and F is the set of all possible one-to-one mappings between assignments and labels Table 1. Number of classes Dimension Table 1: Datasets used in the experiments. Number of classes Dimension Table 2: Specifications of the CNN model used in the experiments. 6 - layer CNN Model name Table 3: Quantitative unsupervised clustering performance (ACC) on MNIST, USPS and SVHN datasets. Results of a broad range of recent existing solutions are also presented for comparison. The last row demonstrates the benchmark scores of the proposed framework in this article. - - 11 . 9% ( \xb10 . 40 ) \u2020 \u2020 MNIST - test 87 . 82% ( \xb15 . 33 ) 82 . 31% ( \xb13 . 75 ) 92 . 77% ( \xb11 . 60 ) 98 . 40% ( \xb10 . 40 ) k 95 . 90% ( \xb11 . 13 ) USPS - full \u2020 - 90 . 45% ( \xb12 . 05 )","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Image Classification\\", \\"Dataset\\": \\"SVHN\\", \\"Metric\\": \\"Acc\\", \\"Score\\": \\"76.80\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Image Classification\\", \\"Dataset\\": \\"MNIST\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"98.32\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"MNIST-full\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.965\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"MNIST-full\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"0.913\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"MNIST-test\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.967\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"MNIST-test\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"0.919\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"Fashion-MNIST\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.628\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"Fashion-MNIST\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"0.644\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"USPS\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.957\\"}}, { \\"LEADERBOARD\\": { "},{"Context":"EfficientNetV2: Smaller Models and Faster Training This paper introduces EfficientNetV2, anew family of convolutional networks that have faster training speed and better parameter efficiency than previous models. To develop this family of models, we use a combination of training-aware neural architecture search and scaling, to jointly optimize training speed and parameter efficiency. The models were searched from the search space enriched with new ops such as Fused-MBConv. Our experiments show that EfficientNetV2 models train much faster than state-of-the-art models while being up to 6.8x smaller.Our training can be further sped up by progressively increasing the image size during training, but it often causes a drop inaccuracy. To compensate for this accuracy drop, we propose an improved method of progressive learning, which adaptively adjusts regularization (e.g., dropout and data augmentation) along with image size.With progressive learning, our EfficientNetV2 significantly outperforms previous models on Im-ageNet and CIFAR/Cars/Flowers datasets. By pretraining on the same ImageNet21k, our Effi-cientNetV2 achieves 87.3% top-1 accuracy on ImageNet ILSVRC2012, outperforming the recent ViT by 2.0% accuracy while training 5x-11x faster using the same computing resources. Code will be available at https Setup: We evaluate our models on four transfer learning datasets: CIFAR-10, CIFAR-100, Flowers and Cars includes the statistics of these datasets For all datasets, we train each model for fixed 10,000 steps In general, our models outperform previous Con-vNets and Vision Transformers for all these datasets, sometimes by a non-trivial margin: for example, on CIFAR-100, EfficientNetV2-L achieves 0.6% better accuracy than prior GPipe/EfficientNets and 1.5% better accuracy than prior ViT/DeiT models Table 1. EfficientNets have good parameter and FLOPs efficiency. 192M 43M Top - 1 Acc . Table 2. EfficientNet-B6 accuracy and training throughput for dif- ferent batch sizes and image size. OOM batch=24 batch=12 TPUv3 imgs / sec / core batch=32 batch=128 V100 imgs / sec / gpu Top - 1 Acc . Table 3. Replacing MBConv with Fused-MBConv. No fused denotes all stages use MBConv, Fused stage1-3 denotes re- placing MBConv with Fused-MBConv in stage {2, 3, 4}. ( B ) FLOPs imgs / sec / core TPU Params V100 ( M ) Top - 1 Acc . imgs / sec / gpu Table 4. EfficientNetV2-S architecture -MBConv and Fused- MBConv blocks are described in Figure 2. Stride 15 Stage #Layers 272 Table 5. ImageNet top-1 accuracy. We use RandAug Size=128 Size=192 Size=300 Table 6. Progressive training settings for EfficientNetV2. 25 S min 300 15 max 5 128 380 L","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"121M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"86.8%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"55M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"86.1%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"85.7%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"85.1%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"24M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"85.0%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"83.9%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"Stanford Cars\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"Stanford Cars\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"94.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"Stanford Cars\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"93.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"Flowers-102\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"98.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"Flowers-102\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"98.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"Flowers-102\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"97.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"92.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"92.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"91.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"PARAMS\\", \\"Score\\": \\"121M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"99.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"PARAMS\\", \\"Score\\": \\"55M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"99.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"PARAMS\\", \\"Score\\": \\"24M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"98.7\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"78.35%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"94.83%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"77.21%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"93.57%\\"}} ]"},{"Context":"A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling Intent detection and slot filling are two main tasks for building a spoken language understanding(SLU) system. Multiple deep learning based models have demonstrated good results on these tasks . The most effective algorithms are based on the structures of sequence to sequence models (or \\"encoder-decoder\\" models), and generate the intents and semantic tags either using separate models ((Yao et al., 2014;Mesnil et al., 2015;Peng and Yao, 2015;Kurata et al., 2016;Hahn et al., 2011)) or a joint model ((Liu and Lane, 2016a;Hakkani-T\xfcr et al., 2016;Guo et al., 2014)). Most of the previous studies, however, either treat the intent detection and slot filling as two separate parallel tasks, or use a sequence to sequence model to generate both semantic tags and intent. Most of these approaches use one (joint) NN based model (including encoderdecoder structure) to model two tasks, hence may not fully take advantage of the crossimpact between them. In this paper, new Bi-model based RNN semantic frame parsing network structures are designed to perform the intent detection and slot filling tasks jointly, by considering their cross-impact to each other using two correlated bidirectional LSTMs (BLSTM). Our Bi-model structure with a decoder achieves state-of-the-art result on the benchmark ATIS data (Hemphill et al., 1990;Tur et al., 2010), with about 0.5% intent accuracy improvement and 0.9 % slot filling improvement. In this section, our new proposed Bi-model structures are trained and tested on two datasets, one is the public ATIS dataset containing audio recordings of flight reservations, and the other is our self-collected datset in three different domains: Food, Home and Movie The ATIS dataset used in this paper follows the same format as in The number of data for our self-collected dataset will be given in the corresponding experiment sections with a more detailed explanation The performance is evaluated based on the classification accuracy for intent detection task and F1-score for slot filling task Our first experiment is conducted on the ATIS benchmark dataset, and compared with the current existing approaches, by evaluating their intent detection accuracy and slot filling F1 scores It can be observed that the new proposed Bi-model structures outperform the current state-of-the-art results on both intent detection and slot filling tasks, and the Bi-model with a Table 1: Performance of Different Models on ATIS Dataset ( Guo et al . , 2014 ) ( Peng and Yao , 2015 ) ( Liu and Lane , 2015 ) ( Liu and Lane , 2016b ) ( Xu and Sarikaya , 2013 ) ( Liu and Lane , 2016a ) ( Mesnil et al . , 2015 ) ( Kurata et al . , 2016 ) ( Zhang and Wang , 2016 ) F1 Score Intent Accuracy Table 1. Some of the models are designed for single slot filling task, hence only F1 scores are given. It can be observed that the new proposed Bi-model structures outperform the current state-of-the-art results on both intent detection and slot filling tasks, and the Bi-model with a decoder also outperform that without a decoder on our ATIS dataset. The current Bi-model with a decoder shows the state-of-the-art performance on ATIS benchmark dataset","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Slot Filling\\", \\"Dataset\\": \\"ATIS\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"0.969\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Intent Detection\\", \\"Dataset\\": \\"ATIS\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"98.99\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Intent Detection\\", \\"Dataset\\": \\"ATIS\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"96.89\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Slot Filling\\", \\"Dataset\\": \\"ATIS\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"0.958\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Intent Detection\\", \\"Dataset\\": \\"SNIPS\\", \\"Metric\\": \\"Intent Accuracy\\", \\"Score\\": \\"97.43\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Intent Detection\\", \\"Dataset\\": \\"SNIPS\\", \\"Metric\\": \\"Slot F1 Score\\", \\"Score\\": \\"91.46\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Intent Detection\\", \\"Dataset\\": \\"ATIS\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.76\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Intent Detection\\", \\"Dataset\\": \\"ATIS\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"95.80\\"}} ]"},{"Context":"Flowtron: an Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis In this paper we propose Flowtron: an autoregressive flow-based generative network for textto-speech synthesis with control over speech variation and style transfer. Flowtron borrows insights from IAF and revamps Tacotron in order to provide high-quality and expressive melspectrogram synthesis. Flowtron is optimized by maximizing the likelihood of the training data, which makes training simple and stable. Flowtron learns an invertible mapping of data to a latent space that can be manipulated to control many aspects of speech synthesis (pitch, tone, speech rate, cadence, accent). Our mean opinion scores (MOS) show that Flowtron matches state-of-the-art TTS models in terms of speech quality. In addition, we provide results on control of speech variation, interpolation between samples and style transfer between speakers seen and unseen during training. Code and pretrained models will be made publicly available at https://github.com/NVIDIA/flowtron.  Table 1: Mean Opinion Score (MOS) evaluations with 95% confidence intervals for various sources. manipulation of the latent space . with 95% con - Mean Opinion Score ( MOS )","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Text-To-Speech Synthesis\\", \\"Dataset\\": \\"LJSpeech\\", \\"Metric\\": \\"Pleasantness MOS\\", \\"Score\\": \\"3.665\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Text-To-Speech Synthesis\\", \\"Dataset\\": \\"LJSpeech\\", \\"Metric\\": \\"Pleasantness MOS\\", \\"Score\\": \\"3.521\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Speech Enhancement\\", \\"Dataset\\": \\"DEMAND\\", \\"Metric\\": \\"CBAK\\", \\"Score\\": \\"3.18\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Speech Enhancement\\", \\"Dataset\\": \\"DEMAND\\", \\"Metric\\": \\"COVL\\", \\"Score\\": \\"2.96\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Speech Enhancement\\", \\"Dataset\\": \\"DEMAND\\", \\"Metric\\": \\"CSIG\\", \\"Score\\": \\"3.52\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Speech Enhancement\\", \\"Dataset\\": \\"DEMAND\\", \\"Metric\\": \\"PESQ\\", \\"Score\\": \\"2.4\\"}} ]"},{"Context":"Synthetic Training for Accurate 3D Human Pose and Shape Estimation in the Wild This paper addresses the problem of monocular 3D human shape and pose estimation from an RGB image. Despite great progress in this field in terms of pose prediction accuracy, state-of-the-art methods often predict inaccurate body shapes. We suggest that this is primarily due to the scarcity of in-the-wild training data with diverse and accurate body shape labels. Thus, we propose STRAPS (Synthetic Training for Real Accurate Pose and Shape), a system that utilises proxy representations, such as silhouettes and 2D joints, as inputs to a shape and pose regression neural network, which is trained with synthetic training data (generated on-the-fly during training using the SMPL statistical body model) to overcome data scarcity. We bridge the gap between synthetic training inputs and noisy real inputs, which are predicted by keypoint detection and segmentation CNNs at test-time, by using data augmentation and corruption during training. In order to evaluate our approach, we curate and provide a challenging evaluation dataset for monocular human shape estimation, Sports Shape and Pose 3D (SSP-3D). It consists of RGB images of tightly-clothed sports-persons with a variety of body shapes and corresponding pseudo-ground-truth SMPL shape and pose parameters, obtained via multi-frame optimisation. We show that STRAPS outperforms other state-of-the-art methods on SSP-3D in terms of shape prediction accuracy, while remaining competitive with the state-of-the-art on pose-centric datasets and metrics. Evaluations are carried outwith two types of input proxy representations: synthetic silhouettes and 2D joints generated from GT SMPL labels and \\"real\\" silhouettes and 2D joints predicted from test RGB images using DensePose Results from SPIN, CMR and HMR are shown for comparison SSP-3D evaluates 3D shape prediction across a diverse range of body shapes, while Human 3.6M and 3DPW evaluate 3D pose prediction Incorporating shape augmentation alleviates the first problem, since the network sees a greater variety of shapes during training Incorporating PR augmentation shrinks the performance deterioration when using real versus synthetic inputs by explicitly modelling input noise and occlusion during the synthetic training process By combining PR and shape augmentation, we are able to predict a diverse range of body shapes, improve our pose accuracy significantly over the baseline and produce semantically-plausible outputs on all datasets, even when the input is heavily corrupted (see) The dis-, suggests that","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3DPW\\", \\"Metric\\": \\"PA-MPJPE\\", \\"Score\\": \\"66.8\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3DPW\\", \\"Metric\\": \\"MPJPE\\", \\"Score\\": \\"72.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3DPW\\", \\"Metric\\": \\"MPVPE\\", \\"Score\\": \\"88.2\\"}} ]"},{"Context":"Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing Pretraining large neural language models, such as BERT, has led to impressive gains on many natural language processing (NLP) tasks. However, most pretraining efforts focus on general domain corpora, such as newswire and Web. A prevailing assumption is that even domain-specific pretraining can benefit by starting from general-domain language models. In this paper, we challenge this assumption by showing that for domains with abundant unlabeled text, such as biomedicine, pretraining language models from scratch results in substantial gains over continual pretraining of general-domain language models. To facilitate this investigation, we compile a comprehensive biomedical NLP benchmark from publicly-available datasets. Our experiments show that domain-specific pretraining serves as a solid foundation fora wide range of biomedical NLP tasks, leading to new state-of-the-art results across the board. Further, in conducting a thorough evaluation of modeling choices, both for pretraining and task-specific fine-tuning, we discover that some common practices are unnecessary with BERT models, such as using complex tagging schemes in named entity recognition (NER). To help accelerate research in biomedical NLP, we have released our state-of-the-art pretrained and task-specific models for the community, and created a leaderboard featuring our BLURB benchmark  Table 3. Datasets used in the BLURB biomedical NLP benchmark. We list the numbers of instances in train, dev, and test (e.g., entity mentions in NER and PICO elements in evidence-based medical information extraction). F1 entity - level Micro F1 16364 18035 339167 960 Dev Test 787 535 85321 Train 11268 64 15745 Table 6. Comparison of pretrained language models on the BLURB biomedical NLP benchmark. The standard task-specific models are used in the same fine-tuning process for all BERT models. The BLURB score is the macro average of average test results for each of the six tasks (NER, PICO, relation extraction, sentence similarity, document classification, question answering). See PubMedBERT RoBERTa uncased cased ClinicalBERT SciBERT BlueBERT BioBERT Table 7. Evaluation of the impact of vocabulary and whole word masking on the performance of PubMedBERT on BLURB. Word Piece Wiki + Books Whole Word PubMed Table 8. Comparison of the average input","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"GAD\\", \\"Metric\\": \\"Micro F1\\", \\"Score\\": \\"82.34\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"ChemProt\\", \\"Metric\\": \\"Micro F1\\", \\"Score\\": \\"77.24\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"DDI\\", \\"Metric\\": \\"Micro F1\\", \\"Score\\": \\"82.36\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"PubMedQA\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"55.84\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"BioASQ\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"87.56\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"BC5CDR-chemical\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"94.06\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"NCBI Disease\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"88.81\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"BC5CDR-disease\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"86.63\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"JNLPBA\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"81.36\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"BC2GM\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"87.81\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Document Classification\\", \\"Dataset\\": \\"HoC\\", \\"Metric\\": \\"Micro F1\\", \\"Score\\": \\"82.32\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"ChemProt\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"77.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Natural Language Inference\\", \\"Dataset\\": \\"MedNLI\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"84\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Similarity\\", \\"Dataset\\": \\"MedSTS\\", \\"Metric\\": \\"Pearson Correlation\\", \\"Score\\": \\"0.948\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Similarity\\", \\"Dataset\\": \\"BIOSSES\\", \\"Metric\\": \\"Pearson Correlation\\", \\"Score\\": \\"0.9159999999999999\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"CoNLL 2003 (English)\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"91.82\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"BC5CDR-chemical\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"93.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"BC5CDR-disease\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"8}}]"},{"Context":"Temporal Smoothing for 3D Human Pose Estimation and Localization for Occluded People In multi-person pose estimation actors can be heavily occluded, even become fully invisible behind another person. While temporal methods can still predict a reasonable estimation fora temporarily disappeared pose using past and future frames, they exhibit large errors nevertheless. We present an energy minimization approach to generate smooth, valid trajectories in time, bridging gaps in visibility. We show that it is better than other interpolation based approaches and achieves state of the art results. In addition, we present the synthetic MuCo-Temp dataset, a temporal extension of the MuCo-3DHP dataset. Our code is made publicly available. 1 We evaluated our method on the multi-person 3D pose dataset MuPoTS-3D Therefore, we created the MuCo-Temp synthetic dataset The latter dataset was recorded in a green-screen studio, so segmenting of the actors is easy We did not augmented the background, as the 2D pose estimator was already trained on a visually diverse dataset Our method was trained on the concatenation of the MPI-INF-3DHP and MuCo-Temp datasets Table 1. Comparison with state-of-the-art MPJPE and MRPE errors are in mm. * Non-temporal methods. \u2020 Error is calculated on detected frames only. 3D - PCK MRPE MPJPE Table 2. Comparison with baselines Interpolation uses simple linear interpolation for unseen poses. 1-Euro applies a 1-Euro filter on interpolated poses. (N-)MPJPE and MRPE errors are in mm. N - MPJPE N - MRPE MRPE MPJPE 3D - PCK Table 3. Results of ablation studies. a) Results when components are turned on sequentially. b) Errors calculated on visible poses only. b ) Results on visible poses a ) Performance of components N - MPJPE N - MRPE MRPE MPJPE 3D - PCK","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"3D Multi-Person Pose Estimation (root-relative)\\", \\"Dataset\\": \\"MuPoTS-3D\\", \\"Metric\\": \\"3DPCK\\", \\"Score\\": \\"85.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Multi-Person Pose Estimation (root-relative)\\", \\"Dataset\\": \\"MuPoTS-3D\\", \\"Metric\\": \\"MPJPE\\", \\"Score\\": \\"103\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Multi-Person Pose Estimation\\", \\"Dataset\\": \\"MuPoTS-3D\\", \\"Metric\\": \\"3DPCK\\", \\"Score\\": \\"85.3\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Multi-Person Pose Estimation (root-relative)\\", \\"Dataset\\": \\"MuPoTS-3D\\", \\"Metric\\": \\"MPJPE\\", \\"Score\\": \\"89.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Multi-Person Pose Estimation (absolute)\\", \\"Dataset\\": \\"MuPoTS-3D\\", \\"Metric\\": \\"MPJPE\\", \\"Score\\": \\"88.2\\"}} ]"},{"Context":"A FUZZY COMMITMENT SCHEME This paper attempt has been made to explain a fuzzy commitment scheme. In the conventional Commitment schemes, both committed string m and valid opening key are required to enable the sender to prove the commitment. However there could be many instances where the transmission involves noise or minor errors arising purely because of the factors over which neither the sender nor the receiver have any control. The fuzzy commitment scheme presented in this paper is to accept the opening key that is close to the original one in suitable distance metric, but not necessarily identical. The concept itself is illustrated with the help of simple situation.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"The Incidence Chromatic Number of Toroidal Grid\u015b An incidence in a graph G is a pair (v, e) with v \u2208 V (G) and e \u2208 E(G), such that v and e are incident. Two incidences (v, e) and (w, f ) are adjacent if v = w, ore = f , or the edge vw equals e or f . The incidence chromatic number of G is the smallest k for which there exists a mapping from the set of incidences of G to a set of k colors that assigns distinct colors to adjacent incidences.In this paper, we prove that the incidence chromatic number of the toroidal grid T m,n = Cm \u2737C n equals 5 when m, n \u2261 0 (mod 5) and 6 otherwise.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Multi-view Convolutional Neural Networks for 3D Shape Recognition A longstanding question in computer vision concerns the representation of 3D shapes for recognition: should 3D shapes be represented with descriptors operating on their native 3D formats, such as voxel grid or polygon mesh, or can they be effectively represented with view-based descriptors? We address this question in the context of learning to recognize 3D shapes from a collection of their rendered views on 2D images. We first present a standard CNN architecture trained to recognize the shapes\' rendered views independently of each other, and show that a 3D shape can be recognized even from a single view at an accuracy far higher than using state-of-the-art 3D shape descriptors. Recognition rates further increase when multiple views of the shapes are provided. In addition, we present a novel CNN architecture that combines information from multiple views of a 3D shape into a single and compact shape descriptor offering even better recognition performance. The same architecture can be applied to accurately recognize human hand-drawn sketches of shapes. We conclude that a collection of 2D views can be highly informative for 3D shape recognition and is amenable to emerging CNN architectures and their derivatives.  Table 1. Classification and retrieval results on the ModelNet40 dataset. On the top are results using state-of-the-art 3D shape descriptors. Our view-based descriptors including Fisher vectors (FV) significantly outperform these even when a single view is available at test time (#Views = 1). When multiple views (#Views=12 or 80) are available at test time, the performance of view-based methods improve significantly. The multi-view CNN (MVCNN) architecture outperforms the view-based methods, especially for retrieval. Method Retrieval Classification ( Accuracy ) #Views ( mAP )","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"3D Point Cloud Classification\\", \\"Dataset\\": \\"ModelNet40\\", \\"Metric\\": \\"Overall Accuracy\\", \\"Score\\": \\"90.1\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Recognition\\", \\"Dataset\\": \\"ModelNet40\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"33.5\\"}} ]"},{"Context":"Meta Pseudo Labels We present Meta Pseudo Labels, a semi-supervised learning method that achieves anew state-of-the-art top-1 accuracy of 90.2% on ImageNet, which is 1.6% better than the existing state-of-the-art [16]. Like Pseudo Labels, Meta Pseudo Labels has a teacher network to generate pseudo labels on unlabeled data to teach a student network. However, unlike Pseudo Labels where the teacher is fixed, the teacher in Meta Pseudo Labels is constantly adapted by the feedback of the student\'s performance on the labeled dataset. As a result, the teacher generates better pseudo labels to teach the student. 1 We first study the role of feedback in Meta Pseudo Labels on the simple TwoMoon dataset We conclude the section with experiments on the standard ResNet-50 architecture with the full ImageNet dataset To understand the role of feedback in Meta Pseudo Labels, we conduct an experiment on the simple and classic TwoMoon dataset The 2D nature of the TwoMoon dataset allows us to visualize how Meta Pseudo Labels behaves compared to Supervised Learning and Pseudo Labels We randomly generate the TwoMoon dataset fora few times and repeat the three methods: Supervised Learning, Pseudo Labels, and Meta Pseudo Labels As a result, Meta Pseudo Labels finds a good classifier for this dataset Datasets We directly compare Meta Pseudo Labels against two baselines: Supervised Learning with full dataset and Unsupervised Data Augmentation (UDA) Supervised Learning with full dataset represents the headroom because it unfairly makes use of all labeled data (e.g., for CIFAR-10, Table 1: Summary of our key results on ImageNet ILSVRC 2012 validation set Top - 1 Accuracy Precision@1 Table 2: Image classification accuracy on CIFAR-10-4K, SVHN-1K, and ImageNet-10%. Higher is better. For CIFAR-10-4K and SVHN- 1K, we report mean \xb1 std over 10 runs, while for ImageNet-10%, we report Top-1/Top-5 accuracy of a single run. For fair comparison, we only include results that share the same model architecture: WideResNet-28-2 for CIFAR-10-4K and SVHN-1K, and ResNet-50 for ImageNet-10%. * indicates our implementation which uses the same experimental protocols. Except for UDA, results in the first two blocks are from representative important papers, and hence do not share the same controlled environment with ours. \u2212 Method CIFAR - 10 - 4K SVHN - 1K ( mean \xb1 std ) ImageNet - 10% Top - 5 Top - 1 Table 4: Top-1 and Top-5 accuracy of Meta Pseudo Labels and previous state-of-the-art methods on","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet ReaL\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"91.12%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet ReaL\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"91.02%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"480M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"90.2%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"98.8%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"390M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"90%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"98.7%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"83.2%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"96.5%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 10% labeled data\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"73.89%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 10% labeled data\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"91.38%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"SVHN, 1000 labels\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"98.01\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"CIFAR-10, 4000 Labels\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"96.11\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"78.95%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"92.21%\\"}} ]"},{"Context":"Towards Better Accuracy-efficiency Trade-offs: Divide and Co-training The width of a neural network matters since increasing the width will necessarily increase the model capacity. However, the performance of a network does not improve linearly with the width and soon gets saturated. In this case, we argue that increasing the number of networks (ensemble) can achieve better accuracy-efficiency trade-offs than purely increasing the width. To prove it, one large network is divided into several small ones regarding its parameters and regularization components. Each of these small networks has a fraction of the original one\'s parameters. We then train these small networks together and make them see various views of the same data to increase their diversity. During this co-training process, networks can also learn from each other. As a result, small networks can achieve better ensemble performance than the large one with few or no extra parameters or FLOPs. Small networks can also achieve faster inference speed than the large one by concurrent running on different devices. We validate our argument with 8 different neural architectures on common benchmarks through extensive experiments. The code is available at https://github. com/mzhaoshuai/Divide-and-Co-training. Datasets We adopt CIFAR-10, CIFAR-100, and Im-ageNet 2012 datasets CIFAR-10 and CIFAR-100 datasets contain 50K training and 10K test RGB images of size 32\xd732, labeled with 10 and 100 classes, respectively ImageNet 2012 dataset contains 1.28 million training images and 50K validation images from 1000 classes For {EfficientNet-B3, ResNeXt-29 (8\xd764d), WRN-28-10, WRN-40-10} on CIFAR datasets, wd =5e-4 Results on CIFAR-100 dataset Results on CIFAR-100 are shown in Table 1: Influence of various settings of ResNet-110 on CIFAR-100. step-lr means step learning rate decay policy as described in ResNet of some settings is shown in Table 1 . The baseline is solid . mixup Top - 1 err . ( % ) random erasing Method ResNet variants adopt the modifications introduced of some settings is shown in Table 1 . The baseline is solid . mixup Top - 1 err . ( % ) random erasing Method ResNet variants adopt the modifications introduced Table 2. Dividing and co-training achieve consistent improvements with few extra or even fewer parameters or FLOPs. Additional cost occurs since the division of a network is not perfect, as mentioned in Sec. 3.1. Some conclusions can be drawn from the data. of some settings is shown in Table 1 . The baseline is solid . mixup Top - 1 err . ( % ) random","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"83.34%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"96.61%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"82.13%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"95.98%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"PARAMS\\", \\"Score\\": \\"32.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"89.46\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"PARAMS\\", \\"Score\\": \\"26.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"87.44\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"86.90\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"85.74\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"PARAMS\\", \\"Score\\": \\"32.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"98.71\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"98.38\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"PARAMS\\", \\"Score\\": \\"36.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"98.32\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"PARAMS\\", \\"Score\\": \\"26.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"98.31\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"78.35%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"94.35%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"77.21%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"93.57%\\"}} ]"},{"Context":"Best of Both Worlds: Transferring Knowledge from Discriminative Learning to a Generative Visual Dialog Model We present a novel training framework for neural sequence models, particularly for grounded dialog generation. The standard training paradigm for these models is maximum likelihood estimation (MLE), or minimizing the cross-entropy of the human responses. Across a variety of domains, a recurring problem with MLE trained generative neural dialog models (G) is that they tend to produce \'safe\' and generic responses (\'I don\'t know\', \'I can\'t tell\'). In contrast, discriminative dialog models (D) that are trained to rank a list of candidate human responses outperform their generative counterparts; in terms of automatic metrics, diversity, and informativeness of the responses. However, Dis not useful in practice since it cannot be deployed to have real conversations with users. Our work aims to achieve the best of both worlds -the practical usefulness of G and the strong performance of D -via knowledge transfer from D to G. Our primary contribution is an end-to-end trainable generative visual dialog model, where G receives gradients from D as a perceptual (not adversarial) loss of the sequence sampled from G. We leverage the recently proposed Gumbel-Softmax (GS) approximation to the discrete distribution -specifically, a RNN augmented with a sequence of GS samplers, coupled with the straight-through gradient estimator to enable end-to-end differentiability. We also introduce a stronger encoder for visual dialog, and employ a self-attention mechanism for answer encoding along with a metric learning loss to aid D in better capturing semantic similarities in answer responses. Overall, our proposed model outperforms state-of-the-art on the VisDial dataset by a significant margin (2.67% on recall@10). The source code can be downloaded from https://github.com/jiasenlu/visDial.pytorch * Work was done while at Facebook AI Research. Dataset and Setup We evaluate our proposed approach on the VisDial dataset, which was collected by Das et al Evaluation Protocol Following the evaluation protocol established in, we use a retrieval setting to evaluate the responses at each round in the dialog Specifically, every question in VisDial is coupled with a list of 100 candidate answer options, which the models are asked to sort for evaluation purposes Models are evaluated on standard retrieval metrics -(1) mean rank, (2) recall @k, and (3) mean reciprocal rank (MRR) -of the human response in the returned sorted list Table 1: Results (generative) on VisDial dataset. \\"MRR\\" is mean reciprocal rank and \\"Mean\\" is mean rank. Model MRR R@1 R@5 R@10 Mean is mean reciprocal rank and \\" Mean \\" is mean rank . Table 1 : Results ( generative ) on VisDial dataset . \\" MRR \\" R@1 MRR R@5 R@10 Mean Table 2: Results (discriminative) on VisDial dataset. R@1 MRR R@5 R@10 Mean Table 4: Adversarial training results on VisDial dataset. Mean R@1 Generative Discriminative R@5 R@10 MRR -","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"62.22\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"Mean Rank\\", \\"Score\\": \\"4.81\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"48.48\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@10\\", \\"Score\\": \\"87.59\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@5\\", \\"Score\\": \\"78.75\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.6285\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"Mean Rank\\", \\"Score\\": \\"4.57\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"48.95\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@10\\", \\"Score\\": \\"88.36\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@5\\", \\"Score\\": \\"79.65\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"Visual Dialog v1.0 test-std\\", \\"Metric\\": \\"MRR (x 100)\\", \\"Score\\": \\"61.37\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"Visual Dialog v"},{"Context":"Type-Driven Incremental Semantic Parsing with Polymorphism Semantic parsing has made significant progress, but most current semantic parsers are extremely slow (CKY-based) and rather primitive in representation. We introduce three new techniques to tackle these problems. First, we design the first linear-time incremental shift-reduce-style semantic parsing algorithm which is more efficient than conventional cubic-time bottom-up semantic parsers. Second, our parser, being type-driven instead of syntax-driven, uses type-checking to decide the direction of reduction, which eliminates the need fora syntactic grammar such as CCG. Third, to fully exploit the power of type-driven semantic parsing beyond simple types (such as entities and truth values), we borrow from programming language theory the concepts of subtype polymorphism and parametric polymorphism to enrich the type system in order to better guide the parsing. Our system learns very accurate parses in GEOQUERY, JOBS and ATIS domains. We implement our type-driven incremental semantic parser (TISP) using Python, and evaluate its performance of both speed and accuracy on GEOQUERY and JOBS datasets For evaluation, we follow We first evaluate TISP on GEOQUERY dataset Soto find the best number of iterations to stop the training, we do a 10-fold cross-validation training over the training set, and choose to train 20 iterations and then evaluate This is actually because our method parses a lot more questions in the dataset, as the column of the percentage of successfully parsed sentences suggests We also evaluate the performance of TISP on ATIS dataset as in ATIS dataset contains more than 5,000 examples and is a lot larger than GEOQUERY and JOBS Our method achieves comparable performance on this dataset use \\"on-the-fly\\" matching to fetch the most possible predicate in the dataset for some MR subexpression Table 1: Performances (precision, recall, and F1) of various parsing algorithms on GEOQUERY, JOBS, and ATIS datasets. : \u03bb-WASP for GEOQUERY is trained on 792 examples. P R ATIS JOBS GEOQUERY F1 -","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Parsing\\", \\"Dataset\\": \\"ATIS\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"84.2\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Parsing\\", \\"Dataset\\": \\"ATIS\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"85.3\\"}} ]"},{"Context":"THE RELATIONAL MODEL IS INJECTIVE FOR MULTIPLICATIVE EXPONENTIAL LINEAR LOGIC (WITHOUT WEAKENINGS) We show that for Multiplicative Exponential Linear Logic (without weakenings) the syntactical equivalence relation on proofs induced by cut-elimination coincides with the semantic equivalence relation on proofs induced by the multiset based relational model: one says that the interpretation in the model (or the semantics) is injective. We actually prove a stronger result: two cut-free proofs of the full multiplicative and exponential fragment of linear logic whose interpretations coincide in the multiset based relational model are the same \\"up to the connections between the doors of exponential boxes\\". 1 terms) when they have the same interpretation. It is worth noticing that the study of both these equivalence relations is at the heart of the whole research area between proof-theory and theoretical computer science: cut-elimination is a crucial property of logical systems since Gentzen (with a renewal of interest in this property after the discovery of the Curry-Howard correspondence: a proof is a program whose execution corresponds to applying the cut-elimination procedure to the proof) and the general goal of denotational semantics is to give a \\"mathematical\\" counterpart to syntactical devices such as proofs and programs, bringing to the fore their essential properties. The basic pattern is to associate with every formula/type an object of some category and with every proof/program a morphism of this category (its interpretation).The works [12] and [13] give partial results and counterexamples to the question of injectivity, mainly for the (multiset based) coherent model: in particular the counterexamples show that this model is not injective for multiplicative and exponential LL (M ELL). Also, it was conjectured that the (multiset based) relational model is injective for M ELL, but despite many efforts ([12], [13], [14], [15], [9], [16]...) all the attempts to prove the conjecture failed up to now: no real progress has been done since [13], where a proof of injectivity of the relational model is given fora fragment of M ELL 1 . Game semantics is much closer to syntax than relational and coherent semantics, and positive answers have been obtained for little fragments like the multiplicative fragment M LL or the fragment corresponding to the \u03bb-calculus ([17], [18]), but also for the polarized fragment of LL ([19]).We prove here that for M ELL without weakenings (and without the multiplicative unit \u22a5) relational semantics is injective (Corollary 3). This tremendous improvement w.r.t. the previous situation is an immediate consequence of a much stronger result: in the full M ELL fragment (with units) two proof-nets Rand R \u2032 with the same interpretation are the same \\"up to the connections between the doors of exponential boxes\\" (we say they have the same LPS: Theorem 1 and Corollary 1). This result can be expressed in terms of differential nets ([20]): two cut-free proof-nets with different LPS have different Taylor expansions. We also believe this work is an essential step towards the proof of the full conjecture.In the style of [21] and [22] we work in an untyped framework; we do not define (proof-)nets nor cut-elimination but only cut-free proof-structures (PS, Definition 13): we prove that two PS with the same interpretation have the same LPS (Corollary 1). A (proof-)net (as defined in [22]) is a particular case of PS so that the result holds for untyped (so as for typed) M ELL (proof-)nets (Remark 6). Since we want to prove that two PS are isomorphic in Theorem 1, it is mandatory to have a (simple and clear) notion of isomorphism between PS (Definition 15) 2 , and this is why in Section 2 we give a very sharp description of the syntax in the style of interaction nets ([23], [24]): we cannot only rely on a graphic intuition. The notion of Linear Proof-Structure (LPS), which comes from [13], is our main syntactical tool: with every (proof-)net R of (say) [22] is associated a LPS, which is obtained from R by forgetting some informations about R\'s exponential boxes, namely which auxiliary doors correspond to which !-link (using standard LL\'s terminology); this is particularly clear in Definition 13 of PS: a PS is a LPS and a function allowing to recover boxes. Recovering this function from the interpretation of a PS is the only missing point in the proof of the full conjecture, but a simple remark shows that the function can be recovered from the LPS when the PS is a connected graph: this yields injectivity for M ELL without 1 Precisely, for the (?\u2118)LL fragment given by A ::= X | ?A\u2118A | A\u2118?A | A\u2118A | A \u2297 A | !A . 2 We actually use in our theorem an even subtler notion: the one of isomorphism between k-experiments of indexed LPS (Definition 35). FIGURE 1. Example of PS. In the standard syntax of [22] we have a box with a unique auxiliary door represented by the port p 2 (the dashed arrow allows to determine the doors of the box) and a dereliction link (the port p 1 ); the conclusions of the auxiliary door and the dereliction are then contracted.weakenings and \u22a5 (Corollary 3). In Section 3, we introduce a domain D to interpret PS which is exactly the one already defined in [22]. Like in [13], we use here experiments (introduced in [5]) which can bethought as objects in between syntax and semantics and are related to type derivations in the \u03bb-calculus ([25]). Experiments are functions defined on (proof-)nets allowing to compute the interpretation pointwise: the set of results of all the experiments of a given (proof-)net is its interpretation 3 . Usually an experiment e of a (proof-)net R is a labeling of R at depth 0 and a function associating with every !-link l of Ra set of experiments of the content of the box associated with l. We noticed that a particular kind of experiment called k-experiment (Definition 30) can be defined directly on LPS (boxes are not needed). We conclude Section 3 by stating our results and reducing the problem of injectivity to Proposition 1, which is proven in Section 4. The paper ends with a technical appendix, containing some obvious definitions and the formal details of some constructions previously used.In [13], a single (well-chosen!) point of the interpretation of a proof-net allowed to \\"rebuild\\" the entire proof-net (in some particular cases and for coherent semantics). Something similar happens in this paper, with a notable difference that makes everything much more complicated: in [13] the well-chosen point of the interpretation of a proof-net allowed not only to rebuild the proof-net but also the experiment having this point as result. This is not the case here, where the well-chosen points of the interpretation of a PS are atomic injective k-points (Definition 20): we show using Figure 1 that there exist different experiments having as result the same atomic injective k-point. We can define two experiments e 1 and e 2 of the PS R represented in Figure 1 in such away that e 1 (p 1 ) = [\u03b6 1 ], e 2 (p 1 ) = [\u03b6 2 ], e 1 (p 2 ) = [\u03b6 2 , \u03b6 3 , \u03b6 4 ] and e 2 (p 2 ) = [\u03b6 1 , \u03b6 3 , \u03b6 4 ], where \u03b6 j = (\u2212, \u03b3 j , \u03b3 j ) and the \u03b3 j are distinct atoms. The two (different) experiments have the same result, which is anatomic and injective 3-point. Let us conclude by mentioning the main novelties in our proof:\u2022 the use of injective experiments in a completely different sense than in [13]: intuitively, our injective k-experiments associate with an axiom link with depth d, k d different labels, while the injective k-obsessional experiments of [13] associate a unique label with such an axiom link (see Remark 2). A crucial aspect of our new injective k-experiments is that they can be recognized by their results 3  The result of an experiment e is the image of the conclusions of the (proof-)net through the function e; so that contrary to an experiment its result is a truly semantic object. Fact 17. Let k \u2208 N. Let \u03b2 \u2208 D \u2032 such that (dig k 1 ([\u03b2])) * = []. Then ([\u03b2]) * = [\u03b2].Proof. From (dig k 1 ([\u03b2])) * = [], we deduce that At\'(\u03b2) = \u2205.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Attention-Based Models for Speech Recognition Recurrent sequence generators conditioned on input data through an attention mechanism have recently shown very good performance on a range of tasks including machine translation, handwriting synthesis [1, 2] and image caption generation [3]. We extend the attention-mechanism with features needed for speech recognition. We show that while an adaptation of the model used for machine translation in [2] reaches a competitive 18.7% phoneme error rate (PER) on the TIMIT phoneme recognition task, it can only be applied to utterances which are roughly as long as the ones it was trained on. We offer a qualitative explanation of this failure and propose a novel and generic method of adding location-awareness to the attention mechanism to alleviate this issue. The new method yields a model that is robust to long inputs and achieves 18% PER in single utterances and 20% in 10-times longer (repeated) utterances. Finally, we propose a change to the attention mechanism that prevents it from concentrating too much on single frames, which further reduces PER to 17.6% level. All experiments were performed on the TIMIT corpus Table 1: Phoneme error rates (PER). The bold-faced PER corresponds to the best error rate with an attention-based recurrent sequence generator (ARSG) incorporating convolutional attention features and a smooth focus. Model Dev Test Baseline Model 15.9% 18.7% Baseline + Conv. Features 16.1% 18.0% Baseline + Conv. Features + Smooth Focus 15.8% 17.6% RNN Transducer [16] N/A 17.7% HMM over Time and Frequency Convolutional Net [25] 13.9% 16.7% and a smooth focus . Dev Test Table 1 : Phoneme error rates ( PER ) . The bold - faced PER corresponds to the best error rate with an","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"TIMIT\\", \\"Metric\\": \\"Percentage error\\", \\"Score\\": \\"17.6\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"TIMIT\\", \\"Metric\\": \\"Percentage error\\", \\"Score\\": \\"18.0\\"}} ]"},{"Context":"Unobtrusive Pain Monitoring in Older Adults with Dementia using Pairwise and Contrastive Training Although pain is frequent in old age, older adults are often undertreated for pain. This is especially the case for longterm care residents with moderate to severe dementia who cannot report their pain because of cognitive impairments that accompany dementia. Nursing staff acknowledge the challenges of effectively recognizing and managing pain in long-term care facilities due to lack of human resources and, sometimes, expertise to use validated pain assessment approaches on a regular basis. Vision-based ambient monitoring will allow for frequent automated assessments so care staff could be automatically notified when signs of pain are displayed. However, existing computer vision techniques for pain detection are not validated on faces of older adults or people with dementia, and this population is not represented in existing facial expression datasets of pain. We present the first fully automated vision-based technique validated on a dementia cohort. Our contributions are threefold. First, we develop a deep learning-based computer vision system for detecting painful facial expressions on a video dataset that is collected unobtrusively from older adult participants with and without dementia. Second, we introduce a pairwise comparative inference method that calibrates to each person and is sensitive to changes in facial expression while using training data more efficiently than sequence models. Third, we introduce a fast contrastive training method that improves cross-dataset performance. Our pain estimation model outperforms baselines by a wide margin, especially when evaluated on faces of people with dementia. Pre-trained model and demo code available at https://github.com/TaatiTeam/pain_detection_demo We used two datasets to conduct our experiments, the University of Regina (UofR) Pain in Severe Dementia dataset and the UNBC-McMaster Shoulder Pain Expression Archive Database The publicly available portion of the UNBC-McMaster dataset contains video data from 25 participants (13 females) with a shoulder injury during painful and non-painful movements, recorded at 30 frames per second (fps) and in Quarter VGA (240\xd7320) resolution The dataset contains 48,391 image frames in total (1936 \xb1 837 per participant) The UofR dataset contains video data from 102 older adult participants with and without dementia, recorded at 15 fps Videos of 95 people from the dataset (74 females) were annotated manually by trained annotators according to PSPI and PACSLAC-II pain rating scales depicts the distribution of pain levels (PSPI) in each dataset For instance, the ratio of frames with PSPI > 5 to those with PSPI < 2 is 1.8% for the UNBC-McMaster dataset,","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Pain Intensity Regression\\", \\"Dataset\\": \\"UNBC-McMaster ShoulderPain dataset\\", \\"Metric\\": \\"Pearson Correlation Coefficient\\", \\"Score\\": \\"0.71\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Anomaly Detection\\", \\"Dataset\\": \\"UCF-MNIST\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.94\\"}} ]"},{"Context":"MUSE: PARALLEL MULTI-SCALE ATTENTION FOR SEQUENCE TO SEQUENCE LEARNING In sequence to sequence learning, the self-attention mechanism proves to be highly effective, and achieves significant improvements in many tasks. However, the self-attention mechanism is not without its own flaws. Although self-attention can model extremely long dependencies, the attention in deep layers tends to overconcentrate on a single token, leading to insufficient use of local information and difficultly in representing long sequences. In this work, we explore parallel multi-scale representation learning on sequence data, striving to capture both long-range and short-range language structures. To this end, we propose the Parallel MUlti-Scale attEntion (MUSE) and MUSE-simple. MUSE-simple contains the basic idea of parallel multi-scale sequence representation learning, and it encodes the sequence in parallel, in terms of different scales with the help from self-attention, and pointwise transformation. MUSE builds on MUSE-simple and explores combining convolution and self-attention for learning sequence representations from more different scales. We focus on machine translation and the proposed approach achieves substantial performance improvements over Transformer, especially on long sequences. More importantly, we find that although conceptually simple, its success in practice requires intricate considerations, and the multi-scale attention must build on unified semantic space. Under common setting, the proposed model achieves substantial performance and outperforms all previous models on three main machine translation tasks. In addition, MUSE has potential for accelerating inference due to its parallelism. Code will be available at https://github.com/lancopku/MUSE. We evaluate MUSE on four machine translation tasks This section describes the datasets, experimental settings, detailed results, and analysis The length penalty is set to 0.8 for En-Fr according to the validation results, 1 for the two small datasets following the default setting of The BLEU 1 metric is adopted to evaluate the model performance during evaluation Table 1: MUSE-large outperforms all previous models under the standard training and evaluation setting on WMT14 En-De and WMT14 En-Fr datasets. - Table 2: MUSE-base outperforms previous state-of-the-art models on IWSLT De-En translation datasets and outperforms previous models without BPE processing on IWSLT En-Vi. - De - En En - Vi Table 3: Comparisons between MUSE and its variants on the IWSLT 2015 De-En translation task. BLEU Table 4: The comparison between the inference speed of MUSE and Transformer. modules and Transformer with 6 base blocks . The hidden size is set to 512 . 31% increase in inference speed can be obtained . The experiments use MUSE with 6 MUSE - simple Inference Speed ( tokens / s )","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-French\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"43.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"IWSLT2014 German-English\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"36.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-German\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"29.9\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-French\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"43.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-German\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"21.7\\"}} ]"},{"Context":"Obstacle Constrained Total Area Coverage in Wireless Sensor Networks This paper deals with the accomplishment of total area coverage of an arbitrary region using sensors with a finite sensing radius of rs. For a given region, we aim to obtain a deterministic placement of sensors which, apart from ensuring that the entire region comes under the purview of at least a single sensor, minimises the number of sensors utilised. We begin by considering regions devoid of obstacles and thus having every location amenable for placement. Herein, we formalise the popular notion that sensors at the centres of the hexagons of a hexagonal tessellation provide the most optimal placement. We then move onto regions which may comprise obstacles of arbitrary size at arbitrary locations. We recognise two distinct classes of obstacles, namely transparent and opaque obstacles, which are distinguished by their ability (or the lack of it) to permit sensing radiation through them. In the real world, transparent obstacles model lakes, ponds and swamps, while the opaque ones stand for, inter alia, hills, trees and walls. We propose a polynomial-time algorithm for achieving optimal placement in the aforesaid scenarios and we prove its convergence.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"\'Q-Feed\' -An Effective Solution for the Free-riding Problem in Unstructured P2P Networks This paper presents a solution for reducing the ill effects of free-riders in decentralised unstructured P2P networks. An autonomous replication scheme is proposed to improve the availability and enhance system performance. Q-learning is widely employed in different situations to improve the accuracy in decision making by each peer. Based on the performance of neighbours of a peer, every neighbour is awarded different levels of ranks. At the same time a low-performing node is allowed to improve its rank in different ways. Simulation results show that Q-learning based free riding control mechanism effectively limits the services received by free-riders and also encourages the low-performing neighbours to improve their position. The popular files are autonomously replicated to nodes possessing required parameters. Due to this improvement of quantity of popular files, free riders are given opportunity to lift their position for active participation in the network for sharing files. Q-feed effectively manages queries from free riders and reduces network traffic significantly.  Table 1. Q-Table of a node Node-id N 1 N 2 N 3 N 4 N 5 Q-value 150 80 35 245 70 Table 1 . Q - Table of a node Table 3. A Replication Q-Table nodes 3 - hops away A Replication Q - Table B C D E F H Table 3 . N Table 4. Status of Q-table of node \'A\' before and after replication operations Bandwidth , Table 4 . Status of Q - table of node \' A \' before and after replication B C D E F H N 175 682 122 441 466 324 336","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"A Strong Baseline and Batch Normalization Neck for Deep Person Re-identification This study proposes a simple but strong baseline for deep person re-identification (ReID). Deep person ReID has achieved great progress and high performance in recent years. However, many state-of-the-art methods design complex network structures and concatenate multi-branch features. In the literature, some effective training tricks briefly appear in several papers or source codes. The present study collects and evaluates these effective training tricks in person ReID. By combining these tricks, the model achieves 94.5% rank-1 and 85.9% mean average precision on Market1501 with only using the global features of ResNet50. The performance surpasses all existing global-and part-based baselines in person ReID. We propose a novel neck structure named as batch normalization neck (BNNeck). BNNeck adds a batch normalization layer after global pooling layer to separate metric and classification losses into two different feature spaces because we observe they are inconsistent in one embedding space. Extended experiments show that BNNeck can boost the baseline, and our baseline can improve the performance of existing state-of-the-art methods. Our codes and models are available at: https://github.com/michuanhaohao/reid-strongbaseline We evaluate our models on Market1501 and DukeMTMC-reID datasets, because both datasets are widely used and large scale Following the previous works, we use rank-1 accuracy and mAP for evaluation on both datasets Single-query evaluation is used in this study DukeMTMC-reID is anew large-scale person ReID dataset and collects 36,411 images from 1,404 identities of eight camera views Single-query evaluation is used in this study ID and triplet loss curves of different models on Market1501 and DukeMTMC-reID datasets","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"Market-1501\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"88.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"DukeMTMC-reID\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"79.1\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"Market-1501\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"83.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"Market-1501\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"93.6\\"}} ]"},{"Context":"An in-place truncated Fourier transform and applications to polynomial multiplication The truncated Fourier transform (TFT) was introduced by van der Hoeven in 2004 as a means of smoothing the \\"jumps\\" in running time of the ordinary FFT algorithm that occur at power-of-two input sizes. However, the TFT still introduces these jumps in memory usage. We describe in-place variants of the forward and inverse TFT algorithms, achieving time complexity O(n log n) with only O(1) auxiliary space. As an application, we extend the second author\'s results on space-restricted FFT-based polynomial multiplication to polynomials of arbitrary degree.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"INDEPENDENCE AND CONCURRENT SEPARATION LOGIC * A compositional Petri net-based semantics is given to a simple language allowing pointer manipulation and parallelism. The model is then applied to give a notion of validity to the judgements made by concurrent separation logic that emphasizes the process-environment duality inherent in such rely-guarantee reasoning. Soundness of the rules of concurrent separation logic with respect to this definition of validity is shown. The independence information retained by the Petri net model is then exploited to characterize the independence of parallel processes enforced by the logic. This is shown to permit a refinement operation capable of changing the granularity of atomic actions. C Tc(t 1 ) in N t 1 and \u03c0 2 :Proof. Induction on the length of path \u03c0. * C Tc(t 0 ) in N t 0 .","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Co-localization with Category-Consistent Features and Geodesic Distance Propagation Co-localization is the problem of localizing categorical objects using only positive set of example images, without any form of further supervision. This is a challenging task as there is no pixel-level annotations. Motivated by human visual learning, we find the common features of an object category from convolutional kernels of a pretrained convolutional neural network (CNN). We call these category-consistent CNN features. Then, we co-propagate their activated spatial regions using superpixel geodesic distances for localization. In our first set of experiments, we show that the proposed method achieves state-of-the-art performance on three related benchmarks: PASCAL 2007, PASCAL-2012, and the Object Discovery dataset. We also show that our method is able to detect and localize truly unseen categories, using six held-out ImagNet subset of categories with state-of-the-art accuracies. Our intuitive approach achieves this success without any region proposals or object detectors, and can be based on a CNN that was pre-trained purely on image classification tasks without further fine-tuning. * We evaluate our proposed 2-step framework with different parameter settings to illustrate different characteristics of our method We also evaluate our method on multiple benchmarks, with intermediate and final results to show the localization effects of our proposed method We use the conventional CorLoc metric to evaluate our co-localization results To benchmark our method performance, we evaluate our method on three commonly used datasets for the problem of co-localization These are VOC 2007 and 2012, and Object Discovery dataset For experiments on VOC datasets, we followed previous works that used all images on the trainval set excluding the images that only contain the object instances annotated as difficult or truncated For experiments on the Object Discovery dataset, we used the 100image subset following in order to make an appropriate comparison with related methods The ground truth bounding box for each image in the Object Discovery dataset is defined as the smallest Table 1. CorLoc scores of our approach and state-of-the-art co-localization methods on Pascal VOC 2007 dataset. Table 1 . CorLoc scores of our approach and state - of - the - art co - localization methods on Pascal VOC 2007 dataset . mbike bus sofa tv chair cow bottle aero boat bike horse car person mean bird cat plant dog table sheep train Table 2. CorLoc scores of our approach and state-of-the-art co-localization methods on Pascal VOC 2012 dataset. Table 2 . CorLoc scores of our approach and state - of - the - art co - localization methods on Pascal VOC 2012 dataset . Table 1 . CorLoc scores of our approach and state - of - the - art co - localization methods on Pascal VOC 2007 dataset . mbike bus sofa tv chair cow bottle aero boat bike horse car person mean bird cat plant dog table sheep","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Object Localization\\", \\"Dataset\\": \\"PASCAL VOC 2012\\", \\"Metric\\": \\"CorLoc\\", \\"Score\\": \\"47.45\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Localization\\", \\"Dataset\\": \\"PASCAL VOC 2007\\", \\"Metric\\": \\"CorLoc\\", \\"Score\\": \\"41.2\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL VOC 2007\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"74.4%\\"}} ]"},{"Context":"Minimizing the Maximum Interference is Hard We consider the following interference model for wireless sensor and ad hoc networks: the receiver interference of anode is the number of transmission ranges it lies in. We model transmission ranges as disks. For this case we show that choosing transmission radii which minimize the maximum interference while maintaining a connected symmetric communication graph is NP-complete.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"A Capsule Network-based Embedding Model for Knowledge Graph Completion and Search Personalization In this paper, we introduce an embedding model, named CapsE, exploring a capsule network to model relationship triples (subject, relation, object). Our CapsE represents each triple as a 3-column matrix where each column vector represents the embedding of an element in the triple. This 3-column matrix is then fed to a convolution layer where multiple filters are operated to generate different feature maps. These feature maps are reconstructed into corresponding capsules which are then routed to another capsule to produce a continuous vector. The length of this vector is used to measure the plausibility score of the triple. Our proposed CapsE obtains better performance than previous state-of-the-art embedding models for knowledge graph completion on two benchmark datasets WN18RR and FB15k-237, and outperforms strong search personalization baselines on SEARCH17. Dataset: We use the SEARCH17 dataset of query logs of 106 users collected by a large-scale web search engine The rank position of the relevant labeled documents is used as the ground truth to evaluate the search performance before and after re-ranking The dataset was uniformly split into the training, validation and test sets Evaluation protocol: Our CapsE is used to rerank the original list of documents returned by a search engine as follows: (i) We train our model and employ the trained model to calculate the score for each (s, r, o) triple To evaluate the performance of our proposed model, we use two standard evalu-ation metrics: mean reciprocal rank (MRR) and Hits@1 Table 1: Statistics of the experimental datasets. #E is the number of entities. #R is the number of relations. and FB15k - 237 . 11 presents the statistics of WN18RR #R Table 2: Experimental results on the WN18RR and FB15k-237 test sets. Hits@10 (H@10) is reported in %. Results of DISTMULT, ComplEx and ConvE are taken from Dettmers et al. (2018). Results of TransE on FB15k- 237 are taken from Nguyen et al. (2018). Our CapsE Hits@1 scores are 33.7% on WN18RR and 48.9% on FB15k-237. Formulas of MRR and Hits@1 show a strong correlation, so using Hits@1 does not really reveal any additional information for this task. The best score is in bold, while the second best score is in underline. denotes our new results for TransE and ConvKB, which are better than those published by Nguyen et al. (2018). belled 1 - 1 , 1 - M , M","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.56\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"MR\\", \\"Score\\": \\"719.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.415\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Evaluation Protocol\\", \\"Score\\": \\"Can be affected with a more appropriate protocol. See the row of CapsE (Corrected).\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.593\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"MR\\", \\"Score\\": \\"303.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.523\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.461\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.581\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.483\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.44\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.261\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.547\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.304\\"}}, { \\"LEADERBOARD\\": { \'Ta"},{"Context":"Improved Fully Dynamic Reachability Algorithm for Directed Graph We propose a fully dynamic algorithm for maintaining reachability information in directed graphs. The proposed deterministic dynamic algorithm has an update time of O((ins * n 2 ) + (del * (m + n * log(n)))) where m is the current number of edges, n is the number of vertices in the graph, ins is the number of edge insertions and del is the number of edge deletions. Each query can be answered in O(1) time after each update. The proposed algorithm combines existing fully dynamic reachability algorithm with well known witness counting technique to improve efficiency of maintaining reachability information when edges are deleted. The proposed algorithm improves by a factor of O( n 2 m+n * log(n) ) for edge deletion over the best existing fully dynamic algorithm for maintaining reachability information.  Table 3: Insert(E v ) from scratch when node v acts as an witness . So we decrement witness count by one for each pair in [ RZ04 ] v v is a previous insertion center then for each u in In [ v ] do end if This we perform before we compute new In [ v ] and Out [ v ] . Now we remove assumption that v is not a insertion center before . compute new In and Out trees rooted at node v using algorithm mentioned current number of edges in the graph and n is number of vertices in the graph . for each z in Out [ v ] do end for Table 5: U pdateT CM witness for directed path from node u to node z any more iff u \u2208 In delete [ v ] and z \u2208 Out [ v ]","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Similarity-based Reasoning in Qualified Logic Programming Revised Edition Similarity-based Logic Programming (briefly, SLP ) has been proposed to enhance the LP paradigm with a kind of approximate reasoning which supports flexible information retrieval applications. This approach uses a fuzzy similarity relation R between symbols in the program\'s signature, while keeping the syntax for program clauses as in classical LP . Another recent proposal is the QLP (D) scheme for Qualified Logic Programming, an extension of the LP paradigm which supports approximate reasoning and more. This approach uses annotated program clauses and a parametrically given domain D whose elements qualify logical assertions by measuring their closeness to various users\' expectations. In this paper we propose a more expressive scheme SQLP (R, D) which subsumes both SLP and QLP (D) as particular cases. We also show that SQLP (R, D) programs can be transformed into semantically equivalent QLP (D) programs. As a consequence, existing QLP (D) implementations can be used to give efficient support for similarity-based reasoning.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Supervised Relation Classification as Two-way Span-Prediction The current supervised relation classification (RC) task uses a single embedding to represent the relation between a pair of entities. We argue that a better approach is to treat the RC task as span-prediction (SP) problem, similar to Question answering (QA). We present a span-prediction based system for RC and evaluate its performance compared to the embedding based system. We demonstrate that the supervised SP objective works significantly better then the standard classification based objective. We achieve state-of-the-art results on the TACRED and SemEval task 8 datasets. We compare ourselves on three RC datasets TACRED is the currently most popular and largest RC dataset To show this bias empirically, they created a Wikipedia based dataset intended to be used only for testing, which contains 3000 manually tagged sentences from the TACRED relations Each sentence in the dataset contains two entity pairs that are compatible with the same relation The evaluation of the CRE is binary -the model goal is to indicate if a given relation is found or not found in the dataset The model was evaluated with both SP and RC models Table 1: CRE. Span prediction model result on CRE, compared to traditional RC and QA model. RC models are relation classification models and SQuAD models are QA models that were trained on the SQuAD 2.0 dataset. are relation classification models and SQuAD models dataset . P R F 1 Table 1 : CRE . Span prediction model result on CRE , Table 2: TACRED. Supervised results on the TACRED datasets. Top: Using BERT. This is a direct compari- son to the MTB span-prediction model. MTB F 1 is taken from the original paper. SP models (except token) suppress MTB. Bottom: Using ALBERT. Here the ref- erence point is KEPLLER, the current best performing model on this dataset. All the supervised SP-ALBERT models outperform KEPPLER. P R F 1 Table 3: SemEval. Supervised results on the SemEval datasets. LiTian is the current state of the art. P 1 R F Table 4:","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"TACRED\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"74.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"SemEval-2010 Task 8\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"91.9\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"Re-TACRED\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"83.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"TACRED\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"68.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"TACRED\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"67.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"TACRED\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"66.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"TACRED\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"64.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"SemEval-2010 Task 8\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"89.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"SemEval-2010 Task 8\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"90.3\\"}} ]"},{"Context":"Self-Supervised Model Adaptation for Multimodal Semantic Segmentation Learning to reliably perceive and understand the scene is an integral enabler for robots to operate in the realworld. This problem is inherently challenging due to the multitude of object types as well as appearance changes caused by varying illumination and weather conditions. Leveraging complementary modalities can enable learning of semantically richer representations that are resilient to such perturbations. Despite the tremendous progress in recent years, most multimodal convolutional neural network approaches directly concatenate feature maps from individual modality streams rendering the model incapable of focusing only on the relevant complementary information for fusion. To address this limitation, we propose a mutimodal semantic segmentation framework that dynamically adapts the fusion of modalityspecific features while being sensitive to the object category, spatial location and scene context in a self-supervised manner. Specifically, we propose an architecture consisting of two modality-specific encoder streams that fuse intermediate encoder representations into a single decoder using our proposed self-supervised model adaptation fusion mechanism which optimally combines complementary features. As intermediate representations are not aligned across modalities, we introduce an attention scheme for better correlation. In addition, we propose a computationally efficient unimodal segmentation architecture termed AdapNet++ that incorporates anew encoder with multiscale residual units and an efficient atrous spatial pyramid pooling that has a lar-Abhinav Valada ger effective receptive field with more than 10\xd7 fewer parameters, complemented with a strong decoder with a multiresolution supervision scheme that recovers high-resolution details. Comprehensive empirical evaluations on Cityscapes, Synthia, SUN RGB-D, ScanNet and Freiburg Forest benchmarks demonstrate that both our unimodal and multimodal architectures achieve state-of-the-art performance while simultaneously being efficient in terms of parameters and inference time as well as demonstrating substantial robustness in adverse perceptual conditions. In this section, we first describe the datasets that we benchmark on, followed by comprehensive quantitative results for unimodal segmentation using our proposed AdapNet++ architecture in Section 5.3 and the results for model compression in Section 5.4 We present the multimodal fusion benchmarking experiments with the various modalities contained in the datasets in Section 5.7 and the ablation study on our multimodal fusion architecture in Section 5.10 We evaluate our proposed AdapNet++ architecture on five publicly available diverse scene understanding benchmarks ranging from urban driving scenarios to unstructured forested scenes and cluttered indoor environments The datasets were particularly chosen based on the criteria of containing scenes with challenging perceptual conditions including rain, snow, fog, night-time, glare, motion blur and other seasonal appearance changes Each of the datasets contain multiple modalities that we utilize for benchmarking our fusion approach We briefly describe the datasets and their constituting semantic categories in this section Table 1 Performance comparison of AdapNet++ with baseline models on the Cityscapes validation set with 11 semantic class labels (input image dim: 768 \xd7 384). Note that no left-right flips or multiscale testing is performed. Note: Corresponding multimodal results are reported in Table 17. ( % ) Sky Building mIoU Vegetation Pole Car Road Sign Cyclist Sidewalk Fence Person Table 2 Benchmarking results on the Cityscapes dataset with full resolution evaluation on 19 semantic class labels. Only the eight top performing published models in the leaderboard are listed in this table. The inference time is reported for an input image resolution of 768 \xd7 384 pixels and it was computed on an NVIDIA TITAN X (PASCAL) GPU using the official implementation of each method. val mIoU ( % ) test Parms . Time ( M ) ( ms ) Table 3 Performance comparison of AdapNet++ with baseline models on the Synthia","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Scene Recognition\\", \\"Dataset\\": \\"ScanNet\\", \\"Metric\\": \\"Average Recall\\", \\"Score\\": \\"54.28\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"SUN-RGBD\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"45.73\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"SUN-RGBD\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"38.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Freiburg Forest\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"84.18\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Freiburg Forest\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"83.09\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"82.3%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"81.24%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"SYNTHIA-CVPR\u201916\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"92.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"SYNTHIA-CVPR\u201916\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"87.87\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ScanNetV2\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"57.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ScanNetV2\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"50.3\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"82.6%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"61.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"51.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ScanNet\\", \\"Metric\\": \\"3DIoU\\", \\"Score\\": \\"0.44\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Semantic Segmentation\\", \\"Dataset\\": \\"SemanticKITTI\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"35.9%\\"}} ]"},{"Context":"Generative Image Modeling Using Spatial LSTMs Modeling the distribution of natural images is challenging, partly because of strong statistical dependencies which can extend over hundreds of pixels. Recurrent neural networks have been successful in capturing long-range dependencies in a number of problems but only recently have found their way into generative image models. We here introduce a recurrent image model based on multidimensional long short-term memory units which are particularly suited for image modeling due to their spatial structure. Our model scales to images of arbitrary size and its likelihood is computationally tractable. We find that it outperforms the state of the art in quantitative comparisons on several image datasets and produces promising results when used for texture synthesis and inpainting.  Table 1: Average log-likelihoods and log-likelihood rates for image patches (without/with DC comp.) and large images extracted from BSDS300 [25]. each patch \' s DC component was zero . Because the resulting image patches live on a 63 dimensional Model - \u221e dim . 64 dim . [ nat ] [ bit / px ] 63 dim . Table 2: Average log-likelihood rates for im- age patches and large images extracted from van Hateren\'s dataset [48]. Model - 256 dim . \u221e dim . [ bit / px ] Table 3: Average log-likelihood rates on dead leaf images. A deep recurrent image model is on a par with a deep diffusion model [ bit / px ]","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"bits/dimension\\", \\"Score\\": \\"3.47\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"bits/dimension\\", \\"Score\\": \\"3.03\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"ImageNet 64x64\\", \\"Metric\\": \\"Bits per dim\\", \\"Score\\": \\"3.57\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"ImageNet 32x32\\", \\"Metric\\": \\"bpd\\", \\"Score\\": \\"3.83\\"}} ]"},{"Context":"R-FCN: Object Detection via Region-based Fully Convolutional Networks We present region-based, fully convolutional networks for accurate and efficient object detection. In contrast to previous region-based detectors such as Fast/Faster R-CNN [6,18] that apply a costly per-region subnetwork hundreds of times, our region-based detector is fully convolutional with almost all computation shared on the entire image. To achieve this goal, we propose position-sensitive score maps to address a dilemma between translation-invariance in image classification and translation-variance in object detection. Our method can thus naturally adopt fully convolutional image classifier backbones, such as the latest Residual Networks (ResNets) [9], for object detection. We show competitive results on the PASCAL VOC datasets (e.g., 83.6% mAP on the 2007 set) with the 101-layer ResNet. Meanwhile, our result is achieved at a test-time speed of 170ms per image, 2.5-20\xd7 faster than the Faster R-CNN counterpart. Code is made publicly available at: https://github.com/daijifeng001/r-fcn. * This work was done when Yi Li was an intern at Microsoft Research. 2 Only the last layer is fully-connected, which is removed and replaced when fine-tuning for object detection. We train the models on the union set of VOC 2007 trainval and VOC 2012 trainval (\\"07+12\\") following, and evaluate on VOC 2007 test set Next we evaluate on the MS COCO dataset that has 80 object categories We extend the alternating training from 4-step to 5-step (i.e., stopping after one more RPN training step), which slightly improves accuracy on this dataset when the features are shared; we also report that 2-step training is sufficient to achieve comparably good accuracy but the features are not shared Considering COCO\'s wide range of object scales, we further evaluate a multi-scale testing variant following, and use testing scales of {200,400,600,800,1000} Table 2: Comparisons among fully convolutional (or \\"almost\\" fully convolutional) strategies using ResNet-101. All competitors in this table use the \xe0 trous trick. Hard example mining is not conducted. fail RoI output size ( k \xd7 k ) mAP on VOC 07 ( % ) Table 3: Comparisons between Faster R-CNN and R-FCN using ResNet-101. Timing is evaluated on a single Nvidia K40 GPU. With OHEM, N RoIs per image are computed in the forward pass, and 128 samples are selected for backpropagation. 300 RoIs are used for testing following [18]. N / A mAP ( % ) on VOC07 train time test time ( sec / img ) Table 4: Comparisons on PASCAL VOC 2007 test set using ResNet-101. \\"Faster R-CNN +++\\" [9] uses iterative box regression, context, and multi-scale testing. mAP ( % ) test time ( sec / img ) Table 5: Comparisons on PASCAL VOC 2012 test","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"PASCAL VOC 2007\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"80.5%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Real-Time Object Detection\\", \\"Dataset\\": \\"PASCAL VOC 2007\\", \\"Metric\\": \\"FPS\\", \\"Score\\": \\"9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Real-Time Object Detection\\", \\"Dataset\\": \\"PASCAL VOC 2007\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"80.5%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"PASCAL VOC 2007\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"82.6%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"91.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"79.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"83.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"47.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"26.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"43.3\\"}}, { \'"},{"Context":"Canonical Coin Systems for Change-Making Problems The Change-Making Problem is to represent a given value with the fewest coins under a given coin system. As a variation of the knapsack problem, it is known to be NP-hard. Nevertheless, inmost real money systems, the greedy algorithm yields optimal solutions. In this paper, we study what type of coin systems that guarantee the optimality of the greedy algorithm. We provide new proofs fora sufficient and necessary condition for the so-called canonical coin systems with four or five types of coins, and a sufficient condition for non-canonical coin systems, respectively. Moreover, we present an O(m 2 ) algorithm that decides whether a tight coin system is canonical.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"FABRICATION OF SWTICHES ON POLYMER-BASED BY HOT EMBOSSING In MEMS technology, most of the devices are fabricated on glass or silicon substrate. However, this research presents a novel manufacture method that is derived from conventional hot embossing technology to fabricate the electrostatic switches on polymer material. The procedures of fabrication involve the metal deposition, photolithography, electroplating, hot embossing and hot embed techniques. The fundamental concept of the hot embed technology is that the temperature should be increased above Tg of polymer, and the polymer becomes plastic and viscous and could be molded. According to the fundamental concept, the metal layer on the silicon/glass substrate could be embedded into polymer material during the hot embossing process. Afterward, the metal layer is bonded together with the polymer after removing the substrate in the de-embossing step. Finally, the electrostatic switch is fabricated on polymethylmethacrylate(PMMA) material to demonstrate the novel method.  Table 1 The polymer materials, PMMA and PC. Polymer material 105 conductivity kg / m ( W / m \u2022 K ) Density \xb0C ) Thermal Table 2. The parameters of hot embossing Fixed electrode mold temperature ( \xb0C ) 2 Table 2 . The parameters of hot embossing electrode Gap layer Actuating mold ) Fixed 120","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Activity Driven Weakly Supervised Object Detection Weakly supervised object detection aims at reducing the amount of supervision required to train detection models. Such models are traditionally learned from images/videos labelled only with the object class and not the object bounding box. In our work, we try to leverage not only the object class labels but also the action labels associated with the data. We show that the action depicted in the image/video can provide strong cues about the location of the associated object. We learn a spatial prior for the object dependent on the action (e.g. \\"ball\\" is closer to \\"leg of the person\\" in \\"kicking ball\\"), and incorporate this prior to simultaneously train a joint object detection and action classification model. We conducted experiments on both video datasets and image datasets to evaluate the performance of our weakly supervised object detection model. Our approach outperformed the current state-of-the-art (SOTA) method by more than 6% in mAP on the Charades video dataset. Object bounding box annotations are used only during evaluation Video datasets: The Charades dataset includes 9,848 videos of 157 action classes, among which, 66 are interactive actions with objects The official Charades dataset doesn\'t provide object bounding box annotations and we use the annotations released by We follow the same practice as in: train on 7,986 videos (54,000 clips) and evaluate on 5,000 randomly selected test frames from 200 test videos The EPIC-KITCHENS is an ego-centric video dataset which is captured by head-mounted camera in different kitchen scenes Image dataset The HICO-DET dataset is designed for human-object interaction (HOI) detection task This dataset includes 38,118 training images and 9,658 test images We use the HOI labels as action class labels during training and the object bounding box annotations are used only for evaluation Table 1: Detection performance of different variants on Charades Table 1 : Detection performance of different variants on Charades mAP CorLoc Table 2: AP performance (%) on each object class and mAP (%) comparison with different weakly supervised methods on Charades. bed sofa tv chair broom towel vacuum window shelf mAP ( % ) dish door laptop mirror pillow table cup refri Table 3: AP performance (%) on selected object classes and mAP (%) comparison with other weakly supervised methods on HICO-DET. apple mAP ( % ) bicycle surfboard umbrella chair cellphone bottle frisbee kite train Table 4: mAP (%) comparison with other weakly supervised meth- ods on EPIC KITCHENS ods on EPIC KITCHENS mAP Table 4 : mAP ( % ) comparison with other weakly supervised meth - CorLoc","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Weakly Supervised Object Detection\\", \\"Dataset\\": \\"Charades\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"10.03\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Weakly Supervised Object Detection\\", \\"Dataset\\": \\"HICO-DET\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"5.39\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Weakly Supervised Object Detection\\", \\"Dataset\\": \\"HICO-DET\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"41.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Weakly Supervised Object Detection\\", \\"Dataset\\": \\"Charades\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"21.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Weakly Supervised Object Detection\\", \\"Dataset\\": \\"Charades\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"46.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Weakly Supervised Object Detection\\", \\"Dataset\\": \\"HICO-DET\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"36.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Weakly Supervised Object Detection\\", \\"Dataset\\": \\"HICO-DET\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"17.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Weakly Supervised Object Detection\\", \\"Dataset\\": \\"HICO-DET\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"42.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Weakly Supervised Object Detection\\", \\"Dataset\\": "},{"Context":"Predicting intubation support requirement of patients using Chest X-ray with Deep Representation Learning Recent developments in medical imaging with Deep Learning presents an evidence of automated diagnosis and prognosis. It can also be a complement to currently available diagnosis methods. Deep Learning can be leveraged for diagnosis, severity prediction, intubation support prediction and many similar tasks. We present prediction of intubation support requirement for patients from the Chest X-ray using Deep representation learning. We release our source code publicly on https://github.com/aniketmaurya/covid-research. We use covid-chestxray-dataset, an open dataset collected from public and indirect collection from hospitals and physicians The dataset is available on GitHub The metadata of this dataset contains labels of 25 lungs disease, shown in Table 1: covid-chestxray-datset pathology negative and positive frequency 22 11 23 48 15 16 17 1 3 4 5 8 9 Negative Positive","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Intubation Support Prediction\\", \\"Dataset\\": \\"COVID chest X-ray\\", \\"Metric\\": \\"AUC-ROC\\", \\"Score\\": \\"0.84\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-tissue Nucleus Segmentation\\", \\"Dataset\\": \\"Kumar\\", \\"Metric\\": \\"Dice\\", \\"Score\\": \\"0.826\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-tissue Nucleus Segmentation\\", \\"Dataset\\": \\"Kumar\\", \\"Metric\\": \\"Hausdorff Distance (mm)\\", \\"Score\\": \\"59.7\\"}} ]"},{"Context":"On Compact Routing for the Internet The Internet\'s routing system is facing stresses due to its poor fundamental scaling properties. Compact routing is a research field that studies fundamental limits of routing scalability and designs algorithms that try to meet these limits. In particular, compact routing research shows that shortest-path routing, forming a core of traditional routing algorithms, cannot guarantee routing table (RT) sizes that on all network topologies grow slower than linearly as functions of the network size. However, there are plenty of compact routing schemes that relax the shortest-path requirement and allow for improved, sublinear RT size scaling that is mathematically provable for all static network topologies. In particular, there exist compact routing schemes designed for grids, trees, and Internet-like topologies that offer RT sizes that scale logarithmically with the network size.In this paper, we demonstrate that in view of recent results in compact routing research, such logarithmic scaling on Internet-like topologies is fundamentally impossible in the presence of topology dynamics or topology-independent (flat) addressing. We use analytic arguments to show that the number of routing control messages per topology change cannot scale better than linearly on Internet-like topologies. We also employ simulations to confirm that logarithmic RT size scaling gets broken by topology-independent addressing, a cornerstone of popular locator-identifier split proposals aiming at improving routing scaling in the presence of network topology dynamics or host mobility. These pessimistic findings lead us to the conclusion that a fundamental re-examination of assumptions behind routing models and abstractions is needed in order to find a routing architecture that would be able to scale \\"indefinitely.\\"1 We clarify upfront that scalability is only one of several problems of the current Internet routing architecture. Other problems include security, isolation, configuration control, etc. See [2] fora long list of future routing architecture requirements.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Vehicle Re-identification Using Quadruple Directional Deep Learning Features In order to resist the adverse effect of viewpoint variations for improving vehicle re-identification performance, we design quadruple directional deep learning networks to extract quadruple directional deep learning features (QD-DLF) of vehicle images. The quadruple directional deep learning networks are with similar overall architecture, including the same basic deep learning architecture but different directional feature pooling layers. Specifically, the same basic deep learning architecture is a shortly and densely connected convolutional neural network to extract basic feature maps of an input square vehicle image in the first stage. Then, the quadruple directional deep learning networks utilize different directional pooling layers, i.e., horizontal average pooling (HAP) layer, vertical average pooling (VAP) layer, diagonal average pooling (DAP) layer and anti-diagonal average pooling (AAP) layer, to compress the basic feature maps into horizontal, vertical, diagonal and anti-diagonal directional feature maps, respectively. Finally, these directional feature maps are spatially normalized and concatenated together as a quadruple directional deep learning feature for vehicle re-identification. Extensive experiments on both VeRi and VehicleID databases show that the proposed QD-DLF approach outperforms multiple state-of-the-art vehicle re-identification methods.Jianqing Zhu received the B.S. degree in communication engineering and the M.S. degree in communication and information system from the And two commonly used criteria in the re-identification field, i.e., cumulative match curve (CMC) and mean average precision (MAP), are used to evaluate the performance The MAP is used to evaluate the overall performance Then, the mean value of APs of all queries is calculated as MAP, which considers both precision and recall of a re-identification method, and thus provides a more comprehensive performance evaluation","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Vehicle Re-Identification\\", \\"Dataset\\": \\"VeRi-776\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"61.83\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Vehicle Re-Identification\\", \\"Dataset\\": \\"VehicleID Small\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"76.54\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Vehicle Re-Identification\\", \\"Dataset\\": \\"VehicleID Medium\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"74.63\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Vehicle Re-Identification\\", \\"Dataset\\": \\"VehicleID Large\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"68.41\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Vehicle Re-Identification\\", \\"Dataset\\": \\"VeRi-7\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"96.78\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Vehicle Re-Identification\\", \\"Dataset\\": \\"VeRi-7\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"83.41\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Vehicle Re-Identification\\", \\"Dataset\\": \\"VehicleID Small\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"83.64\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Vehicle Re-Identification\\", \\"Dataset\\": \\"VeRi\\", \\"Metric\\": \\"Rank-5\\", \\"Score\\": \\"96.78\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Vehicle Re-Identification\\", \\"Dataset\\": \\"VeRi\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"83.41\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Vehicle Re-Identification\\", \\"Dataset\\": \\"VehicleID Medium\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"81.35\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Vehicle Re-Identification\\", \\"Dataset\\": \\"Veh"},{"Context":"Learning to Learn via Self-Critique In few-shot learning, a machine learning system learns from a small set of labelled examples relating to a specific task, such that it can generalize to new examples of the same task. Given the limited availability of labelled examples in such tasks, we wish to make use of all the information we can. Usually a model learns taskspecific information from a small training-set (support-set) to predict on an unlabelled validation set (target-set). The target-set contains additional task-specific information which is not utilized by existing few-shot learning methods. Making use of the target-set examples via transductive learning requires approaches beyond the current methods; at inference time, the target-set contains only unlabelled input data-points, and so discriminative learning cannot be used. In this paper, we propose a framework called Self-Critique and Adapt or SCA, which learns to learn an label-free loss function, parameterized as a neural network. A base-model learns on a support-set using existing methods (e.g. stochastic gradient descent combined with the cross-entropy loss), and then is updated for the incoming target-task using the learnt loss function. The label-free loss function is learned such that the target-set-updated model achieves higher generalization performance. Experiments demonstrate that SCA offers substantially reduced errorrates compared to baselines which only adapt on the support-set, and results instate of the art benchmark performance on Mini-ImageNet and Caltech-UCSD Birds 200. To evaluate the proposed methods we first establish baselines on both the low-end and high-end variants of MAML++ on the Mini-ImageNet and Caltech-UCSD Birds 200 (CUB) 5-way 1/5-shot tasks Table 1: SCA Ablation Studies on Mini-ImageNet and CUB: All variants utilizing the proposed SCA method perform substantially better than the non-SCA baseline variant. Interestingly, the best type of critic conditioning features varies depending on the backbone architecture. Based on our experiments, the best critic conditioning features for the Low-End MAML++ is the combination of predictions, task-embedding and network parameters, whereas on High-End MAML++, using just the target-set predictions appears to be enough to obtain the highest performance observed in our experiments. 5 - shot - 1 - shot Table 2: Comparative Results on Mini-ImageNet and CUB: The proposed method appears to im- prove the baseline model by over 4 percentage points, allowing it to set a new state-of-the-art result on both the 1/5-way Mini-ImageNet tasks. 5 - shot CUB Mini - ImageNet Test Accuracy - 1 - shot","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"CUB 200 5-way 1-shot\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"70.46\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"CUB 200 5-way 1-shot\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"67.48\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"CUB 200 5-way 5-shot\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"85.63\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"CUB 200 5-way 5-shot\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"83.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"Mini-Imagenet 5-way (1-shot)\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"62.86\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"Mini-Imagenet 5-way (5-shot)\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"77.64\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"Mini-ImageNet - 1-Shot Learning\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"63.73%\\"}} ]"},{"Context":"On cycles through two arcs in strong multipartite tournaments A multipartite tournament is an orientation of a complete c-partite graph. In [L. Volkmann, A remark on cycles through an arc in strongly connected multipartite tournaments, Appl. Math. Lett. 20 (2007) 1148-1150], Volkmann proved that a strongly connected cpartite tournament with c 3 contains an arc that belongs to a directed cycle of length m for every m \u2208 {3, 4, . . . , c}. He also conjectured the existence of three arcs with this property. In this note, we prove the existence of two such arcs.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Switchable Whitening for Deep Representation Learning Normalization methods are essential components in convolutional neural networks (CNNs). They either standardize or whiten data using statistics estimated in predefined sets of pixels. Unlike existing works that design normalization techniques for specific tasks, we propose Switchable Whitening (SW), which provides a general form unifying different whitening methods as well as standardization methods. SW learns to switch among these operations in an end-to-end manner. It has several advantages. First, SW adaptively selects appropriate whitening or standardization statistics for different tasks (see Fig.1), making it well suited fora wide range of tasks without manual design. Second, by integrating the benefits of different normalizers, SW shows consistent improvements over its counterparts in various challenging benchmarks. Third, SW serves as a useful tool for understanding the characteristics of whitening and standardization techniques.We show that SW outperforms other alternatives on image classification (CIFAR-10/100, ImageNet), semantic segmentation (ADE20K, Cityscapes), domain adaptation (GTA5, Cityscapes), and image style transfer (COCO). For example, without bells and whistles, we achieve state-ofthe-art performance with 45.33% mIoU on the ADE20K dataset. Code is available at https://github.com/ XingangPan/Switchable-Whitening. We evaluate SW on image classification (CIFAR-10/100, ImageNet), semantic segmentation (ADE20K, Cityscapes), domain adaptation (GTA5, Cityscapes), and image style transfer (COCO) Table 2. Test errors (%) on CIFAR-10/100 and ImageNet valida- tion sets [16]. For each model, we evaluate different normalization or whitening methods. SW a and SW b correspond to \u2126 = {bw, iw} and \u2126 = {bw, iw, bn, in, ln} respectively. Results on CIFAR are averaged over 5 runs. SW BW CIFAR - 10 SN SW has \u2126 = {bw , iw} . CIFAR - 100 SW a b SW BW ( a ) ResNet20 on CIFAR - 10 SN BN epochs Table 3. Results on Cityscapes and ADE20K datasets. \'ss\' and \'ms\' indicate single-scale and multi-scale test respectively. a idation set . * indicates our implementation . Method - ADE20K mIoU ss mIoU ( % ) mIoU ms Cityscapes Pixel Acc . ( % ) Table 4. Comparison with advanced methods on the ADE20K val- idation set. * indicates our implementation. Method mIoU(%) Pixel Acc.(%) DilatedNet [35] 32.31","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Synthetic-to-Real Translation\\", \\"Dataset\\": \\"GTAV-to-Cityscapes Labels\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"35.7\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"75.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"90.7\\"}} ]"},{"Context":"Circle Loss: A Unified Perspective of Pair Similarity Optimization This paper provides a pair similarity optimization viewpoint on deep feature learning, aiming to maximize the within-class similarity s p and minimize the between-class similarity s n . We find a majority of loss functions, including the triplet loss and the softmax cross-entropy loss, embed s n and s pinto similarity pairs and seek to reduce (s n \u2212 s p ). Such an optimization manner is inflexible, because the penalty strength on every single similarity score is restricted to be equal. Our intuition is that if a similarity score deviates far from the optimum, it should be emphasized. To this end, we simply re-weight each similarity to highlight the less-optimized similarity scores. It results in a Circle loss, which is named due to its circular decision boundary. The Circle loss has a unified formula for two elemental deep feature learning paradigms, i.e., learning with class-level labels and pair-wise labels. Analytically, we show that the Circle loss offers a more flexible optimization approach towards a more definite convergence target, compared with the loss functions optimizing (s n \u2212 s p ). Experimentally, we demonstrate the superiority of the Circle loss on a variety of deep feature learning tasks. On face recognition, person re-identification, as well as several finegrained image retrieval datasets, the achieved performance is on par with the state of the art. We comprehensively evaluate the effectiveness of Circle loss under two elemental learning approaches, i.e., learning with class-level labels and learning with pair-wise labels For the former approach, we evaluate our method on face recognition (Section 4.2) and person re-identification (Section 4.3) tasks For the latter approach, we use the fine-grained image retrieval datasets (Section 4.4), which are relatively small and encourage learning with pair-wise labels Table 1: Face identification and verification results on MFC1 dataset. \\"Rank 1\\" denotes rank-1 identification ac- curacy. \\"Veri.\\" denotes verification TAR (True Accepted Rate) at 1e-6 FAR (False Accepted Rate) with 1M dis- tractors. \\"R34\\" and \\"R100\\" denote using ResNet34 and ResNet100 backbones, respectively. Loss function R34 R100 Veri . ( % ) Rank 1 ( % ) Table 2: Face verification accuracy (%) on LFW, YTF and CFP-FP with ResNet34 backbone. LFW [ 10 ] YTF [ 37 ] CFP - FP [ 23 ] Table 3: Comparison of TARs on the IJB-C 1:1 verification task. Loss function LFW [ 10 ] YTF [ 37 ] CFP - FP [ 23 ] 1e - 5 1e - 4 1e - 3 Table 4: Evaluation of Circle loss on re-ID task. We report R-1 accuracy (%) and mAP (%). bone , Circle loss surpasses the most competitive one ( Ar -","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Face Recognition\\", \\"Dataset\\": \\"CFP-FP\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.9602\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Recognition\\", \\"Dataset\\": \\"LFW\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.9973\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"MSMT17\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"76.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"MSMT17\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"52.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"MSMT17\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"76.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"MSMT17\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"50.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"Market-1501\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"87.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"Market-1501\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"96.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"Market-1501\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"84.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"Market-1501\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"94.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Metric Learning\\", \\"Dataset\\": \\"Stanford Online Products\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"78.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Metric Learning\\", \\"Dataset\\": \\"CARS196\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"83.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Metric Learning\\", \\"Dataset\\": \\"CUB-200-2011\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"66.7\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"Mega\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"81.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"IJB-A\\", \\"Metric\\": \\"TAR @ FAR=0.01\\", \\"Score\\": \\"87.8\\"}} ]"},{"Context":"Finetuning Pretrained Transformers into RNNs Transformers have outperformed recurrent neural networks (RNNs) in natural language generation. This comes with a significant computational overhead, as the attention mechanism scales with a quadratic complexity in sequence length. Efficient transformer variants have received increasing interest from recent works. Among them, a linear-complexity recurrent variant has proven well suited for autoregressive generation. It approximates the softmax attention with randomized or heuristic feature maps, but can be difficult to train or yield suboptimal accuracy. This work aims to convert a pretrained transformer into its efficient recurrent counterpart, improving the efficiency while retaining the accuracy. Specifically, we propose a swap-then-finetune procedure: in an off-the-shelf pretrained transformer, we replace the softmax attention with its linear-complexity recurrent alternative and then finetune. With a learned feature map, our approach provides an improved tradeoff between efficiency and accuracy over the standard transformer and other recurrent variants. We also show that the finetuning process needs lower training cost than training these recurrent variants from scratch. As many recent models for natural language tasks are increasingly dependent on large-scale pretrained transformers, this work presents a viable approach to improving inference efficiency without repeating the expensive pretraining process.  Table 1: WikiText-103 language modeling results in perplexity. Train time is measured in GPU hours. The top two rows are our reimplementations of Katharopou- los et al. (2020) and Peng et al. (2021). Pretrain in- dicates initialization with a pretrained transformer for language modeling. T2R 75% indicates a model where every fourth layer from the top is kept as the original transformer layer. Perplexity (ppl.) is measured by pre- dicting the last 256 words out of the input of 512 con- secutive words. All models use 128 head dimensions. 470h 104h 98h 512h 97h 95h - 474h dev . ppl . test Table 2: Machine translation test results. The top two rows are our reimplementations of 80h 123h 90h 135h - 120h 82h EN - DE EN - FR WMT17 ZH - EN WMT14 Table 3: Language modeling hyperparameters when randomly initialized in the fairseq library. 4096 1e - 9 1e","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-French\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"42.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2017 Chinese-English\\", \\"Metric\\": \\"BLEU\\", \\"Score\\": \\"23.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-German\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"28.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-103\\", \\"Metric\\": \\"Test perplexity\\", \\"Score\\": \\"19.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-103\\", \\"Metric\\": \\"Validation perplexity\\", \\"Score\\": \\"19\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-French\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"38.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-French\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"34.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-103\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"23.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-103\\", \\"Metric\\": \\"Test perplexity\\", \\"Score\\": \\"29.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-103\\", \\"Metric\\": \\"Validation perplexity\\", \\"Score\\": \\"32.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-103\\", \\"Metric\\": \\"Test perplexity\\", \\"Score\\": \\"32.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-103\\", "},{"Context":"WHEN ARE TWO ALGORITHMS THE SAME? People usually regard algorithms as more abstract than the programs that implement them. The natural way to formalize this idea is that algorithms are equivalence classes of programs with respect to a suitable equivalence relation. We argue that no such equivalence relation exists.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"On Delay Constrained Multicast Capacity of Large-Scale Mobile Ad-Hoc Networks This paper studies the delay constrained multicast capacity of large scale mobile ad hoc networks (MANETs). We consider a MANET consists of ns multicast sessions. Each multicast session has one source and p destinations. The wireless mobiles move according to a two-dimensional i.i.d. mobility model. Each source sends identical information to the p destinations in its multicast session, and the information is required to be delivered to all the p destinations within D time-slots. Given the delay constraint D, we first prove that the capacity per multicast session is O \\" min n 1, (log p)(log (nsp)) q","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Implicit Class-Conditioned Domain Alignment for Unsupervised Domain Adaptation We present an approach for unsupervised domain adaptation-with a strong focus on practical considerations of within-domain class imbalance and between-domain class distribution shift-from a class-conditioned domain alignment perspective. Current methods for class-conditioned domain alignment aim to explicitly minimize a loss function based on pseudo-label estimations of the target domain. However, these methods suffer from pseudo-label bias in the form of error accumulation. We propose a method that removes the need for explicit optimization of model parameters from pseudo-labels directly. Instead, we present a sampling-based implicit alignment approach, where the sample selection procedure is implicitly guided by the pseudo-labels. Theoretical analysis reveals the existence of a domain-discriminator shortcut in misaligned classes, which is addressed by the proposed implicit alignment approach to facilitate domain-adversarial learning. Empirical results and ablation studies confirm the effectiveness of the proposed approach, especially in the presence of within-domain class imbalance and between-domain class distribution shift. We find it ineffective to incorporate prototype-based explicit alignment into MDD Table 1. Per-class average accuracy on Office-Home dataset with RS-UT label shifts (ResNet-50). Pr Avg Rw Cl Table 2. Accuracy (%) on Office-31 (standard) for unsupervised domain adaptation (ResNet-50). We repeated each experiment 5 times with different random seeds and report the average and the standard error of the accuracy. A Avg D W Table 3. Accuracy (%) on Office-Home (standard) for unsupervised domain adaptation (ResNet-50). Rw Pr Cl Ar Pr Avg Ar Cl Ar Pr Ar Cl Pr Ar Pr Rw Rw Pr Cl Ar Rw Cl Rw Rw Cl Table 4. VisDA2017 target accuracy (ResNet-50) acc . ( % ) Table 6. Per-class average accuracy (%) with mismatched prior where the source domain is balanced while the target domain is imbalanced. Table 7. Per-class average accuracy (%) with mismatched prior where the source domain is imbalanced while the target domain is balanced. Table 8. Per-class average accuracy (%) with","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Domain Adaptation\\", \\"Dataset\\": \\"Office-Home (RS-UT imbalance)\\", \\"Metric\\": \\"Average Per-Class Accuracy\\", \\"Score\\": \\"61.67\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Domain Adaptation\\", \\"Dataset\\": \\"Office-Home (RS-UT imbalance)\\", \\"Metric\\": \\"Average Per-Class Accuracy\\", \\"Score\\": \\"58.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Domain Adaptation\\", \\"Dataset\\": \\"Office-Home (RS-UT imbalance)\\", \\"Metric\\": \\"Average Per-Class Accuracy\\", \\"Score\\": \\"56.91\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Domain Adaptation\\", \\"Dataset\\": \\"Office-Home (RS-UT imbalance)\\", \\"Metric\\": \\"Average Per-Class Accuracy\\", \\"Score\\": \\"55.44\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Domain Adaptation\\", \\"Dataset\\": \\"Office-Home (RS-UT imbalance)\\", \\"Metric\\": \\"Average Per-Class Accuracy\\", \\"Score\\": \\"52.81\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Domain Adaptation\\", \\"Dataset\\": \\"Office-Home\\", \\"Metric\\": \\"Avg accuracy\\", \\"Score\\": \\"69.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Domain Adaptation\\", \\"Dataset\\": \\"Office-31\\", \\"Metric\\": \\"Avg accuracy\\", \\"Score\\": \\"88.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Domain Adaptation\\", \\"Dataset\\": \\"VisDA2017\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"75.8\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Domain Adaptation\\", \\"Dataset\\": \\"Office-31\\", \\"Metric\\": \\"Average Accuracy\\", \\"Score\\": \\"89.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Domain Adaptation\\", \\"Dataset\\": \\"Office-Home\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"72.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Domain Adaptation\\", \\"Dataset\\": \\"VisDA2017\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"84.4\\"}} ]"},{"Context":"End-to-end Learning of a Fisher Vector Encoding for Part Features in Fine-grained Recognition Part-based approaches for fine-grained recognition do not show the expected performance gain over global methods, although being able to explicitly focus on small details that are relevant for distinguishing highly similar classes. We assume that part-based methods suffer from a missing representation of local features, which is invariant to the order of parts and can handle a varying number of visible parts appropriately. The order of parts is artificial and often only given by ground-truth annotations, whereas viewpoint variations and occlusions result in parts that are not observable. Therefore, we propose integrating a Fisher vector encoding of part features into convolutional neural networks. The parameters for this encoding are estimated jointly with those of the neural network in an end-to-end manner. Our approach improves state-of-the-art accuracies for bird species classification on CUB-200-2011 from 90.40% to 90.95%, on NA-Birds from 89.20% to 90.30%, and on Birdsnap from 84.30% to 86.97%. We have evaluated our method on widely used datasets for fine-grained bird species categorization since it is the most challenging domain in our opinion For bird species classification, results are slightly below 90 % except for one approach that exceeds this value on one specific dataset In the following, we give a short description of the datasets used in our experiments is the most popular fine-grained dataset for benchmarking Besides the class labels for 200 bird species, the dataset provides additional annotations Table 1. Comparison of our proposed FVE with global average pooling (GAP) re- garding order and visibility of parts. separate estimation of GMM parameters after CNN training [ % ] Method Accuracy ( std ) Table 2. Comparison of our proposed FVE for part features with various state-of-the- art methods (bold = best per dataset). - CUB - 200 - 2011 NA - Birds Birdsnap - Table 3. Computation times for our proposed FVE-Layer. - CUB - 200 - 2011 NA - Birds Birdsnap -","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"CUB-200-2011\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"90.95%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Part Segmentation\\", \\"Dataset\\": \\"ShapeNet-Part\\", \\"Metric\\": \\"Class Average IoU\\", \\"Score\\": \\"84.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Part Segmentation\\", \\"Dataset\\": \\"ShapeNet-Part\\", \\"Metric\\": \\"Instance Average IoU\\", \\"Score\\": \\"85.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Point Cloud Classification\\", \\"Dataset\\": \\"ScanObjectNN\\", \\"Metric\\": \\"Overall Accuracy\\", \\"Score\\": \\"73.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Point Cloud Classification\\", \\"Dataset\\": \\"ModelNet40\\", \\"Metric\\": \\"Overall Accuracy\\", \\"Score\\": \\"92.4\\"}} ]"},{"Context":"A Single Stream Network for Robust and Real-time RGB-D Salient Object Detection Existing RGB-D salient object detection (SOD) approaches concentrate on the cross-modal fusion between the RGB stream and the depth stream. They do not deeply explore the effect of the depth map itself. In this work, we design a single stream network to directly use the depth map to guide early fusion and middle fusion between RGB and depth, which saves the feature encoder of the depth stream and achieves a lightweight and real-time model. We tactfully utilize depth information from two perspectives: (1) Overcoming the incompatibility problem caused by the great difference between modalities, we build a single stream encoder to achieve the early fusion, which can take full advantage of ImageNet pre-trained backbone model to extract rich and discriminative features. (2) We design a novel depth-enhanced dual attention module (DEDA) to efficiently provide the fore-/back-ground branches with the spatially filtered features, which enables the decoder to optimally perform the middle fusion. Besides, we put forward a pyramidally attended feature extraction module (PAFE) to accurately localize the objects of different scales. Extensive experiments demonstrate that the proposed model performs favorably against most state-of-the-art methods under different evaluation metrics. Furthermore, this model is 55.5% lighter than the current lightest model and runs at a real-time speed of 32 FPS when processing a 384 \xd7 384 image. We evaluate the proposed model on six public RGB-D SOD datasets which are NJUD, RGBD135 NLPR, SSD, DUTLF-D and SIP Following most state-ofthe-art methods, we randomly select 1400 samples from the NJUD dataset and 650 samples from the NLPR dataset for training Their remaining images and other three datasets are used for testing We adopt several widely used metrics for quantitative evaluation: precision-recall (PR) curves, F-measure score, mean absolute error (MAE, M), the recently released S-measure (S m ) and E-measure (E m ) scores S-measure: It evaluates the spatial structure similarity by combining the region-aware structural similarity Sr and the object-aware structural similarity S o : where \u03b1 is set to 0.5 Table 1. Quantitative comparison. \u2191 and \u2193 indicate that the larger and smaller scores are better, respectively. Among the CNN-based methods, the best results are shown in red. The subscript in each model name is the publication year. \u03b2 Metric [ 46 ] [ 8 ] Ours [ 16 ] [ 26 ] CDCP17 DF17 [ 25 ] [ 18 ] [ 28 ] \u03b2 CTMF18 PCANet18 MMCI19 TANet19 CPFP19 DANet DMRA19 DANet DES14 DCMC16 [ 51 ] [ 3 ] VGG - 19 Traditional Methods [ 2 ] VGG - 16 [ 4 ] [ 7 ] Table 2. The model sizes and average speed of different methods. \u03b2 Metric [ 46 ] [ 8 ] Ours [ 16 ] [ 26 ] CDCP17 DF17 [ 25 ] [ 18 ] [ 28 ] \u03b2 CTMF18 PCANet18 MMCI19 TANet19 CPFP19 DANet DMRA19 DANet DES14 DCMC16 [ 51 ] [ 3","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"RGB-D Salient Object Detection\\", \\"Dataset\\": \\"NJU2K\\", \\"Metric\\": \\"Average MAE\\", \\"Score\\": \\"0.046\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"RGB-D Salient Object Detection\\", \\"Dataset\\": \\"NJU2K\\", \\"Metric\\": \\"S-Measure\\", \\"Score\\": \\"89.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"RGB-D Salient Object Detection\\", \\"Dataset\\": \\"NJU2K\\", \\"Metric\\": \\"max F-Measure\\", \\"Score\\": \\"90.5\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"RGB-D Salient Object Detection\\", \\"Dataset\\": \\"NJU2K\\", \\"Metric\\": \\"Average MAE\\", \\"Score\\": \\"0.037\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"RGB-D Salient Object Detection\\", \\"Dataset\\": \\"NJU2K\\", \\"Metric\\": \\"S-Measure\\", \\"Score\\": \\"91.1\\"}} ]"},{"Context":"FUZZY FEEDBACK SCHEDULING OF RESOURCE-CONSTRAINED EMBEDDED CONTROL SYSTEMS The quality of control (QoC) of a resource-constrained embedded control system maybe jeopardized in dynamic environments with variable workload. This gives rise to the increasing demand of co-design of control and scheduling. To deal with uncertainties in resource availability, a fuzzy feedback scheduling (FFS) scheme is proposed in this paper. Within the framework of feedback scheduling, the sampling periods of control loops are dynamically adjusted using the fuzzy control technique. The feedback scheduler provides QoC guarantees in dynamic environments through maintaining the CPU utilization at a desired level. The framework and design methodology of the proposed FFS scheme are described in detail. A simplified mobile robot target tracking system is investigated as a case study to demonstrate the effectiveness of the proposed FFS scheme. The scheme is independent of task execution times, robust to measurement noises, and easy to implement, while incurring only a small overhead. To evaluate the performance of the proposed FFS scheme, this section conducts simulations for the case study system described in Section 4 Table 2. Look-up table for fuzzy feedback scheduler. - 1 \u03b7 ec - 1 Table 3. The nominal period for each control task is 3, 4 and 5 ms, respectively, where the period of non-control task 3 (i.e., h 3 ) is fixed. The maximum allowable sampling periods of two control loops are h max = 7 ms. 1 - 2 3 - 4 0 - 1 2 - 3 Table 3. Average execution times of the tasks. 1 - 2 3 - 4 0 - 1 2 - 3","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Intrusion-aware Alert Validation Algorithm for Cooperative Distributed Intrusion Detection Schemes of Wireless Sensor Networks Existing anomaly and intrusion detection schemes of wireless sensor networks have mainly focused on the detection of intrusions. Once the intrusion is detected, an alerts or claims will be generated. However, any unidentified malicious nodes in the network could send faulty anomaly and intrusion claims about the legitimate nodes to the other nodes. Verifying the validity of such claims is a critical and challenging issue that is not considered in the existing cooperative-based distributed anomaly and intrusion detection schemes of wireless sensor networks. In this paper, we propose a validation algorithm that addresses this problem. This algorithm utilizes the concept of intrusion-aware reliability that helps to provide adequate reliability at a modest communication cost. In this paper, we also provide a security resiliency analysis of the proposed intrusion-aware alert validation algorithm.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"\xc5 \xd1\xd3\xd6\xdd \xd2\xd8 \xd7 \xd9\xd0 \xd2 \xd3 \xcb\xd8\xd6 \xd7\xd7 \xd2\xb9\xcf \xd2\xd3 \xd6 \xb3\xd7 \xd1 \xd8\xd6 \xdc \xd1\xd9\xd0\xd8 \xd4\xd0 \xd8 \xd3\xd2 \xd0 \xd3\xd6 \xd8 \xd1 * \xd7\xd8\xd6 \xd8 \xcf \xd4\xd6\xd3\xd4\xd3\xd7 \xd7 \xda \xd6 \xd0 \xd2 \xdb \xd7 \xd9\xd0 \xd7 \xd3\xd6 \xcb\xd8\xd6 \xd7\xd7 \xd2\xb9\xcf \xd2\xd3 \xd6 \xb3\xd7 \xd1 \xd8\xd6 \xdc \xd1\xd9\xd0\xb9 \xd8 \xd4\xd0 \xd8 \xd3\xd2 \xd0 \xd3\xd6 \xd8 \xd1\xb8\xd8 \xdd \xd6 \xd9 \xd8 \xdc\xd8\xd6 \xd1 \xd1\xd3\xd6\xdd \xd0\xd0\xd3 \xd8 \xd3\xd2 \xd6 \xd5\xd9 \xd6 \xb9 \xd1 \xd2\xd8\xd7 \xdd \xd8 \xd6 \xd6 \xd2\xd8 \xd1 \xd2\xd7 \xdd \xd2\xd8\xd6\xd3 \xd9 \xd2 \xdb \xd4\xd6 \xb9 \xd8 \xd3\xd2\xd7\xb8 \xdd \xd3\xda \xd6\xdb\xd6 \xd8 \xd2 \xd8 \xd2\xd4\xd9\xd8 \xd1 \xd8\xd6 \xd7\xb8\xd3\xd6 \xdd \xd9\xd7 \xd2 \xd6\xd7\xd8 \xd6 \xd9\xd6\xd7 \xda \xd0 \xda \xd0 \xd3 \xd0 \xd7\xb9 \xd7 \xd0 \xd1\xd9\xd0\xd8 \xd4\xd0 \xd8 \xd3\xd2\xba \xc1\xd2 \xd4 \xd6\xd8 \xd9\xd0 \xd6\xb8\xdb \xd7 \xd3\xdb \xd8\xdb\xd3 \xd9\xd0\xd0\xdd \xd2\xb9\xd4\xd0 \xd7 \xd9\xd0 \xd7 \xd3\xd2 \xda \xd2 \xd8 \xd7 \xd1 \xd2\xd9\xd1 \xd6 \xd3 \xd3\xd4 \xd6 \xd8 \xd3\xd2\xd7\xb8 \xd8 \xd2\xd4\xd9\xd8 \xd1 \xd8\xd6 \xd7 \xd2 \xd3\xda \xd6\xdb\xd6 \xd8\xd8 \xd2 \xd8 \xd3\xd8 \xd6 \xd3\xd2 \xb8\xd7\xd0 \xd8\xd0\xdd \xd2\xd6 \xd7 \xd2 \xd8 \xd3\xd2\xd7\xd8 \xd2\xd8 \xd3 \xd8 \xd0 \xd2 \xd8 \xd6\xd1 \xd3 \xd8 \xd3\xd1\xd4\xd0 \xdc \xd8\xdd\xb8 \xd8 \xd2\xd4\xd9\xd8 \xd1 \xd8\xd6 \xd7 \xd6 \xd6 \xb9\xd3\xd2\xd0\xdd\xba \xc5 \xd2\xdd \xd3 \xd8 \xd7 \xd7 \xd9\xd0 \xd7 \xda \xd2 \xd3\xd9\xd2 \xdd \xd2 \xd1\xd4\xd0 \xd1 \xd2\xd8 \xd8 \xd3\xd2 \xd3 \xd2 \xdc \xd9\xd7\xd8 \xda \xd7 \xd6 \xd0 \xd3\xd6 \xd8 \xd1 \xd7 \xd3\xd2 \xd4 \xd0 \xd1 \xba \xc3 \xdd\xdb\xd3\xd6 \xd7 \xc5 \xd8\xd6 \xdc \xd1\xd9\xd0\xd8 \xd4\xd0 \xd8 \xd3\xd2\xb8\xcb\xd8\xd6 \xd7\xd7 \xd2\xb9\xcf \xd2\xd3 \xd6 \xb3\xd7 \xd0 \xd3\xd6 \xd8 \xd1\xb8\xc5 \xd1\xd3\xd6\xdd \xd4\xd0 \xd1 \xd2\xd8\xba \xbd \xc1\xd2\xd8\xd6\xd3 \xd9\xd8 \xd3\xd2 \xcb\xd8\xd6 \xd7\xd7 \xd2\xb3\xd7 \xd0 \xd3\xd6 \xd8 \xd1 \xbd \u2104 \xdb \xd7 \xd8 \xd6\xd7\xd8 \xd7\xd9 \xb9\xd9 \xd0 \xd3\xd6 \xd8 \xd1 \xd3\xd6 \xd1 \xd8\xd6 \xdc \xd1\xd9\xd0\xd8 \xd4\xd0 \xb9 \xd8 \xd3\xd2\xba \xc1\xd8\xd7 \xd1\xd4\xd6\xd3\xda \xd1 \xd2\xd8 \xdd \xcf \xd2\xd3 \xd6 \xbd \u2104 \xd0 \xd8\xd3 \xd0\xdd \xd4\xd6 \xd8 \xd0 \xd0 \xd3\xd6 \xd8 \xd1\xba * \xc5\xb8\xbe\xbc\xbc \xba \xcc \xd7 \xd7 \xd8 \xd9\xd8 \xd3\xd6\xb3\xd7 \xda \xd6\xd7 \xd3\xd2 \xd3 \xd8 \xdb\xd3\xd6 \xba \xc1\xd8 \xd7 \xd4\xd3\xd7\xd8 \xd6 \xdd \xd4 \xd6\xd1 \xd7\xd7 \xd3\xd2 \xd3 \xc5 \xd3\xd6 \xdd\xd3\xd9\xd6 \xd4 \xd6\xd7\xd3\xd2 \xd0 \xd9\xd7 \xba AE\xd3\xd8 \xd3\xd6 \xd6 \xd7\xd8\xd6 \xd9\xd8 \xd3\xd2\xba \xcc \xd2 \xd8 \xda \xda \xd6\xd7 \xd3\xd2 \xdb \xd7 \xd4\xd9 \xd0 \xd7 \xd2 \xc1\xcb\xcb \xbe\xbc\xbc \xba \u2020 \xc4 \xd3\xd6 \xd8\xd3 \xd6 \xc2\xba \xc3\xd9\xd2\xd8\xde\xd1 \xd2\xd2\xb8\xcd\xd2 \xda \xd6\xd7 \xd8 \xd6 \xd2\xd3 \xd0 \xba \xbd\xb8\xd6\xd9 \xd7 \xc5 \xd8 \xd1 \xd8 \xd5\xd9 \xd7\xb8\xd9\xd1\xd6 AE\xca\xcb \xbe\xbe \xb8 \xd4 \xbf \xb8 \xbf \xbc \xbd \xd6 \xd2\xd3 \xd0 \xb8 \xd6 \xd2 \xb8 \xd4\xd6\xd3\xd8 \xd8 \xcc\xbd \xd8 \xdc\xd8 \xd6 \xd0 \xd8 \xd6 \xba \xd3\xdd \xd6\xb8\xc2 \xd2\xb9 \xd9 \xd0\xd0 \xd9\xd1 \xba \xd9\xd1 \xd7 \xd4\xd6\xd3\xd8 \xd8 \xcc\xbd \xd8 \xdc\xd8 \xd6 \xd6 \xd8 \xd1 \xba \xd6 \u2021 \xc4 \xd3\xd6 \xd8\xd3 \xd6 \xc4\xc1 \xb8\xcd\xd2 \xda \xd6\xd7 \xd8 \xd6 \xd2\xd3 \xd0 \xba \xd9\xd1\xd6 AE\xca\xcb\xb8 \xbf \xbf\xbf\xbc \xc5\xd3\xd2\xd8 \xd3\xd2\xd2\xd3\xd8\xb8 \xd6 \xd2 \xba \xd0 \xd1 \xd2\xd8\xba\xc8 \xd6\xd2 \xd8 \xd1 \xba \xd6 \xa7 \xcb \xd3\xd3\xd0 \xd3 \xd3\xd1\xd4\xd9\xd8 \xd6 \xcb \xd2 \xb8\xcd\xd2 \xda \xd6\xd7 \xd8\xdd \xd3 \xcf \xd8 \xd6\xd0\xd3\xd3\xb8\xcf \xd8 \xd6\xd0\xd3\xd3\xb8\xc7AE\xb8AE\xbe \xbf \xbd\xb8 \xd2 \xba \xdb\xbe\xde \xd3\xd9\xd9\xdb \xd8 \xd6\xd0\xd3\xd3\xba \xbd","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Direct Output Connection fora High-Rank Language Model This paper proposes a state-of-the-art recurrent neural network (RNN) language model that combines probability distributions computed not only from a final RNN layer but also from middle layers. Our proposed method raises the expressive power of a language model based on the matrix factorization interpretation of language modeling introduced by Yang et al. (2018). The proposed method improves the current state-of-the-art language model and achieves the best score on the Penn Treebank and WikiText-2, which are the standard benchmark datasets. Moreover, we indicate our proposed method contributes to two application tasks: machine translation and headline generation. Our code is publicly available at: https://github.com/nttcslabnlp/doc lm. Moreover, we evaluate various combinations of layers to explore which combination achieves the best score We used the Penn Treebank (PTB) and WikiText-2 datasets, which are the standard benchmark datasets for the word-level language modeling task and respectively published preprocessed PTB 3 and WikiText-2 4 datasets We used these preprocessed datasets for fair comparisons with previous studies To investigate the effect of DOC on an encoder-decoder model, we incorporate DOC into the decoder and examine its performance We used the Wall Street Journal of the Penn Treebank dataset We applied the preprocessing codes of Choe and Charniak (2016) 12 to the dataset and converted a token that appears fewer than ten times in the training dataset into a special token unk To investigate the effectiveness of DOC, we evaluate our language models following their configurations Table 1: Statistics of PTB and WikiText-2. 12 650 960 WikiText - 2 300 620 15 60 280 1150 20 PTB Table 3: Perplexities of AWD-LSTM with DOC on the PTB dataset. We varied the number of probability dis- tributions from each layer in situation J = 20 except for the top row. The top row ( \u2020) represents MoS scores reported in Yang et al. (2018) as a baseline. \u2021 represents the perplexity obtained by the implementation of Yang et al. (2018) 6 with identical hyperparameters except for i 3 . \u03b2 #DOC Valid Test i0 i1 i2 \u03bb Table 4: Coefficient of variation of Equation 10: \u221a \u03b2 in validation and test sets of PTB. \u03b2 Valid Test \u03bb Table 5: Rank of output matrix (\xc3 in Equation 9) on the PTB dataset. D 3 of AWD-LSTM is 400. 60 AWD - LSTM - DOC Valid Test Model 10000","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-2\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"185M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-2\\", \\"Metric\\": \\"Test perplexity\\", \\"Score\\": \\"53.09\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-2\\", \\"Metric\\": \\"Validation perplexity\\", \\"Score\\": \\"54.19\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-2\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"37M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-2\\", \\"Metric\\": \\"Test perplexity\\", \\"Score\\": \\"58.03\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-2\\", \\"Metric\\": \\"Validation perplexity\\", \\"Score\\": \\"60.29\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"Penn Treebank (Word Level)\\", \\"Metric\\": \\"Params\\", \\"Score\\": \\"185M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"Penn Treebank (Word Level)\\", \\"Metric\\": \\"Test perplexity\\", \\"Score\\": \\"47.17\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"Penn Treebank (Word Level)\\", \\"Metric\\": \\"Validation perplexity\\", \\"Score\\": \\"48.63\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"Penn Treebank (Word Level)\\", \\"Metric\\": \\"Params\\", \\"Score\\": \\"23M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"Penn Treebank (Word Level)\\", \\"Metric\\": \\"Test perplexity\\", \\"Score\\": \\"52.38\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"Penn Treebank (Word Level)\\", \\"Metric\\": \\"Validation perplexity\\", \\"Score\\": \\"54.12\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Constituency Parsing\\", \\"Dataset\\": \\"Penn Treebank\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"94.47\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-2\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"33M\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-2\\", \\"Metric\\": \\"Test perplexity\\", \\"Score\\": \\"43.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-2\\", \\"Metric\\": \\"Validation perplexity\\", \\"Score\\": \\"41.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-2\\", \\"Metric\\": \\"Test perplexity\\", \\"Score\\": \\"61.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-2\\", \\"Metric\\": \\"Validation perplexity\\", \\"Score\\": \\"64.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-2\\", \\"Metric\\": \\"Test perplexity\\", \\"Score\\": \\"61.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-2\\", \'Met"},{"Context":"Why Systems-on-Chip Needs More UML like a Hole in the Head Let\'s be clear from the outset: SoC can most certainly make use of UML; SoC just doesn\'t need more UML, or even all of it. The advent of model mappings, coupled with marks that indicate which mapping rule to apply, enable a major simplification of the use of UML in SoC.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Howl: A Deployed, Open-Source Wake Word Detection System We describe Howl, an open-source wake word detection toolkit with native support for open speech datasets, like Mozilla Common Voice and Google Speech Commands. We report benchmark results on Speech Commands and our own freely available wake word detection dataset, built from MCV. We operationalize our system for Firefox Voice, a plugin enabling speech interactivity for the Firefox web browser. Howl represents, to the best of our knowledge, the first fully productionized yet open-source wake word detection toolkit with a web browser deployment target. Our codebase is at https://github.com/ castorini/howl.  Table 1: Model accuracy on Google Speech Com- mands. Bolded denotes the best and # par. the number of parameters. 202K 94 . 3 / 94 . 5 128K 96 . 8 / 97 . 1 478K 107K 97 . 0 / 97 . 8 111K 250K Dev / Test # Par . 110K","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Keyword Spotting\\", \\"Dataset\\": \\"Google Speech Commands\\", \\"Metric\\": \\"Google Speech Commands V1 12\\", \\"Score\\": \\"97.8\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Keyword Spotting\\", \\"Dataset\\": \\"Google Speech Commands\\", \\"Metric\\": \\"Google Speech Commands V2 12\\", \\"Score\\": \\"95.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Keyword Spotting\\", \\"Dataset\\": \\"Google Speech Commands\\", \\"Metric\\": \\"Google Speech Commands V2 12\\", \\"Score\\": \\"97.7\\"}} ]"},{"Context":"Orthogonal Relation Transforms with Graph Context Modeling for Knowledge Graph Embedding Distance-based knowledge graph embeddings have shown substantial improvement on the knowledge graph link prediction task, from TransE to the latest state-of-the-art RotatE. However, complex relations such as N-to-1, 1to-N and N-to-N still remain challenging to predict. In this work, we propose a novel distance-based approach for knowledge graph link prediction. First we extend the RotatE from 2D complex domain to high dimensional space with orthogonal transforms to model relations. The orthogonal transform embedding for relations keeps the capability for modeling symmetric/anti-symmetric, inverse and compositional relations while achieves better modeling capacity. Second, the graph context is integrated into distance scoring functions directly. Specifically, graph context is explicitly modeled via two directed context representations. Each node embedding in knowledge graph is augmented with two context representations, which are computed from the neighboring outgoing and incoming nodes/edges respectively. The proposed approach improves prediction accuracy on the difficult N-to-1, 1to-N and N-to-N cases. Our experimental results show that it achieves state-of-the-art results on two common benchmarks FB15k-237 and WNRR-18, especially on FB15k-237 which has many high in-degree nodes. Following the evaluation protocol in, each test triple (h, r, t) is measured under two scenarios: head focused (?, r, t) and tail focused (h, r, ?) Those true triples observed in either train/validation/test set except the test triple will be excluded during evaluation Specially, for FB15k-237, we set embedding dimension d = 400, sub-embedding dimension d s = 20, and the learning rates to 2e-3 and 2e-4 for pre-training and fine-tuning stages respectively; for WN18RR dataset, we set d = 400, d s = 4, and the learning rates to 1e-4 and 3e-5 for pre-training and fine-tuning stages Table 1: Statistics of datasets. test leakage due to redundant inverse relation . Two commonly used benchmark datasets ( FB15k - 4 14 , 541 FB15k - 237 WN18RR WN18 consists of 18 relations and However , many text triples ob - Experiments Table 2: Link prediction for FB15k-237 and WN18RR on test sets. Model FB15k - 237 H10 WN18RR H1 H3 MRR - Table 3: Ablation study on FB15k-237 validation set. #param MRR @10 Table 4: H@10 from FB15-237 validation set by cate- gories (1-to-N, N-to-1 and N-to-N). RotatE - L GC - OTE A T H","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.442\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.583\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.511\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"MR\\", \\"Score\\": \\"2715\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.491\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.267\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.550\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.396\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"MR\\", \\"Score\\": \\"154\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.361\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.490\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.581\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.495\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.481\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.261\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.579\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.319\\"}}, { \\"LEADERBOARD\\": { \'Ta"},{"Context":"Estimating individual treatment effect: generalization bounds and algorithms There is intense interest in applying machine learning to problems of causal inference in fields such as healthcare, economics and education. In particular, individual-level causal inference has important applications such as precision medicine. We give anew theoretical analysis and family of algorithms for predicting individual treatment effect (ITE) from observational data, under the assumption known as strong ignorability. The algorithms learn a \\"balanced\\" representation such that the induced treated and control distributions look similar. We give a novel, simple and intuitive generalization-error bound showing that the expected ITE estimation error of a representation is bounded by a sum of the standard generalization-error of that representation and the distance between the treated and control distributions induced by the representation. We use Integral Probability Metrics to measure distances between distributions, deriving explicit bounds for the Wasserstein and Maximum Mean Discrepancy (MMD) distances. Experiments on real and simulated data show the new algorithms match or outperform the state-of-the-art. One is by using synthetic or semi-synthetic datasets, where the outcome or treatment assignment are fully known; we use the semi-synthetic IHDP dataset from We partially overcome this problem by using the Jobs dataset from LaLonde (1986), which includes both a randomized and a non-randomized component We use both for training, but can only use the randomized component for evaluation This alleviates, but does not solve, the issue of a completely balanced dataset being unsuited for our method We evaluate our framework CFR, and its variant without Algorithm 1 CFR: Counterfactual regression with integral probability metrics 1: Input: Factual sample (x 1 , t 1 , y 1 ), We evaluate our model in two different settings On the Jobs dataset, we use the policy risk on the validation set Table 1. Results on IHDP (left) and Jobs (right). MMD is squared linear MMD. Lower is better. Within-sample IHDP JOBS \u221a Random policy of Out - of - sample Treatment inclusion rate CFR ATT ATE JOBS CFR MMD PEHE Causal Forests IHDP risk \u221a RPOL BART","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Causal Inference\\", \\"Dataset\\": \\"IDHP\\", \\"Metric\\": \\"Average Treatment Effect Error\\", \\"Score\\": \\"0.27\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Causal Inference\\", \\"Dataset\\": \\"IDHP\\", \\"Metric\\": \\"Average Treatment Effect Error\\", \\"Score\\": \\"0.28\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Causal Inference\\", \\"Dataset\\": \\"IDHP\\", \\"Metric\\": \\"Average Treatment Effect Error\\", \\"Score\\": \\"0.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Causal Inference\\", \\"Dataset\\": \\"IDHP\\", \\"Metric\\": \\"Average Treatment Effect Error\\", \\"Score\\": \\"0.42\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Causal Inference\\", \\"Dataset\\": \\"IDHP\\", \\"Metric\\": \\"Average Treatment Effect Error\\", \\"Score\\": \\"0.79\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Causal Inference\\", \\"Dataset\\": \\"IDHP\\", \\"Metric\\": \\"Average Treatment Effect Error\\", \\"Score\\": \\"0.93\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Causal Inference\\", \\"Dataset\\": \\"IDHP\\", \\"Metric\\": \\"Average Treatment Effect Error\\", \\"Score\\": \\"0.96\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-day Continuous Classification\\", \\"Dataset\\": \\"USHCN-Daily\\", \\"Metric\\": \\"MSE (10-2, 50% missing)\\", \\"Score\\": \\"0.748\\"}} ]"},{"Context":"Enhanced Residual Networks for Context-based Image Outpainting Although humans perform well at predicting what exists beyond the boundaries of an image, deep models struggle to understand context and extrapolation through retained information. This task is known as image outpainting and involves generating realistic expansions of an images boundaries. Current models use generative adversarial networks to generate results which lack localized image feature consistency and appear fake. We propose two methods to improve this issue: the use of a local and global discriminator, and the addition of residual blocks within the encoding section of the network. Comparisons of our model and the baselines L1 loss, mean squared error (MSE) loss, and qualitative differences reveal our model is able to naturally extend object boundaries and produce more internally consistent images compared to current methods but produces lower fidelity images. 2 To evaluate the effectiveness of our model we compare MSE and L1 loss between each of our models We use MIT CSAIL Places365-Standard, a large scale scene dataset used to train models for image context and recognition This dataset contains around 2 million images, combined, of random scenes from outdoor and indoor scenery, including both simple landscapes and detailed, object-heavy images We use this dataset as our primary method of evaluation because of its usage in Van Hoorick Unfortunately, due to computing time constraints, training on the whole of the dataset was deemed implausible, therefore we drastically reduced the size of the training set to approximately 25,000 images and trained for 50 epochs During this process, we kept images which were chosen randomly from the full dataset, a process which adds some inherent weaknesses to the training of our model To address the weakness which training on a subset of the Table 1. Architecture of generator G, including parameters. Trans-Conv is transposed convolution. Table 4. Comparison of all loss results across each of the models. Adversarial L1 MSE","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Outpainting\\", \\"Dataset\\": \\"Places365-Standard\\", \\"Metric\\": \\"Adversarial\\", \\"Score\\": \\"0.0941\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Outpainting\\", \\"Dataset\\": \\"Places365-Standard\\", \\"Metric\\": \\"L1\\", \\"Score\\": \\"0.08\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Outpainting\\", \\"Dataset\\": \\"Places365-Standard\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.7814\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Outpaining\\", \\"Dataset\\": \\"Places365-Standard\\", \\"Metric\\": \\"L1\\", \\"Score\\": \\"0.0791\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Outpaining\\", \\"Dataset\\": \\"Places365-Standard\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.023\\"}} ]"},{"Context":"Divide-and-conquer based Large-Scale Spectral Clustering Spectral clustering is one of the most popular clustering methods. However, how to balance the efficiency and effectiveness of the large-scale spectral clustering with limited computing resources has not been properly solved fora longtime. In this paper, we propose a divide-and-conquer based largescale spectral clustering method to strike a good balance between efficiency and effectiveness. In the proposed method, a divide-and-conquer based landmark selection algorithm and a novel approximate similarity matrix approach are designed to construct a sparse similarity matrix within low computational complexities. Then clustering results can be computed quickly through a bipartite graph partition process. The proposed method achieves the lower computational complexity than most existing large-scale spectral clustering methods. Experimental results on ten large-scale datasets have demonstrated the efficiency and effectiveness of the proposed methods. The MATLAB code of the proposed method and experimental datasets are available at https://github.com/Li-Hongmin/MyPaperWithCode. In this section, we conduct experiments on five real and five synthetic datasets to evaluate the performance of the proposed DnC-SC methods Our experiments are conducted on eight large-scale datasets, varying from nine thousand to as large as twenty million data shows the synthetic datasets The properties of the datasets are summarized in We adopt two widely used evaluation metrics, i.e., Normalized Mutual Information (NMI) and Accuracy (ACC), to evaluate the clustering results.., ] be the data matrix In the experiments, = 200 is used for the datasets whose size is less than 100,000, otherwise = 50 Table 2 Properties of the real and synthetic datasets. 7 2 3 #Dimension #Class Table 3 Clustering performance (ACC% \xb1 std) for large-scale spectral clustering methods Clustering performance ( NMI% \xb1 std ) for large - scale spectral clustering methods Clustering performance ( ACC% \xb1 std ) for large - scale spectral clustering methods SC LSC - R KM DnC - SC Nystr\xf6m LSC - RH U - SPEC Table 3 LSC - K LSC - KH Table 4 Clustering performance (NMI% \xb1 std) for large-scale spectral clustering methods Clustering performance ( NMI% \xb1 std ) for large - scale spectral clustering methods Clustering performance ( ACC% \xb1 std ) for large - scale spectral clustering methods SC LSC - R KM DnC - SC Nystr\xf6m LSC - RH U - SPEC Table 3 LSC - K LSC - KH Table 5 Time costs(s) of large-scale spectral clustering methods. SC LSC","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image/Document Clustering\\", \\"Dataset\\": \\"pendigits\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"81.55\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image/Document Clustering\\", \\"Dataset\\": \\"pendigits\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"79.15\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image/Document Clustering\\", \\"Dataset\\": \\"pendigits\\", \\"Metric\\": \\"runtime (s)\\", \\"Score\\": \\"0.77\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image/Document Clustering\\", \\"Dataset\\": \\"pendigits\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"74.02\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image/Document Clustering\\", \\"Dataset\\": \\"pendigits\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"81.37\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image/Document Clustering\\", \\"Dataset\\": \\"pendigits\\", \\"Metric\\": \\"runtime (s)\\", \\"Score\\": \\"1.20\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image/Document Clustering\\", \\"Dataset\\": \\"pendigits\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"81.68\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image/Document Clustering\\", \\"Dataset\\": \\"pendigits\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"81.68\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image/Document Clustering\\", \\"Dataset\\": \\"pendigits\\", \\"Metric\\": \\"runtime (s)\\", \\"Score\\": \\"2.07\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"Den-full\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.965\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"Den-full\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"0.638\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"Darmstadt Noise Dataset\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.951\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"Darmstadt Noise Dataset\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"0.942\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"FRGC\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.972\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"FRGC\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"0.882\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"Darmstadt Noise Dataset\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.929\\"}}, { \\"LEADERBOARD\\": { \'Task\'"},{"Context":"Bottom-up rewriting for words and terms For the whole class of linear term rewriting systems, we define bottom-up rewriting which is a restriction of the usual notion of rewriting. We show that bottom-up rewriting effectively inverse-preserves recognizability and analyze the complexity of the underlying construction. The Bottom-Up class (BU) is, by definition, the set of linear systems for which every derivation can be replaced by a bottom-up derivation. Membership to BU turns out to be undecidable, we are thus lead to define more restricted classes: the classes SBU(k), k \u2208 N of Strongly Bottom-Up(k) systems for which we show that membership is decidable. We define the class of Strongly Bottom-Up systems by SBU = k\u2208N SBU(k). We give a polynomial sufficient condition fora system to be in SBU. The class SBU contains (strictly) several classes of systems which were already known to inverse preserve recognizability: the inverse left-basic semi-Thue systems (viewed as unary term rewriting systems), the linear growing term rewriting systems, the inverse Linear-Finite-Path-Ordering systems. new decidable call-by-need [12] class, decidability results for confluence, accessibility, joinability. Also, recently, this notion has been used to prove termination of systems for which none of the already known termination techniques work [18]. Such a preservation property is also a tool for studying the recognizable/rational subsets of various monoids which are defined by a presentation X, R , where X is a finite alphabet and Ra Thue system (see for example [25,26]). Consequently, the seek of new decidable classes of systems which preserve (or inverse preserve) recognizability is worthwile.Many such classes defined so far have been defined by imposing syntactical restrictions on the rewrite rules. For instance, in growing systems ([21, 27]) variables at depth strictly greater than 1 in the left-handside of a rule cannot appear in the corresponding right-handside. Finite-path Overlapping systems [35] are also defined by syntactic restrictions on the system. The class of Finite-path Overlapping systems contains the class of growing systems [27]. Previous works on semi-Thue systems also prove recognizability preservation, under syntactic restrictions: cancellation systems [2], monadic systems [4], basic systems [1], and left-basic systems [30] (see [32] fora survey).Other works establish that some strategies i.e. restrictions on the derivations rather than on the rules, ensure preservation of recognizability. Various such strategies were studied in [16], [29], [33].We rather follow here this second approach: we define anew rewriting strategy which we call bottom-up rewriting for linear term rewriting systems. The bottom-up derivations are, intuitively, those derivations in which the rules are applied, roughly speaking, from the bottom of the term towards the top (this set of derivations contains strictly the bottom-up derivations of [29] and the one-pass leaf-started derivations of [16]). An important feature of this strategy, as opposed to the ones quoted above, is that it allows overlaps between successive applications of rules. A class of systems is naturally associated with this strategy: it consists of the systems R for which the binary relation \u2192 * R coincides with its restriction to the bottom-up strategy. We call \\"bottom-up\\" such systems and denote by BU the set of all bottom-up systems.Overview of the paper. Most of the results proved in this paper were announced in [13], which can thus be considered as a medium-scale overview of this paper. Let us give here a large-scale overview, section by section, of the contents of the paper. the subject of tree-automata and to [22] for term rewriting.2.1. Sets, binary relations Abstract rewriting. Given a set E, we denote by P(E) its powerset i.e.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Voice-controlled Debugging of Spreadsheets Voice-controlled Debugging of Spreadsheets Computing are putting pressure on the software industry to research new modes of interaction that do not rely on the traditional keyboard and mouse combination. Computer users suffering from Repetitive Strain Injury also seek an alternative to keyboard and mouse devices to reduce suffering in wrist and finger joints. Voice-control is an alternative approach to spreadsheet development and debugging that has been researched and used successfully in other domains. While voice-control technology for spreadsheets is available its effectiveness has not been investigated. This study is the first to compare the performance of a set of expert spreadsheet developers that debugged a spreadsheet using voice-control technology and another set that debugged the same spreadsheet using keyboard and mouse. The study showed that voice, despite its advantages, proved to be slower and less accurate. However, it also revealed ways in which the technology might be improved to redress this imbalance.  Table 4: Average time to enter numbers in seconds Group","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"STOCHASTIC VARIATIONAL VIDEO PREDICTION Predicting the future in real-world settings, particularly from raw sensory observations such as images, is exceptionally challenging. Real-world events can be stochastic and unpredictable, and the high dimensionality and complexity of natural images require the predictive model to build an intricate understanding of the natural world. Many existing methods tackle this problem by making simplifying assumptions about the environment. One common assumption is that the outcome is deterministic and there is only one plausible future. This can lead to low-quality predictions in real-world settings with stochastic dynamics. In this paper, we develop a stochastic variational video prediction (SV2P) method that predicts a different possible future for each sample of its latent variables. To the best of our knowledge, our model is the first to provide effective stochastic multi-frame prediction for real-world videos. We demonstrate the capability of the proposed method in predicting detailed future frames of videos on multiple real-world datasets, both action-free and action-conditioned. We find that our proposed method produces substantially improved video predictions when compared to the same model without stochasticity, and to other stochastic video prediction methods. Our SV2P implementation will be open sourced upon publication. To highlight the importance of stochasticity in video prediction, we created a toy video dataset with intentionally stochastic motion Each video in this dataset is four frames long To evaluate SV2P, we test it on three real-world video datasets by comparing it to the CDNA model, as a deterministic baseline, as well as a baseline that outputs the last seen frame as the prediction We quantitatively and qualitatively evaluate SV2P on following real-world datasets: \u2022 BAIR robot pushing dataset: This dataset contains action-conditioned videos collected by a Sawyer robotic arm pushing a variety of objects All of the videos in this datasets have similar tabletop settings with static background An interesting property of this dataset is the fact that the arm movements are quite unpredictable in the absence of actions (compared to the robot pushing dataset which the arm moves to the center of the bin) For this dataset, we train Table 1: Hyper-parameters used for experiments. Inference Network 50000 Optimization model type Generative Network ADAM 200000 # of masks 16 batch size CDNA # of iterations 10","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Video Generation\\", \\"Dataset\\": \\"BAIR Robot Pushing\\", \\"Metric\\": \\"FVD score\\", \\"Score\\": \\"262.5\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Video Generation\\", \\"Dataset\\": \\"BAIR Robot Pushing\\", \\"Metric\\": \\"FVD score\\", \\"Score\\": \\"90.9\\"}} ]"},{"Context":"Unprocessing Images for Learned Raw Denoising Machine learning techniques work best when the data used for training resembles the data used for evaluation. This holds true for learned single-image denoising algorithms, which are applied to real raw camera sensor readings but, due to practical constraints, are often trained on synthetic image data. Though it is understood that generalizing from synthetic to real images requires careful consideration of the noise properties of camera sensors, the other aspects of an image processing pipeline (such as gain, color correction, and tone mapping) are often overlooked, despite their significant effect on how raw measurements are transformed into finished images. To address this, we present a technique to \\"unprocess\\" images by inverting each step of an image processing pipeline, thereby allowing us to synthesize realistic raw sensor measurements from commonly available Internet photos. We additionally model the relevant components of an image processing pipeline when evaluating our loss function, which allows training to be aware of all relevant photometric processing that will occur after denoising. By unprocessing and processing training data and model outputs in this way, we are able to train a simple convolutional neural network that has 14%-38% lower error rates and is 9\xd7-18\xd7 faster than the previous state of the art on the Darmstadt Noise Dataset [30], and generalizes to sensors outside of that dataset as well.  Table 1. Performance of our model and its ablations on the Darmstadt Noise Dataset Ablations of \\" Our Model ( sRGB ) \\" ( 62 . 5% ) ( 28 . 5% ) ( 52 . 5% ) ( 51 . 5% ) ( 0 . 0% ) ( 29 . 7% ) Raw ( 59 . 1% ) ( 67 . 9% ) ( 0 . 3% ) ( 41 . 7% ) ( 39 . 9% ) ( 49 . 0% ) PSNR SSIM ( 49 . 2% ) ( 53 . 2% ) ( 9 . 8% ) ( 4 . 8% ) ( 18 . 6% ) sRGB ( 49 . 6% ) ( 44 . 2% ) ( 38 . 0% ) ( 31 . 2% )","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Color Image Denoising\\", \\"Dataset\\": \\"Darmstadt Noise Dataset\\", \\"Metric\\": \\"PSNR (Raw)\\", \\"Score\\": \\"48.88\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Color Image Denoising\\", \\"Dataset\\": \\"Darmstadt Noise Dataset\\", \\"Metric\\": \\"PSNR (sRGB)\\", \\"Score\\": \\"40.35\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Color Image Denoising\\", \\"Dataset\\": \\"Darmstadt Noise Dataset\\", \\"Metric\\": \\"SSIM (Raw)\\", \\"Score\\": \\"0.9821\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Color Image Denoising\\", \\"Dataset\\": \\"Darmstadt Noise Dataset\\", \\"Metric\\": \\"SSIM (sRGB)\\", \\"Score\\": \\"0.9641\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Denoising\\", \\"Dataset\\": \\"SIDD\\", \\"Metric\\": \\"PSNR (sRGB)\\", \\"Score\\": \\"38.49\\"}} ]"},{"Context":"This paper proposes a novel remote user authentication scheme using smart cards which allows both the authentication server (AS) and the user to verify each other\'s authenticity. Our scheme is efficient enough to resist the known attacks that could be launched against remote user authentication process.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Fast-SCNN: Fast Semantic Segmentation Network The encoder-decoder framework is state-of-the-art for offline semantic image segmentation. Since the rise in autonomous systems, real-time computation is increasingly desirable. In this paper, we introduce fast segmentation convolutional neural network (Fast-SCNN), an above realtime semantic segmentation model on high resolution image data (1024 \xd7 2048px) suited to efficient computation on embedded devices with low memory. Building on existing two-branch methods for fast segmentation, we introduce our \'learning to downsample\' module which computes lowlevel features for multiple resolution branches simultaneously. Our network combines spatial detail at high resolution with deep features extracted at lower resolution, yielding an accuracy of 68.0% mean intersection over union at 123.5 frames per second on Cityscapes. We also show that large scale pre-training is unnecessary. We thoroughly validate our metric in experiments with ImageNet pre-training and the coarse labeled data of Cityscapes. Finally, we show even faster computation with competitive results on subsampled inputs, without any network modifications. We evaluated our proposed fast segmentation convolutional neural network (Fast-SCNN) on the validation set of the Cityscapes dataset, and report its performance on the Cityscapes test set, i.e We evaluate our proposed Fast-SCNN on Cityscapes, the largest publicly available dataset on urban roads This dataset contains a diverse set of high resolution images (1024\xd72048px) captured from 50 different cities in Europe The label for the training set and validation set are available and test results can be evaluated on the evaluation server Cityscapes provides 30 class labels, while only 19 classes are used for evaluation We evaluate overall performance on the withheld test set of Cityscapes Table 1. Fast-SCNN uses standard convolution (Conv2D), depth- wise separable convolution (DSConv), inverted residual bottle- neck blocks (bottleneck), a pyramid pooling module (PPM) and a feature fusion module (FFM) block. Parameters t, c, n and s rep- resent expansion factor of the bottleneck block, number of output channels, number of times block is repeated and stride parameter which is applied to first sequence of the repeating block. The hori- zontal lines separate the modules: learning to down-sample, global feature extractor, feature fusion and classifier (top to bottom). s t Block - - n Table 4. Class and category mIoU of the proposed Fast-SCNN compared to other state-of-the-art semantic segmentation methods on the Cityscapes test set. Number of parameters is listed in mil- lions. 44 . - lions . Category 1024 \xd7 2048 Params Class 256 \xd7 512 - 512 \xd7 1024 Table 5. Runtime (fps) on Nvidia Titan X (Maxwell, 3,072","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"68%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"69.19%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"67.5%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"18.0%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"74.7%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"73.0%\\"}} ]"},{"Context":"Published as a conference paper at ICLR 2020 ATOMNAS: FINE-GRAINED END-TO-END NEURAL ARCHITECTURE SEARCH Search space design is very critical to neural architecture search (NAS) algorithms. We propose a fine-grained search space comprised of atomic blocks, a minimal search unit that is much smaller than the ones used in recent NAS algorithms. This search space allows a mix of operations by composing different types of atomic blocks, while the search space in previous methods only allows homogeneous operations. Based on this search space, we propose a resource-aware architecture search framework which automatically assigns the computational resources (e.g., output channel numbers) for each operation by jointly considering the performance and the computational cost. In addition, to accelerate the search process, we propose a dynamic network shrinkage technique which prunes the atomic blocks with negligible influence on outputs on the fly. Instead of a searchand-retrain two-stage paradigm, our method simultaneously searches and trains the target architecture. Our method achieves state-of-the-art performance under several FLOPs configurations on ImageNet with a small searching cost. We open our entire codebase at: https://github.com/meijieru/AtomNAS. * This work was done during the internship program at Bytedance.  Table 1: Comparision with state-of-the-arts on ImageNet under the mobile setting. \u2020 denotes meth- ods using extra network modules such as Swish activation and Squeeze-and-Excitation module. \u2021 de- notes using extra data augmentation such as MixUp and AutoAugment. * denotes models searched and trained simultaneously. - Parameters Top - 1 ( % ) Top - 5 ( % ) Table 2: Influence of awareness of resource metric. The upper block uses equal penalties for all atomic blocks. The lower part uses our resource-aware atomic block selection. Our dynamic network shrinkage algorithm speedups the search and train process significantly . For Top - 1 ( % ) \u03bb COST OF DYNAMIC NETWORK SHRINKAGE Table 3: Influence of BN recalibration. w / o Recalibration w / Recalibration Model Table 4: Comparision with baseline backbones on COCO object detection and instance segmenta- tion. Cls denotes the ImageNet top-1 accuracy; detect-mAP and seg-mAP denotes mean","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"77.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"MACs\\", \\"Score\\": \\"363M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Params\\", \\"Score\\": \\"5.9M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top-1 Error Rate\\", \\"Score\\": \\"22.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"77.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"MACs\\", \\"Score\\": \\"329M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Params\\", \\"Score\\": \\"5.5M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top-1 Error Rate\\", \\"Score\\": \\"22.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"76.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"MACs\\", \\"Score\\": \\"260M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Params\\", \\"Score\\": \\"4.7M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top-1 Error Rate\\", \\"Score\\": \\"23.7\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"77.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"MACs\\", \\"Score\\": \\"325M\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top-1 Error Rate\\", \\"Score\\": \\"22.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"76.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"MACs\\", \\"Score\\": \\"238M\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top-1 Error Rate\\", \\"Score\\": \\"24.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"73.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": "},{"Context":"Domain Adaptation for sEMG-based Gesture Recognition with Recurrent Neural Networks Surface Electromyography (sEMG/EMG) is to record muscles\' electrical activity from a restricted area of the skin by using electrodes. The sEMG-based gesture recognition is extremely sensitive of inter-session and inter-subject variances. We propose a model and a deep-learning-based domain adaptation method to approximate the domain shift for recognition accuracy enhancement. Analysis performed on sparse and High-Density (HD) sEMG public datasets validate that our approach outperforms state-of-the-art methods. We have tested the approach on HD sEMG and sparse sEMG datasets: 1) CapgMyo dataset: includes HD-sEMG data for 128 channels acquired from 23 intact subjects 2) NinaPro dataset: a) DB1: The NinaPro sub-database 1 (DB-1) is for the development of hand prostheses, and contains sparse multi-channel sEMG recordings The domain adaptation layer has the M \u2208 Rf \xd7f where f is 128 in case of the CapgMyo dataset and 10 in case of the NinaPro","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Gesture Recognition\\", \\"Dataset\\": \\"CapgMyo DB-b\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"97.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Gesture Recognition\\", \\"Dataset\\": \\"CapgMyo DB-a\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"97.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Gesture Recognition\\", \\"Dataset\\": \\"Ninapro DB-1 12 gestures\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"84.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Gesture Recognition\\", \\"Dataset\\": \\"Ninapro DB-1 8 gestures\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"90.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Gesture Recognition\\", \\"Dataset\\": \\"CapgMyo DB-c\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"96.8\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Hand Gesture Recognition\\", \\"Dataset\\": \\"Banglas\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"87.75\\"}} ]"},{"Context":"New Binomial Bent Function over the Finite Fields of Odd Characteristic * The p-ary function f (x) mapping GF(p 4k ) to GF(p) given by f (x) = Tr 4k`x p 3k +p 2k \u2212p k +1 + x 2\xb4i s proven to be a weakly regular bent function and the exact values of its Walsh transform coefficients are found. The proof is based on a few new results in the area of exponential sums and polynomials over finite fields that may also be interesting as independent problems.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Large Area Roller Embossing of Multilayered Ceramic Green Composites This paper presents our latest achievements in developing large area patterning of multilayered ceramic green composites using micro roller embossing. The aim of this research is to develop large area pattern technique for ceramic green substrates using a modified roller laminator, which is compatible with screen printing apparatus, for integration of micro embossing and printing in the future stage. A thin film nickel mold was developed via photolithography, nickel electroplating and photoresist strip-off. The mold had an effective panel size of 150 mm\xd7 \xd7 \xd7 \xd7 150 mm with the height of protrusive micro patterns being about 40 \xb5m. Formation of micro patterns was successfully demonstrated over the whole panel area using roller embossing on laminated ceramic green tapes (HL2000 from Heraeus). Micro patterns for inductors, capacitors as well as interconnection with 50 \xb5m line width were embossed on ceramic green substrates. With the optimized process parameters (including feeding speed, roller temperature and applied pressure), we have demonstrated that micro roller embossing is a promising method for large area patterning of ceramic green substrates.I.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Factor Graph Attention Dialog is an effective way to exchange information, but subtle details and nuances are extremely important. While significant progress has paved a path to address visual dialog with algorithms, details and nuances remain a challenge. Attention mechanisms have demonstrated compelling results to extract details in visual question answering and also provide a convincing framework for visual dialog due to their interpretability and effectiveness. However, the many data utilities that accompany visual dialog challenge existing attention techniques. We address this issue and develop a general attention mechanism for visual dialog which operates on any number of data utilities. To this end, we design a factor graph based attention mechanism which combines any number of utility representations. We illustrate the applicability of the proposed approach on the challenging and recently introduced VisDial datasets, outperforming recent state-of-the-art methods by 1.1% for VisDial0.9 and by 2% for VisDial1.0 on MRR. Our ensemble model improved the MRR score on VisDial1.0 by more than 6%. Evaluation metrics: Evaluating dialog systems, or any other generative tasks is challenging We follow and evaluate each individual response at each of the T = 10 rounds in a multiple-choice setup The model is hence evaluated on retrieval metrics: Recall@k is the percentage of questions where the human response was part of the top k predicted answers In contrast, our general attention mechanism allows to attend to the entire set of cues in the dataset, letting the model automatically choose the more relevant cues Their introduced question prediction dataset is based on VisDial v0.9, along with a collected set of 100 question candidates Other Datasets: When we replace the attention unit of other methods with our FGA unit we observe improvements in visual question answering (VQA) and audio-visual scene aware dialog (AVSD) Lastly, in, we evaluate question generation and let the model interact with the answer predictor Table 1: Performance of discriminative models on VisDial v0.9. Higher is better for MRR and recall@k, while lower is better for mean rank. (*) denotes use of external knowledge. Mean R@1 R@5 R@10 MRR Table 2: Performance on the question generation task. Higher is better for MRR and recall@k, while lower is better for mean rank. Model MRR R@1 R@5 R@10 Mean SF-QIH-se-2 [21] 0.4060 26.76 55.17 70.39 9.32 FGA 0.4138 27.42 56.33 71.32 9.1 better for MRR and recall@k , while lower is better for mean rank . Mean R@1 Table 2 : Performance on the question generation task . Higher is R@5 R@10 MRR Table 3: Performance of discriminative models on VisDial v1.0 test- std. Higher is better for MRR and recall@k, while lower is better for mean rank and NDCG. (*) denotes use of external knowledge. Mean R@1 R@5 R@10 MRR NDCG Table 4: Attention-related ablation analysis. Mean","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"68.92\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"Mean Rank\\", \\"Score\\": \\"3.39\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"55.16\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@10\\", \\"Score\\": \\"92.95\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@5\\", \\"Score\\": \\"86.26\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"Visual Dialog v1.0 test-std\\", \\"Metric\\": \\"MRR (x 100)\\", \\"Score\\": \\"69.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"Visual Dialog v1.0 test-std\\", \\"Metric\\": \\"Mean\\", \\"Score\\": \\"3.14\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"Visual Dialog v1.0 test-std\\", \\"Metric\\": \\"NDCG (x 100)\\", \\"Score\\": \\"57.20\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"Visual Dialog v1.0 test-std\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"55.65\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"Visual Dialog v1.0 test-std\\", \\"Metric\\": \\"R@10\\", \\"Score\\": \\"94.05\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"Visual Dialog v1.0 test-std\\", \\"Metric\\": \\"R@5\\", \\"Score\\": \\"86.73\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"63.98\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"Mean Rank\\", \\"Score\\": \\"4.47\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"50.29\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@10\\", \\"Score\\": \\"88.81\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@5\\", \\"Score\\": \\"80.71\\"}} ]"},{"Context":"Minimum Manhattan network problem in normed planes with polygonal balls: a factor 2.5 approximation algorithm Let B be a centrally symmetric convex polygon of R 2 and ||p \u2212 q|| be the distance between two points p, q \u2208 R 2 in the normed plane whose unit ball is B. For a set T of n points (terminals) in R 2 , a B-Manhattan network on T is a network N (T ) = (V, E) with the property that its edges are parallel to the directions of B and for every pair of terminals ti and t j , the network N (T ) contains a shortest B-path between them, i.e., a path of length ||t i \u2212 t j ||. A minimum B-Manhattan network on T is a B-Manhattan network of minimum possible length. The problem of finding minimum B-Manhattan networks has been introduced by Gudmundsson, Levcopoulos, and Narasimhan (APPROX\'99) in the case when the unit ball B is a square (and hence the distance ||p \u2212 q|| is the l 1 or the l \u221e -distance between p and q) and it has been shown recently by Chin, Guo, and Sun [6] to be strongly NP-complete. Several approximation algorithms (with factors 8,4,3, and 2) for the minimum Manhattan problem are known. In this paper, we propose a factor 2.5 approximation algorithm for the minimum B-Manhattan network problem. The algorithm employs a simplified version of the strip-staircase decomposition proposed in our paper [5] and subsequently used in other factor 2 approximation algorithms for the minimum Manhattan problem.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"On the Protocol Composition Logic PCL * Manuscript A recent development informal security protocol analysis is the Protocol Composition Logic (PCL). We identify a number of problems with this logic as well as with extensions of the logic, as defined in [DDMP05,HSD + 05,He05,Dat05,Der06,DDMR07]. The identified problems imply strong restrictions on the scope of PCL, and imply that some currently claimed PCL proofs cannot be proven within the logic, or make use of unsound axioms. Where possible, we propose solutions for these problems. * This work was supported by the Hasler Foundation, ManCom project 2071.In this paper, we identify a number of problems with PCL as defined in [DDMP05, Dat05, Der06, DDMR07, HSD + 05, He05]. They have implications for the scope of PCL, a number of claimed formal proofs, and several extensions to the base model. In particular, we show that in contrast with the claims in e.g. the introduction of [DDMR07], PCL as defined in [DDMP05, Dat05, Der06, DDMR07] cannot be used to prove common authentication properties of protocols that do not include signatures. We show that a number of claimed proofs in PCL cannot be correct because (a) there is noway to establish preceding actions in a thread, and (b) there is noway to express type restrictions in PCL. With respect to existing PCL extensions, we identify two problems: the Diffie-Hellman extension from [DDMP05, Dat05, Der06, DDMR07] does not correctly capture the algebraic behaviour of Diffie-Hellman-like protocols, and the extension for hash functions from [HSD + 05, He05] is not sound. Some of these problems can be resolved by minor modifications to PCL, but other problems require further investigation. Our observations suggest that it is at least required to make changes to existing axioms, to introduce new axioms, and to add a mechanism fora type system.The purpose of this paper is to identify some of the challenges that need to be addressed in order to make a logic like PCL work. We hope it will contribute to the improvement of PCL, and will lead to a better understanding of some of the pitfalls of designing a compact and usable formal logic for security protocols.The scope of this paper. The presentation of this paper is inherently difficult, not least because there area number of different papers on PCL, which vary in notation and technical details. Many ideas were already present in precursors of PCL, e.g. [DMP01, DMP03], but these variants use different concepts than later versions of PCL. These early variants in [DMP01, DMP03] have no notion of thread (a.k.a. process, run, or role instance), and events are bound to agents. More recent versions of PCL bind events to threads of agents, and therefore distinguish between several threads of the same agent. PCL versions of the latter type can be found in [DDMP03b,DDMP03a,DDMP04b,DDMP04a]. Subsequently, [DDMP03b, DDMP03a, DDMP04b, DDMP04a] have been claimed to be either subsumed, or revised and extended, by more recent works [DDMP05, Dat05, Der06, DDMR07]. Hence we choose hereto focus on [DDMP05, Dat05, Der06, DDMR07], which contain similar descriptions of PCL. Throughout this paper we write basic PCL to refer to [DDMP05, Dat05, Der06, DDMR07]. The publications on basic PCL describe the fundamental part of PCL that focusses on authentication. In general, the comments in this paper apply to basic PCL. The comments in Section 4.2 apply only to the extensions found in [HSD + 05, He05]. Our comments here do not cover the recent extensions to basic PCL for the analysis of secrecy, as found in [RDD + 06], nor the computational variants of PCL, as found in e.g. [DDMW06].Syntax and page references. In order to pinpoint our observations to specific formulas, we select a specific version of PCL to refer to. We have chosen the most recent description of PCL from 2007 as found in [DDMR07]. In particular, we will use [DDMR07] as a reference for the syntax of PCL formulas, and to provide specific page references. Hence we use [DDMR07] as the reference paper to present the problems with basic PCL from the papers [DDMP05,Dat05,Der06,DDMR07].For the technical details, in particular the formulas, we assume the reader is at least somewhat familiar with one of the papers from [DDMP05, Dat05, Der06, DDMR07] or [He05, HSD + 05]. However, the main points should be clear to readers familiar with formal security protocol analysis.The remainder of the paper is structured in the following way. We start off by recalling some PCL notation and concepts in Section 2. Then, in Section 3 we discuss problems with the basic definition of PCL. In Section 4 we identify two problems with existing PCL extensions. We conclude in Section 5.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Combinatorial Approximation Algorithms for MaxCut using Random Walks We give the first combinatorial approximation algorithm for MaxCut that beats the trivial 0.5 factor by a constant. The main partitioning procedure is very intuitive, natural, and easily described. It essentially performs a number of random walks and aggregates the information to provide the partition. We can control the running time to get an approximation factor-running time tradeoff. We show that for any constant b > 1.5, there is an O(n b ) algorithm that outputs a (0.5 + \u03b4)-approximation for MaxCut, where \u03b4 = \u03b4(b) is some positive constant.One of the components of our algorithm is a weak local graph partitioning procedure that maybe of independent interest. Given a starting vertex i and a conductance parameter \u03c6, unless a random walk of length = O(log n) starting from i mixes rapidly (in terms of \u03c6 and ), we can find a cut of conductance at most \u03c6 close to the vertex. The work done per vertex found in the cut is sublinear inn. arXiv:1008.3938v1 [cs.DS] 23 Aug 2010 2. Even though the core of our algorithm is completely combinatorial, relying only on simple random walks and integer operations, the analysis of the algorithm is based on spectral methods. We obtain a combinatorial version of Trevisan\'s algorithm by showing two key facts: (a) the \\"flipping signs\\" random walks we use corresponds to running the power method on the graph Laplacian, and (b) a random starting vertex yields a good starting vector for the power method with constant probability. These two facts replace numerical matrix computations with the combinatorial problem of estimating certain probabilities, which can be done effectively by sampling and concentration bounds. This also allows improved running times since we can selectively find portions of the graph and classify them.3. A direct application of the partitioning procedure yields an algorithm whose running time is O(n 2+\xb5 ). To design the sub-quadratic time algorithm, we have to ensure that the random walks in the algorithm mix rapidly. To do this, we design a sort of a local graph partitioning algorithm of independent interest based on simple random walks of logarithmic length. Given a starting vertex i, either it finds a low conductance cut or certifies that the random walk from i has somewhat mixed, in the sense that the ratio of the probability of hitting any vertex j to its probability in the stationary distribution is bounded. The work done per vertex output in the cut is sublinear inn. The precise statement is given in Theorem 4.1. Previous local partitioning algorithms [ST04, ACL06, AL08] are more efficient than our procedure, but can only output a low conductance cut, if the actual conductance of some set containing i is O(1/ log n). In this paper, we need to be able to find low conductance cuts in more general settings, even if there is no cut of conductance of O(1/ log n), and hence the previous algorithms are unsuitable for our purposes.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"graph2vec: Learning Distributed Representations of Graphs Recent works on representation learning for graph structured data predominantly focus on learning distributed representations of graph substructures such as nodes and subgraphs. However, many graph analytics tasks such as graph classification and clustering require representing entire graphs as fixed length feature vectors. While the aforementioned approaches are naturally unequipped to learn such representations, graph kernels remain as the most effective way of obtaining them. However, these graph kernels use handcrafted features (e.g., shortest paths, graphlets, etc.) and hence are hampered by problems such as poor generalization. To address this limitation, in this work, we propose a neural embedding framework named graph2vec to learn data-driven distributed representations of arbitrary sized graphs. graph2vec\'s embeddings are learnt in an unsupervised manner and are task agnostic. Hence, they could be used for any downstream task such as graph classification, clustering and even seeding supervised representation learning approaches. Our experiments on several benchmark and large real-world datasets show that graph2vec achieves significant improvements in classification and clustering accuracies over substructure representation learning approaches and are competitive with state-of-the-art graph kernels. We evaluate graph2vec\'s accuracy and efficiency both in graph classification and clustering tasks Besides experimenting with benchmark datasets, we also evaluate our approach on two real-world graph analytics tasks from the field of program analysis, namely, malware detection and malware familial clustering on large malware datasets Specifically, we intend to address the following research questions: (1) How does graph2vec compare to state-of-the-art substructure representation learning approaches and graph kernels for graph classification tasks in terms of accuracy and efficiency on benchmark datasets, (2) How does graph2vec compare to the aforementioned state-of-the-art approaches on a realworld graph classification task, namely, malware detection detection, and (3) How does graph2vec compare to the aforementioned state-of-the-art approaches on a real-world graph clustering task, namely, malware familial clustering Deep WL 4 see for the explanations on obtaining kernel matrix with substructure embedding approaches Datasets Five benchmark graph classification datasets namely MUTAG, PTC, PROTEINS, NCI1 and NCI109 Table 1: Benchmark dataset statistics 3 37 on a server with 36 CPU cores ( Intel E5 - 2699 2 . 30GHz pro - 7 19 # nodes # samples # distinct ( avg . ) node labels Table 1 : Benchmark dataset statistics Thus , the ker - Table 2: Average Accuracy (\xb1 std dev.) for graph2vec and state-of-the-art graph kernels on benchmark graph classification datasets MUTAG NCI1 NCI109 PROTEINS PTC Table 2 : Average Accuracy ( \xb1 std dev . ) for graph2vec and state - of - the - art graph kernels on benchmark graph classification datasets Table 3: Large real-world datasets used in graph classifications and clustering tasks 4271 and clustering tasks # nodes ( avg . ) Table 3 : Large real - world datasets used in graph classifications # edges source Table 4: Malware Detection -Results 4271 and clustering tasks # nodes ( avg .","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Malware Detection\\", \\"Dataset\\": \\"Android Malware Dataset\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"99.03\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Graph Classification\\", \\"Dataset\\": \\"NCI1\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"73.22%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Graph Classification\\", \\"Dataset\\": \\"PTC\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"60.17%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Graph Classification\\", \\"Dataset\\": \\"NCI109\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"74.26\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Graph Classification\\", \\"Dataset\\": \\"PROTEINS\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"73.3%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Graph Classification\\", \\"Dataset\\": \\"MUTAG\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"83.15%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Movie Classification\\", \\"Dataset\\": \\"MovieLens 20M\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.36%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Muade Classification\\", \\"Dataset\\": \\"MovieLens 20M\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"92.82%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Muade Classification\\", \\"Dataset\\": \\"MovieLens 20M\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"82.82%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Muade Classification\\", \\"Dataset\\": \\"MovieLens 20M\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"80.42%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Muade Classification\\", \\"Dataset\\": \\"MovieLens 20M\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"80.42%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Muade Classification\\", \\"Dataset\\": \\"MovieLens 20M\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"80.42%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Muade Classification\\", \\"Dataset\\": \\"Text Classification"},{"Context":"Sub-frame Appearance and 6D Pose Estimation of Fast Moving Objects TbD-NC 3D position & angular velocity 6-DOF Trajectory Input Video 2D trajectory Object snapshots shape & appearance Piece-wise Deblatting : Estimation of appearance, shape and 6D pose (3D position and rotation) of fast moving objects. The input video and 2D trajectories estimated by Non-Causal Tracking by Deblatting, , are processed by the proposed piecewise deblatting that generates, with sub-frame temporal resolution, the object appearance and shape (snapshots), from which the complete 6-DOF trajectory is estimated.We propose a novel method that tracks fast moving objects, mainly non-uniform spherical, in full 6 degrees of freedom, estimating simultaneously their 3D motion trajectory, 3D pose and object appearance changes with a time step that is a fraction of the video frame exposure time. The sub-frame object localization and appearance estimation allows realistic temporal super-resolution and precise shape estimation. The method, called TbD-3D (Tracking by Deblatting in 3D) relies on a novel reconstruction algorithm which solves a piece-wise deblurring and matting problem. The 3D rotation is estimated by minimizing the reprojection error. As a second contribution, we present anew challenging dataset with fast moving objects that change their appearance and distance to the camera. High speed camera recordings with zero lag between frame exposures were used to generate videos with different frame rates annotated with ground-truth trajectory and pose. We created anew annotated dataset containing fast moving objects All previous datasets with FMOs, such as FMO dataset and TbD dataset, included only objects moving in a 2D plane parallel to the camera plane and their appearance was close to static The introduced dataset is the first dataset with nonnegligible 3D object motion and with changing appearance of non-uniform fast moving objects The dataset is called TbD-3D and it contains nine sequences with annotated object location, pose, and size from a high-speed camera In contrast to previous datasets, the perceived size of objects in TbD-3D dataset varies throughout the whole sequence due to depth of the scene, as shown in The dataset sequences were generated by averaging 2, 4 and 8 frames, which corresponds to real videos captured at 30, 60, 120 fps, respectively The proposed method is evaluated on the TbD-3D dataset for all three frame-rate settings Table 1: TbD-3D dataset -comparison of TbD \u2022 # TbD - NC Radius Error [ pixels ] Axis Error [ TbD TIoU - 3D TbD - 3D Angle Error [ TbD - 3D - O ]","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\"TbD-3D\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"23.13\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\"TbD-3D\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.651\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\"TbD-3D\\", \\"Metric\\": \\"TIoU\\", \\"Score\\": \\"0.598\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\"TbD\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"25.21\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\"TbD\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.674\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\"TbD\\", \\"Metric\\": \\"TIoU\\", \\"Score\\": \\"0.542\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\"Falling Objects\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"23.42\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\"Falling Objects\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.671\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\"Falling Objects\\", \\"Metric\\": \\"TIoU\\", \\"Score\\": \\"0.539\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Reconstruction\\", \\"Dataset\\": \\"TbD-3D\\", \\"Metric\\": \\"Avg F1\\", \\"Score\\": \\"78.3\\"}} ]"},{"Context":"Named Entity Recognition with Bidirectional LSTM-CNNs Named entity recognition is a challenging task that has traditionally required large amounts of knowledge in the form of feature engineering and lexicons to achieve high performance.In this paper, we present a novel neural network architecture that automatically detects word-and character-level features using a hybrid bidirectional LSTM and CNN architecture, eliminating the need for most feature engineering. We also propose a novel method of encoding partial lexicon matches in neural networks and compare it to existing approaches. Extensive evaluation shows that, given only tokenized text and publicly available word embeddings, our system is competitive on the CoNLL-2003 dataset and surpasses the previously reported state of the art performance on the OntoNotes 5.0 dataset by 2.13 F1 points. By using two lexicons constructed from publicly-available sources, we establish new state of the art performance with an F1 score of 91.62 on CoNLL-2003 and 86.28 on OntoNotes, surpassing systems that employ heavy feature engineering, proprietary lexicons, and rich entity linking information. Evaluation was performed on the well-established CoNLL-2003 NER shared task dataset (Tjong Kim and the much larger but less-studied OntoNotes 5.0 dataset gives an overview of these two different datasets For all datasets, we performed the following preprocessing: \u2022 All digit sequences are replaced by a single \\"0\\" In addition, for the OntoNotes dataset, in order to handle the Date, Time, Money, Percent, Quantity, Ordinal, and Cardinal named entity tags, we split tokens before and after every digit The CoNLL-2003 dataset (Tjong Kim consists of newswire from the Reuters RCV1 corpus tagged with four types of named entities: location, organization, person, and miscellaneous As the dataset is small compared to OntoNotes, we trained the model on both the training and development sets after performing hyperparameter optimization on the development set compiled a core portion of the OntoNotes 5.0 dataset for the CoNLL-2012 shared task and described a standard train/dev/test split, which Table 1: Number of entries for each category in the SENNA lexicon and our DBpedia lexicon. Table 2: Dataset sizes in number of tokens (entities) Dataset CoNLL - 2003 ( 23 , 499 ) Table 3: Hyper-parameter search space and final values used for all experiments [ 15 , 100 ] [ 100 , 400 ] - Table 3 : Hyper - parameter search space and final values used for all experiments [ 3 , 7 ] Hyper - parameter LSTM layers [ 1 , 4 ] Mini - batch size Range [ 2 , 4 ] 1 2 3 9 Final [ 3 , 9 ] Convolution width Table 5: Results of our models, with various feature sets, compared to other published results. The three sections are, in order, our models, published neural network models, and published non-neural network models. For the features, emb = Collobert word embeddings, caps =","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"CoNLL 2003 (English)\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"91.62\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"Ontonotes v5 (English)\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"86.19\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"Ontonotes v5 (English)\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"84.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"Ontonotes v5 (English)\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"84.8\\"}} ]"},{"Context":"Model Based Ceramic tile inspection using Discrete Wavelet Transform and Euclidean Distance Visual inspection of industrial products is used to determine the control quality for these products. This paper deals with the problem of visual inspection of ceramic tiles industry using Wavelet Transform. The third level the coefficients of two dimensions Haar Discrete Wavelet Transform (HDWT) is used in this paper to process the images and feature extraction. The proposed algorithm consists of two main phases. The first phase is to compute the wavelet transform for an image free of defects which known as reference image, and the image to be inspected which known as test image. The second phase is used to decide whether the tested image is defected or not using the Euclidean distance similarity measure. The experimentation results of the proposed algorithm give 97% for correct detection of ceramic defects.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Study of Mechanical Response in Embossing of Ceramic Green Substrate by Micro-Indentation Micro-indentation test with a micro flat-end cone indenter was employed to simulate micro embossing process and investigate the thermo-mechanical response of ceramic green substrates. The laminated low temperature co-fired ceramic green tapes were used as the testing material; the correlations of indentation depth versus applied force and applied stress at the temperatures of 25 \xb0C and 75\xb0C were studied. The results showed that permanent indentation cavities could be formed at temperatures ranging from 25 \xb0C to 75 \xb0C, and the depth of cavities created was applied force, temperature and dwell time dependent. Creep occurred and made a larger contribution to the plastic deformation at elevated temperatures and high peak loads. There was instantaneous recovery during the unloading and retarded recovery in the first day after indentation. There was no significant pile-up due to material flow observed under compression at the temperature up to 75 \xb0C. The plastic deformation was the main cause for formation of cavity on the ceramic green substrate under compression. The results can be used as a guideline for embossing ceramic green substrates.I.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Disp R-CNN: Stereo 3D Object Detection via Shape Prior Guided Instance Disparity Estimation In this paper, we propose a novel system named Disp R-CNN for 3D object detection from stereo images. Many recent works solve this problem by first recovering a point cloud with disparity estimation and then apply a 3D detector. The disparity map is computed for the entire image, which is costly and fails to leverage category-specific prior. In contrast, we design an instance disparity estimation network (iDispNet) that predicts disparity only for pixels on objects of interest and learns a category-specific shape prior for more accurate disparity estimation. To address the challenge from scarcity of disparity annotation in training, we propose to use a statistical shape model to generate dense disparity pseudo-ground-truth without the need of LiDAR point clouds, which makes our system more widely applicable. Experiments on the KITTI dataset show that, even when LiDAR ground-truth is not available at training time, Disp R-CNN achieves competitive performance and outperforms previous state-of-the-art methods by 20% in terms of average precision. The code will be available at https://github.com/zju3dv/disprcnn. We evaluate the proposed approach on the 3D object detection benchmark of KITTI dataset Table 1. 3D object detection results on the KITTI object validation set. We report average precision of bird\'s eye view (AP bev ) and 3D boxes (AP 3d ) for the car category. LiDAR supervision indicates if the method uses the sparse LiDAR point cloud as a supervision signal during training. We report the reproduced result for PL (AVOD) since [30] didn\'t provide full results on experiments without LiDAR supervision. Besides published state-of-the-art methods, we also present the results of concurrent works (grey background) for comparison. Method bev ( IoU=0 . 7 ) Mod . Easy bev ( IoU=0 . 5 ) AP bev ( IoU=0 . 7 ) LiDAR 3D object detection results on the KITTI object validation set . Hard AP 3d ( IoU=0 . 7 ) AP 3d ( IoU=0 . 7 ) Supervision 3d ( IoU=0 . 5 ) Table 2. 3D object detection results on the","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Vehicle Pose Estimation\\", \\"Dataset\\": \\"KITTI Cars Hard\\", \\"Metric\\": \\"Average Orientation Similarity\\", \\"Score\\": \\"67.16\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Moderate val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"75.54%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Moderate val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"84.83\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Easy val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"92.57\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Easy\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"90.14%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Moderate val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"82.69\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Moderate val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"81.94%\\"}} ]"},{"Context":"Integrated Modeling and Verification of Real-Time Systems through Multiple Paradigms Complex systems typically have many different parts and facets, with different characteristics. Ina multi-paradigm approach to modeling, formalisms with different natures are used in combination to describe complementary parts and aspects of the system. This can have a beneficial impact on the modeling activity, as different paradigms can be better suited to describe different aspects of the system. While each paradigm provides a different view on the many facets of the system, it is of paramount importance that a coherent comprehensive model emerges from the combination of the various partial descriptions. In this paper we present a technique to model different aspects of the same system with different formalisms, while keeping the various models tightly integrated with one another. In addition, our approach leverages the flexibility provided by a bounded satisfiability checker to encode the verification problem of the integrated model in the propositional satisfiability (SAT) problem; this allows users to carryout formal verification activities both on the whole model and on parts thereof. The effectiveness of the approach is illustrated through the example of a monitoring system.  Table 2: Checking properties of the data monitoring system. \u2212 + T SAT ( hrs . ) PRE ( min . ) # CL\xb710 K CNF ( hrs . ) T2 T3","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Joint Parsing and Generation for Abstractive Summarization Sentences produced by abstractive summarization systems can be ungrammatical and fail to preserve the original meanings, despite being locally fluent. In this paper we propose to remedy this problem by jointly generating a sentence and its syntactic dependency parse while performing abstraction. If generating a word can introduce an erroneous relation to the summary, the behavior must be discouraged. The proposed method thus holds promise for producing grammatical sentences and encouraging the summary to stay true-to-original. Our contributions of this work are twofold. First, we present a novel neural architecture for abstractive summarization that combines a sequential decoder with a tree-based decoder in a synchronized manner to generate a summary sentence and its syntactic parse. Secondly, we describe a novel human evaluation protocol to assess if, and to what extent, a summary remains true to its original meanings. We evaluate our method on a number of summarization datasets and demonstrate competitive results against strong baselines. We present our datasets, settings, baselines, qualitative and quantitative evaluation of our proposed method Summarization We present summarization results on all datasets Evaluation is performed using the automatic metric of ROUGE, which measures the n-gram overlap between system and reference summaries, as well as human evaluation of grammaticality and preservation of meanings In we present summarization results on the NEWSROOM, CNN/DM-R, and WEBMERGE datasets Instead, we train the pointer-generator networks with coverage mechanism (PointerGen;, one of the best performed neural abstractive summarizers, on the train split of each dataset, then report results on the test split; we apply a similar process to our GenParse systems We observe that the GenParse-FULL model consistently outperforms strong baselines across all datasets 5 PointerGen: Summarization results on Newsroom, CNN/DM-R, and WebMerge datasets NEWSROOM dataset, respectively Overall, we notice that the GenParse-FULL method performs exceptionally well on retaining relations on the CNN/DM-R dataset We proceed by Table 3: Statistics of our datasets. |y| is number of words. 4 , 020 , 581 199 , 341 472 , 872 |y| Table 4: Summarization results on Gigaword dataset. Our GenParse systems perform on par with or superior to state- of-the-art systems on the standard test set. R - 1 Gigaword Test Set R - 2 R - L Table 5: Summarization results on Newsroom, CNN/DM-R, and WebMerge datasets. Our GenParse-FULL method jointly decodes a summary and its dependency structure using a novel architecture that performs competitively against strong baselines. It outperforms both pointer-generator networks and the ablated model GenParse-BASE without using the tree-decoder. \u2022 55 45 \u2022 35 25 15 Newsroom JtParseSumm \u2212 Base JtParseSumm \u2212 Full PointerGen Source CNN / DM ( % ) Summary 60 \u2022 JtParseSumm \u2212 Base 50 40 30 20 Table 7: Human assessment of grammaticality and seman- tic accuracy of various summaries. Our","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Text Summarization\\", \\"Dataset\\": \\"GigaWord\\", \\"Metric\\": \\"ROUGE-1\\", \\"Score\\": \\"36.61\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Text Summarization\\", \\"Dataset\\": \\"GigaWord\\", \\"Metric\\": \\"ROUGE-2\\", \\"Score\\": \\"18.85\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Text Summarization\\", \\"Dataset\\": \\"GigaWord\\", \\"Metric\\": \\"ROUGE-L\\", \\"Score\\": \\"34.33\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Text Summarization\\", \\"Dataset\\": \\"WebNLG\\", \\"Metric\\": \\"ROUGE-1\\", \\"Score\\": \\"28.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Text Summarization\\", \\"Dataset\\": \\"NYT\\", \\"Metric\\": \\"ROUGE-1\\", \\"Score\\": \\"42.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Text Summarization\\", \\"Dataset\\": \\"WebNLI\\", \\"Metric\\": \\"ROUGE-1\\", \\"Score\\": \\"42.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Text Summarization\\", \\"Dataset\\": \\"NYT\\", \\"Metric\\": \\"ROUGE-2\\", \\"Score\\": \\"22.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Text Summarization\\", \\"Dataset\\": \\"NYT\\", \\"Metric\\": \\"ROUGE-L\\", \\"Score\\": \\"41.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Text Summarization\\", \\"Dataset\\": \\"arXimetric Thermal Face Dataset\\", \\"Metric\\": \\"ROUGE-1\\", \\"Score\\": \\"41.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Text Summarization\\", \\"Dataset\\": \\"arXimetric Thermal Face Dataset\\", \\"Metric\\": \\"ROUGE-2\\", \\"Score\\": \\"31.2\\"}}]"},{"Context":"WELL-CENTERED TRIANGULATION \xb6 Meshes composed of well-centered simplices have nice orthogonal dual meshes (the dual Voronoi diagram). This is useful for certain numerical algorithms that prefer such primal-dual mesh pairs. We prove that well-centered meshes also have optimality properties and relationships to Delaunay and minmax angle triangulations. We present an iterative algorithm that seeks to transform a given triangulation in two or three dimensions into a well-centered one by minimizing a cost function and moving the interior vertices while keeping the mesh connectivity and boundary vertices fixed. The cost function is a direct result of anew characterization of well-centeredness in arbitrary dimensions that we present. Ours is the first optimization-based heuristic for wellcenteredness, and the first one that applies in both two and three dimensions. We show the results of applying our algorithm to small and large two-dimensional meshes, some with a complex boundary, and obtain a well-centered tetrahedralization of the cube. We also show numerical evidence that our algorithm preserves gradation and that it improves the maximum and minimum angles of acute triangulations created by the best known previous method.AMS subject classifications. 65N50, 65M50, 65D18, 51M04 \xb6 Preliminary results for the 2-dimensional problem of well-centered planar triangulations appeared previously in the","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"INFOGRAPH: UNSUPERVISED AND SEMI-SUPERVISED GRAPH-LEVEL REPRESENTATION LEARNING VIA MU- TUAL INFORMATION MAXIMIZATION This paper studies learning the representations of whole graphs in both unsupervised and semi-supervised scenarios. Graph-level representations are critical in a variety of real-world applications such as predicting the properties of molecules and community analysis in social networks. Traditional graph kernel based methods are simple, yet effective for obtaining fixed-length representations for graphs but they suffer from poor generalization due to hand-crafted designs. There are also some recent methods based on language models (e.g. graph2vec) but they tend to only consider certain substructures (e.g. subtrees) as graph representatives. Inspired by recent progress of unsupervised representation learning, in this paper we proposed a novel method called InfoGraph for learning graph-level representations. We maximize the mutual information between the graph-level representation and the representations of substructures of different scales (e.g., nodes, edges, triangles). By doing so, the graph-level representations encode aspects of the data that are shared across different scales of substructures. Furthermore, we further propose InfoGraph*, an extension of InfoGraph for semi-supervised scenarios. InfoGraph* maximizes the mutual information between unsupervised graph representations learned by InfoGraph and the representations learned by existing supervised methods. As a result, the supervised encoder learns from unlabeled data while preserving the latent semantic space favored by the current supervised task. Experimental results on the tasks of graph classification and molecular property prediction show that InfoGraph is superior to state-of-the-art baselines and InfoGraph* can achieve performance competitive with state-of-the-art semi-supervised models. We evaluate the effectiveness of the graph-level representation learned by InfoGraph on downstream graph classification tasks and on semi-supervised molecular property prediction tasks For graph classification, we conduct experiments on 6 well-known benchmark datasets: MUTAG, PTC, REDDIT-BINARY, REDDIT-MULTI-5K, IMDB-BINARY, and IMDB-MULTI) For semi-supervised learning tasks, we use the publicly available QM9 dataset Additional details of the datasets can be found in Appendix B (2017) but we did not run it on all datasets as the implementation details are not clear in the paper The QM9 dataset has 130462 molecules in it We minimize the mean squared error between the model output and the target, although we evaluate mean absolute error C.1 GRAPH CLASSIFICATION DATASETS MUTAG contains 188 mutagenic aromatic and heteroaromatic nitro compounds with 7 different discrete labels PTC is a dataset of 344 different chemical compounds that have been tested for carcinogenicity in male and female rats This dataset has Table 1: Classification accuracy on 6 datasets. The result in bold indicates the best reported classification accuracy. The top half of the table compares results with various graph kernel approaches while bottom half compares results with other state-of-the-art unsupervised graph representation learning methods. \'> 1 day\' represents that the computation exceeds 24 hours. \'OMR\' is out of memory error. Graph Kernels Other Unsupervised Methods IMDB - B RDT - B 1000 2000 IMDB - M - PTC - MR 188 2 344 1500 3 5 MUTAG RDT - M5K 4999 Table 2: Results of semi-supervised experiments on QM9 dataset. The result in bold indicates the best performance. The top half of the table shows the mean absolute error (MAE) of the supervised model. The bottom half shows the error ratio (with respect to supervised result) of the semi-supervised models using the same underlying model. Lower scores are better and values less","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Graph Classification\\", \\"Dataset\\": \\"PTC\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"61.65\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Graph Classification\\", \\"Dataset\\": \\"IMDb-M\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"49.69%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Graph Classification\\", \\"Dataset\\": \\"MUTAG\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"89.01%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Graph Classification\\", \\"Dataset\\": \\"IMDb-B\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"73.03%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Citeseer\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"73.50%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Pubmed\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"89.35%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Cora\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"93.14%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"CiteSeer with Public Split: fixed 20 nodes per class\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"72.88%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"PubMed with Public Split: fixed 20 nodes per class\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"80.06%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"PubMed with Public Split: fixed 20 nodes per class\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"82.84%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Cora with Public Split: fixed 20 nodes per"},{"Context":"Adversarial training for multi-context joint entity and relation extraction Adversarial training (AT) is a regularization method that can be used to improve the robustness of neural network methods by adding small perturbations in the training data. We show how to use AT for the tasks of entity recognition and relation extraction. In particular, we demonstrate that applying AT to a general purpose baseline model for jointly extracting entities and relations, allows improving the state-of-the-art effectiveness on several datasets in different contexts (i.e., news, biomedical, and real estate data) and for different languages (English and Dutch). We evaluate our models on four datasets, using the code as available from our github codebase 1 Specifically, we follow the 5-fold crossvalidation defined by for the ACE04 dataset We also evaluate our models on the NER task similar to in the same dataset using 10-fold cross validation For the Dutch Real Estate Classifieds, DREC (Bekoulis et al., 2017) dataset, we use train-test splits as in We use three types of evaluation, namely: (i) S(trict): we score an entity as correct if both the entity boundaries and the entity type are correct (ACE04, ADE, CoNLL04, DREC), (ii) B(oundaries): we score an entity as correct if only the entity boundaries are correct while the entity type is not taken into account (DREC) and (iii) R(elaxed): a multi-token entity is considered correct if at least one correct type is assigned to the tokens comprising the entity, assuming that the: Comparison of our method Table 1: Comparison of our method with the state- of-the-art in terms of F 1 score. The proposed mod- els are: (i) baseline, (ii) baseline EC (predicts only entity classes) and (iii) baseline (EC) + AT (reg- ularized by AT). The and symbols indicate whether the models rely on external NLP tools. We include different evaluation types (S, R and B). Entity Overall Relation","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"CoNLL04\\", \\"Metric\\": \\"NER Macro F1\\", \\"Score\\": \\"83.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"CoNLL04\\", \\"Metric\\": \\"RE+ Macro F1\\", \\"Score\\": \\"61.95\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"ADE Corpus\\", \\"Metric\\": \\"NER Macro F1\\", \\"Score\\": \\"86.73\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"ADE Corpus\\", \\"Metric\\": \\"RE+ Macro F1\\", \\"Score\\": \\"75.52\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"ACE 2004\\", \\"Metric\\": \\"NER Micro F1\\", \\"Score\\": \\"81.64\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"ACE 2004\\", \\"Metric\\": \\"RE+ Micro F1\\", \\"Score\\": \\"47.45\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"CoNLL04\\", \\"Metric\\": \\"NER Macro F1\\", \\"Score\\": \\"83.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"CoNLL04\\", \\"Metric\\": \\"RE+ Macro F1\\", \\"Score\\": \\"62.04\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"ADE Corpus\\", \\"Metric\\": \\"NER Macro F1\\", \\"Score\\": \\"86.40\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"ADE Corpus\\", \\"Metric\\": \\"RE+ Macro F1\\", \\"Score\\": \\"74.58\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"ACE 2004\\", \\"Metric\\": \\"NER Micro F1\\", \\"Score\\": \\"81.16\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"ACE 2004\\", \\"Metric\\": \\"RE+ Micro F1\\", \\"Score\\": \\"47.14\\"}} ]"},{"Context":"Negative Augmentation with Language Model for Reading Comprehension of Abstract Meaning This paper presents our systems for the three Subtasks of SemEval Task4: Reading Comprehension of Abstract Meaning (ReCAM). We explain the algorithms used to learn our models and the process of tuning the algorithms and selecting the best model. Inspired by the similarity of the ReCAM task and the language pre-training, we propose a simple yet effective technology, namely, negative augmentation with language model. Evaluation results demonstrate the effectiveness of our proposed approach. Our models achieve the 4th rank on both official test sets of Subtask 1 and Subtask 2 with an accuracy of 87.9% and an accuracy of 92.8%, respectively 1 . We further conduct comprehensive model analysis and observe interesting error cases, which may promote future researches.  Table 2: Statistics of the SemEval 2021 Task 4 dataset. 3 , 227 2 , 017 1 , 000 Subtask 2 2 , 025 Subtask 1 3 , 318 Table 3: Results (Accuracy) on Subtask 1. Ours Baseline - Dev Test Table 4: Results (Accuracy) on Subtask 2. Ours Baseline - Dev Test","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Reading Comprehension\\", \\"Dataset\\": \\"ReCAM\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"87.9/92.8\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"SemEval-Based Task 4 Sub Task 2\\", \\"Dataset\\": \\"SemEval-R Task 20\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"87.9%\\"}} ]"},{"Context":"Not All Pixels Are Equal: Difficulty-Aware Semantic Segmentation via Deep Layer Cascade We propose a novel deep layer cascade (LC) method to improve the accuracy and speed of semantic segmentation. Unlike the conventional model cascade (MC) that is composed of multiple independent models, LC treats a single deep model as a cascade of several sub-models. Earlier sub-models are trained to handle easy and confident regions, and they progressively feed-forward harder regions to the next sub-model for processing. Convolutions are only calculated on these regions to reduce computations. The proposed method possesses several advantages. First, LC classifies most of the easy regions in the shallow stage and makes deeper stage focuses on a few hard regions. Such an adaptive and \'difficulty-aware\' learning improves segmentation performance. Second, LC accelerates both training and testing of deep network thanks to early decisions in the shallow stage. Third, in comparison to MC, LC is an endto-end trainable framework, allowing joint learning of all sub-models. We evaluate our method on PASCAL VOC and Cityscapes datasets, achieving state-of-the-art performance and fast speed. We evaluate our method on the PASCAL VOC 2012 (VOC12) and Cityscapes datasets VOC12 dataset is a generic object segmentation benchmark with 21 classes Cityscapes dataset, on the other hand, focuses on street scenes segmentation and contains 19 categories We adopt mean intersection over union (mIoU) to evaluate the performance of different methods Table 1: Ablation study on probability thresholds \u03c1. Table 1 : Ablation study on probability thresholds Table 2: Comparisons with related methods. mIoU ( % ) Table 3: A comparison of performance and speed of Layer Cascade (LC) against existing methods. mIoU ms FPS Table 4: Per-class results on VOC12 test set. Approaches pre-trained on COCO [20] are marked with \u2020 . bus sofa tv chair mbike person plant cow bottle boat bike horse mIoU car areo bird cat dog table sheep train Table 5: Per-class results on Cityscapes test set. \\"sub\\" denotes whether the method used subsampling images for training. bus truck sign veg . person rider mbike bike mIoU road car swalk build . wall tlight terrain sky fence pole train Table 6: Comparisons with state-of-the-art methods on VOC12 test set. \'-\' indicates the corresponding information was not disclosed in the previous papers. IRNet - LC improves FPS of","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL VOC 2012 test\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"82.7%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"81.4%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL VOC 2012 test\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"86.9%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"78.5%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL VOC 2012 val\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"82.70%\\"}} ]"},{"Context":"Unraveling BitTorrent\'s File Unavailability: Measurements, Analysis and Solution Exploration BitTorrent suffers from one fundamental problem: the long-term availability of content. This occurs on a massivescale with 38% of torrents becoming unavailable within the first month. In this paper we explore this problem by performing two large-scale measurement studies including 46K torrents and 29M users. The studies go significantly beyond any previous work by combining per-node, per-torrent and system-wide observations to ascertain the causes, characteristics and repercussions of file unavailability. The study confirms the conclusion from previous works that seeders have a significant impact on both performance and availability. However, we also present some crucial new findings: (i) the presence of seeders is not the sole factor involved in file availability, (ii) 23.5% of nodes that operate in seedless torrents can finish their downloads, and (iii) BitTorrent availability is discontinuous, operating in cycles of temporary unavailability. Due to our new findings, we consider it is important to revisit the solution space; to this end, we perform large-scale trace-based simulations to explore the potential of two abstract approaches. To evaluate the two possible solutions approaches, the BitTorrent simulator of Bharambe et al Table 1. Characteristics of resilient torrents (those that maintain availability in seedless state) and susceptible torrents (those that cannot reconstruct the file). 1 affected ( micros - 2 ) 1 hour 24 hours Time before seedless state Susceptible Resilient 6 hours Time after torrent \' s birth Table 2. Overview about system-level results. ( in KBps ) S D S F Metric ( in % ) Avg . seeding time ( in hours )","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Refinement and Verification of Real-Time Systems \u2020 This paper discusses highly general mechanisms for specifying the refinement of a real-time system as a collection of lower level parallel components that preserve the timing and functional requirements of the upper level specification. These mechanisms are discussed in the context of ASTRAL, which is a formal specification language for real-time systems. Refinement is accomplished by mapping all of the elements of an upper level specification into lower level elements that maybe split among several parallel components. In addition, actions that can occur in the upper level are mapped to actions of components operating at the lower level. This allows several types of implementation strategies to be specified in a natural way, while the price for generality (in terms of complexity) is paid only when necessary. The refinement mechanisms are first illustrated using a simple digital circuit; then, through a highly complex phone system; finally, design guidelines gleaned from these specifications are presented.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Emotion Recognition in Conversation: Research Challenges, Datasets, and Recent Advances Emotion is intrinsic to humans and consequently emotion understanding is a key part of human-like artificial intelligence (AI). Emotion recognition in conversation (ERC) is becoming increasingly popular as anew research frontier in natural language processing (NLP) due to its ability to mine opinions from the plethora of publicly available conversational data in platforms such as Facebook, Youtube, Reddit, Twitter, and others. Moreover, it has potential applications in health-care systems (as a tool for psychological analysis), education (understanding student frustration) and more. Additionally, ERC is also extremely important for generating emotion-aware dialogues that require an understanding of the user\'s emotions. Catering to these needs calls for effective and scalable conversational emotion-recognition algorithms. However, it is a strenuous problem to solve because of several research challenges. In this paper, we discuss these challenges and shed light on the recent research in this field. We also describe the drawbacks of these approaches and discuss the reasons why they fail to successfully overcome the research challenges in ERC. In this section, we discuss the publicly available ERC datasets as well as the shortcomings of these datasets There area few publicly available datasets for ERC -IEMO-CAP, SEMAINE, Emotionlines, MELD, DailyDialog and EmoContext A detailed comparison of these datasets is drawn in Out of these five datasets, IEMOCAP, SEMAINE and MELD are multimodal (containing acoustic, visual and textual information) and the remaining two are textual Apart from SEMAINE dataset, rest of the 255) and power ([0, \u221e)) We also show the emotion label distribution of these datasets in In EmoContext dataset, an emotion label is assigned to only the last utterance of each dialogue None of these datasets can be used for emotion reasoning as they lack necessary annotation details required for the reasoning task Readers should also note that, all these datasets do not contain fine-grained and topic level emotion annotation","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Emotion Recognition in Conversation\\", \\"Dataset\\": \\"EC\\", \\"Metric\\": \\"Micro-F1\\", \\"Score\\": \\"0.758\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Emotion Recognition in Conversation\\", \\"Dataset\\": \\"MELD\\", \\"Metric\\": \\"Weighted Macro-F1\\", \\"Score\\": \\"65.21\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Emotion Recognition in Conversation\\", \\"Dataset\\": \\"IEMOCAP\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"65.28\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Emotion Recognition in Conversation\\", \\"Dataset\\": \\"EmoryNLP\\", \\"Metric\\": \\"Weighted Macro-F1\\", \\"Score\\": \\"34.73\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Emotion Recognition in Conversation\\", \\"Dataset\\": \\"DailyDialog\\", \\"Metric\\": \\"Weighted Macro-F1\\", \\"Score\\": \\"54.93\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Emotion Recognition in Conversation\\", \\"Dataset\\": \\"DailyDialog\\", \\"Metric\\": \\"Weighted Macro-F1\\", \\"Score\\": \\"58.84\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Emotion Recognition in Conversation\\", \\"Dataset\\": \\"DailyDialog\\", \\"Metric\\": \\"Weakly Supervised Macro-F1\\", \\"Score\\": \\"85.64\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Emotion Recognition in Conversation\\", \\"Dataset\\": \\"Da"},{"Context":"MultiFiT: Efficient Multi-lingual Language Model Fine-tuning Pretrained language models are promising particularly for low-resource languages as they only require unlabelled data. However, training existing models requires huge amounts of compute, while pretrained cross-lingual models often underperform on low-resource languages. We propose Multi-lingual language model Fine-Tuning (MultiFiT) to enable practitioners to train and fine-tune language models efficiently in their own language. In addition, we propose a zero-shot method using an existing pretrained cross-lingual model. We evaluate our methods on two widely used cross-lingual classification datasets where they outperform models pretrained on orders of magnitude more data and compute. We release all models and code 1 . Data We evaluate our models on the Multilingual Document Classification Corpus (MLDoc; product reviews in four languages We provide an overview of the datasets in In the supervised setting, every model is fine-tuned and evaluated on examples from the target language In the zero-shot setting, every model is fine-tuned on source language examples and evaluated on target language examples Baselines We compare against the state-ofthe-art cross-lingual embedding models LASER, which uses a large parallel corpus, multilingual BERT (MultiB- ERT) 10 , and monolingual BERT 11 We also compare against the best models on each dataset, Mul-tiCCA, a cross-lingual word embedding model, and BiDRL, which translates source and target data Our methods We evaluate our monolingual LMs in the supervised setting (MultiFit) and our LMs fine-tuned with pseudo labels from LASER in the zero-shot setting (pseudo forms the comparison methods as the shared embedding space between many languages is overly restrictive For Table 1: The domain, languages, and number of train- ing, development, and test examples in each dataset. Supervised ( 100 target language examples ) Supervised ( 1 , 000 target language examples ) Zero - shot ( 1 , 000 source language examples ) DE RU JA IT FR ES ZH Table 2: Comparison of zero-shot and supervised meth- ods on MLDoc. Supervised ( 100 target language examples ) Supervised ( 1 , 000 target language examples ) Zero - shot ( 1 , 000 source language examples ) DE RU JA IT FR ES ZH Table 3: Comparison of zero-shot, translation-based and supervised methods (with 2k training examples) on all domains of CLS. MT-BOW and CL-SCL results are from (Zhou et al., 2016). DE DVD Music JA Books FR Table 4: Comparison of LSTM and QRNN per-batch training speed on a Tesla V100 (in ms) in MultiFiT. 71 LSTM QRNN","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-Lingual Document Classification\\", \\"Dataset\\": \\"MLDoc Zero-Shot English-to-Japanese\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"69.57\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-Lingual Document Classification\\", \\"Dataset\\": \\"MLDoc Zero-Shot English-to-French\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"89.42\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-Lingual Document Classification\\", \\"Dataset\\": \\"MLDoc Zero-Shot English-to-Russian\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"67.83\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-Lingual Document Classification\\", \\"Dataset\\": \\"MLDoc Zero-Shot English-to-Chinese\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"82.48\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-Lingual Document Classification\\", \\"Dataset\\": \\"MLDoc Zero-Shot English-to-Spanish\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"79.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-Lingual Document Classification\\", \\"Dataset\\": \\"MLDoc Zero-Shot English-to-Italian\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"76.02\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-Lingual Document Classification\\", \\"Dataset\\": \\"MLDoc Zero-Shot English-to-German\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"91.62%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-lingualDocument Classification\\", \\"Dataset\\": \\"Multi-lingualDomain\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"74.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-lingualDocument Classification\\", \\"Dataset\\": \\"Multi-lingualDomain\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"74.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-lingualDocument Classification\\", \\"Dataset\\": \\"Multi-lingualDomain\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"77.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-lingualDocument Classification\\", \\"Dataset\\": \\"Multi-lingualDomain\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"76.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-lingualDocument Classification\\", \\"Dataset\\": \\"Multi-lingualDomain\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-lingualDocument Classification\\", \\"Dataset\\": \\"Multi-lingualDomain\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"96.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-lingualDocument Classification\\", \\"Dataset\\": \\"Multi-lingualDomain\\", \'Metric\'"},{"Context":"Monotony in Service Orchestrations Centre de recherche INRIA Rennes -Bretagne Atlantique IRISA, Campus universitaire de Beaulieu, 35042 Rennes Cedex Monotony in Service Orchestrations * Th\xe8me COM -Syst\xe8mes communicant\u015b Equipes-Projets Distribcom Rapport de recherche n 6528 - Monotonie dans les orchestrations de web services Web Service orchestrations are compositions of different Web Services to form anew service. The services called during the orchestration guarantee a given performance to the orchestrater, usually in the form of contracts. These contracts can be used by the orchestrater to deduce the contract it can offer to its own clients, by performing contract composition. An implicit assumption in contract based QoS management is: \\"the better the component services perform, the better the orchestration\'s performance will be\\". Thus, contract based QoS management for Web services orchestrations implicitly assumes monotony.In some orchestrations, however, monotony can be violated, i.e., the performance of the orchestration improves when the performance of a component service degrades. This is highly undesirable since it can render the process of contract composition inconsistent.In this paper we define monotony for orchestrations modelled by Colored Occurrence Nets (CO-nets) and we characterize the classes of monotonic orchestrations. We show that few orchestrations are indeed monotonic, mostly since latency can be traded for quality of data. We also propose a sound refinement of monotony, called conditional monotony, which forbids this kind of cheating and show that conditional monotony is widely satisfied by orchestrations. This finding leads to reconsidering the way SLAs should be formulated.R\xe9sum\xe9 : Les orchestrations de services web sont des compositions de services\xe9l\xe9mentaires. Ces services, fournissent un \'contrat\'\xe0 l\'orchestrateur, ce qui garantit une certaine performance de leur service. Ces contrats sont utilis\xe9s par l\'orchestrateur pour proposer un contrat\xe0 un client pour son propre service. Cela se fait par la \'compostion de contrats\'. Du point vue de la performance, la composition de contrats suppose implicitement que \\"L\'am\xe9lioration de la performance d\'un service va rendre l\'orchestration plus performante\\". La composition de contrats suppose ainsi que les orchestrations sont \\"monotones\\".Dans quelques orchestrations, cependant, la monotonie peut ne pas\xeatre respect\xe9e. Lorsque la performance d\'un service s\'am\xe9liore, la performance de l\'orchestration se d\xe9grade. Ceci est tr\xe8s g\xeanant car cela rend le processus de composition de contrats invalide. Dans ce rapport, nous d\xe9finissons la monotonie pour les orchestrations mod\xe9lis\xe9es par des r\xe9seaux d\'occurrence color\xe9s (CO-nets) et nous caract\xe9risons la classe des orchestrations monotones. Nous d\xe9montrons que tr\xe8s peu d\'orchestrations sont monotone en pratique, ce qui est largement d\xfb\xe0 la possibilit\xe9 d\'am\xe9liorer la latence en d\xe9gradant la qualit\xe9 de la r\xe9ponse donn\xe9. Nous proposons ensuite un raffinement de la monotonie, la \\"monotonie conditionnelle\\", qui interdit ce type de \'triche\'. Nous montrons que la monotonie conditionnelle est tr\xe8s g\xe9n\xe9ralement satisfaite par les orchestrations. Cette\xe9tude nous m\xe8ne\xe0 reconsid\xe9rer la formulation des contrats dans le cadre des orchestrations de services web.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Stochastic Power Grid Analysis Considering Process Variations In this paper, we investigate the impact of interconnect and device process variations on voltage fluctuations in power grids. We consider random variations in the power grid\'s electrical parameters as spatial stochastic processes and propose anew and efficient method to compute the stochastic voltage response of the power grid. Our approach provides an explicit analytical representation of the stochastic voltage response using orthogonal polynomials in a Hilbert space. The approach has been implemented in a prototype software called OPERA (Orthogonal Polynomial Expansions for Response Analysis). Use of OPERA on industrial power grids demonstrated speed-ups of up to two orders of magnitude. The results also show a significant variation of about \xb1 35% in the nominal voltage drops at various nodes of the power grids and demonstrate the need for variation-aware power grid analysis. If there are n random variables, the response expansion obtained by limiting the order top would be The error due to truncation is given by Once we have the truncated expansion from Equation, we need to evaluate the best deterministic coefficients {a i } that result in the best minimization of the truncation error Table 1. Results for grids from OPERA and Monte Carlo simulations for order 2 expansion 101 124 % MC 0 ) OPERA Max . % Error ( % of nominal Speedup CPU time Monte ( sec ) ( # nodes ) \xb1 3\u03c3 variation in \u03c3 in \xb5 OPERA ( sec ) Ave . % Error","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"A DYNAMIC REDUCTION NETWORK FOR POINT CLOUDS A PREPRINT Classifying whole images is a classic problem in machine learning, and graph neural networks area powerful methodology to learn highly irregular geometries. It is often the case that certain parts of a point cloud are more important than others when determining overall classification. On graph structures this started by pooling information at the end of convolutional filters, and has evolved to a variety of staged pooling techniques on static graphs. In this paper, a dynamic graph formulation of pooling is introduced that removes the need for predetermined graph structure. It achieves this by dynamically learning the most important relationships between data via an intermediate clustering.The network architecture yields interesting results considering representation size and efficiency. It also adapts easily to a large number of tasks from image classification to energy regression in high energy particle physics. 12","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Superpixel Image Classification\\", \\"Dataset\\": \\"75 Superpixel MNIST\\", \\"Metric\\": \\"Classification Error\\", \\"Score\\": \\"0.95\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"82.95\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"96.71\\"}} ]"},{"Context":"Voxel R-CNN: Towards High Performance Voxel-based 3D Object Detection Recent advances on 3D object detection heavily rely on how the 3D data are represented, i.e., voxel-based or point-based representation. Many existing high performance 3D detectors are point-based because this structure can better retain precise point positions. Nevertheless, point-level features lead to high computation overheads due to unordered storage. In contrast, the voxel-based structure is better suited for feature extraction but often yields lower accuracy because the input data are divided into grids. In this paper, we take a slightly different viewpoint -we find that precise positioning of raw points is not essential for high performance 3D object detection and that the coarse voxel granularity can also offer sufficient detection accuracy. Bearing this view in mind, we devise a simple but effective voxel-based framework, named Voxel R-CNN. By taking full advantage of voxel features in a two stage approach, our method achieves comparable detection accuracy with state-of-the-art point-based models, but at a fraction of the computation cost. Voxel R-CNN consists of a 3D backbone network, a 2D bird-eye-view (BEV) Region Proposal Network and a detect head. A voxel RoI pooling is devised to extract RoI features directly from voxel features for further refinement. Extensive experiments are conducted on the widely used KITTI Dataset and the more recent Waymo Open Dataset. Our results show that compared to existing voxel-based methods, Voxel R-CNN delivers a higher detection accuracy while maintaining a realtime frame processing rate, i.e., at a speed of 25 FPS on an NVIDIA RTX 2080 Ti GPU. The code is available at https://github.com/djiajunustc/Voxel-R-CNN. We evaluate our Voxel R-CNN on KITTI Dataset following the common protocol to report the average precision (AP) of class Car with the 0.7 (IoU) threshold And the results evaluated by the test server utilize AP setting of recall 40 positions 1 The AP for 3D object detection and BEV object detection of our Voxel R-CNN on KITTI Dataset is presented in We also conduct experiments on the larger Waymo Open Dataset to further validate the effectiveness of our proposed Voxel R-CNN The objects on the Waymo Open Dataset are split into two levels based on the number of points of a single object, where the LEVEL 1 objects have more than 5 points while the LEVEL 2 objects have 1\u223c5 points We evaluate our Voxel R-CNN on both LEVEL 1 and LEVEL 2 objects and compare with several top-performing methods on the Waymo Open Dataset Specifically, with the commonly used Table 1: Performance comparison for adding BEV detect head on the top of SECOND. These results are evaluated on the KITTI val set with average precision calculated by 11 recall positions for car class. recall positions for car class . Methods Mod . Easy 2D backbone VSA Hard 3D backbone Detect head AP3D ( % ) Table 2: Running time comparison for each component in PV-RCNN. This result is calculated by the average over the 3,769 samples in the KITTI val set. recall positions for car class . Methods Mod . Easy 2D backbone VSA Hard 3D backbone Detect head AP3D ( % ) Table 4: Performance of Voxel R-CNN on the KITTI val set with AP calculated by 40 recall positions for car class LEVEL 2 BEV mAP ( IoU=0 . 7 ) : 2 the methods . By taking full advantage of voxel - based rep - LEVEL 2","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Hard\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"77.06%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Moderate val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"84.52\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Easy val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"89.41\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Easy\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"90.9%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Hard val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"78.93\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Moderate\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"81.62%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Moderate val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"76.82%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Easy val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"90.25%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cyclists Easy val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"57.44%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Pedestrians Moderate val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"44.24%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cars Moderate val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"82.69\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"KITTI Cyclists Easy val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"84.32%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection"},{"Context":"Th \\" emes COM et COG et SYM et NUM et BIO Computing a Finite Size Representation of the Set of Approximate Solutions of an MOP Computing a Finite Size Representation of the Set of Approximate Solutions of an MOP * Th\xe8mes COM et COG et SYM et NUM et BIO -Syst\xe8mes communicants et Syst\xe8mes cognitifs et Syst\xe8mes symboliques et Syst\xe8mes num\xe9riques et Syst\xe8mes biologiques Projets Apics et Op\xe9ra Computing a Finite Size Representation of the Set of Approximate Solutions of an MOP Recently, a framework for the approximation of the entire set of \u01eb-efficient solutions (denote by E \u01eb ) of a multi-objective optimization problem with stochastic search algorithms has been proposed. It was proven that such an algorithm produces -under mild assumptions on the process to generate new candidate solutions -a sequence of archives which converges to E \u01eb in the limit and in the probabilistic sense. The result, though satisfactory for most discrete MOPs, is at least from the practical viewpoint not sufficient for continuous models: in this case, the set of approximate solutions typically forms an n-dimensional object, where n denotes the dimension of the parameter space, and thus, it may come to perfomance problems since in practise one has to cope with a finite archive. Here we focus on obtaining finite and tight approximations of E \u01eb , the latter measured by the Hausdorff distance. We propose and investigate a novel archiving strategy theoretically and empirically. For this, we analyze the convergence behavior of the algorithm, yielding bounds on the obtained approximation quality as well as on the cardinality of the resulting approximation, and present some numerical results.R\xe9sum\xe9 : Dans des travaux pr\xe9c\xe9dent, nous avons propos\xe9 un environnement (\\"framework\\") pour l\\"approximation de l\'int\xe9gralit\xe9 de l\'ensemble des solutions \u01eb-efficaces (not\xe9 E \u01eb ) d\'un probl\xe8me d\'optimisation multi-objectifs\xe0 l\'aide d\'une recherche stochastique. Il a\xe9t\xe9 prouv\xe9 que suivant certaines hypoth\xe8ses relatives au processus de g\xe9n\xe9ration de nouvelles solutions candidates, un tel algorithme produit une s\xe9quence d\'archives qui converge asymptotiquement vers E \u01eb , au sens probabiliste du terme. Le r\xe9sultat, s\'il est satisfaisant pour la plupart des MOP discrets, ne l\'est pas d\'un point de vue pratique pour les probl\xe8mes continus. Dans ce dernier cas, l\'ensemble des solutions approxim\xe9es forme un objet\xe0 n dimentions, o\xf9 nest la dimension de l\'espace des param\xe8tres. Ceci peut amener\xe0 des probl\xe8mes de performances puisqu\'en pratique la taille de l\'archive est finie.Dans le travail pr\xe9sent\xe9, nous nous concentrons sur l\'obtention d\'approximations finies et pr\xe9cises de E \u01eb qui est mesur\xe9 par la distance de Hausdorff. Nous proposons et nous\xe9tudions une nouvelle strat\xe9gie d\'archivage des points de vue th\xe9orique et pratique. Pour ce faire, nous analysons le comportement asymptotique de l\'algorithme, en fournissant les limites de qualit\xe9 de l\'approximation obtenue, aussi bien que la cardinalit\xe9 de l\'approximation et nous pr\xe9sentons\xe9galement quelques r\xe9sultats num\xe9riques.optimisation multi-objectif, convergence, solutions \u01eb-efficaces, solutions approwim\xe9es, algorithmes de recherche stochastique.Representing the \u01eb-Efficient Set of an MOP  Table 1: Comparison of the magnitudes of the final archive (|A f inal |, rounded) and the corresponding update times (T , in seconds) for MOP (38) and for different values of \u2206. We have taken the average result of 100 test runs. \u2206 |A f inal | T 0 3836 32.98 0.01 827 6.22 0.05 68 1.80 have taken the average result of 100 test runs . T \u2206 Comparison of the magnitudes of the final archive ( |A Table 2: .. x","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Bringing Alive Blurred Moments We present a solution for the goal of extracting a video from a single motion blurred image to sequentially reconstruct the clear views of a scene as beheld by the camera during the time of exposure. We first learn motion representation from sharp videos in an unsupervised manner through training of a convolutional recurrent video autoencoder network that performs a surrogate task of video reconstruction. Once trained, it is employed for guided training of a motion encoder for blurred images. This network extracts embedded motion information from the blurred image to generate a sharp video in conjunction with the trained recurrent video decoder. As an intermediate step, we also design an efficient architecture that enables real-time single image deblurring and outperforms competing methods across all factors: accuracy, speed, and compactness. Experiments on real scenes and standard datasets demonstrate the superiority of our framework over the state-of-the-art and its ability to generate a plausible sequence of temporally consistent sharp frames.  Table 1. Performance comparison of our deblurring network with existing methods on the benchmark dataset [ 23 ] [ 34 ] [ 33 ] Ours [ 42 ] [ 18 ] [ 39 ] [ 7 ]","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Deblurring\\", \\"Dataset\\": \\"GoPro\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"30.58\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Deblurring\\", \\"Dataset\\": \\"GoPro\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.941\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Deblurring\\", \\"Dataset\\": \\"GoPro\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"31.79\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Deblurring\\", \\"Dataset\\": \\"GoPro\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.949\\"}} ]"},{"Context":"Fast Neural Architecture Search of Compact Semantic Segmentation Models via Auxiliary Cells Automated design of neural network architectures tailored fora specific task is an extremely promising, albeit inherently difficult, avenue to explore. While most results in this domain have been achieved on image classification and language modelling problems, here we concentrate on dense per-pixel tasks, in particular, semantic image segmentation using fully convolutional networks. In contrast to the aforementioned areas, the design choices of a fully convolutional network require several changes, ranging from the sort of operations that need to be used-e.g., dilated convolutions-to a solving of a more difficult optimisation problem. In this work, we are particularly interested in searching for high-performance compact segmentation architectures, able to run in real-time using limited resources. To achieve that, we intentionally over-parameterise the architecture during the training time via a set of auxiliary cells that provide an intermediate supervisory signal and can be omitted during the evaluation phase. The design of the auxiliary cell is emitted by a controller, a neural network with the fixed structure trained using reinforcement learning. More crucially, we demonstrate how to efficiently search for these architectures within limited time and computational budgets. In particular, we rely on a progressive strategy that terminates non-promising architectures from being further trained, and on Polyak averaging coupled with knowledge distillation to speed-up the convergence. Quantitatively, in 8 GPU-days our approach discovers a set of architectures performing on-par with stateof-the-art among compact models on the semantic segmentation, pose estimation and depth prediction tasks. Code will be made available here: https://github.com/ drsleep/nas-segm-pytorch  Table 3. Among other compact real-time networks, we achieve significantly better results across all the metrics without any additional tricks. Note also that the work in \u2212 arch2 CReaM [ 40 ] Ours arch0 arch1 RF - LW [ 27 ]","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Monocular Depth Estimation\\", \\"Dataset\\": \\"NYU-Depth V2\\", \\"Metric\\": \\"RMSE\\", \\"Score\\": \\"0.523\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Monocular Depth Estimation\\", \\"Dataset\\": \\"NYU-Depth V2\\", \\"Metric\\": \\"RMSE\\", \\"Score\\": \\"0.525\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Monocular Depth Estimation\\", \\"Dataset\\": \\"NYU-Depth V2\\", \\"Metric\\": \\"RMSE\\", \\"Score\\": \\"0.526\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL VOC 2012 val\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"78.0%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL VOC 2012 val\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"77.3%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL VOC 2012 val\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"77.1%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Tityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"82.6%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL Context\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"61.7\\"}} ]"},{"Context":"POLY-GAN: MULTI-CONDITIONED GAN FOR FASHION SYNTHESIS A PREPRINT We present Poly-GAN, a novel conditional GAN architecture that is motivated by Fashion Synthesis, an application where garments are automatically placed on images of human models at an arbitrary pose. Poly-GAN allows conditioning on multiple inputs and is suitable for many tasks, including image alignment, image stitching and inpainting. Existing methods have a similar pipeline where three different networks are used to first align garments with the human pose, then perform stitching of the aligned garment and finally refine the results. Poly-GAN is the first instance where a common architecture is used to perform all three tasks. Our novel architecture enforces the conditions at all layers of the encoder and utilizes skip connections from the coarse layers of the encoder to the respective layers of the decoder. Poly-GAN is able to perform a spatial transformation of the garment based on the RGB skeleton of the model at an arbitrary pose. Additionally, Poly-GAN can perform image stitching, regardless of the garment orientation, and inpainting on the garment mask when it contains irregular holes. Our system achieves state-of-the-art quantitative results on Structural Similarity Index metric and Inception Score metric using the DeepFashion dataset. * Use footnote for providing further information about author (webpage, alternative address)-not for acknowledging funding agencies. while creating our training and testing datasets from the publicly available DeepFashion dataset Liu et al. We have 14,221 training samples, as in the VITON dataset, and 900 paired samples for testing our method which are widely accepted metrics for evaluation of images generated by GANs Since the code for CP-VTON is publicly released WangB et al., we are able to obtain results on our dataset for comparison We perform our evaluation on test data that consist of 900 paired images This limitation can be overcome by using a larger and more diverse dataset for training For qualitative evaluation, we also present images that were randomly generated with StyleGAN in Table 1: Fashion Synthesis Quantitative Results. Bold numbers indicate best performance. SSIM Metric IS","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Virtual Try-on\\", \\"Dataset\\": \\"Deep-Fashion\\", \\"Metric\\": \\"IS\\", \\"Score\\": \\"2.7904\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Virtual Try-on\\", \\"Dataset\\": \\"Deep-Fashion\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.7251\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Inpainting\\", \\"Dataset\\": \\"RealBl\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"7.73\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Inpainting\\", \\"Dataset\\": \\"RealBl\\", \\"Metric\\": \\"Inception score\\", \\"Score\\": \\"8.12\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Inpainting\\", \\"Dataset\\": \\"RealBl\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.59\\"}} ]"},{"Context":"Sparse and noisy LiDAR completion with RGB guidance and uncertainty This work proposes anew method to accurately complete sparse LiDAR maps guided by RGB images. For autonomous vehicles and robotics the use of LiDAR is indispensable in order to achieve precise depth predictions. A multitude of applications depend on the awareness of their surroundings, and use depth cues to reason and react accordingly. On the one hand, monocular depth prediction methods fail to generate absolute and precise depth maps. On the other hand, stereoscopic approaches are still significantly outperformed by LiDAR based approaches. The goal of the depth completion task is to generate dense depth predictions from sparse and irregular point clouds which are mapped to a 2D plane. We propose anew framework which extracts both global and local information in order to produce proper depth maps. We argue that simple depth completion does not require a deep network. However, we additionally propose a fusion method with RGB guidance from a monocular camera in order to leverage object information and to correct mistakes in the sparse input. This improves the accuracy significantly. Moreover, confidence masks are exploited in order to take into account the uncertainty in the depth predictions from each modality. This fusion method outperforms the state-of-the-art and ranks first on the KITTI depth completion benchmark [21]. Our code with visualizations is available at https: // github. com/ wvangansbeke/ Sparse-Depth-Completion . We evaluate our framework by computing the loss on all pixels of the ground truth since not all input pixels of the Li-DAR are correct The KITTI dataset provides 85898 frames for training, 1000 frames for evaluation and 1000 frames for testing Table 1. Hourglass network. Filters Table 2. Ablation study on KITTI\'s selected val- idation set. 3223 1473 RMSE [ mm ] MAE [ mm ] Table 3. Comparison with state-of-the-art on the testset based on RMSE[mm], MAE[mm] and t[s]. MAE t RMSE","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Depth Completion\\", \\"Dataset\\": \\"KITTI Depth Completion\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"215.02\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Depth Completion\\", \\"Dataset\\": \\"KITTI Depth Completion\\", \\"Metric\\": \\"RMSE\\", \\"Score\\": \\"772.87\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Depth Completion\\", \\"Dataset\\": \\"KITTI Depth Completion\\", \\"Metric\\": \\"Runtime [ms]\\", \\"Score\\": \\"20\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Depth Completion\\", \\"Dataset\\": \\"KITTI Depth Completion\\", \\"Metric\\": \\"iMAE\\", \\"Score\\": \\"0.93\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Depth Completion\\", \\"Dataset\\": \\"KITTI Depth Completion\\", \\"Metric\\": \\"iRMSE\\", \\"Score\\": \\"2.19\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Depth Completion\\", \\"Dataset\\": \\"KITTI Depth Completion\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"749.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Depth Completion\\", \\"Dataset\\": \\"KITTI Depth Completion\\", \\"Metric\\": \\"RMSE\\", \\"Score\\": \\"8.2\\"}} ]"},{"Context":"An Efficient Admission Control Algorithm for Load Balancing In Hierarchical Mobile IPv6 Networks Anchor Point (MAP) may become a single point of bottleneck as it handles more and more mobile nodes (MNs). A number of schemes have been proposed to achieve load balancing among different MAPs. However, signaling reduction is still imperfect because these schemes also avoid the effect of the number of CN\'s. Also only the balancing of MN is performed, but not the balancing of the actual traffic load, since CN of each MN maybe different. This paper proposes an efficient admission control algorithm along with a replacement mechanism for HMIPv6 networks. The admission control algorithm is based on the number of serving CNs and achieves actual load balancing among MAPs. Moreover, a replacement mechanism is introduced to decrease the new MN blocking probability and the handoff MN dropping probability. By simulation results, we show that, the handoff delay and packet loss are reduced in our scheme, when compared with the standard HMIPv6 based handoff.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Rotation Equivariant CNNs for Digital Pathology We propose anew model for digital pathology segmentation, based on the observation that histopathology images are inherently symmetric under rotation and reflection. Utilizing recent findings on rotation equivariant CNNs, the proposed model leverages these symmetries in a principled manner. We present a visual analysis showing improved stability on predictions, and demonstrate that exploiting rotation equivariance significantly improves tumor detection performance on a challenging lymph node metastases dataset. We further present a novel derived dataset to enable principled comparison of machine learning models, in combination with an initial benchmark. Through this dataset, the task of histopathology diagnosis becomes accessible as a challenging benchmark for fundamental machine learning research. * Equal contribution. To evaluate the proposed model, we use Camelyon16 and PCam (1) The Camelyon16 dataset contains 400 H&E stained WSIs of sentinel lymph node sections split into 270 slides with pixel-level annotations for training and 130 unlabeled slides for testing In the Camelyon16 challenge, model performance is evaluated using the FROC curve for tumor localization (2) The PCam dataset contains 327,680 patches extracted from Camelyon16 at a size of 96 \xd7 96 pixels @ 10\xd7 magnification, with a 75/12.5/12.5% train/validate/test split, selected using a hard-negative mining regime 1 (3) The BreakHis dataset contains 7909 H&E stained microscopy images at a size of 700 \xd7 460 pixels We limit our evaluation to the images at 4\xd7 magnification, for which previous approaches have reported the highest accuracy For the evaluation on the WSI-level Camelyon16 benchmarks, we largely follow the pipeline proposed in, uniformly sampling WSIs and drawing tumor/nontumor patches with equal probability We focus Table 1: Performance on PCam, measured by negative log-likelihood, accuracy and AUC. Experiments with additional data augmentation with 90 \u2022 rotations and reflections are marked by +. M indicates matching number of Z 2 maps, #W number of weights, K number of Z 2 maps per layer. Acc NLL AUC DenseNet 90 80 70 60 50 40 FROC 100 70 Data P4M - DenseNet","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Breast Tumour Classification\\", \\"Dataset\\": \\"PCam\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.963\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Medical Image Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"PQ\\", \\"Score\\": \\"47.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Medical Image Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"PQst\\", \\"Score\\": \\"11.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Medical Image Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"PQth\\", \\"Score\\": \\"0.56\\"}} ]"},{"Context":"Continual Occlusions and Optical Flow Estimation Two optical flow estimation problems are addressed: i) occlusion estimation and handling, and ii) estimation from image sequences longer than two frames. The proposed ContinualFlow method estimates occlusions before flow, avoiding the use of flow corrupted by occlusions for their estimation. We show that providing occlusion masks as an additional input to flow estimation improves the standard performance metric by more than 25% on both KITTI and Sintel. As a second contribution, a novel method for incorporating information from past frames into flow estimation is introduced. The previous frame flow serves as an input to occlusion estimation and as a prior in occluded regions, i.e. those without visual correspondences. By continually using the previous frame flow, ContinualFlow performance improves further by 18% on KITTI and 7% on Sintel, achieving top performance on KITTI and Sintel. The ContinualFlow network is trained using a curriculum learning approach starting from a dataset with less complex motions and increasing gradually the task complexity First, we train on FlyingChairs dataset using the training parameters introduced in and following the learning rate schedule from Since the FlyingChairs dataset contains only two frames sequences and no occlusion ground truth, we cannot train the full ContinualFlow model with temporal connections and the occlusion map estimation Next, the all parts of the ContinualFlow network are trained on the Fly-ingThings dataset Since occlusion maps were not available for this dataset, we computed them using the available backward and forward ground truth flows and the object segmentation masks Finally, the ContinualFlow is trained on data from six datasets: Driving, KITTI\'15, VirtualKITTI, Sintel, HD1K and the FlyingChairs small motions dataset These datasets, except for FlyingChairs, contain sequences longer than two frames and are suitable for the training of Table 1: Ablation study of ContinualFlow. The leftmost column codes the experiment configurations: occlusion estimator (+OC); refinement network (+R); temporal connection with forward warping (W f ), backward warping (W b ) and both warping methods (W bf ); previous flow input in the refinement (RW x ); and two pass (2pass) initialisation of the first frame of the sequence N frames long. Performance measure are the KITTI 3-pixel error metric (column Fl) and the end-point error (in pixels, all other columns) for background (bg), fore- ground (fg), occluded (occ), non-occluded (noc) and all (all) pixels. The best performance in bold. All models trained on FlyingChairs and fine-tuned on Fly- ingThings. See section 3 for details. all Sintel Clean Influence of coordinate warping methods noc Occlusion map learning common : baseline The specialised refinement block Number of refinement blocks occ - bg occ - fg noc - bg noc - fg","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Optical Flow Estimation\\", \\"Dataset\\": \\"Sintel-final\\", \\"Metric\\": \\"Average End-Point Error\\", \\"Score\\": \\"4.52\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Optical Flow Estimation\\", \\"Dataset\\": \\"Sintel-clean\\", \\"Metric\\": \\"Average End-Point Error\\", \\"Score\\": \\"3.52\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Optical Flow Estimation\\", \\"Dataset\\": \\"Sintel-final\\", \\"Metric\\": \\"Average End-Point Error\\", \\"Score\\": \\"4.01\\"}} ]"},{"Context":"Iterative Context-Aware Graph Inference for Visual Dialog Visual dialog is a challenging task that requires the comprehension of the semantic dependencies among implicit visual and textual contexts. This task can refer to the relation inference in a graphical model with sparse contexts and unknown graph structure (relation descriptor), and how to model the underlying context-aware relation inference is critical. To this end, we propose a novel Context-Aware Graph (CAG) neural network. Each node in the graph corresponds to a joint semantic feature, including both objectbased (visual) and history-related (textual) context representations. The graph structure (relations in dialog) is iteratively updated using an adaptive top-K message passing mechanism. Specifically, in every message passing step, each node selects the most K relevant nodes, and only receives messages from them. Then, after the update, we impose graph attention on all the nodes to get the final graph embedding and infer the answer. In CAG, each node has dynamic relations in the graph (different related K neighbor nodes), and only the most relevant nodes are attributive to the context-aware relational graph inference. Experimental results on VisDial v0.9 and v1.0 datasets show that CAG outperforms comparative methods. Visualization results further validate the interpretability of our method. Datasets Table 1. Ablation studies of different iterative steps T and the main components on VisDial val v0.9. features . Our model with VGG features is denoted as CAG - VGG . As shown in Table 1 , compared with CAG , CAG w / o relational reasoning . Learning the implicit relations among Graph - based Models CAG Attention - based Models s , CAG removes the whole dynamic directed - graph inference MRR\u2191 R@1 Mean\u2193 R@10\u2191 R@5 Top8 Top16 Top36 R@1\u2191 R@10 MRR R@5\u2191 Main Component Comparison . A few variants are pro - the nodes is helpful to predict the final answer . CAG w / o Infer denotes that of T = 3 already performs well . In the following experi - Top2 Top1 posed for ablation study . CAG w / o Q - att , which replaces ques - Table 2. Performance comparison on VisDial val","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.6756\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"Mean Rank\\", \\"Score\\": \\"3.75\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"54.64\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@10\\", \\"Score\\": \\"91.48\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@5\\", \\"Score\\": \\"83.72\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"Visual Dialog v1.0 test-std\\", \\"Metric\\": \\"MRR (x 100)\\", \\"Score\\": \\"63.49\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"Visual Dialog v1.0 test-std\\", \\"Metric\\": \\"Mean\\", \\"Score\\": \\"4.11\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"Visual Dialog v1.0 test-std\\", \\"Metric\\": \\"NDCG (x 100)\\", \\"Score\\": \\"56.64\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"Visual Dialog v1.0 test-std\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"49.85\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"Visual Dialog v1.0 test-std\\", \\"Metric\\": \\"R@10\\", \\"Score\\": \\"90.15\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"Visual Dialog v1.0 test-std\\", \\"Metric\\": \\"R@5\\", \\"Score\\": \\"80.63\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.6285\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"Mean Rank\\", \\"Score\\": \\"4.57\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"48.95\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@10\\", \\"Score\\": \\"88.36\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"VisDial v0.9 val\\", \\"Metric\\": \\"R@5\\", \\"Score\\": \\"79.65\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"Visual Dialog v1.0 test-std\\", \\"Metric\\": \\"MRR (x 100)\\", \\"Score\\": \\"61.37\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Dialog\\", \\"Dataset\\": \\"Visual Dialog v"},{"Context":"Open Question Answering with Weakly Supervised Embedding Models Building computers able to answer questions on any subject is along standing goal of artificial intelligence. Promising progress has recently been achieved by methods that learn to map questions to logical forms or database queries. Such approaches can be effective but at the cost of either large amounts of human-labeled data or by defining lexicons and grammars tailored by practitioners. In this paper, we instead take the radical approach of learning to map questions to vectorial feature representations. By mapping answers into the same space one can query any knowledge base independent of its schema, without requiring any grammar or lexicon. Our method is trained with anew optimization procedure combining stochastic gradient descent followed by a fine-tuning step using the weak supervision provided by blending automatically and collaboratively generated resources. We empirically demonstrate that our model can capture meaningful signals from its noisy supervision leading to major improvements over paralex, the only existing method able to be trained on similar weakly labeled data. In this last experimental section, we tend to evaluate how generic our learned system is To this end, we propose to ask our model to answer questions coming from another dataset from the literature, but without retraining it with labeled data, just by directly using the parameters learned on WikiAnswers+ReVerb Still, fora system trained with almost no manual annotation nor prior information on another dataset, with another -very noisy-KB, the results can be seen as particularly promising Besides, evaluation is broad since, in ReVerb, most entities actually appear many times under different names as explained in Section 3 Hence, there might be higher ranked answers but they are missed by our evaluation script Table 3. Performance of variants of our embedding models and Paralex [10] for rerank- ing question-answer pairs from the WikiAnswers+ReVerb test set. F1 Prec Recall MAP Table 4. Performance of our embedding model for retrieving answers for questions from the WikiAnswers+ReVerb test set, among the whole ReVerb KB (14M candidates). F1 Table 6. Performance of our embedding model for retrieving answers for questions from the WebQuestions test set, among the whole ReVerb KB (14M candidates). Top - 1 Top - 10 F1","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"WebQuestions\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"29.7%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"Reverb\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"73%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"Weakly-supervised\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"76.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"Weakly-supervised\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"80.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"Weakly-supervised\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"74.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"Weakly-supervised\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"80.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"Weakly-supervised\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"68.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"Weakly-supervised\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"76.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"Weakly-supervised\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"75.4\\"}}, { \'LEADERBOARD\'"},{"Context":"MAGNN: Metapath Aggregated Graph Neural Network for Heterogeneous Graph Embedding A large number of real-world graphs or networks are inherently heterogeneous, involving a diversity of node types and relation types. Heterogeneous graph embedding is to embed rich structural and semantic information of a heterogeneous graph into low-dimensional node representations. Existing models usually define multiple metapaths in a heterogeneous graph to capture the composite relations and guide neighbor selection. However, these models either omit node content features, discard intermediate nodes along the metapath, or only consider one metapath. To address these three limitations, we propose anew model named Metapath Aggregated Graph Neural Network (MAGNN) to boost the final performance. Specifically, MAGNN employs three major components, i.e., the node content transformation to encapsulate input node attributes, the intra-metapath aggregation to incorporate intermediate semantic nodes, and the inter-metapath aggregation to combine messages from multiple metapaths. Extensive experiments on three real-world heterogeneous graph datasets for node classification, node clustering, and link prediction show that MAGNN achieves more accurate prediction results than state-of-the-art baselines. How do we understand the representation capability of different graph embedding methods? We adopt three widely used heterogeneous graph datasets from different domains to evaluate the performance of MAGNN as compared to state-of-the-art baselines Specifically, the IMDb and DBLP datasets are used in the experiments for node classification and node clustering The Last.fm dataset is used in the experiments for link prediction Simple statistics of the three datasets are summarized in, and network schemas are illustrated in We assign one-hot id vectors to nodes with no attributes as their dummy input features.: Network schemas of the three heterogeneous graph datasets used in this paper We adopt a dataset released by HetRec 2011, consisting of 1892 users, 17632 artists, and 1088 artist tags after data preprocessing This dataset is used for the link prediction task, and no label or feature is included in this dataset Table 3: Experiment results (%) on the IMDb and DBLP datasets for the node classification task. Train % ESim Semi - supervised GCN HERec HAN node2vec LINE MAGNN Unsupervised metapath2vec GAT Table 4: Experiment results (%) on the IMDb and DBLP datasets for the node clustering task. Metrics ESim Semi - supervised GCN HERec HAN node2vec LINE MAGNN Unsupervised metapath2vec GAT Table 5: Experiment results (%) on the Last.fm dataset for the link prediction task. ESim GCN HERec HAN node2vec GATNE LINE MAGNN metapath2vec GAT Table 6: Quantitative results (%) for ablation study. Variant IMDb Macro - F1 N / A ARI Last . fm NMI DBLP Micro - F1 AUC AP","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"Last.FM\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"98.93\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"Last.FM\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"98.91\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"DBLP\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"84.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"DBLP\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"DBLP\\", \\"Metric\\": \\"Macro F1\\", \\"Score\\": \\"83.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"DBLP\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"81.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"DBLP\\", \\"Metric\\": \\"Macro F1\\", \\"Score\\": \\"69.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"DBLP\\", \\"Metric\\": \\"Macro F1\\", \\"Score\\": \\"73.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"DBLP\\", \\"Metric\\": \\"Macro F1\\", \\"Score\\": \\"75.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction"},{"Context":"End-to-End Object Detection with Transformers We present anew method that views object detection as a direct set prediction problem. Our approach streamlines the detection pipeline, effectively removing the need for many hand-designed components like a non-maximum suppression procedure or anchor generation that explicitly encode our prior knowledge about the task. The main ingredients of the new framework, called DEtection TRansformer or DETR, area set-based global loss that forces unique predictions via bipartite matching, and a transformer encoder-decoder architecture. Given a fixed small set of learned object queries, DETR reasons about the relations of the objects and the global image context to directly output the final set of predictions in parallel. The new model is conceptually simple and does not require a specialized library, unlike many other modern detectors. DETR demonstrates accuracy and run-time performance on par with the well-established and highly-optimized Faster R-CNN baseline on the challenging COCO object detection dataset. Moreover, DETR can be easily generalized to produce panoptic segmentation in a unified manner. We show that it significantly outperforms competitive baselines. Training code and pretrained models are available at https://github.com/facebookresearch/detr. We show that DETR achieves competitive results compared to Faster R-CNN in quantitative evaluation on COCO We perform experiments on COCO 2017 detection and panoptic segmentation datasets, containing 118k training images and 5k validation images Table 1: Comparison with Faster R-CNN with a ResNet-50 and ResNet-101 backbones on the COCO validation set. The top section shows results for Faster R-CNN models in Detectron2 [50], the middle section shows results for Faster R-CNN models with GIoU [38], random crops train-time augmentation, and the long 9x training schedule. DETR models achieve comparable results to heavily tuned Faster R-CNN baselines, having lower APS but greatly improved APL. We use torchscript Faster R-CNN and DETR models to measure FLOPS and FPS. Results without R101 in the name corre- spond to ResNet-50. longer schedule used to compare with Faster R - CNN we train for 500 epochs AP50 AP75 APS APM APL AP Table 2: Effect of encoder size. Each row corresponds to a model with varied number of encoder layers and fixed number of decoder layers. Performance gradually improves with more encoder layers. AP50 APS #params APL APM AP Table","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"33\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"PQ\\", \\"Score\\": \\"45.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"PQst\\", \\"Score\\": \\"37\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"PQth\\", \\"Score\\": \\"50.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"RQ\\", \\"Score\\": \\"55.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"RQst\\", \\"Score\\": \\"46\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"RQth\\", \\"Score\\": \\"61.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"SQ\\", \\"Score\\": \\"79.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"SQst\\", \\"Score\\": \\"78.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"SQth\\", \\"Score\\": \\"80.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"39.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"PQ\\", \\"Score\\": \\"44.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"PQst\\", \\"Score\\": \\"33.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"PQth\\", \\"Score\\": \\"51.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"RQ\\", \\"Score\\": \\"53.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"RQst\\", \\"Score\\": \\"42.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"RQth\\", \\"Score\\": \\"60.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"SQ\\", \\"Score\\": \\"79.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"SQst\\", \\"Score\\": \\"74.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO panoptic\\", \\"Metric\\": \\"SQth\\", \\"Score\\": \\"83.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"64.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"47.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"62.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"49.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"23.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"44.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"63.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"47.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"56\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"48.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"27.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"44\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"PQ\\", \\"Score\\": \\"48.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"PQst\\", \\"Score\\": \\"38.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"PQth\\", \\"Score\\": \\"52.0\\"}} ]"},{"Context":"Parallelizing Legendre Memory Unit Training Recently, anew recurrent neural network (RNN) named the Legendre Memory Unit (LMU) was proposed and shown to achieve state-of-the-art performance on several benchmark datasets. Here we leverage the linear time-invariant (LTI) memory component of the LMU to construct a simplified variant that can be parallelized during training (and yet executed as an RNN during inference), thus overcoming a well known limitation of training RNNs on GPUs. We show that this reformulation that aids parallelizing, which can be applied generally to any deep network whose recurrent components are linear, makes training up to 200 times faster. Second, to validate its utility, we compare its performance against the original LMU and a variety of published LSTM and transformer networks on seven benchmarks, ranging from psMNIST to sentiment analysis to machine translation. We demonstrate that our models exhibit superior performance on all datasets, often using fewer parameters. For instance, our LMU sets anew state-of-the-art result on psMNIST, and uses half the parameters while outperforming Dis-tilBERT and LSTM models on IMDB sentiment analysis.  Table 2. psMNIST results. The first three rows are from Voelker et al. (2019), and the fourth row is from Gu et al. (2020). results . Accuracy Table 3 . Mackey - Glass Table 3. Mackey-Glass results. NRMSE Table 4. IMDB, QQP and SNLI results. IMDB result is from 86 . 95 / 85 . 36 82 . 58 / 81 . 4 LSTM 1201 ) . Param . Acc . Our Model Table 5. IMDB results with pre-training. First row is from Radford et al. (2017), and the second row is from Sanh et al. (2019). Accuracy Table 6. Language modelling and translation results. text8 score is from Zhang et al. (2016), and IWSLT score is from Luong & Manning (2015). a (case sensitive), b (case insensitive). text8 IWSLT \' 15","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"93.20\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Sequential Image Classification\\", \\"Dataset\\": \\"Sequential MNIST\\", \\"Metric\\": \\"Permuted Accuracy\\", \\"Score\\": \\"98.49%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"IWSLT2015 German-English\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"36.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-German\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"28.9\\"}} ]"},{"Context":"3D Building Model Fitting Using A New Kinetic Framework We describe anew approach to fit the polyhedron describing a 3D building model to the point cloud of a Digital Elevation Model (DEM). We introduce anew kinetic framework that hides to its user the combinatorial complexity of determining or maintaining the polyhedron topology, allowing the design of a simple variational optimization.This new kinetic framework allows the manipulation of a bounded polyhedron with simple faces by specifying the target plane equations of each of its faces. It proceeds by evolving continuously from the polyhedron defined by its initial topology and its initial plane equations to a polyhedron that is as topologically close as possible to the initial polyhedron but with the new plane equations. This kinetic framework handles internally the necessary topological changes that maybe required to keep the faces simple and the polyhedron bounded. For each intermediate configurations where the polyhedron looses the simplicity of its faces or its boundedness, the simplest topological modification that is able to reestablish the simplicity and the boundedness is performed.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"ROAD: Reality Oriented Adaptation for Semantic Segmentation of Urban Scenes Exploiting synthetic data to learn deep models has attracted increasing attention in recent years. However, the intrinsic domain difference between synthetic and real images usually causes a significant performance drop when applying the learned model to real world scenarios. This is mainly due to two reasons: 1) the model overfits to synthetic images, making the convolutional filters incompetent to extract informative representation for real images; 2) there is a distribution difference between synthetic and real data, which is also known as the domain adaptation problem. To this end, we propose anew reality oriented adaptation approach for urban scene semantic segmentation by learning from synthetic data. First, we propose a target guided distillation approach to learn the real image style, which is achieved by training the segmentation model to imitate a pretrained real style model using real images. Second, we further take advantage of the intrinsic spatial structure presented in urban scene images, and propose a spatialaware adaptation scheme to effectively align the distribution of two domains. These two modules can be readily integrated with existing state-of-the-art semantic segmentation networks to improve their generalizability when adapting from synthetic to real urban scenes. We evaluate the proposed method on Cityscapes dataset by adapting from GTAV and SYNTHIA datasets, where the results demonstrate the effectiveness of our method.\u2022 real distribution orientation: To deal with the dis- Following previous works, the experimental validation are conducted on the GTAV dataset and Cityscapes dataset We use GTAV dataset as our source domain, and we have access to the pixel-level annotation, and we use Cityscapes dataset as the target domain We briefly introduce the datasets used in our experiment in below: Cityscapes is a dataset focused on autonomous driving, which consists of 2, 975 images in training set, and 500 images for validation GTAV is a dataset recently proposed for learning from synthetic data The resolution of images is around 2000 \xd7 1000 pixels which is similar with Cityscapes, the semantic categories are also compatible between the two datasets Table 1. The segmentation results on the Cityscapes dataset by using the GTAV dataset as the source domain. DeepLab and PSPNet are sidewalk sky motorbike bus bicycle truck sign vegetation pole rider building IoU light road car person mean wall fence terrain traffic train Table 2. Comparison with state-of-the-arts methods for semantic segmentation on Cityscapes using synthetic datasets as the training data. Top: adapting from GTAV, Bottom: adapting from SYNTHIA. Results of state-of-the-art methods are from their papers. We use VGG-16 as the backbone network for fair comparison. The best results are denoted in bold. sidewalk sky motorbike bus bicycle truck sign vegetation pole rider building IoU light road car person mean wall fence terrain traffic train","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Synthetic-to-Real Translation\\", \\"Dataset\\": \\"GTAV-to-Cityscapes Labels\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"39.4\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"82.6%\\"}} ]"},{"Context":"A Peer to Peer Protocol for Online Dispute Resolution over Storage Consumption In bilateral accounting of resource consumption both the consumer and provider independently measure the amount of resources consumed by the consumer. The problem here is that potential disparities between the provider\'s and consumer\'s accountings, might lead to conflicts between the two parties that need to be resolved. We argue that with the proper mechanisms available, most of these conflicts can be solved online, as opposite to in court resolution; the design of such mechanisms is still a research topic; to help cover the gap, in this paper we propose a peer-to-peer protocol for online dispute resolution over storage consumption. The protocol is peer-to-peer and takes into consideration the possible causes (e.g, transmission delays, unsynchronized metric collectors, etc.) of the disparity between the provider\'s and consumer\'s accountings to make, if possible, the two results converge.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Defense Strategies Against Modern Botnets Botnets are networks of compromised computers with malicious code which are remotely controlled and which are used for starting distributed denial of service (DDoS) attacks, sending enormous number of e-mails (SPAM) and other sorts of attacks. Defense against modern Botnets is areal challenge. This paper offers several strategies for defense against Botnets with a list and description of measures and activities which should be carried out in order to establish successful defense. The paper also offers parallel preview of the strategies with their advantages and disadvantages considered in accordance with various criteria.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Hierarchical Transformer Network for Utterance-level Emotion Recognition While there have been significant advances in detecting emotions in text, in the field of utterancelevel emotion recognition (ULER), there are still many problems to be solved. In this paper, we address some challenges in ULER in dialog systems.(1) The same utterance can deliver different emotions when it is in different contexts or from different speakers.(2) Long-range contextual information is hard to effectively capture. (3) Unlike the traditional text classification problem, this task is supported by a limited number of datasets, among which most contain inadequate conversations or speech. To address these problems, we propose a hierarchical transformer framework (apart from the description of other studies, the \\"transformer\\" in this paper usually refers to the encoder part of the transformer) with a lower-level transformer to model the word-level input and an upper-level transformer to capture the context of utterance-level embeddings. We use a pretrained language model bidirectional encoder representations from transformers (BERT) as the lower-level transformer, which is equivalent to introducing external data into the model and solve the problem of data shortage to some extent. In addition, we add speaker embeddings to the model for the first time, which enables our model to capture the interaction between speakers. Experiments on three dialog emotion datasets, Friends, Emotion-Push, and EmoryNLP, demonstrate that our proposed hierarchical transformer network models achieve 1.98%, 2.83%, and 3.94% improvement, respectively, over the state-of-the-art methods on each dataset in terms of macro-F1. In this section, we present the datasets, evaluation metrics, baselines and experimental results of our model Friends: The dataset is annotated from the Friends TV Scripts, and each dialog in the dataset consists of a scene of multiple speakers EmotionPush: The dataset consists of private conversations between friends on Facebook include 1,000 dialogs, which are split into 720, 80, and 200 dialogs for training, validation and testing, respectively Each utterance is tagged with an emotion in a set of emotions as in the Friends dataset EmoryNLP: The dataset is annotated from the Friends TV Scripts as well For the first two datasets, we follow previous works to consider only four emotion classes, i.e., anger, joy, sadness, and neutral, and consider all the emotion classes for EmoryNLP Following, which achieved the best performance on several ULER datasets, we choose macro-averaged F1-score as the primary metric for evaluating the performance of our models Table 1: Detailed descriptions of Friends and EmotionPush Others Hap / Joy Neu Table 2: Detailed descriptions of EmoryNLP Dataset #Dialog ( #Utterance ) Neutral Mad Joyful Peaceful Scared Table 1 : Detailed descriptions of Friends and EmotionPush Emotion Powerful Table 3: Testing results on Friend, EmotionPush, and EmoryNLP Model - Macro - F1 EmoryNLP Friends WA - UWA EmotionPush","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Emotion Recognition in Conversation\\", \\"Dataset\\": \\"EmotionPush\\", \\"Metric\\": \\"Unweighted Accuracy\\", \\"Score\\": \\"63.03\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Emotion Recognition in Conversation\\", \\"Dataset\\": \\"EmotionPush\\", \\"Metric\\": \\"Weighted Accuracy\\", \\"Score\\": \\"86.92\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Emotion Recognition in Conversation\\", \\"Dataset\\": \\"EC\\", \\"Metric\\": \\"Micro-F1\\", \\"Score\\": \\"83.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Emotion Recognition in Conversation\\", \\"Dataset\\": \\"EC\\", \\"Metric\\": \\"Micro-F1\\", \\"Score\\": \\"83.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Emotion Recognition in Conversation\\", \\"Dataset\\": \\"NYT\\", \\"Metric\\": \\"Micro-F1\\", \\"Score\\": \\"73.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Emotion Recognition in Conversation\\", \\"Dataset\\": \\"NYT\\", \\"Metric\\": \\"Micro-F1\\", \\"Score\\": \\"71\\"}} ]"},{"Context":"Spectral Sparsification of Graphs * We introduce anew notion of graph sparsification based on spectral similarity of graph Laplacians: spectral sparsification requires that the Laplacian quadratic form of the sparsifier approximate that of the original. This is equivalent to saying that the Laplacian of the sparsifier is a good preconditioner for the Laplacian of the original.We prove that every graph has a spectral sparsifier of nearly-linear size. Moreover, we present an algorithm that produces spectral sparsifiers in time O (m log c m), where m is the number of edges in the original graph and c is some absolute constant. This construction is a key component of a nearly-linear time algorithm for solving linear equations in diagonallydominant matrices.Our sparsification algorithm makes use of a nearly-linear time algorithm for graph partitioning that satisfies a strong guarantee: if the partition it outputs is very unbalanced, then the larger part is contained in a subgraph of high conductance. * This paper is the second in a sequence of three papers expanding on material that appeared first under the title \\"Nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems\\" [ST04]. The first paper, \\"A Local Clustering Algorithm for Massive Graphs and its Application to Nearly-Linear Time Graph Partitioning\\" [ST08a] contains graph partitioning algorithms that are used to construct the sparsifiers in this paper. The third paper, \\"Nearly-Linear Time Algorithms for Preconditioning and Solving Symmetric, Diagonally Dominant Linear Systems\\" [ST08b] contains the results on solving linear equations and approximating eigenvalues and eigenvectors.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Hierarchical Neural Networks for Sequential Sentence Classification in Medical Scientific Abstracts Prevalent models based on artificial neural network (ANN) for sentence classification often classify sentences in isolation without considering the context in which sentences appear. This hampers the traditional sentence classification approaches to the problem of sequential sentence classification, where structured prediction is needed for better overall classification performance. In this work, we present a hierarchical sequential labeling network to make use of the contextual information within surrounding sentences to help classify the current sentence. Our model outperforms the state-of-the-art results by 2%-3% on two benchmarking datasets for sequential sentence classification in medical scientific abstracts. We evaluate our model on two sources of benchmarking datasets on medical scientific abstracts, where each sentence of the abstract is annotated with one label that is associated with the rhetorical structure summarizes the statistics of the two datasets NICTA-PIBOSO This dataset 2 was shared from the ALTA 2012 Shared Task, the goal of which is to build automatic sentence classifiers that can map the sentences from biomedical abstracts into a set of pre-defined categories for Evidence-Based Medicine (EBM) PubMed RCT This new dataset was curated by 3 and is currently the largest dataset for sequential sentence classification Table 1: Datasets statistics. |C| denotes the number of labels, |V | represents the vocabulary size. For the train, validation, and test sets, we indicate the number of abstracts followed by the number of sentences in parentheses. Validation 200 ( 2 . 2k ) Test 80 ( 0 . 9k ) Table 3: Hyperparameter settings. d hs : hidden size of the sentence-level RNN layer (single direction); d hd : hidden size of the abstract-level bi-LSTM layer (single direction); d a : dimension of the context vector u s ; r: number of context vectors; \u03b2: coefficient of the dropout regularization added to the total loss; dr: dropout. c Parameter hd - 75 1 CNN RNN 15 4 5 NICTA PubMed Table 4: Comparison of F1 scores (weighted average by support (the number of true instances for each la- bel)) between our model and the best published meth- ods. The presented","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Sentence Classification\\", \\"Dataset\\": \\"PubMed 20k RCT\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"92.60\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"83.24\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"61. Intervention\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"89.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"83.38\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"82.81\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"82.44\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"81.42\\"}}, { \'LEADER"},{"Context":"TVQA: Localized, Compositional Video Question Answering Recent years have witnessed an increasing interest in image-based question-answering (QA) tasks. However, due to data limitations, there has been much less work on video-based QA. In this paper, we present TVQA, a largescale video QA dataset based on 6 popular TV shows. TVQA consists of 152,545 QA pairs from 21,793 clips, spanning over 460 hours of video. Questions are designed to be compositional in nature, requiring systems to jointly localize relevant moments within a clip, comprehend subtitle-based dialogue, and recognize relevant visual concepts. We provide analyses of this new dataset as well as several baselines and a multi-stream end-to-end trainable neural network framework for the TVQA task. The dataset is publicly available at We collected our dataset on 6 long-running TV shows from 3 genres: 1) sitcoms: The Big Bang Theory, How I Met Your Mother, Friends, 2) medical dramas: Grey\'s Anatomy, House, 3) crime drama: Castle On average, our questions contain 13.5 words, which is fairly long compared to other datasets The prompt of \\"when\\", \\"after\\", \\"before\\" account for 60.03%, 30.19% and 9.78% respectively of our dataset Differences among our 6 TV Shows: The videos used in our dataset are from 6 different TV shows.: Human accuracy on test-public set based on different sources Comparison with Other Datasets: presents a comparison of our dataset to some recently proposed video question answering datasets MovieQA is most similar to our dataset, with both multiple choice questions and timestamp annotation Human Evaluation on Usefulness of Video and Subtitle in Dataset: To gain a better understand-ing of the roles of videos and subtitles in the our dataset, Table 1: Statistics for different question types based on first question word. Q = question, CA = correct answer, WA = wrong answer. Length is defined as the number of words in the sentence. Person ( who ) 10% Reasoning ( why ) 6% 15% #QA Q . Len . WA . Len . CA . Len . Method ( how ) Reasoning ( why ) Table 2: Data Statistics for each TV show. BBT = The Big Bang Theory, HIMYM = How I Met You Mother, Grey = Grey\'s Anatomy, House = House M.D., Epi = Episode, Sea. = Season #Epi . #QA 58 29 , 384 4 , 198 72 4 , 621 4 , 698 Table 5: Comparison of TVQA to various existing video QA datasets. OE = open-ended, MC = multiple-choices. Q. Src. = Question Sources, it indicates where the questions are raised from. TVQA dataset is","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Video Question Answering\\", \\"Dataset\\": \\"SUTD-TrafficQA\\", \\"Metric\\": \\"1/2\\", \\"Score\\": \\"63.15\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Video Question Answering\\", \\"Dataset\\": \\"SUTD-TrafficQA\\", \\"Metric\\": \\"1/4\\", \\"Score\\": \\"35.16\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Video Question Answering\\", \\"Dataset\\": \\"TVQA\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"76.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Question Answering\\", \\"Dataset\\": \\"TVQA\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"69.34\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Question Answering\\", \\"Dataset\\": \\"TVQA\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"62.55\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Question Answering\\", \\"Dataset\\": \\"TVQA\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"63.48\\"}} ]"},{"Context":"Building Language Models for Text with Named Entities Text in many domains involves a significant amount of named entities. Predicting the entity names is often challenging fora language model as they appear less frequent on the training corpus. In this paper, we propose a novel and effective approach to building a discriminative language model which can learn the entity names by leveraging their entity type information. We also introduce two benchmark datasets based on recipes and Java programming codes, on which we evaluate the proposed model. Experimental results show that our model achieves 52.2% better perplexity in recipe generation and 22.06% on code generation than the stateof-the-art language models. 7 http://dbpedia.org/page/Lionel Messi We evaluate our proposed model on two different language generation tasks where there exist a lot of entity names in the text In this paper, we release all the codes and datasets For this task, we analyze a cooking recipe corpus Each instance in this corpus is an individual recipe and consists of many ingredi-6 While calculating the final probability distribution overall candidate words, with our joint inference schema, a strong state-of-art language model, without the type information, itself can work sufficiently well and replace the entity composite model We construct a Java code corpus where each instance is a Java method (i.e., function) We use the same dimensional word embedding (400 for recipe corpus, 300 for code corpus) to represent both of the entity name (e.g., \\"apple\\") and their entity type (e.g., \\"fruits\\") in all the models Accordingly, for the entity composite model which takes the concatenation of the entity Table 1: Comparing the performance of recipe gen- type model with type feature Size Perplexity Table 2: Comparing the performance of code genera- Size Perplexity Table 3: Performance of fill in the blank task. Accuracy Free - Form AWD LSTM MCQ Our","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Code Generation\\", \\"Dataset\\": \\"Android Repos\\", \\"Metric\\": \\"Perplexity\\", \\"Score\\": \\"2.65\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Recipe Generation\\", \\"Dataset\\": \\"Now You\'re Cooking!\\", \\"Metric\\": \\"Perplexity\\", \\"Score\\": \\"9.67\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Recipe Generation\\", \\"Dataset\\": \\"Recipe\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.275\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Recipe Generation\\", \\"Dataset\\": \\"Recipe\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"0.695\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Recipe Generation\\", \\"Dataset\\": \\"Recipe\\", \\"Metric\\": \\"Handbags\\", \\"Score\\": \\"0.295\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Recipe Generation\\", \\"Dataset\\": \\"Recipe\\", \\"Metric\\": \\"Distribution\\", \\"Score\\": \\"0.151\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Recipe Generation\\", \\"Dataset\\": \\"Recipe\\", \\"Metric\\": \\"Open-Domain Question Answering\\", \\"Score\\": \\"0.175\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Recipe Generation\\", \\"Dataset\\": \\"Recipe\\", \\"Metric\\": \\"Handbags\\", \\"Score\\": \\"0.374\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Recipe Generation\\", \\"Dataset\\": \\"Recipe\\", \\"Metric\\": \\"Dismatched\\", \\"Score\\": \\"0.468\\"}}, { \\"LEADERBOARD\\": { \'"},{"Context":"Competitive Multi-scale Convolution In this paper, we introduce anew deep convolutional neural network (ConvNet) module that promotes competition among a set of multi-scale convolutional filters. This new module is inspired by the inception module, where we replace the original collaborative pooling stage (consisting of a concatenation of the multi-scale filter outputs) by a competitive pooling represented by a maxout activation unit. This extension has the following two objectives: 1) the selection of the maximum response among the multi-scale filters prevents filter co-adaptation and allows the formation of multiple sub-networks within the same model, which has been shown to facilitate the training of complex learning problems; and 2) the maxout unit reduces the dimensionality of the outputs from the multi-scale filters. We show that the use of our proposed module in typical deep ConvNets produces classification results that are either better than or comparable to the state of the art on the following benchmark datasets: MNIST, CIFAR-10, CIFAR-100 and SVHN. We quantitatively measure the performance of our proposed models Competitive Multi-scale Convolution and Competitive Inception on four computer vision/machine learning benchmark datasets: CIFAR-10, CIFAR-100, MNIST and SVHN Finally, we compare the performance of the proposed Competitive Multi-scale Convolution and Competitive Inception with respect to the current state of the art in the four benchmark datasets mentioned above The CIFAR-10 dataset contains 60000 images of 10 commonly seen object categories (e.g., animals, vehicles, etc.), where 50000 images are used for training and the rest 10000 for testing, and all 10 categories have equal volume of training and test images The CIFAR-100 dataset extends CIFAR-10 by increasing the number of categories to 100, whereas the total number of images remains the same, so the CIFAR-100 dataset is considered as a harder classification problem than CIFAR-10 since it contains 10 times less images per class and 10 times more categories The well-known MNIST dataset Table 1. Results on CIFAR-10 of the proposed models, in addi- tion to the Competitive Single-scale Convolution and Competitive DropConnect Single-scale Convolution that test our research ques- tions posed in Sec. 3.1. Convolution DropConnect Single - scale Convolution that test our research ques - ( mean \xb1 std dev ) Test Error No . of Params Train Time ( h ) Test Time ( ms ) Table 2. Results on MNIST of the proposed models, in addition to the Competitive Single-scale Convolution and Competitive Drop- Connect Single-scale Convolution that test our research questions posed in Sec. 3.1. Convolution ( mean \xb1 std dev ) Test Error No . of Params Train Time ( h ) Test Time ( ms )","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"MNIST\\", \\"Metric\\": \\"Percentage error\\", \\"Score\\": \\"0.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"72.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"SVHN\\", \\"Metric\\": \\"Percentage error\\", \\"Score\\": \\"1.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"93.1\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"MNIST\\", \\"Metric\\": \\"Percentage error\\", \\"Score\\": \\"0.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"73.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"91.7\\"}} ]"},{"Context":"Spoken Language Identification using ConvNets Language Identification (LI) is an important first step in several speech processing systems. With a growing number of voice-based assistants, speech LI has emerged as a widely researched field. To approach the problem of identifying languages, we can either adopt an implicit approach where only the speech fora language is present or an explicit one where text is available with its corresponding transcript. This paper focuses on an implicit approach due to the absence of transcriptive data. This paper benchmarks existing models and proposes anew attention based model for language identification which uses log-Mel spectrogram images as input. We also present the effectiveness of raw waveforms as features to neural network models for LI tasks. For training and evaluation of models, we classified six languages (English, French, German, Spanish, Russian and Italian) with an accuracy of 95.4% and four languages (English, French, German, Spanish) with an accuracy of 96.3% obtained from the VoxForge dataset. This approach can further be scaled to incorporate more languages. We classified six languages (English, French, German, Spanish, Russian and Italian) from the VoxForge dataset VoxForge is an open-source speech corpus which primarily consists of samples recorded and submitted by users using their own microphone Our dataset consists of 1,500 samples for each of six languages Out of 1,500 samples for each language, 1,200 were randomly selected as training dataset for that language and rest 300 as validation dataset using k-fold cross-validation Table 2: Architecture of the 1D-ConvNet model ( Convolutional Block 1 ) ( 128 , 26664 ) 384 Table 2 : Architecture of the 1D - ConvNet model # of parameters Table 3: Architecture of the 2D-ConvNet model Table 4: Results of the two models and all its variations 2D ConvNet log - Mel Spectra 2D ConvNet Table 4 : Results of the two models and all its variations Mixup Accuracy log - Mel Spectra","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Spoken language identification\\", \\"Dataset\\": \\"VoxForge European\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"96.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Spoken language identification\\", \\"Dataset\\": \\"VoxForge European\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"96.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Spoken language identification\\", \\"Dataset\\": \\"VoxForge European\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"94.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Spoken language identification\\", \\"Dataset\\": \\"VoxForge European\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"94.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Spoken language identification\\", \\"Dataset\\": \\"VoxForge European\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"93.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Spoken language identification\\", \\"Dataset\\": \\"VoxForge Commonwealth\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"95.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Spoken language identification\\", \\"Dataset\\": \\"VoxForge Commonwealth\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"95.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Spoken language identification\\", \\"Dataset\\": \\"VoxForge Commonwealth\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"94.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Spoken language identification\\", \\"Dataset\\": \\"VoxForge Commonwealth\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"93.7\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"VoxFornch\\", \\"Metric\\": \\"Word Error Rate (WER)\\", \\"Score\\": \\"6.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"VoxFornch\\", \\"Metric\\": \\"Word Error Rate (WER)\\", \\"Score\\": \\"16.5\\"}} ]"},{"Context":"GLOBAL-TO-LOCAL MEMORY POINTER NETWORKS FOR TASK-ORIENTED DIALOGUE End-to-end task-oriented dialogue is challenging since knowledge bases are usually large, dynamic and hard to incorporate into a learning framework. We propose the global-to-local memory pointer (GLMP) networks to address this issue. In our model, a global memory encoder and a local memory decoder are proposed to share external knowledge. The encoder encodes dialogue history, modifies global contextual representation, and generates a global memory pointer. The decoder first generates a sketch response with unfilled slots. Next, it passes the global memory pointer to filter the external knowledge for relevant information, then instantiates the slots via the local memory pointers. We empirically show that our model can improve copy accuracy and mitigate the common out-of-vocabulary problem. As a result, GLMP is able to improve over the previous state-of-theart models in both simulated bAbI Dialogue dataset and human-human Stanford Multi-domain Dialogue dataset on automatic and human evaluation. We use two public multi-turn task-oriented dialogue datasets to evaluate our model: the bAbI dialogue and Stanford multi-domain dialogue (SMD) On the other hand, SMD is a human-human, multi-domain dialogue dataset The key difference between these two datasets is, the former has longer dialogue turns but the regular user and system behaviors, the latter has few conversational turns but variant responses, and the KB information is much more complicated Table 3: In SMD dataset, our model achieves highest BLEU score and entity F1 score over baselines, including previous state-of-the-art result from Madotto et al. (2018). (Models with * are reported from Eric et al. (2017), where the problem is simplified to the canonicalized forms.) Human Evaluation Automatic Evaluation Human GLMP GLMP K3 GLMP K6 100 ( 100 ) including previous state - of - the - art result from Madotto et al . ( 2018 ) . ( Models with * are reported GLMP K1 Mem2Seq S2S S2S + Attn KVR * Ptr - Unk Rule - Based * Table 5: Selected hyper-parameters in each dataset for different hops. The values is the embedding dimension and the GRU hidden size, and the values between parenthesis is the dropout rate. For all the models we used learning rate equal to 0.001, with a decay rate of 0.5. 128 ( 0 .","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Task-Oriented Dialogue Systems\\", \\"Dataset\\": \\"KVRET\\", \\"Metric\\": \\"BLEU\\", \\"Score\\": \\"14.79\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Task-Oriented Dialogue Systems\\", \\"Dataset\\": \\"KVRET\\", \\"Metric\\": \\"Entity F1\\", \\"Score\\": \\"59.97\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Task-Oriented Dialogue Systems\\", \\"Dataset\\": \\"KVRET\\", \\"Metric\\": \\"BLEU\\", \\"Score\\": \\"12.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Task-Oriented Dialogue Systems\\", \\"Dataset\\": \\"KVRET\\", \\"Metric\\": \\"Entity F1\\", \\"Score\\": \\"51.9\\"}} ]"},{"Context":"Adapt or Get Left Behind: Domain Adaptation through BERT Language Model Finetuning for Aspect-Target Sentiment Classification Sentiment Classification (ATSC) is a subtask of Aspect-Based Sentiment Analysis (ABSA), which has many applications e.g. in e-commerce, where data and insights from reviews can be leveraged to create value for businesses and customers. Recently, deep transfer-learning methods have been applied successfully to a myriad of Natural Language Processing (NLP) tasks, including ATSC. Building on top of the prominent BERT language model, we approach ATSC using a two-step procedure: selfsupervised domain-specific BERT language model finetuning, followed by supervised task-specific finetuning. Our findings on how to best exploit domain-specific language model finetuning enable us to produce new state-of-the-art performance on the SemEval 2014 Task 4 restaurants dataset. In addition, to explore the real-world robustness of our models, we perform cross-domain evaluation. We show that a cross-domain adapted BERT language model performs significantly better than strong baseline models like vanilla BERT-base and XLNet-base. Finally, we conduct a case study to interpret model prediction errors. In our experiments we aim to answer the following research questions (RQs): RQ1: How does the number of training iterations in the BERT language model finetuning stage influence the ATSC end-task performance? At what point does performance start to improve, when does it converge? RQ2: If trained in-domain, what ATSC endtask performance can be reached through fully exploited finetuning of the BERT language model? RQ3: If trained cross-domain in the special case of domain adaptation, what ATSC end-task performance can be reached if BERT language model finetuning is fully exploited? We conduct experiments using the two SemEval 2014 Task 4 Subtask 2 datasets 1 for the laptops and the restaurants domain The two datasets contain sentences with one or multiple marked aspect-targets that each have a 3level sentiment polarity (positive, neutral or negative) associated In the original dataset the conflict class is also present Detailed statistics for both datasets are shown Table 1. Dataset Neutral 15 10 , 000 , 000 3 Negative Positive Test 2 , 007 , 213 Sentences 1 , 007 , 209 Finetuning Epochs Train 30 Table 1: Top: Detailed statistics of the corpora for BERT language model finetuning. Bottom: Number of labels for each category of the SemEval 2014 Task 4 Subtask 2 laptop and restaurant datasets for Aspect- Target Sentiment Classification. Dataset Neutral 15 10 , 000 , 000 3 Negative Positive Test 2 , 007 , 213 Sentences 1 , 007 , 209 Finetuning Epochs Train 30 Table 2: Summary of results for Aspect-Target Sentiment Classification for in-domain, cross-domain, and joint- domain training on SemEval 2014 Task 4 Subtask 2 datasets. The cells with gray background correspond to the cross-domain adaptation case, where the language model is finetuned on the target domain. As evaluation metrics accuracy (Acc) and Macro-F1 (MF1) are used. Ours Baselines Acc","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Aspect-Based Sentiment Analysis\\", \\"Dataset\\": \\"SemEval 2014 Task 4 Sub Task 2\\", \\"Metric\\": \\"Laptop (Acc)\\", \\"Score\\": \\"80.23\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Aspect-Based Sentiment Analysis\\", \\"Dataset\\": \\"SemEval 2014 Task 4 Sub Task 2\\", \\"Metric\\": \\"Mean Acc (Restaurant + Laptop)\\", \\"Score\\": \\"84.06\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Aspect-Based Sentiment Analysis\\", \\"Dataset\\": \\"SemEval 2014 Task 4 Sub Task 2\\", \\"Metric\\": \\"Restaurant (Acc)\\", \\"Score\\": \\"87.89\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Aspect-Based Sentiment Analysis\\", \\"Dataset\\": \\"SemEval 2014 Task 4 Sub Task 2\\", \\"Metric\\": \\"Laptop (Acc)\\", \\"Score\\": \\"70.06\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Aspect-Based Sentiment Analysis\\", \\"Dataset\\": \\"SemEval 2014 Task 4 Sub Task 2\\", \\"Metric\\": \\"Mean Acc (Restaurant + Laptop)\\", \\"Score\\": \\"74.63\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Aspect-Based Sentiment Analysis\\", \\"Dataset\\": \\"SemEval 2014 Task 4 Sub Task 2\\", \\"Metric\\": \\"Restaurant (Acc)\\", \\"Score\\": \\"79.20\\"}} ]"},{"Context":"Rewrite based Verification of XML Updates Rewrite based Verification of XML Updates Th\xe8me : Knowledge and Data Representation and Management Equipes-Projets DAHU and CASSIS Rewrite based Verification of XML Updates We consider problems of access control for update of XML document. In the context of XML programming, types can be viewed as hedge automata, and static type checking amounts to verify that a program always converts valid source documents into also valid output documents. Given a set of update operations we are particularly interested by checking safety properties such as preservation of document types along any sequence of updates. We are also interested by the related policy consistency problem, that is detecting whether a sequence of authorized operations can simulate a forbidden one. We reduce these questions to type checking problems, solved by computing variants of hedge automata characterizing the set of ancestors and descendants of the initial document type for the closure of parameterized rewrite rules.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"V2V-PoseNet: Voxel-to-Voxel Prediction Network for Accurate 3D Hand and Human Pose Estimation from a Single Depth Map Most of the existing deep learning-based methods for 3D hand and human pose estimation from a single depth map are based on a common framework that takes a 2D depth map and directly regresses the 3D coordinates of keypoints, such as hand or human body joints, via 2D convolutional neural networks (CNNs). The first weakness of this approach is the presence of perspective distortion in the 2D depth map. While the depth map is intrinsically 3D data, many previous methods treat depth maps as 2D images that can distort the shape of the actual object through projection from 3D to 2D space. This compels the network to perform perspective distortion-invariant estimation. The second weakness of the conventional approach is that directly regressing 3D coordinates from a 2D image is a highly nonlinear mapping, which causes difficulty in the learning procedure. To overcome these weaknesses, we firstly cast the 3D hand and human pose estimation problem from a single depth map into a voxel-to-voxel prediction that uses a 3D voxelized grid and estimates the per-voxel likelihood for each keypoint. We design our model as a 3D CNN that provides accurate estimates while running in real-time. Our system outperforms previous methods in almost all publicly available 3D hand and human pose estimation datasets and placed first in the HANDS 2017 frame-based 3D hand pose estimation challenge. The code is available in 1 . ICVL Hand Posture Dataset The ICVL dataset consists of 330K training and 1.6K testing depth images NYU Hand Pose Dataset The NYU dataset consists of 72K training and 8.2K testing depth images Most of the previous works only used frames from the frontal view and 14 out of 36 joints in the evaluation, and we also followed them MSRA Hand Pose Dataset The MSRA dataset [39] contains 9 subjects with 17 gestures for each subject For evaluation, the leave-one-subject-out cross-validation strategy is utilized HANDS 2017 Frame-based 3D Hand Pose Estimation Challenge Dataset The HANDS 2017 frame-based 3D hand pose estimation challenge dataset consists of 957K training and 295K testing depth images that are sampled from BigHand2.2M and First-Person Hand Action datasets The ground-truth of this dataset is the 3D coordinates of We used 3D distance error and percentage of success frame metrics for 3D hand pose estimation following Table 3: Comparison of the proposed method (V2V-PoseNet) with state-of-the-art methods on the three 3D hand pose datasets. Mean error indicates the average 3D distance error. ( c ) MSRA middle : NYU dataset , right : MSRA dataset . Top row : the percentage of success frames over different error thresholds . Left : ICVL dataset , Mean error ( mm ) Bottom row : 3D distance errors per hand keypoints . Table 5: Comparison of the proposed method (V2V-PoseNet) with state-of-the-art methods on the front and top views of the ITOP dataset. VI ( Ours ) RF RTW V2V - PoseNet mAP ( front - view ) mAP ( top - view ) IEF REN - 9x6x6","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Hand Pose Estimation\\", \\"Dataset\\": \\"NYU Hands\\", \\"Metric\\": \\"Average 3D Error\\", \\"Score\\": \\"8.42\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Hand Pose Estimation\\", \\"Dataset\\": \\"MSRA Hands\\", \\"Metric\\": \\"Average 3D Error\\", \\"Score\\": \\"7.49\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Hand Pose Estimation\\", \\"Dataset\\": \\"HANDS 2017\\", \\"Metric\\": \\"Average 3D Error\\", \\"Score\\": \\"9.95\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Hand Pose Estimation\\", \\"Dataset\\": \\"ICVL Hands\\", \\"Metric\\": \\"Average 3D Error\\", \\"Score\\": \\"6.28\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Pose Estimation\\", \\"Dataset\\": \\"ITOP top-view\\", \\"Metric\\": \\"Mean mAP\\", \\"Score\\": \\"83.44\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Pose Estimation\\", \\"Dataset\\": \\"ITOP front-view\\", \\"Metric\\": \\"Mean mAP\\", \\"Score\\": \\"88.74\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Hand Pose Estimation\\", \\"Dataset\\": \\"NYU Hands\\", \\"Metric\\": \\"Average 3D Error\\", \\"Score\\": \\"11.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Hand Pose Estimation\\", \\"Dataset\\": \\"MSRA Hands\\", \\"Metric\\": \\"Average 3D Error\\", \\"Score\\": \\"8.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Hand Pose Estimation\\", \\"Dataset\\": \\"HANDS 2017\\", \\"Metric\\": \\"Average 3D Error\\", \\"Score\\": \\"11.70\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Hand Pose Estimation\\", \\"Dataset\\": \\"ICVL Hands\\", \\"Metric\\": \\"Average 3D Error\\", \\"Score\\": \\"6.8\\"}} ]"},{"Context":"IEEE TRANSACTION ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 PAC-Bayesian Meta-learning with Implicit Prior and Posterior We introduce anew and rigorously-formulated PAC-Bayes few-shot meta-learning algorithm that implicitly learns a prior distribution of the model of interest. Our proposed method extends the PAC-Bayes framework from a single task setting to the few-shot learning setting to upper-bound generalisation errors on unseen tasks and samples. We also propose a generative-based approach to model the shared prior and the posterior of task-specific model parameters more expressively compared to the usual diagonal Gaussian assumption. We show that the models trained with our proposed meta-learning algorithm are well calibrated and accurate, with state-of-the-art calibration and classification results on few-shot classification (mini-ImageNet and tiered-ImageNet) and regression (multi-modal task-distribution regression) benchmarks. We evaluate SImPa on few-shot regression and classification problems Mini - ImageNet [ 37 ] - non - standard network Tiered - ImageNet [ 38 ] Omniglot [ 21 ] - standard 4 - block CNN Mini - ImageNet [ 37 ] - standard 4 - block CNN 5 - SHOT 1 - SHOT \u2212 5 \u2212 4 \u2212 2 Non - standard 2 1024 Notation network","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"Tiered ImageNet 5-way (1-shot)\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"70.82\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"Tiered ImageNet 5-way (5-shot)\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"81.84\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"Mini-Imagenet 5-way (1-shot)\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"52.11\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"Mini-Imagenet 5-way (5-shot)\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"63.87\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"Mini-Imagenet 5-way (1-shot)\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"71.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"Mini-Imagenet 5-way (5-shot)\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"82.2\\"}} ]"},{"Context":"CU-Net: Coupled U-Nets We design anew connectivity pattern for the U-Net architecture. Given several stacked U-Nets, we couple each U-Net pair through the connections of their semantic blocks, resulting in the coupled U-Nets (CU-Net). The coupling connections could make the information flow more efficiently across U-Nets. The feature reuse across U-Nets makes each U-Net very parameter efficient. We evaluate the coupled U-Nets on two benchmark datasets of human pose estimation. Both the accuracy and model parameter number are compared. The CU-Net obtains comparable accuracy as state-of-the-art methods. However, it only has at least 60% fewer parameters than other approaches. Datasets For human pose estimation, we use benchmark datasets: MPII Human Pose and Leeds Sports Pose (LSP) Table 1: Comparison of different hyper-parameters m and n measured by the model parameter number and the PCKh on the MPII validation set. The PCKh increase becomes less from the left to the right while the parameter number growly consistently. A good trade-off between the PCKh and parameter number is m=128 and n=32. m 64 128 128 128 192 192 n 16 16 24 32 24 32 # Parameters 0.5M 1.0M 1.4M 1.9M 2.4M 2.9M PCKh@0.5 (%) 81.6 84.2 85.6 86.0 86.3 86.6 the PCKh and parameter number is m=128 and n=32 . . CU - Net - 2 24 16 CU - Net - 4 Table 1 : Comparison of different hyper - parameters m and n measured by the model parameter 192 PCKh of CU - Net - 2 . m n 1 2 3 4 128 However , it improves the PCKh of deeper networks CU - Net","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Pose Estimation\\", \\"Dataset\\": \\"MPII Human Pose\\", \\"Metric\\": \\"PCKh-0.5\\", \\"Score\\": \\"89.4%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Pose Estimation\\", \\"Dataset\\": \\"MPII Human Pose\\", \\"Metric\\": \\"PCKh-0.5\\", \\"Score\\": \\"91.9\\"}} ]"},{"Context":"Deeply-Learned Part-Aligned Representations for Person Re-Identification In this paper, we address the problem of person reidentification, which refers to associating the persons captured from different cameras. We propose a simple yet effective human part-aligned representation for handling the body part misalignment problem. Our approach decomposes the human body into regions (parts) which are discriminative for person matching, accordingly computes the representations over the regions, and aggregates the similarities computed between the corresponding regions of a pair of probe and gallery images as the overall matching score. Our formulation, inspired by attention models, is a deep neural network modeling the three steps together, which is learnt through minimizing the triplet loss function without requiring body part labeling information. Unlike most existing deep learning algorithms that learn a global or spatial partition-based local representation, our approach performs human body partition, and thus is more robust to pose changes and various human spatial distributions in the person bounding box. Our approach shows state-of-the-art results over standard datasets, Market-1501, CUHK03, CUHK01 and VIPeR. 1 This dataset is one of the largest benchmark datasets for person re-identification This dataset consists of 13, 164 images of 1, 360 persons, captured by six cameras This dataset contains 971 identities captured from two camera views in the same campus with CUHK03 This dataset contains two views of 632 persons We adopt the widely-used evaluation protocol The performances are evaluated by the cumulated matching characteristics (CMC) curves, which is an estimate of the expectation of finding the correct match in the top n matches Table 1. The performance (%) of our approach and spatial partition based methods (stripe and grid) over Market-1501 and CUHK03. rank - 1 rank - 10 rank - 20 rank - 5 Table 2. The performance of our approach, and separate part seg- mentation over Market-1501 and CUHK-03. rank - 1 rank - 10 rank - 20 rank - 5 Table 3. The validation performance with different numbers (K) of parts over CUHK03. The model is trained over a random half of the training data, and the performance is reported over the re- maining half (as the validation set). The best results are in bold. #parts rank-1 rank-5 rank-10 rank-20 maining half ( as the validation set ) . The best results are in bold . tation over Market - 1501 and CUHK03 . rank - 1 rank - 10 rank - 20 rank - 5 Table 3 . The validation","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"Market-1501\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"63.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"Market-1501\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"81.0\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"Market-1501\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"83.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"Market-1501\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"93.6\\"}} ]"},{"Context":"Bootstrap Your Own Latent A New Approach to Self-Supervised Learning We introduce Bootstrap Your Own Latent (BYOL), anew approach to self-supervised image representation learning. BYOL relies on two neural networks, referred to as online and target networks, that interact and learn from each other. From an augmented view of an image, we train the online network to predict the target network representation of the same image under a different augmented view. At the same time, we update the target network with a slow-moving average of the online network. While state-of-the art methods rely on negative pairs, BYOL achieves anew state of the art without them. BYOL reaches 74.3% top-1 classification accuracy on ImageNet using a linear evaluation with a ResNet-50 architecture and 79.6% with a larger ResNet. We show that BYOL performs on par or better than the current state of the art on both transfer and semi-supervised benchmarks. Our implementation and pretrained models are given on GitHub. 3 * Equal contribution; the order of first authors was randomly selected. We assess the performance of BYOL\'s representation after self-supervised pretraining on the training set of the ImageNet ILSVRC-2012 dataset We first evaluate it on ImageNet (IN) in both linear evaluation and semisupervised setups We then measure its transfer capabilities on other datasets and tasks, including classification, segmentation, object detection and depth estimation In Appendix E, we assess the generality of BYOL by pretraining a representation on the Places365-Standard dataset before reproducing this evaluation protocol Linear evaluation on ImageNet We first evaluate BYOL\'s representation by training a linear classifier on top of the frozen representation, following the procedure described in, and appendix C.1; we report top-1 and top-5 accuracies in % on the test set in Semi-supervised training on ImageNet Next, we evaluate the performance obtained when fine-tuning BYOL\'s representation on a classification task with a small subset of ImageNet\'s train set, this time using label information Transfer to other classification tasks Table 1: Top-1 and top-5 accuracies (in %) under linear evaluation on ImageNet. - Top - 5 Top - 1 Table 2. BYOL consistently outperforms previous approaches across a wide range of architectures. Additionally, as detailed in Appendix C.1, BYOL reaches 77.7% top-1 accuracy with ResNet-50 when fine-tuning over 100% of ImageNet labels. 1% 10% Top - 5 Top - 1 Table 2: Semi-supervised training with a fraction of ImageNet labels. 1% 10% Top - 5 Top - 1 Table 3: Transfer learning results from ImageNet (IN) with the standard ResNet-50 architecture. Linear evaluation : Fine - tuned : Cars SUN397 VOC2007 Pets CIFAR100 DTD Birdsnap Flowers Food101 CIFAR10 Aircraft Caltech - 101 Table 4: Results on transferring BYOL\'s representation to other vision tasks. mIoU 2 3 AP50 Lower better rel rms Higher better Table 5: Ablations with top-1 accuracy (in %) at 300 epochs under linear evaluation on ImageNet. 18","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 1% labeled data\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"71.2%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 1% labeled data\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"89.5%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 1% labeled data\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"69.1%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 1% labeled data\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"87.9%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 1% labeled data\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"62.2%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 1% labeled data\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"84.1%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 1% labeled data\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"53.2%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 1% labeled data\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"78.4%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of Params\\", \\"Score\\": \\"250M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"79.6%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"94.8%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of Params\\", \\"Score\\": \\"375M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"78.6%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"94.2%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of Params\\", \\"Score\\": \\"94M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"77.4%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"93.6%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"74.3%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"91.6%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 1% labeled data\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"74.96%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet - 1% labeled data\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"82.21%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"7.8%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"84.58%\\"}} ]"},{"Context":"UVid-Net: Enhanced Semantic Segmentation of UAV Aerial Videos by Embedding Temporal Information Semantic segmentation of aerial videos has been extensively used for decision making in monitoring environmental changes, urban planning, and disaster management. The reliability of these decision support systems is dependent on the accuracy of the video semantic segmentation algorithms. The existing CNN based video semantic segmentation methods have enhanced the image semantic segmentation methods by incorporating an additional module such as LSTM or optical flow for computing temporal dynamics of the video which is a computational overhead. The proposed research work modifies the CNN architecture by incorporating temporal information to improve the efficiency of video semantic segmentation.In this work, an enhanced encoder-decoder based CNN architecture (UVid-Net) is proposed for UAV video semantic segmentation. The encoder of the proposed architecture embeds temporal information for temporally consistent labelling. The decoder is enhanced by introducing the feature retainer module, which aids in accurate localization of the class labels. The proposed UVid-Net architecture for UAV video semantic segmentation is quantitatively evaluated on extended ManipalUAVid dataset. The performance metric mIoU of 0.79 has been observed which is significantly greater than the other state-of-the-art algorithms. Further, the proposed work produced promising results even for the pre-trained model of UVid-Net on urban street scene with fine tuning the final layer on UAV aerial videos. This paper presents an extended version of ManipalUAVid dataset for semantic segmentation of UAV videos This extended dataset consists of new videos captured at additional locations The extended dataset consists of 37 videos with annotations provided for 711 keyframes More details of this dataset can be found in Besides, the performance of semantic segmentation algorithms which analyses each keyframe individually was provided in on the ManipalUAVid dataset The earlier version of ManipalUAVid dataset consists of last two keyframes of each video in the test split which might not be sufficient to observe the temporal smoothness or the error (if any) accumulated over the period of time in the video Therefore, in this work, ManipalUAVid is extended by incorporating four new videos (total key frames: 44) which are entirely in the test split Besides, the training-test split distribution is slightly modified so that a greater number of frames (4-5 frames) per video","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ManipalUAVid\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"0.79\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\":\\"scapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"78.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL Context\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"42.3\\"}} ]"},{"Context":"Multiscale Vision Transformers We present Multiscale Vision Transformers (MViT) for video and image recognition, by connecting the seminal idea of multiscale feature hierarchies with transformer models. Multiscale Transformers have several channel-resolution scale stages. Starting from the input resolution and a small channel dimension, the stages hierarchically expand the channel capacity while reducing the spatial resolution. This creates a multiscale pyramid of features with early layers operating at high spatial resolution to model simple low-level visual information, and deeper layers at spatially coarse, but complex, high-dimensional features. We evaluate this fundamental architectural prior for modeling the dense nature of visual signals fora variety of video recognition tasks where it outperforms concurrent vision transformers that rely on large scale external pre-training and are 5-10\xd7 more costly in computation and parameters. We further remove the temporal dimension and apply our model for image classification where it outperforms prior work on vision transformers. Code is available at: https: //github.com/facebookresearch/SlowFast. Datasets Table 1. Vision Transformers (ViT) base model starts from a data layer that samples visual input with rate \u03c4 \xd71\xd71 to T \xd7H\xd7W resolution, where T is the number of frames H height and W width. The first layer, patch1 projects patches (of shape 1\xd716\xd716) to form a sequence, processed by a stack of N transformer blocks (stage2) at uniform channel dimension (D) and resolution (T \xd7 H 16 \xd7 W 16 ). a sequence , processed by a stack of N transformer blocks ( stage2 ) MHA ( D ) 1\xd716\xd716 , D T \xd7H\xd7W output sizes D\xd7T \xd7 H \xd7 W Table 3. Comparing ViT-B to two instantiations of MViT with varying complexity, MViT-S in (c) and MViT-B in (b). MViT-S operates at a lower spatial resolution and lacks a first high-resolution stage. The top-1 accuracy corresponds to 5-Center view testing on K400. FLOPs correspond to a single inference","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"81.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@5\\", \\"Score\\": \\"95.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"80.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@5\\", \\"Score\\": \\"94.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"78.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@5\\", \\"Score\\": \\"93.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"76\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@5\\", \\"Score\\": \\"92.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Charades\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"47.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Charades\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"47.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Charades\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"46.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Charades\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"44.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Charades\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"43.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Charades\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"40\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-600\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"83.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-600\\", \\"Metric\\": \\"Vid acc@5\\", \\"Score\\": \\"96.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-600\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"83.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-600\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"82.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-600\\", \\"Metric\\": \\"Vid acc@5\\", \\"Score\\": \\"95.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"AVA v2.2\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"28.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"AVA v2.2\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"27.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"AVA v2.2\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"27.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"AVA v2.2\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"26.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"AVA v2.2\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"26.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"AVA v2.2\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"24.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"Something-Something V2\\", \\"Metric\\": \\"Top-1 Accuracy\\", \\"Score\\": \\"68.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"Something-Something V2\\", \\"Metric\\": \\"Top-5 Accuracy\\", \\"Score\\": \\"91.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"Something-Something V2\\", \\"Metric\\": \\"Top-1 Accuracy\\", \\"Score\\": \\"67.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"Something-Something V2\\", \\"Metric\\": \\"Top-5 Accuracy\\", \\"Score\\": \\"91.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"Something-Something V2\\", \\"Metric\\": \\"Top-1 Accuracy\\", \\"Score\\": \\"66.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"Something-Something V2\\", \\"Metric\\": \\"Top-5 Accuracy\\", \\"Score\\": \\"90.2\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Action Detection\\", \\"Dataset\\": \\"ViTube\\", \\"Metric\\": \\"F1-score\\", \\"Score\\": \\"94.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Detection\\", \\"Dataset\\": \\"ViTube\\", \\"Metric\\": \\"F1-score\\", \\"Score\\": \\"95.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Detection\\", \\"Dataset\\": \\"UCF101\\", \\"Metric\\": \\"F1-score\\", \\"Score\\": \\"94.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Detection\\", \\"Dataset\\": \\"UCF101\\", \\"Metric\\": \\"F1-score\\", \\"Score\\": \\"93.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Detection\\", \\"Dataset\\": \\"Middlebury\\", \\"Metric\\": \\"F1-score\\", \\"Score\\": \\"0.44\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Detection\\", \\"Dataset\\": \\"Middlebury\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"82.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Detection\\", \\"Dataset\\": \\"Middlebury\\", \\"Metric\\": \\"Vid"},{"Context":"An Effective Domain Adaptive Post-Training Method for BERT in Response Selection We focus on multi-turn response selection in a retrieval-based dialog system. In this paper, we utilize the powerful pre-trained language model Bi-directional Encoder Representations from Transformer (BERT) fora multi-turn dialog system and propose a highly effective post-training method on domain-specific corpus. Although BERT is easily adopted to various NLP tasks and outperforms previous baselines of each task, it still has limitations if a task corpus is too focused on a certain domain. Posttraining on domain-specific corpus (e.g., Ubuntu Corpus) helps the model to train contextualized representations and words that do not appear in general corpus (e.g., English Wikipedia). Experimental results show that our approach achieves new stateof-the-art on two response selection benchmarks (i.e., Ubuntu Corpus V1, Advising Corpus) performance improvement by 5.9% and 6% on R10@1. We evaluate our model on two multi-turn dyadic data sets, Ubuntu IRC (Internet Relay Chat) Corpus V1 and Advising Corpus 1 For the Ubuntu Corpus, training set is composed of 0.5M dialog context containing positive and negative response with the ratio of 1:1 Advising Corpus consists of 100k dialogs for training set and 500 for validation and test set We only use one negative sample for training to make same conditions with Ubuntu Corpus For an evaluation metric, we use Rn@k, evaluating if the ground truth exists in top k from n candidates We also use another evaluation metric mean reciprocal rank (MRR) 10 @1 10 @2 10 @5 Table 2: Model comparison on Ubuntu Corpus V1. 10 @1 10 @2 10 @5 Table 2. Dual Encoder is simple dialogue-response matching model based on RNN, CNN, LSTM, and BiLSTM 10 @1 10 @2 10 @5 Table 3: Evaluation results on the Advising Corpus. improvements . Ubuntu effective on not only small sets but also domain - specific sets . Variable Fine - Tuning Advising Variable for reducing Table 5: Comparison of MLM and NSP on Ubuntu Corpus V1. Experiments are conducted depending on the use of [EOT]. with EOT without","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Conversational Response Selection\\", \\"Dataset\\": \\"Ubuntu Dialogue (v1, Ranking)\\", \\"Metric\\": \\"R10@1\\", \\"Score\\": \\"0.855\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Conversational Response Selection\\", \\"Dataset\\": \\"Ubuntu Dialogue (v1, Ranking)\\", \\"Metric\\": \\"R10@2\\", \\"Score\\": \\"0.928\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Conversational Response Selection\\", \\"Dataset\\": \\"Ubuntu Dialogue (v1, Ranking)\\", \\"Metric\\": \\"R10@5\\", \\"Score\\": \\"0.985\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Conversational Response Selection\\", \\"Dataset\\": \\"Ubuntu Dialogue (v1, Ranking)\\", \\"Metric\\": \\"R10@1\\", \\"Score\\": \\"0.726\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Conversational Response Selection\\", \\"Dataset\\": \\"Ubuntu Dialogue (v1, Ranking)\\", \\"Metric\\": \\"R10@2\\", \\"Score\\": \\"0.822\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Conversational Response Selection\\", \\"Dataset\\": \\"Ubuntu Dialogue (v1, Ranking)\\", \\"Metric\\": \\"R10@5\\", \\"Score\\": \\"0.974\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Conversational Response Selection\\", \\"Dataset\\": \\"Ubuntu Dialogue (v1, Ranking)\\", \\"Metric\\": \\"R2@1\\", \\"Score\\": \\"0.926\\"}} ]"},{"Context":"Re-verification of a Lip Synchronization Protocol using Robust Reachability The timed automata formalism is an important model for specifying and analysing real-time systems. Robustness is the correctness of the model in the presence of small drifts on clocks or imprecision in testing guards. A symbolic algorithm for the analysis of the robustness of timed automata has been implemented. In this paper, we re-analyse an industrial case lip synchronization protocol using the new robust reachability algorithm. This lip synchronization protocol is an interesting case because timing aspects are crucial for the correctness of the protocol. Several versions of the model are considered: with an ideal video stream, with anchored jitter, and with non-anchored jitter.  Table 1: Verification results for streams with possible initial delay for both normal and robust semantics (marked with *) Anchored Ideal Non - anchored Table 2: Verification results for streams without initial delay for both normal and robust semantics (marked with *) Anchored Ideal Non - anchored","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Efficient MIMO-OFDM Schemes for Future Terrestrial Digital TV with Unequal Received Powers Golden code offers the highest robustness to power unbalance at the receiving side.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Tr\xe4umerAI: Dreaming Music with StyleGAN","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Music Auto-Tagging\\", \\"Dataset\\": \\"TimeTravel\\", \\"Metric\\": \\"0..5sec\\", \\"Score\\": \\"5\\"}}]","LLM prediction":"unanswerable"},{"Context":"Simulation of Coating -Visco-Elastic liquid in the Mico-Nip of Metering Size Press fora set of operating conditions and coating color formulations, undesirable phenomena like color spitting and coating ribs maybe triggered in the Micro-nip during the coating process. Therefore, our interest in this work focus on another parameter affect on the undesirable phenomena as the vortices in the Micro-nip. The problem deals with the flow through the Micro-nip of metering size press. The flow enters and exits at a tangential velocity of 20 m/s between two rollers with diameter 80 cm and 60 m apart. In the upper and bottom part of the domain the angular velocity is 314 rad /s. It has one sub-domain. Previous studies focus on the Micro-nip without considering the inertia and the viscoelasticity of the material. Roll coating is a technique commonly used in the coating industry to meter a thin fluid film on a moving substrate. During the film formation, the fluid is subjected to very high shear and extensional rates over a very short period of time. The fluid domain changes as a function of the hydrodynamic pressure within the nip as a result of the deformable cover usually used on one of the rolls. The free surface also adds more complexity to the flow due to the force equilibrium in the fluid gas interface. Last of all, the rheological behavior of the coating fluid is usually non-Newtonian, so the metering flow hydrodynamics is finally very difficult to describe. It is concluded that the normal forces of micro-nip increases with increasing the inhibitors. Therefore, it affects on the smoothness and creates defects. On the other hand, it can be concluded that the creation of big vortex in the middle of micro-nip affects on the coating liquid behavior.I.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Findings of the E2E NLG Challenge This paper summarises the experimental setup and results of the first shared task on end-to-end (E2E) natural language generation (NLG) in spoken dialogue systems. Recent end-to-end generation systems are promising since they reduce the need for data annotation. However, they are currently limited to small, delexicalised datasets. The E2E NLG shared task aims to assess whether these novel approaches can generate better-quality output by learning from a dataset containing higher lexical richness, syntactic complexity and diverse discourse phenomena. We compare 62 systems submitted by 17 institutions, covering a wide range of approaches, including machine learning architectures -with the majority implementing sequence-to-sequence models (seq2seq) -as well as systems based on grammatical rules and templates. Therefore, we decided to use pictorial MRs to collect 20% of the dataset Our crowd workers were asked to verbalise all information from the MR; however, they were not However, the human evaluation study provides a different picture Rank-based Magnitude Estimation (RankME) was used for evaluation, where crowd workers compared outputs of 5 systems for the same MR and assigned scores on a continuous scale We evaluated output naturalness and overall quality in separate tasks; for naturalness evaluation, the source MR was not shown to workers The final evaluation results were produced using the TrueSkill algorithm, with partial ordering into significance clusters computed using bootstrap resampling Table 2: Total number of MRs and human refer- ences in the E2E data sections. 4 , 672 4 , 862 MRs Table 3: A list of primary systems in the E2E NLG challenge, with word-overlap metric scores. decoder ) , heuristic slot aligner reranking , data augmentation classification reranking memory \u2663 \u2665 model ( Wen et al . , 2015b ) + controlling the first generated word \u2666 coverage penalty reranking , diverse ensembling BLEU NIST norm . avg . METEOR ROUGE - L CIDEr Table 4: TrueSkill measurements of quality (left) and naturalness (right). 3 4 \u2660 5 - 8 \u2663 10 - 12 \u2665 \u2666 13 - 16 9 - 12 13 - 17 3 - 6 18 - 19 20 - 21 1 - 1 7 - 11 15 - 17 4 - 8 TrueSkill 5 - 10 2 - 4 2 - 3","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Data-to-Text Generation\\", \\"Dataset\\": \\"E2E NLG Challenge\\", \\"Metric\\": \\"BLEU\\", \\"Score\\": \\"65.93\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Data-to-Text Generation\\", \\"Dataset\\": \\"E2E NLG Challenge\\", \\"Metric\\": \\"CIDEr\\", \\"Score\\": \\"2.2338\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Data-to-Text Generation\\", \\"Dataset\\": \\"E2E NLG Challenge\\", \\"Metric\\": \\"METEOR\\", \\"Score\\": \\"44.83\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Data-to-Text Generation\\", \\"Dataset\\": \\"E2E NLG Challenge\\", \\"Metric\\": \\"NIST\\", \\"Score\\": \\"8.6094\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Data-to-Text Generation\\", \\"Dataset\\": \\"E2E NLG Challenge\\", \\"Metric\\": \\"ROUGE-L\\", \\"Score\\": \\"68.50\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Spoken language identification\\", \\"Dataset\\": \\"E2E NLG Challenge\\", \\"Metric\\": \\"BLEU\\", \\"Score\\": \\"26.29\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Spoken language identification\\", \\"Dataset\\": \\"E2E NLG Challenge\\", \\"Metric\\": \\"METEOR\\", \\"Score\\": \\"23.15\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Spoken language identification\\", \\"Dataset\\": \\"E2E NLG Challenge\\", \\"Metric\\": \\"ROUGE-L\\", \\"Score\\": \\"27.68\\"}} ]"},{"Context":"Question Directed Graph Attention Network for Numerical Reasoning over Text Numerical reasoning over texts, such as addition, subtraction, sorting and counting, is a challenging machine reading comprehension task, since it requires both natural language understanding and arithmetic computation. To address this challenge, we propose a heterogeneous graph representation for the context of the passage and question needed for such reasoning, and design a question directed graph attention network to drive multi-step numerical reasoning over this context graph. Our model, which combines deep learning and graph reasoning, achieves remarkable results in benchmark datasets such as DROP. We performed experiments on the DROP dataset, which was recently released for research on numerical machine reading comprehension (MRC) Following the previous work, we used Exact Match (EM) and F1 score as the evaluation metrics Table 2: Overall results on the development and test set of DROP. For QDGAT p , we used more careful data pre- processing and a RoBERTa pre-trained on the SQuaD dataset. \u2020 denotes that the result is taken from the public leaderboard. Better results are in bold. Method Dev Test EM F1 Table 3: Ablation study results on the development set of DROP. QDGAT NH removes the number type and entity from the graph, and QDGAT NQ removes question direction from QDGAT. Better results are in bold. EM F1 Table 4: Decomposed performance on different answer types in the development set of DROP. Better results are in bold. Method Number EM F1 Span Date Table 5: The cases from the DROP dataset. The predictions from the QDGAT and NumNet+ are illustrated. The differences between the output of these two models demonstrate the properties of the proposed model. The last two columns","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"DROP Test\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"88.38\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"DROP Test\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"86.1\\"}} ]"},{"Context":"A formal proof of the four color theorem A formal proof has not been found for the four color theorem since 1852 when Francis Guthrie first conjectured the four color theorem. Why? A bad idea, we think, directed people to a rough road. Using a similar method to that for the formal proof of the five color theorem, a formal proof is proposed in this paper of the four color theorem, namely, every planar graph is four-colorable. The formal proof proposed can also be regarded as an algorithm to color a planar graph using four colors so that no two adjacent vertices receive the same color.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"A Unified Multi-scale Deep Convolutional Neural Network for Fast Object Detection A unified deep neural network, denoted the multi-scale CNN (MS-CNN), is proposed for fast multi-scale object detection. The MS-CNN consists of a proposal sub-network and a detection sub-network. In the proposal sub-network, detection is performed at multiple output layers, so that receptive fields match objects of different scales. These complementary scale-specific detectors are combined to produce a strong multi-scale object detector. The unified network is learned end-to-end, by optimizing a multi-task loss. Feature upsampling by deconvolution is also explored, as an alternative to input upsampling, to reduce the memory and computation costs. State-of-the-art object detection performance, at up to 15 fps, is reported on datasets, such as KITTI and Caltech, containing a substantial number of small objects. The performance of the MS-CNN detector was evaluated on the KITTI and Caltech Pedestrian benchmarks KITTI contains three object classes: car, pedestrian and cyclist, and three levels of evaluation: easy, moderate and hard In all ablation experiments, the training set was used for learning and the validation set for evaluation We start with an evaluation of the proposal network In this section we evaluate object detection performance Pedestrian detection on Caltech The MS-CNN detector was also evaluated on the Caltech pedestrian benchmark Table 2. Detection recall of the various detection layers on KITTI validation set (car), as a function of object hight in pixels. det - 16 det - 8 det - 64 det - 32 combined Table 3. Results on the KITTI validation set. \\"hXXX\\" indicates an input of height \\"XXX\\", \\"2x\\" deconvolution, \\"ctx\\" context encoding, and \\"c\\" dimensionality reduction convolution. In columns \\"Time\\" and \\"# params\\", entries before the \\"/\\" are for car model and after for pedestrian/cyclist model. 1 # candidates SS Cars Easy Pedestrians Mod IoU overlap threshold Pedestrian Hard IoU MCG 0 1 at recall # params EB BING Table 4. Results on the KITTI benchmark test set (only published works shown). 1 Easy KITTI Car ( moderate ) 3DOP Time SDP+RPN Faster \u2212 RCNN KITTI Cyclist ( moderate ) CompACT \u2212 Deep recall AOG MS \u2212 CNN Cars Pedestrians KITTI Pedestrian ( moderate ) Mod lSVM \u2212","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Face Detection\\", \\"Dataset\\": \\"WIDER Face (Hard)\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"0.809\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Pedestrian Detection\\", \\"Dataset\\": \\"Caltech\\", \\"Metric\\": \\"Reasonable Miss Rate\\", \\"Score\\": \\"9.95\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Pedestrian Detection\\", \\"Dataset\\": \\"Caltech\\", \\"Metric\\": \\"Reasonable Miss Rate\\", \\"Score\\": \\"12.4\\"}} ]"},{"Context":"Bridging the Gap between Community and Node Representations: Graph Embedding via Community Detection Graph embedding has become a key component of many data mining and analysis systems. Current graph embedding approaches either sample a large number of node pairs from a graph to learn node embeddings via stochastic optimization or factorize a high-order node proximity/adjacency matrix via computationally intensive matrix factorization techniques. These approaches typically require significant resources for the learning process and rely on multiple parameters, which limits their applicability in practice. Moreover, most of the existing graph embedding techniques operate effectively in one specific metric space only (e.g., the one produced with cosine similarity), do not preserve higher-order structural features of the input graph and cannot automatically determine a meaningful number of dimensions for the embedding space. Typically, the produced embeddings are not easily interpretable, which complicates further analyses and limits their applicability. To address these issues, we propose DAOR, a highly efficient and parameter-free graph embedding technique producing metric space-robust, compact and interpretable embeddings without any manual tuning. Compared to a dozen state-of-the-art graph embedding algorithms, DAOR yields competitive results on both node classification (which benefits form high-order proximity) and link prediction (which relies on low-order proximity mostly). Unlike existing techniques, however, DAOR does not require any parameter tuning and improves the embeddings generation speed by several orders of magnitude. Our approach has hence the ambition to greatly simplify and speedup data analysis tasks involving graph representation learning.Index Terms-parameter-free graph embedding, unsupervised learning of network representation, automatic feature extraction, interpretable embeddings, scalable graph embedding. This graph is used only to evaluate the efficiency of the embedding techniques, since the ground-truth categories include only 3% of the graph (as opposed to a 100% coverage for the other graphs) For NetHash, as suggested by the authors, \xb7 the algorithm meta parameters are tuned once for all datasets to maximize accuracy : the algorithm parameters are tuned for each dataset to maximize accuracy we search the optimal tree depth in {1, 2, 3}","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"DBLP\\", \\"Metric\\": \\"Macro F1\\", \\"Score\\": \\"87.64\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"DBLP\\", \\"Metric\\": \\"Micro F1\\", \\"Score\\": \\"87.86\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"BlogCatalog\\", \\"Metric\\": \\"Macro F1\\", \\"Score\\": \\"17.25\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"BlogCatalog\\", \\"Metric\\": \\"Micro F1\\", \\"Score\\": \\"33.05\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Wiki\\", \\"Metric\\": \\"Macro F1\\", \\"Score\\": \\"15.97\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Wiki\\", \\"Metric\\": \\"Micro F1\\", \\"Score\\": \\"53.24\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Citeseer\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"75.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Pubmed\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"80.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Cora\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"86.80%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"YouTube\\", \\"Metric\\": \\"Macro-F1@2%\\", \\"Score\\": \\"30.77\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"YouTube\\", \\"Metric\\": \\"Micro-F1@2%\\", \\"Score\\": \\"38.59\\"}} ]"},{"Context":"ECN verbose mode: a statistical method for network path congestion estimation This article introduces a simple and effective methodology to determine the level of congestion in a network with an ECN-like marking scheme. The purpose of the ECN bit is to notify TCP sources of an imminent congestion in order to react before losses occur. However, ECN is a binary indicator which does not reflect the congestion level (i.e. the percentage of queued packets) of the bottleneck, thus preventing any adapted reaction. In this study, we use a counter in place of the traditional ECN marking scheme to assess the number of times a packet has crossed a congested router. Thanks to this simple counter, we drive a statistical analysis to accurately estimate the congestion level of each router on a network path. We detail in this paper an analytical method validated by some preliminary simulations which demonstrate the feasibility and the accuracy of the concept proposed. We conclude this paper with possible applications and expected future work.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"se(3)-TrackNet: Data-driven 6D Pose Tracking by Calibrating Image Residuals in Synthetic Domains Tracking the 6D pose of objects in video sequences is important for robot manipulation. This task, however, introduces multiple challenges: (i) robot manipulation involves significant occlusions; (ii) data and annotations are troublesome and difficult to collect for 6D poses, which complicates machine learning solutions, and (iii) incremental error drift often accumulates in long term tracking to necessitate re-initialization of the object\'s pose. This work proposes a data-driven optimization approach for long-term, 6D pose tracking. It aims to identify the optimal relative pose given the current RGB-D observation and a synthetic image conditioned on the previous best estimate and the object\'s model. The key contribution in this context is a novel neural network architecture, which appropriately disentangles the feature encoding to help reduce domain shift, and an effective 3D orientation representation via Lie Algebra. Consequently, even when the network is trained only with synthetic data can work effectively over real images. Comprehensive experiments over benchmarks -existing ones as well as anew dataset with significant occlusions related to object manipulation -show that the proposed approach achieves consistently robust estimates and outperforms alternatives, even though they have been trained with real images. The approach is also the most computationally efficient among the alternatives and achieves a tracking frequency of 90.9Hz. 1 This section evaluates the proposed approach and compares against state-of-the-art 6D pose tracking methods as well as single-image pose estimation methods on a public benchmark The evaluation closely follows the protocols adopted in comparison methods,,, and reports the AUC (Area Under Curve) results on the keyframes in 12 video test sequences evaluated by the metrics of ADD = 1 m \u2211 x\u2208M ||Rx + T \u2212 (Rx + T )|| which performs exact model matching, and ADD- designed for evaluating symmetric objects, of which the matching between points can be ambiguous for some views Although this dataset contains pose annotated training and validation data collected in real world, the proposed approach does not use any of them but is trained only on synthetic data generated by aforementioned pipeline YCBInEOAT Dataset There have been several public benchmarks, where videos are collected by placing the objects statically on a table-top while a camera","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"6D Pose Estimation\\", \\"Dataset\\": \\"YCB-Video\\", \\"Metric\\": \\"ADDS AUC\\", \\"Score\\": \\"93.3\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Multi-Object Tracking\\", \\"Dataset\\": \\"TrackingNet\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"74.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Multi-Object Tracking\\", \\"Dataset\\": \\"TrackingNet\\", \\"Metric\\": \\"Normalized Precision\\", \\"Score\\": \\"80.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Multi-Object Tracking\\", \\"Dataset\\": \\"TrackingNet\\", \\"Metric\\": \\"Precision\\", \\"Score\\": \\"68.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Multi-Object Tracking\\", \\"Dataset\\": \\"LaSOT\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"56.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Multi-Object Tracking\\", \\"Dataset\\": \\"GOT-10k\\", \\"Metric\\": \\"Average Overlap\\", \\"Score\\": \\"65.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Multi-Object Tracking\\", \\"Dataset\\": \\"GOT-10k\\", \\"Metric\\": \\"Success Rate 0.5\\", \\"Score\\": \\"72.8\\"}} ]"},{"Context":"AXM-Net: Cross-Modal Alignment and Contextual Attention for Person Re-ID Cross-modal person re-identification (Re-ID) is critical for modern video surveillance systems. The key challenge is to align inter-modality representations conforming to semantic information present fora person and ignore background information. In this work, we present a novel convolutional neural network (CNN) based architecture designed to learn semantically Aligned cross-Modal (AXM-Net) visual and textual representations. The underlying building block, AXM-Block, is a unified multi-layer network that dynamically exploits the multi-scale knowledge from both modalities and re-calibrates each modality according to shared semantics. To complement the convolutional design, a contextual attention is applied in text branch to manipulate long-term dependencies. Moreover, we propose contextual attention on local image parts to capture fine-grained details of the person. Our design is unique in its ability to implicitly learn aligned semantics between modalities during feature learning stage. The unified feature learning effectively utilises textual data as a super-annotation signal for visual representation learning and automatically rejects irrelevant information. The entire AXM-Net is trained endto-end on CUHK-PEDES data. We report results on two tasks, person search and cross-modal Re-ID. The AXM-Net outperforms the current state-of-the-art (SOTA) method by 5.22% in Rank@1 on the CUHK-PEDES and by >10% for cross-viewpoint text-to-image Re-ID scenario on CrossRe-ID and CUHK-SYSU datasets.  Table 1. Comparison with SOTA models on the CUHK-PEDES dataset - Rank@5 Rank@10 Rank@1 mAP Table 2. Performance comparison on cross-modal Re-ID. Query \u2212 \u2192 Gallery Rank@1 mAP - Table 3. Performance comparison on the proposed cross-modal split for Market-1501 . Query \u2212 \u2192 Gallery Rank@1 mAP - Table 5. Design parameters for the visual contextual attention part branch Table 4 . Ablation study on the AXM - Net on CUHK - PEDES test set \u2192 Gallery Table 3 . Performance comparison on the proposed cross - modal split for Market - 1501 . Query \u2212 Rank@1 SA","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Text based Person Retrieval\\", \\"Dataset\\": \\"CUHK-PEDES\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"61.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Text based Person Retrieval\\", \\"Dataset\\": \\"CUHK-PEDES\\", \\"Metric\\": \\"R@10\\", \\"Score\\": \\"85.75\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Text based Person Retrieval\\", \\"Dataset\\": \\"CUHK-PEDES\\", \\"Metric\\": \\"R@5\\", \\"Score\\": \\"79.4\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"CUHK-PEDES\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"64.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"CUHK-PEDES\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"45.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"CUHK-PEDES\\", \\"Metric\\": \\"Top-1\\", \\"Score\\": \\"51.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"CUHK-PEDES\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"45.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"CUHK-PEDES\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"34.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"CUHK-PEDES\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"40.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Person Re-Identification\\", \\"Dataset\\": \\"CUHK-PEDES\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"64.0\\"}},"},{"Context":"INVESTIGATION OF DIFFERENT SKELETON FEATURES FOR CNN-BASED 3D ACTION RECOGNITION Deep learning techniques are being used in skeleton based action recognition tasks and outstanding performance has been reported. Compared with RNN based methods which tend to overemphasize temporal information, CNN-based approaches can jointly capture spatio-temporal information from texture color images encoded from skeleton sequences. There are several skeleton-based features that have proven effective in RNN-based and handcrafted-feature-based methods. However, it remains unknown whether they are suitable for CNN-based approaches. This paper proposes to encode five spatial skeleton features into images with different encoding methods. In addition, the performance implication of different joints used for feature extraction is studied. The proposed method achieved state-of-the-art performance on NTU RGB+D dataset for 3D human action analysis. An accuracy of 75.32% was achieved in Large Scale 3D Human Activity Analysis Challenge in Depth Videos. The proposed method was evaluated on NTU RGB+D Dataset Currently, NTU RGB+D Dataset is the largest dataset for action recognition This dataset is challenging and there are two types of protocols for evaluation of methods, cross-subject and cross-view The effectiveness of different types of spatial features, different joint selection schemes were evaluated There are five features evaluated, each of which was evaluated with different feature (joint) selection methods and different encoding methods Table 1. Evaluation results of different features and encoding methods. Feature Method Accuracy Fused Accuracy methods . JLd Accuracy Fused Accuracy Table 1 . Evaluation results of different features and encoding","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (CV)\\", \\"Score\\": \\"82.31\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (CS)\\", \\"Score\\": \\"75.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (CV)\\", \\"Score\\": \\"76.3\\"}} ]"},{"Context":"M3D-RPN: Monocular 3D Region Proposal Network for Object Detection Understanding the world in 3D is a critical component of urban autonomous driving. Generally, the combination of expensive LiDAR sensors and stereo RGB imaging has been paramount for successful 3D object detection algorithms, whereas monocular image-only methods experience drastically reduced performance. We propose to reduce the gap by reformulating the monocular 3D detection problem as a standalone 3D region proposal network. We leverage the geometric relationship of 2D and 3D perspectives, allowing 3D boxes to utilize well-known and powerful convolutional features generated in the image-space. To help address the strenuous 3D parameter estimations, we further design depth-aware convolutional layers which enable location specific feature development and in consequence improved 3D scene understanding. Compared to prior work in monocular 3D detection, our method consists of only the proposed 3D region proposal network rather than relying on external networks, data, or multiple stages. M3D-RPN is able to significantly improve the performance of both monocular 3D Object Detection and Bird\'s Eye View tasks within the KITTI urban autonomous driving dataset, while efficiently using a shared multi-class model. We evaluate our proposed framework on the challenging KITTI dataset under two core 3D localization tasks: Bird\'s Eye View (BEV) and 3D Object Detection We comprehensively compare our method on the official test dataset as well as two validation splits, and perform analysis of the critical components which comprise our framework Table 1. Bird\'s Eye View. Comparison of our method to image-only 3D localization frameworks on the Bird\'s Eye View task (APBEV). Type - Type Easy Mod Bird \' s Eye View . Comparison of our method to image - only 3D localization frameworks on the Bird \' s Eye View task ( APBEV ) . Hard Table 2. 3D Detection. Comparison of our method to image-only 3D localization frameworks on the 3D Detection task (AP3D). Type - Type Easy Mod Bird \' s Eye View . Comparison of our method to image - only 3D localization frameworks on the Bird \' s Eye View task ( APBEV ) . Hard Table 3. Multi-class 3D Localization. The performance of our method when applied as a multi-class 3D detection system using a single shared model. We evaluate using the mod setting on KITTI. AP3D [ val1 / val2 / test ] APBEV [","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Vehicle Pose Estimation\\", \\"Dataset\\": \\"KITTI Cars Hard\\", \\"Metric\\": \\"Average Orientation Similarity\\", \\"Score\\": \\"67.08\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Vehicle Pose Estimation\\", \\"Dataset\\": \\"KITTI Cars Hard\\", \\"Metric\\": \\"Average Orientation Similarity\\", \\"Score\\": \\"34.81\\"}} ]"},{"Context":"Sublinear Algorithms for Approximating String Compressibility We raise the question of approximating the compressibility of a string with respect to a fixed compression scheme, in sublinear time. We study this question in detail for two popular lossless compression schemes: run-length encoding (RLE) and Lempel-Ziv (LZ), and present sublinear algorithms for approximating compressibility with respect to both schemes. We also give several lower bounds that show that our algorithms for both schemes cannot be improved significantly. Our investigation of LZ yields results whose interest goes beyond the initial questions we set out to study. In particular, we prove combinatorial structural lemmas that relate the compressibility of a string with respect to Lempel-Ziv to the number of distinct short substrings contained in it. In addition, we show that approximating the compressibility with respect to LZ is related to approximating the support size of a distribution.Given an extremely long string, it is natural to wonder how compressible it is. This fundamental question is of interest to a wide range of areas of study, including computational complexity theory, machine learning, storage systems, and communications. As massive data sets are now commonplace, the ability to estimate their compressibility with extremely efficient, even sublinear time, algorithms, is gaining in importance. The most general measure of compressibility, Kolmogorov complexity, is not computable (see [14] fora textbook treatment), nor even approximable. Even under restrictions which make it computable (such as abound on the running time of decompression), it is probably hard to approximate in polynomial time, since an approximation would allow distinguishing random from pseudorandom strings and, hence, inverting one-way functions. However, the question of how compressible a large string is with respect to a specific compression scheme maybe tractable, depending on the particular scheme.We raise the question of approximating the compressibility of a string with respect to a fixed compression scheme, in sublinear time, and give algorithms and nearly matching lower bounds for several versions of the problem. While this question is new, for one compression scheme, answers follow from previous work. Namely, compressibility under Huffman encoding is determined by the entropy of the symbol frequencies. Batu et al. [3] and Brautbar and\u22c6","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Evaluation of SystemC Modelling of Reconfigurable Embedded Systems This paper evaluates the use of pin and cycle accurate SystemC models for embedded system design exploration and early software development. The target system is Mi-croBlaze VanillaNet Platform running MicroBlaze uClinux operating system. The paper compares Register Transfer Level (RTL) Hardware Description Language (HDL) simulation speed to the simulation speed of several different SystemC models. It is shown that simulation speed of pin and cycle accurate models can go up to 150 kHz, compared to 100 Hz range of HDL simulation. Furthermore, utilising techniques that temporarily compromise cycle accuracy, effective simulation speed of up to 500 kHz can be obtained.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"A Symphony Conducted by BruNet We introduce BruNet, a general P2P software framework which we use to produce the first implementation of Symphony, a 1-D Kleinberg small-world architecture. Our framework is designed to easily implement and measure different P2P protocols over different transport layers such as TCP or UDP. This paper discusses our implementation of the Symphony network, which allows each node to keep k \u2264 log N shortcut connections and to route to any other node with a short average delay of O( 1 k log 2 N ). We present experimental results taken from several PlanetLab deployments of size up to 1060 nodes. These successful deployments represent some of the largest PlanetLab deployments of P2P overlays found in the literature, and show our implementation\'s robustness to massive node dynamics in a WAN environment. AbstractWe introduce BruNet, a general P2P software framework which we use to produce the first implementation of Symphony, a 1-D Kleinberg small-world architecture. Our framework is designed to easily implement and measure different P2P protocols over different transport layers such as TCP or UDP. This paper discusses our implementation of the Symphony network, which allows each node to keep k \u2264 log N shortcut connections and to route to any other node with a short average delay of O( 1 k log 2 N ). We present experimental results taken from several PlanetLab deployments of size up to 1060 nodes. These successful deployments represent some of the largest PlanetLab deployments of P2P overlays found in the literature, and show our implementation\'s robustness to massive node dynamics in a WAN environment.  Table 1: Packet format 20 Table 1: Packet format net packets , we do not need to include a checksum ( since , similar to Ethernet packets but with a few notable differ - In many respects , the routed P2P packets are 20","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Philosophical Survey of Passwords Over the years security experts in the field of Information Technology have had a tough time in making passwords secure. This paper studies and takes a careful look at this issue from the angle of philosophy and cognitive science. We have studied the process of passwords to rank its strengths and weaknesses in order to establish a quality metric for passwords. Finally we related the process to human senses which enables us to propose a constitutional scheme for the process of password. The basic proposition is to exploit relationship between human senses and password to ensure improvement in authentication while keeping it an enjoyable activity.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Human Intracranial EEG Quantitative Analysis and Automatic Feature Learning for Epileptic Seizure Prediction Objevtive: The aim of this study is to develop an efficient and reliable epileptic seizure prediction system using intracranial EEG (iEEG) data, especially for people with drugresistant epilepsy. The prediction procedure should yield accurate results in a fast enough fashion to alert patients of impending seizures. Methods: We quantitatively analyze the human iEEG data to obtain insights into how the human brain behaves before and between epileptic seizures. We then introduce an efficient pre-processing method for reducing the data size and converting the time-series iEEG data into an image-like format that can be used as inputs to convolutional neural networks (CNNs). Further, we propose a seizure prediction algorithm that uses cooperative multi-scale CNNs for automatic feature learning of iEEG data. Results: 1) iEEG channels contain complementary information and excluding individual channels is not advisable to retain the spatial information needed for accurate prediction of epileptic seizures. 2) The traditional PCA is not a reliable method for iEEG data reduction in seizure prediction. 3) Hand-crafted iEEG features may not be suitable for reliable seizure prediction performance as the iEEG data varies between patients and overtime for the same patient. 4) Seizure prediction results show that our algorithm outperforms existing methods by achieving an average sensitivity of 87.85% and AUC score of 0.84. Conclusion: Understanding how the human brain behaves before seizure attacks and far from them facilitates better designs of epileptic seizure predictors. Significance: Accurate seizure prediction algorithms can warn patients about the next seizure attack so they could avoid dangerous activities. Medications could then be administered to abort the impending seizure and minimize the risk of injury. Closed-loop seizure intervention systems could also help to prevent seizures in patients with drug-resistant epilepsy. To examine the generalizability of our seizure prediction algorithm over different subjects, we first evaluate the performance metrics for the three patients individually and then report the average performance","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Seizure prediction\\", \\"Dataset\\": \\"Melbourne University Seizure Prediction\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.840\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Seii-Supervised Image Classification\\", \\"Dataset\\": \\"EBM-NLP\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.93\\"}} ]"},{"Context":"Pyramid Feature Attention Network for Saliency detection Saliency detection is one of the basic challenges in computer vision. How to extract effective features is a critical point for saliency detection. Recent methods mainly adopt integrating multi-scale convolutional features indiscriminately. However, not all features are useful for saliency detection and some even cause interferences. To solve this problem, we propose Pyramid Feature Attention network to focus on effective high-level context features and low-level spatial structural features. First, we design Context-aware Pyramid Feature Extraction (CPFE) module for multi-scale high-level feature maps to capture rich context features. Second, we adopt channel-wise attention (CA) after CPFE feature maps and spatial attention (SA) after low-level feature maps, then fuse outputs of CA & SA together. Finally, we propose an edge preservation loss to guide network to learn more detailed information in boundary localization. Extensive evaluations on five benchmark datasets demonstrate that the proposed method outperforms the state-ofthe-art approaches under different evaluation metrics. The performance evaluation is utilized on five standard benchmark datasets: DUTS-test, ECSSD, HKU-IS, PASCAL-S and DUT-OMRON DUTS is a large scale dataset, which contains 10553 images for training and 5019 images for testing Images of this dataset have one or more salient objects and relatively complex background Same as other state-of-the-art salient object detection methods, three popular criteria are used for performance evaluation, i.e wF \u03b2 is a overall evaluation standard computed by the weighted combination of precision and recall: Image GT Amulet DCL DSS NLDF BDMPM PAGRN RFCN SRM UCF Ours Where \u03b2 2 = 0.3 as used in other approaches Table 1. The wF \u03b2 and M AE of different salient object detection approaches on all test datasets. The best three results are shown in red, blue, and green. Methods HKU - IS \u03b2 PASCAL - S M AE DUTS - test ECSSD DUT - OMRON wF Table 2. The effectiveness of edge preservation loss. The score of wF \u03b2 and M AE in our method when \u03b1 is given different values. The best result is shown in red. The test dataset is DUTS-test. without the edge preservation loss .","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Saliency Detection\\", \\"Dataset\\": \\"DUT-OMRON\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.0414\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Saliency Detection\\", \\"Dataset\\": \\"ECSSD\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.0328\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Saliency Detection\\", \\"Dataset\\": \\"PASCAL-S\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.0677\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Saliency Detection\\", \\"Dataset\\": \\"HKU-IS\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.0324\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Saliency Detection\\", \\"Dataset\\": \\"DUTS-test\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.0405\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"RGB Salient Object Detection\\", \\"Dataset\\": \\"ECS\\", \\"Metric\\": \\"F-measure\\", \\"Score\\": \\"0.93\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"RGB Salient Object Detection\\", \\"Dataset\\": \\"ECS\\", \\"Metric\\": \\"F-measure\\", \\"Score\\": \\"0.93\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"RGB Salient Object Detection\\", \\"Dataset\\": \\"DUT-OMRON\\", \\"Metric\\": \\"F-measure\\", \\"Score\\": \\"0.93\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"RGB Salient Object Detection\\", \\"Dataset\\": \\"DUT-OMRON\\", \\"Metric\\": \\"F-measure\\", \\"Score\\": \\"0.93\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"RGB Salient Object Detection\\", \\"Dataset\\": \\"PAS\\", \\"Metric\\": \\"F-measure\\", \\"Score\\": \\"0.968\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"RGB Salient Object Detection\\", \\"Dataset\\": \\"Annotated\\", \\"Metric\\": \\"F-measure\\", \\"Score\\": \\"0.920\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"RGB Salient Object Detection\\", \\"Dataset\\": \\"HKU-IS\\", "},{"Context":"CSPNET: A NEW BACKBONE THAT CAN ENHANCE LEARNING CAPABILITY OF CNN A PREPRINT Neural networks have enabled state-of-the-art approaches to achieve incredible results on computer vision tasks such as object detection. However, such success greatly relies on costly computation resources, which hinders people with cheap devices from appreciating the advanced technology. In this paper, we propose Cross Stage Partial Network (CSPNet) to mitigate the problem that previous works require heavy inference computations from the network architecture perspective. We attribute the problem to the duplicate gradient information within network optimization. The proposed networks respect the variability of the gradients by integrating feature maps from the beginning and the end of a network stage, which, in our experiments, reduces computations by 20% with equivalent or even superior accuracy on the ImageNet dataset, and significantly outperforms state-of-the-art approaches in terms of AP 50 on the MS COCO object detection dataset. The CSPNet is easy to implement and general enough to cope with architectures based on ResNet, ResNeXt, and DenseNet. Source code is at https://github.com/WongKinYiu/CrossStagePartialNetworks. We will use ImageNet\'s image classification dataset used in ILSVRC 2012 to validate our proposed CSPNet Besides, we also use the MS COCO object detection dataset to verify the proposed EFM Next, we shall conduct an ablation study of EFM based on the MS COCO dataset Table 1: Ablation study of CSPNet on ImageNet. trans . \u03b3 partial Top - 1 BFLOPs two - way dense Table 2: Ablation study of EFM on MS COCO. atten . BFLOPs FPS fusion AP50 AP75 exact AP Table 3: Compare with state-of-the-art methods on ImageNet. - BFLOPs Top - 5 #Parameter Top - 1 Table 4: Compare with state-of-the-art methods on MSCOCO Object Detection. AP75 BFLOPs AP50 APS #Parameter APL APM AP Table 5: Inference rate on mobile GPU (mGPU) and CPU real-time object detectors (in fps). upgraded . For the same CSPPeleeNet Ref . backbone , although EFM ( SAM ) is 62 fps slower than PRN ( 3l ) on GTX Size GPU CPU mGPU AP50","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Real-Time Object Detection\\", \\"Dataset\\": \\"COCO\\", \\"Metric\\": \\"FPS\\", \\"Score\\": \\"58\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Real-Time Object Detection\\", \\"Dataset\\": \\"COCO\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"33.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Real-Time Object Detection\\", \\"Dataset\\": \\"COCO\\", \\"Metric\\": \\"inference time (ms)\\", \\"Score\\": \\"17\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"20.5M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"79.8%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"95.2%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"45.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"71.71%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"94.82%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"79.7%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"45.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"45.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"43.3\\"}}, { \'"},{"Context":"NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection Current state-of-the-art convolutional architectures for object detection are manually designed. Here we aim to learn a better architecture of feature pyramid network for object detection. We adopt Neural Architecture Search and discover anew feature pyramid architecture in a novel scalable search space covering all cross-scale connections. The discovered architecture, named NAS-FPN, consists of a combination of top-down and bottom-up connections to fuse features across scales. NAS-FPN, combined with various backbone models in the RetinaNet framework, achieves better accuracy and latency tradeoff compared to state-ofthe-art object detection models. NAS-FPN improves mobile detection accuracy by 2 AP compared to state-of-the-art SS-DLite with MobileNetV2 model in [32] and achieves 48.3 AP which surpasses Mask R-CNN [10] detection accuracy with less computation time.  Table 1: Performance of RetinaNet with NAS-FPN and other state-of-the-art detectors on test-dev set of COCO. 3 5 Table 1 : Performance of RetinaNet with NAS - FPN and other state - of - the - art detectors on test - dev set of COCO . Figure 10 : Performance comparison of NAS - FPN with fea - @384 +DB @384 3 inference time ( ms ) 5 1200 test - dev AP # params 1000 model # FLOPs image size @256","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Real-Time Object Detection\\", \\"Dataset\\": \\"COCO\\", \\"Metric\\": \\"FPS\\", \\"Score\\": \\"3.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Real-Time Object Detection\\", \\"Dataset\\": \\"COCO\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"48.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Real-Time Object Detection\\", \\"Dataset\\": \\"COCO\\", \\"Metric\\": \\"inference time (ms)\\", \\"Score\\": \\"278.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Real-Time Object Detection\\", \\"Dataset\\": \\"COCO\\", \\"Metric\\": \\"FPS\\", \\"Score\\": \\"3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Real-Time Object Detection\\", \\"Dataset\\": \\"COCO\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"25.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Real-Time Object Detection\\", \\"Dataset\\": \\"COCO\\", \\"Metric\\": \\"inference time (ms)\\", \\"Score\\": \\"285\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"29.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"29.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"25.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"22.6\\"}} ]"},{"Context":"Masked Autoregressive Flow for Density Estimation Autoregressive models are among the best performing neural density estimators. We describe an approach for increasing the flexibility of an autoregressive model, based on modelling the random numbers that the model uses internally when generating data. By constructing a stack of autoregressive models, each modelling the random numbers of the next model in the stack, we obtain a type of normalizing flow suitable for density estimation, which we call Masked Autoregressive Flow. This type of flow is closely related to Inverse Autoregressive Flow and is a generalization of Real NVP. Masked Autoregressive Flow achieves state-of-the-art performance in a range of general-purpose density estimation tasks. In the following paragraphs, we give a brief description of the four UCI datasets (POWER, GAS, HEPMASS, MINIBOONE) and of the way they were preprocessed The POWER dataset contains measurements of electric power consumption in a household over a period of 47 months Created by Fonollosa et al., this dataset represents the readings of an array of 16 chemical sensors exposed to gas mixtures over a 12 hour period Table 1: Average test log likelihood (in nats) for unconditional density estimation. The best performing model for each dataset is shown in bold (multiple models are highlighted if the difference is not statistically significant according to a paired t-test). Error bars correspond to 2 standard deviations. BSDS300 GAS MINIBOONE POWER HEPMASS Table 2: Average test log likelihood (in nats) for conditional density estimation. The best performing model for each dataset is shown in bold. Error bars correspond to 2 standard deviations. \u2212 397 \xb1 21 2568 \xb1 26 2936 \xb1 27 unconditional conditional 147 \xb1 20 3049 \xb1 26 MNIST 2367 \xb1 29 2576 \xb1 27 Table 4: Number of hidden layers L and number of hidden units H given as options for each dataset. Each combination is reported in the format L \xd7 H. BSDS300 GAS MINIBOONE MNIST POWER CIFAR - 10 HEPMASS Table 5: Dimensionality D and number of","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Density Estimation\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Log-likelihood\\", \\"Score\\": \\"3049\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Density Estimation\\", \\"Dataset\\": \\"MNIST\\", \\"Metric\\": \\"Log-likelihood\\", \\"Score\\": \\"-1038.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Density Estimation\\", \\"Dataset\\": \\"CIFAR-10 (Conditional)\\", \\"Metric\\": \\"Log-likelihood\\", \\"Score\\": \\"3058\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Density Estimation\\", \\"Dataset\\": \\"UCI POWER\\", \\"Metric\\": \\"Log-likelihood\\", \\"Score\\": \\"0.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Density Estimation\\", \\"Dataset\\": \\"MNIST (Conditional)\\", \\"Metric\\": \\"Log-likelihood\\", \\"Score\\": \\"-1030.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Density Estimation\\", \\"Dataset\\": \\"BSDS300\\", \\"Metric\\": \\"Log-likelihood\\", \\"Score\\": \\"153.71\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Density Estimation\\", \\"Dataset\\": \\"UCI MINIBOONE\\", \\"Metric\\": \\"Log-likelihood\\", \\"Score\\": \\"-12.27\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Density Estimation\\", \\"Dataset\\": \\"UCI HEPMASS\\", \\"Metric\\": \\"Log-likelihood\\", \\"Score\\": \\"-15.15\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"Binarized MNIST\\", \\"Metric\\": \\"nats\\", \\"Score\\": \\"84.68\\"}} ]"},{"Context":"D\xe9veloppement et analyse multi outils d\'un protocole MAC d\xe9terministe pour un r\xe9seau de capteurs sans fil Nous pr\xe9sentons dans cet article une m\xe9thodologie multi outils de d\xe9veloppement et d\'analyse de protocole utilis\xe9e pour valider une nouvelle m\xe9thode d\'acc\xe8s. La technologie IEEE 802.15.4 / ZigBee sert de base protocolaire \xe0 la proposition d\'une couche MAC d\xe9terministe offrant un haut niveau de QdS. Ce type de WPAN peut typiquement \xeatre utilis\xe9 pour des r\xe9seaux de capteurs sans fil \xe0 fortes contraintes temporelles. Afin de valider les protocoles propos\xe9s, trois outils compl\xe9mentaires et ad\xe9quats sont utilis\xe9s : les R\xe9seaux de Petri pour la validation formelle du s\xe9quencement des trames, un simulateur sp\xe9cifique pour les aspects temporels et des m\xe9trologies sur un prototypage r\xe9el \xe0 base de composants ZigBee FREESCALE pour la caract\xe9risation fine des couches physique et liaison. ABSTRACT. In this article, we present a multi-tool method for the development and the analysis of anew medium access method. IEEE 802.15.4 / ZigBee technology has been used as a basis for this new determinist MAC layer which enables a high level of QoS. This WPAN can be typically used for wireless sensor networks which require strong temporal constraints. To validate the proposed protocol, three complementary and adequate tools are used: Petri Nets for the formal validation of the algorithm, a dedicated simulator for the temporal aspects, and some measures on areal prototype based on a couple of ZigBee FREESCALE components for the hardware characterization of layers #1 and #2. MOTS-CL\xc9S : R\xe9seau de capteur sans fil, IEEE 802.15.4, ZigBee, M\xe9thode d\'acc\xe8s au m\xe9dium, Qualit\xe9 de Service, Prototypage, Validation formelle, RdP, Simulation, Analyse de performance, m\xe9trologie.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Error-Correcting Data Structures We study data structures in the presence of adversarial noise. We want to encode a given object in a succinct data structure that enables us to efficiently answer specific queries about the object, even if the data structure has been corrupted by a constant fraction of errors. This new model is the common generalization of (static) data structures and locally decodable errorcorrecting codes. The main issue is the tradeoff between the space used by the data structure and the time (number of probes) needed to answer a query about the encoded object. We prove a number of upper and lower bounds on various natural error-correcting data structure problems. In particular, we show that the optimal length of error-correcting data structures for the Membership problem (where we want to store subsets of size s from a universe of size n) is closely related to the optimal length of locally decodable codes for s-bit strings.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Computing a Discrete Logarithm in O(n 3 ) This paper presents a means with time complexity of at worst O(n 3 ) to compute the discrete logarithm on cyclic finite groups of integers modulo p. The algorithm makes use of reduction of the problem to that of finding the concurrent zeros of two periodic functions in the real numbers. The problem is treated as an analog to a form of analog rotor code computed cipher.The computation of a Discrete Logarithm [1]  is a problem for which several algorithms [2]  presently exist. The general problem is addressed from a variety of perspectives depending on the subject matter of interest. The Discrete Logarithm problem is also found addressed in conjunction with the more general problem of factoring. [3]  However, the complexity of present solutions is not known to be polynomial.An algorithm is presented that computes a Discrete Logarithm on cyclic finite groups of integers modulo p (i.e. Z p ). The complexity of the algorithm is at worst O(n 3 ). No comprehensive review of existing algorithms is provided. Those interested in or otherwise unfamiliar with existing algorithms are referred to the references, and most any university text on the subject of computational complexity.Most existing algorithms address the problem from the perspective of abstract algebra, working with various aspects of algebraic structures to improve the execution of \\"the na\xefve algorithm\\" of brute force factoring. Our solution addresses the problem by projection onto an arc of 360\xb0. [4]  This transforms the problem into one operating on the angular rotation of the cycle, rather than conventional notion of modular arithmetic. The projection allows us to address the exponentiation in the na\xefve algorithm independent of the value of p by arithmetic operations.The Discrete Logarithm problem over cyclic finite groups has a well known definition as the solution of the equation x k = y, given values for x and y, for the value of k, in some group G. We concern our self herewith the cyclic finite multiplicative groups of integers modulo p.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Session-based Recommendation with Graph Neural Networks The problem of session-based recommendation aims to predict user actions based on anonymous sessions. Previous methods model a session as a sequence and estimate user representations besides item representations to make recommendations. Though achieved promising results, they are insufficient to obtain accurate user vectors in sessions and neglect complex transitions of items. To obtain accurate item embedding and take complex transitions of items into account, we propose a novel method, i.e. Session-based Recommendation with Graph Neural Networks, SR-GNN for brevity. In the proposed method, session sequences are modeled as graphstructured data. Based on the session graph, GNN can capture complex transitions of items, which are difficult to be revealed by previous conventional sequential methods. Each session is then represented as the composition of the global preference and the current interest of that session using an attention network. Extensive experiments conducted on two real datasets show that SR-GNN evidently outperforms the state-of-the-art session-based recommendation methods consistently. In this section, we first describe the datasets, compared methods, and evaluation metrics used in the experiments We evaluate the proposed method on two real-world representative datasets, i.e The Yoochoose dataset is obtained from the RecSys Challenge 2015, which contains a stream of user clicks on an e-commerce website within 6 months The Diginetica dataset comes from CIKM Cup 2016, where only its transactional data is used For fair comparison, following, we filter out all sessions of length 1 and items appearing less than 5 times in both datasets The remaining 7,981,580 sessions and 37,483 items constitute the Yoochoose dataset, while 204,771 sessions and 43097 items construct the Diginetica dataset The statistics of datasets are summarized in Following metrics are used to evaluate compared methods Table 1: Statistics of datasets used in the experiments Yoochoose 1 / 64 60 , 858 29 , 618 Diginetica 369 , 859 16 , 766 43 , 097 Table 1 : Statistics of datasets used in the experiments 557 , 248 5 , 917 , 745 55 , 898 8 , 326 , 407 Yoochoose 1 / 4 982 , 961 719 , 470 Table 2: The performance of SR-GNN with other baseline methods over three datasets Method Yoochoose 1 / 64 Diginetica P@20 Table 2 : The performance of SR - GNN with other baseline MRR@20 Yoochoose 1 / 4 Table 3: The performance of different methods with different session lengths evaluated in terms of P@20 Method Yoochoose 1 / 64 Diginetica Table 3 : The performance of different methods with different Long Short","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"Last.FM\\", \\"Metric\\": \\"HR@20\\", \\"Score\\": \\"22.33\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"Last.FM\\", \\"Metric\\": \\"MRR@20\\", \\"Score\\": \\"8.23\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"Diginetica\\", \\"Metric\\": \\"Hit@20\\", \\"Score\\": \\"50.73\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"Diginetica\\", \\"Metric\\": \\"MRR@20\\", \\"Score\\": \\"17.59\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"yoochoose1/4\\", \\"Metric\\": \\"HR@20\\", \\"Score\\": \\"71.36\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"yoochoose1/4\\", \\"Metric\\": \\"MRR@20\\", \\"Score\\": \\"31.89\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"Gowalla\\", \\"Metric\\": \\"HR@20\\", \\"Score\\": \\"50.32\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"Gowalla\\", \\"Metric\\": \\"MRR@20\\", \\"Score\\": \\"24.25\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"yoochoose1\\", \\"Metric\\": \\"MRR@20\\", \\"Score\\": \\"30.94\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"yoochoose1\\", \\"Metric\\": \\"Precision@20\\", \\"Score\\": \\"70.57\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"yoochoose1/64\\", \\"Metric\\": \\"HR@20\\", \\"Score\\": \\"70.57\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"yoochoose1/64\\", \\"Metric\\": \\"MRR@20\\", \\"Score\\": \\"30.94\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"Diginetica\\", \\"Metric\\": \\"Hit@20\\", \\"Score\\": \\"51.31\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"Diginetica\\", \\"Metric\\": \\"MRR@20\\", \\"Score\\": \\"18.03\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"yoochoose1\\", \\"Metric\\": \\"MRR@20\\", \\"Score\\": \\"31.12\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"yoochoose1\\", \\"Metric\\": \\"Precision@20\\", \\"Score\\": \\"71.02\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"yoochoose1/64\\", \\"Metric\\": \\"HR@20\\", \\"Score\\": \\"71.02\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Session-Based Recommendations\\", \\"Dataset\\": \\"yoochoose1/64\\", \\"Metric\\": \\"MRR@20\\", \\"Score\\": \\"31.12\\"}} ]"},{"Context":"FSS-1000: A 1000-Class Dataset for Few-Shot Segmentation Over the past few years, we have witnessed the success of deep learning in image recognition thanks to the availability of large-scale human-annotated datasets such as PAS-CAL VOC, ImageNet, and COCO. Although these datasets have covered a wide range of object categories, there are still a significant number of objects that are not included. Can we perform the same task without a lot of human annotations? In this paper, we are interested in few-shot object segmentation where the number of annotated training examples are limited to 5 only. To evaluate and validate the performance of our approach, we have built a few-shot segmentation dataset, FSS-1000, which consists of 1000 object classes with pixelwise annotation of ground-truth segmentation. Unique in FSS-1000, our dataset contains significant number of objects that have never been seen or annotated in previous datasets, such as tiny daily objects, merchandise, cartoon characters, logos, etc.We build our baseline model using standard backbone networks such as VGG-16, ResNet-101, and Inception. To our surprise, we found that training our model from scratch using FSS-1000 achieves comparable and even better results than training with weights pre-trained by ImageNet which is more than 100 times larger than FSS-1000. Both our approach and dataset are simple, effective, and easily extensible to learn segmentation of new object classes given very few annotated training examples. Dataset is available at https We conduct experiments to evaluate the practicability of FSS-1000 and the performance of our method under fewshot learning settings We evaluate models with the same network architecture but trained on different datasets to show that FSS-1000 is effective for few-shot segmentation task Table 1. Large-scale datasets comparison. Mean and standard deviation are based on the expected number of images in each class. Table 1 . Large - scale datasets comparison . Mean and standard deviation are based on the expected number of images in each class . FSS - 1000 ImageNet Mean Stddev Dataset of FSS - 1000 Table 2. Different network settings to explore the best settings for our network architecture. our network architecture . MeanIoU Table 3. Different few-shot segmentation networks trained and tested on FSS-1000. MeanIoU Table 4. Comparison of different models on PASCAL-5 i . GN is Guided Network and Ours* is our model trained on FSS-1000. All models are using 5-shot setting. PASCAL - 5 Mean PASCAL - 5 0 PASCAL - 5 2 Table 5. Comparison of models trained and tested on different datasets. Each model (row) shows the training stages, e.g., model I uses the pre-trained","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Semantic Segmentation\\", \\"Dataset\\": \\"FSS-1000\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"80.12\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Few-Shot Semantic Segmentation\\", \\"Dataset\\": \\"FSS-1000\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"78.36\\"}} ]"},{"Context":"Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation Vision-language navigation (VLN) is the task of navigating an embodied agent to carryout natural language instructions inside real 3D environments. In this paper, we study how to address three critical challenges for this task: the cross-modal grounding, the ill-posed feedback, and the generalization problems. First, we propose a novel Reinforced Cross-Modal Matching (RCM) approach that enforces cross-modal grounding both locally and globally via reinforcement learning (RL). Particularly, a matching critic is used to provide an intrinsic reward to encourage global matching between instructions and trajectories, and a reasoning navigator is employed to perform cross-modal grounding in the local visual scene. Evaluation on a VLN benchmark dataset shows that our RCM model significantly outperforms previous methods by 10% on SPL and achieves the new state-of-the-art performance. To improve the generalizability of the learned policy, we further introduce a Self-Supervised Imitation Learning (SIL) method to explore unseen environments by imitating its own past, good decisions. We demonstrate that SIL can approximate a better and more efficient policy, which tremendously minimizes the success rate performance gap between seen and unseen environments (from 30.7% to 11.7%). We evaluate our approaches on the Roomto-Room (R2R) dataset for vision-language navigation in real 3D environments, which is built upon the Matter-port3D dataset The R2R dataset has 7,189 paths that capture most of the visual diversity and 21,567 humanannotated instructions with an average length of 29 words The R2R dataset is split into training, seen validation, unseen validation, and test sets This setting is preferred and able to clearly measure the generalizability of the navigation policy, so we evaluate our RCM approach under the standard testing scenario We report five evaluation metrics as used by the VLN Challenge: Path Length (PL), Navigation Error (NE), Oracle Success Rate (OSR), Success Rate (SR), and Success rate weighted by inverse Path Length (SPL) Table 1: Comparison on the R2R test set [3]. Our RCM model sig- nificantly outperforms the SOTA methods, especially on SPL (the primary metric for navigation tasks [1]). Moreover, using SIL to imitate itself on the training set can further improve its efficiency: the path length is shortened by 3.25m. Note that with beam search, the agent executes K trajectories at test time and chooses the most confident one as the ending point, which results in a super long path and is heavily penalized by SPL. 12 23 Ours 35 38 28 18 Test Set ( VLN Challenge Leaderboard ) SR \u2191 PL \u2193 NE \u2193 OSR \u2191 Table 2: Ablation study on seen and unseen validation sets. We report the performance of the speaker-follower model without beam search as the baseline. Row 1-5 shows the influence of each individual component by successively removing it from the final model. Row 6","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Navigation\\", \\"Dataset\\": \\"R2R\\", \\"Metric\\": \\"spl\\", \\"Score\\": \\"0.38\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Vision-Language Navigation\\", \\"Dataset\\": \\"Room2Room\\", \\"Metric\\": \\"spl\\", \\"Score\\": \\"0.59\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Navigation\\", \\"Dataset\\": \\"VLN Challenge\\", \\"Metric\\": \\"error\\", \\"Score\\": \\"3.09\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Navigation\\", \\"Dataset\\": \\"VLN Challenge\\", \\"Metric\\": \\"length\\", \\"Score\\": \\"40.85\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Navigation\\", \\"Dataset\\": \\"VLN Challenge\\", \\"Metric\\": \\"oracle success\\", \\"Score\\": \\"0.81\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Navigation\\", \\"Dataset\\": \\"VLN Challenge\\", \\"Metric\\":\\"spl\\", \\"Score\\": \\"0.22\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Navigation\\", \\"Dataset\\": \\"VLN Challenge\\", \\"Metric\\":\\"success\\", \\"Score\\": \\"0.71\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Navigation\\", \\"Dataset\\": \\"VLN Challenge\\", \\"Metric\\": \\"error\\", \\"Score\\": \\"3.69\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Navigation\\", \\"Dataset\\": \\"VLN Challenge\\", \\"Metric\\": \\"length\\", \\"Score\\": \\"10.43\\"}}, { \\"LEADERBOARD\\": { \'Tas"},{"Context":"Support Vector Guided Softmax Loss for Face Recognition Face recognition has witnessed significant progresses due to the advances of deep convolutional neural networks (CNNs), the central challenge of which, is feature discrimination. To address it, one group tries to exploit miningbased strategies (e.g., hard example mining and focal loss) to focus on the informative examples. The other group devotes to designing margin-based loss functions (e.g., angular, additive and additive angular margins) to increase the feature margin from the perspective of ground truth class. Both of them have been well-verified to learn discriminative features. However, they suffer from either the ambiguity of hard examples or the lack of discriminative power of other classes. In this paper, we design a novel loss function, namely support vector guided softmax loss (SV-Softmax), which adaptively emphasizes the mis-classified points (support vectors) to guide the discriminative features learning. So the developed SV-Softmax loss is able to eliminate the ambiguity of hard examples as well as absorb the discriminative power of other classes, and thus results in more discrimiantive features. To the best of our knowledge, this is the first attempt to inherit the advantages of mining-based and margin-based losses into one framework. Experimental results on several benchmarks have demonstrated the effectiveness of our approach over state-of-the-arts. The MS-Celeb-1M dataset contains about 100k identities with 10 million images We use two datasets, MegaFace and Trillion Pairs 3 , as the test data MegaFace datasets aim at evaluating the performance of face recognition algorithms at the million scale of distractors, which include gallery set and probe set Trillion Pairs datasets are recently released as a public available testing benchmark, which are consisted of the following two parts, ELFW and DELFW All the reported results in this paper are evaluated by a single model, without model ensemble or other fusion strategies To the evaluation metrics, the cosine distance of features is computed as the similarity score Specifically, for face identification, the Cumulative Match Characteristics (CMC) curves are adopted to evaluate the Rank-1 face identification accuracy We test our models on several popular public face datasets, including LFW, MegaFace Challenge and the recent Trillion Pairs Challenge Table 1. Verification performance (%) of different loss functions on LFW test data. Naive - fused Mining - based Method LFW 6000 LFW BLUFR TPR@FAR=1e - 4 TPR@FAR=1e - 3 Pairs Accuracy TPR@FAR=1e - 5 Table 2. Results (%) of different losses on MegaFace Challenge. SV - Softmax F - AM - Softmax ( % ) Table 2 . Results ( % ) of different losses on MegaFace Challenge . Method SV - AM - Softmax F - Arc - Softmax A - Softmax True Identification Verification Verification with 1M Distractors F - Softmax 1 AM - Softmax HM - Softmax HM - AM - Softmax Rank1@1e6 Arc - Softmax Softmax SV - Arc - Softmax TPR@FAR=1e - 6 HM - Arc - Softmax Table 3. Performance (%) of different loss functions on Trillion Pairs Challenge. Method TPR@FAR=1e - 9 Identification Verification TPR@FAR=1e - 3 Table 4. Performance (%) of SV-AM-Softmax","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"Trillion Pairs Dataset\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"72.71\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"MegaFace\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"97.38%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Identification\\", \\"Dataset\\": \\"Trillion Pairs Dataset\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"73.56\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Identification\\", \\"Dataset\\": \\"MegaFace\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"97.2%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"MS-COCO\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"84.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"MS-COCO\\", \\"Metric\\": \\"Rank-5\\", \\"Score\\": \\"99.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"MS-COCO\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"71.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"MS-COCO\\", \\"Metric\\": \\"Rank-1\\", \\"Score\\": \\"81.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"MS-COCO\\", \\"Metric\\": \\"Rank-5\\", \\"Score\\": \\"95.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"MS-COCO\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"82.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"Text-103\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"81.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": "},{"Context":"FreeBSD Mandatory Access Control Usage for Implementing Enterprise Security Policies FreeBSD was one of the first widely deployed free operating systems to provide mandatory access control. It supports a number of classic MAC models. This tutorial paper addresses exploiting this implementation to enforce typical enterprise security policies of varying complexities.Security needs of organizations are becoming more and more sophisticated nowadays. Most general-purpose operating systems (GPOS) provide access control policies to meet these needs. There are cases when the traditionally deployed Discretionary Access Control (DAC) rules are not sufficient: they tend to quickly become unmanageable in the case of large installations, and also are not enough for controlling information flows. This is when the Mandatory Access Control (MAC) comes in: it provides for better manageability and directly targets the information flows. In their turn, the information flows address the confidentiality and integrity needs of information security within an organization. Until very recently, the GPOSes tended to provide various flavors of DAC only. The FreeBSD OS [1] was one of the first widely deployed open source GPOSes to support MAC [2], [3]. In this paper, a number of organizational policy examples are implemented in the environment of the FreeBSD MAC.The authors strongly believe that in order to implement a sound MAC policy it is important to understand MAC\'s mathematical foundations. These foundations were set by Denning in [4]. There also exists a terminology confusion between MAC and LBAC (lattice-based access control). These models are the same, because MAC security labels [5] directly correspond to security classes of lattice-based models (this was also pointed to by Sandhu [6] and Osborn [7]).Let us first address the definition of the information flow. According to Denning and Sandhu, the security policies regulate how the information \\"flows from one object to another\\". A typical object is a shared memory segment, a file system objector a network packet. Obviously, controlling the information flows is important to prevent the leakage of the confidential information, the one usually sought by insiders. Another goal is the forgery prevention, so that no untrusted reports are ever submitted to the top level of the organization hierarchy, and no top-ranking company officers take any unchecked or untrusted information into account during decision making.To implement the information flow control, every object is assigned a security label (also called a security classification), implemented by the FreeBSD file label. When the information flows from one object into another, an information flow from the security class of the first object to the security class of the second one also takes place. Whether the information flow is allowed is regulated by the relation between the object security classes. The subjects are the entities performing the information transfer between the objects. In our case, a subject appears when a user logs in to the system and is assigned a set of privileges. As we are considering MAC, the set of privileges is rendered as security clearance. It is implemented by the FreeBSD user label.This paper is organized as follows. In the next section an example of an organization and its document flow is described. The following sections implement organization\'s information security goals, which gradually increase in complexity. The information security goals specify the target effect: preserving data and process integrity, restricting access to the confidential information, or implementing a consulting services policy. For every security goal, a corresponding classic MAC model or a combination of them is chosen. The models are then implemented in the FreeBSD MAC framework.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"THE IMPACT OF NEW TECHNOLOGIES IN PUBLIC FINANCIAL MANAGEMENT AND PERFORMANCE: AGENDA FOR PUBLIC FINANCIAL MANAGEMENT REFORMANCE IN THE CONTEXT OF GLOBAL BEST PRACTICES  The evaluation phase is also very adapted for ICT use In the evaluation phase, the decisionmaker who in this case would be the administrator, needs to have feedback from the farmers, so as to assess the adequacy of the proposed services to the farmers\' needs","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"A SOLUTION TO PRODUCT DETECTION IN DENSELY PACKED SCENES  All experiment are conducted on MMDetection Platform with single GPU and run evaluation by library pycocotools on validation set Table 1: Quantitative Statistics of SKU-110k number of annotations in a single image : 61 Data Description and Analysis 1730996 431546 1208482 Test Set1 Method Train Set Image Number 2 After eliminating the invalid data , the size of the data set is shown below : Total 8219 Annotation Number 2936 1 ] . 11743 Table 2: Statistics of Number of Annotations in Single Image number of annotations in a single image : 61 Data Description and Analysis 1730996 431546 1208482 Test Set1 Method Train Set Image Number 2 After eliminating the invalid data , the size of the data set is shown below : Total 8219 Annotation Number 2936 1 ] . 11743 Table 3: Parameter and Results of Cascade R-CNN mmAP ( % ) mmAP ( test ) mmAP IoU Threshold","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Dense Object Detection\\", \\"Dataset\\": \\"SKU-110K\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"0.587\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Dense Object Detection\\", \\"Dataset\\": \\"SKU-110K\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"0.673\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"SKU-110K\\", \\"Metric\\":\\"mAP@0.5\\", \\"Score\\": \\"62.5%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"SKU-110K\\", \\"Metric\\":\\"mAP@0.5\\", \\"Score\\": \\"45.2\\"}} ]"},{"Context":"A computationally-efficient construction for the matrix-based key distribution in sensor network This paper introduces a variant for the symmetric matrix-based key distribution in sensor network introduced by Du et al. Our slight modification shows that the usage of specific structures for the public matrix instead of fully random matrix with elements in Z q can reduce the computation overhead for generating the public key information and the key itself. An intensive analysis followed by modified scheme demonstrates the value of our contribution in relation with the current work and show the equivalence of the security G c (j)[j mod \u03bb] \u2190 g 1j .","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Sentence Similarity Learning by Lexical Decomposition and Composition Most conventional sentence similarity methods only focus on similar parts of two input sentences, and simply ignore the dissimilar parts, which usually give us some clues and semantic meanings about the sentences. In this work, we propose a model to take into account both the similarities and dissimilarities by decomposing and composing lexical semantics over sentences. The model represents each word as a vector, and calculates a semantic matching vector for each word based on all words in the other sentence. Then, each word vector is decomposed into a similar component and a dissimilar component based on the semantic matching vector. After this, a two-channel CNN model is employed to capture features by composing the similar and dissimilar components. Finally, a similarity score is estimated over the composed feature vectors. Experimental results show that our model gets the state-of-the-art performance on the answer sentence selection task, and achieves a comparable result on the paraphrase identification task.Sentence similarity is a fundamental metric to measure the degree of likelihood between a pair of sentences. It plays an important role fora variety of tasks in both NLP and IR communities. For example, in paraphrase identification task, sentence similarity is used to determine whether two sentences are paraphrases or not (Yin and Sch\xfctze, 2015;He et al., 2015). For question answering and information retrieval tasks, sentence similarities between query-answer pairs are used for assessing the relevance and ranking all the candidate answers (Severyn and Moschitti, 2015;Wang and Ittycheriah, 2015).However, sentence similarity learning has following challenges:1. There is a lexical gap between semantically equivalent sentences. Take the E 1 and E 2 in Table 1 for example, they have the similar meaning but with different lexicons.2. Semantic similarity should be measured at different levels of granularity (word-level, phrase-level and syntax-level). E.g., \\"not related\\" in E 2 is an indivisible phrase when matching with \\"irrelevant\\" in E 1 (shown in square brackets).3. The dissimilarity (shown in angle brackets) between two sentences is also a significant clue (Qiu et al., 2006). For example, by judging the dissimilar parts, we can easily identify that E 3 and E 5 share the similar meaning \\"The study is about salmon\\", because \\"sockeye\\" belongs to the salmon family, and \\"flounder\\" does not. Whereas the meaning of E 4 is quite different from E 3 , which emphasizes \\"The study is about red (a special kind of) salmon\\", because both \\"sockeye\\" and \\"coho\\" are in the salmon family. How we can extract and utilize those information becomes another challenge.In order to handle the above challenges, researchers have been working on sentence similarity algorithms fora longtime. To bridge the lexical gap (challenge 1), some word similarity metrics were proposed to match different but semantically related words. Examples include knowledge-based metrics (Resnik, 1995) and corpus-based metrics (Jiang and Conrath, 1997; Yin and Sch\xfctze, 2015;He et al., 2015). To measure sentence similarity from various granularities (challenge 2), researchers have explored features extracted from n-grams, continuous phrases, discontinuous phrases, and parse trees (Yin  and Sch\xfctze, 2015;He et al., 2015;Heilman and Smith, 2010). The third challenge did not get much arXiv:1602.07019v2 [cs.CL] 14 Jul 2017 E1 The research is [irrelevant] to sockeye. E2 The study is [not related] to salmon. E3 The research is relevant to salmon. E4 The study is relevant to sockeye, instead of coho . E5 The study is relevant to sockeye, rather than flounder . We evaluate our model on two tasks: answer sentence selection and paraphrase identification We experiment on two datasets: QASent and WikiQA The statistics of the two datasets can be found in, where QASent was created from the TREC QA track, and WikiQA is constructed from real queries of Bing and Wikipedia We experiment on the Microsoft Research Paraphrase corpus (MSRP), which includes 2753 true and 1323 false instances in the training set, and 1147 true and 578 false instances in the test set Table 2: Results on the QASent dataset. ( CNN + sparse features ) ( Word embedding alignment ) ( CNN only ) win - 1 ( Attention - based CNN ) Figure 2 : Influence of different configuration . win - 5 win - 4 linear win - 3 ( b ) Decomposition . local - 3 local - 2 rigid MRR MAP Table 3: Results on the WikiQA dataset. ( 2 - gram CNN ) ( Attention - based CNN ) ( Attention - based LSTM ) MRR MAP Table 4: Experimental results for paraphrase identification on MSRP corpus. N / A Acc F1","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"WikiQA\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"0.7058\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"WikiQA\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.7226\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Paraphrase Identification\\", \\"Dataset\\": \\"SQuAD1.1\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"90.5\\"}} ]"},{"Context":"Grid R-CNN This paper proposes a novel object detection framework named Grid R-CNN, which adopts a grid guided localization mechanism for accurate object detection. Different from the traditional regression based methods, the Grid R-CNN captures the spatial information explicitly and enjoys the position sensitive property of fully convolutional architecture. Instead of using only two independent points, we design a multi-point supervision formulation to encode more clues in order to reduce the impact of inaccurate prediction of specific points. To take the full advantage of the correlation of points in a grid, we propose a two-stage information fusion strategy to fuse feature maps of neighbor grid points. The grid guided localization approach is easy to be extended to different state-of-the-art detection frameworks. Grid R-CNN leads to high quality object localization, and experiments demonstrate that it achieves a 4.1% AP gain at IoU=0.8 and a 10.0% AP gain at IoU=0.9 on COCO benchmark compared to Faster R-CNN with Res50 backbone and FPN architecture. We perform experiments on two object detection datasets, Pascal VOC and COCO On Pascal VOC dataset, we train our model on VOC07+12 trainval set and evaluate on VOC2007 test set On COCO dataset which contains 80 object categories, we train our model on the union of 80k train images and 35k subset of val images and test on a 5k subset of val (minival) and 20k test-dev Table 1. Comparison of different grid points strategies in Grid R- CNN. Experiments show that more grid points bring performance gains. AP Table 2. Comparison of different feature fusion methods. Bi- directional feature fusion, first order feature fusion and second order fusion all demonstrate improvements. Second order fusion achieves the best performance with an improvement of 0.7% on AP. AP . Table 4 . Comparison with R - FCN and FPN on Pascal VOC small large method Table 2 . Comparison of different feature fusion methods . directional feature fusion , first order feature fusion and second terion which is the average AP across IoU thresholds range from dataset . Note that we evaluate the results with a COCO - style cri - AP Table 3. Comparison of enlarging the proposal directly and ex- tended region mapping strategy. terion which is the average AP across IoU thresholds range from small method","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"60.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"44.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"54.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"45.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"23.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"41.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"58.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"42.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"51.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"43.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"22.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"39.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"63.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"46.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"55.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"46.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"25.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"43.2\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"PASCAL VOC 2007\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"82.6%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Real-Time Object Detection\\", \\"Dataset\\": \\"PASCAL VOC 2007\\", \\"Metric\\": \\"FPS\\", \\"Score\\": \\"24\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Real-Time Object Detection\\", \\"Dataset\\": \\"PASCAL VOC 2007\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"82.4%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Real-Time Object Detection\\", \\"Dataset\\": \\"PASCAL VOC 2007\\", \\"Metric\\": \\"FPS\\", \\"Score\\": \\"19.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Real-Time Object Detection\\", \\"Dataset\\": \\"PASCAL VOC 2007\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"82.1%\\"}} ]"},{"Context":"End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion Knowledge graph embedding has been an active research topic for knowledge base completion, with progressive improvement from the initial TransE, TransH, DistMult et alto the current state-of-the-art ConvE. ConvE uses 2D convolution over embeddings and multiple layers of nonlinear features to model knowledge graphs. The model can be efficiently trained and scalable to large knowledge graphs. However, there is no structure enforcement in the embedding space of ConvE. The recent graph convolutional network (GCN) provides another way of learning graph node embedding by successfully utilizing graph connectivity structure. In this work, we propose a novel end-to-end Structure-Aware Convolutional Network (SACN) that takes the benefit of GCN and ConvE together. SACN consists of an encoder of a weighted graph convolutional network (WGCN), and a decoder of a convolutional network called Conv-TransE. WGCN utilizes knowledge graph node structure, node attributes and edge relation types. It has learnable weights that adapt the amount of information from neighbors used in local aggregation, leading to more accurate embeddings of graph nodes. Node attributes in the graph are represented as additional nodes in the WGCN. The decoder Conv-TransE enables the state-of-the-art ConvE to be translational between entities and relations while keeps the same link prediction performance as ConvE. We demonstrate the effectiveness of the proposed SACN on standard FB15k-237 and WN18RR datasets, and it gives about 10% relative improvement over the state-of-theart ConvE in terms of HITS@1, HITS@3 and HITS@10. Three benchmark datasets (FB15k-237, WN18RR and FB15k-237-Attr) are utilized in this study to evaluate the performance of link prediction The FB15k-237 dataset contains knowledge base relation triples and textual mentions of Freebase entity pairs, as used in the work published in For different datasets, we have found that the following settings work well: for FB15k-237, set the dropout to 0.2, number of kernels to 100, learning rate to 0.003 and embedding size to 200 for SACN; for WN18RR dataset, set dropout to 0.2, number of kernels to 300, learning rate to 0.003, and embedding size to 200 for SACN Each dataset is split into three sets for: training, validation and testing, which is same with the setting of the original ConvE Table 2: Statistics of datasets. FB15k - 237 WN18RR FB15k - 237 - Attr 14 , 744 350 , 449 20 , 466 14 , 541 78 , 334 17 , 535 Table 3: Link prediction for FB15k-237, WN18RR and FB15k-237-Attr datasets. FB15k - 237 @1 Hits @3 WN18RR MRR - @10 Table 4: Kernel size analysis for FB15k-237 and FB15k- 237-Attr datasets. \\"SACN+Attr\\" means the SACN using FB15k-237-Attr dataset. Hits FB15k - 237 @1 @3 MRR @10 Table 5: Node indegree study using FB15k-237 dataset. @3 Average Hits Conv - TransE @10 SACN","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.43\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.54\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.48\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.47\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.26\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.54\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.39\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.35\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.443\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.546\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.494\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"MR\\", \\"Score\\": \\"3533\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.479\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.264\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.535\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": "},{"Context":"Multimodal Differential Network for Visual Question Generation Generating natural questions from an image is a semantic task that requires using visual and language modality to learn multimodal representations. Images can have multiple visual and language contexts that are relevant for generating questions namely places, captions, and tags. In this paper, we propose the use of exemplars for obtaining the relevant context. We obtain this by using a Multimodal Differential Network to produce natural and engaging questions. The generated questions show a remarkable similarity to the natural questions as validated by a human study. Further, we observe that the proposed approach substantially improves over state-of-the-art benchmarks on the quantitative metrics (BLEU, METEOR, ROUGE, and CIDEr). We conduct our experiments on Visual Question Generation (VQG) dataset, which contains human annotated questions based on images of MS-COCO dataset This dataset was developed for generating natural and engaging questions based on commonsense reasoning We use VQG-COCO dataset for our experiments which contains a total of 2500 training images, 1250 validation images, and 1250 testing images Each image in the dataset contains five natural questions and five ground truth captions It is worth noting that the work of (Jain et al., 2017) also used the questions from VQA dataset for training purpose, whereas the work by (Mostafazadeh et al., 2016) uses only the VQG-COCO dataset VQA-1.0 dataset is also built on images from MS-COCO dataset We used pretrained caption generation model to extract captions for VQA dataset as the human annotated captions are not therein the dataset We also get good results on the VQA dataset (as shown in) which Table 1: Analysis of variants of our proposed method on VQG-COCO Dataset as mentioned in section 4.4 and different ways of getting a joint embedding (Atten- tion (AtM), Hadamard (HM), Addition (AM) and Joint (JM) method as given in section 4.1.3) for each method. Refer section 5.1 for more details. variant . Joint Method ( JM ) of combining the embeddings BLEU1 METEOR Among the ablations , the proposed MDN CIDEr ROUGE Table 2: State-of-the-Art comparison on VQA-1.0 Dataset. The first block consists of the state-of-the-art results, second block refers to the baselines mentioned in section 5.2, third block provides the results for the variants of mixture module present in section 4.1.3. BLEU1 METEOR CIDEr ROUGE Table 3: State-of-the-Art (SOTA) comparison on VQG- COCO Dataset. The first block consists of the SOTA results, second block refers to the baselines mentioned in section 5.2, third block shows the results for the best","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Question Generation\\", \\"Dataset\\": \\"Visual Question Generation\\", \\"Metric\\": \\"BLEU-1\\", \\"Score\\": \\"36.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Question Generation\\", \\"Dataset\\": \\"COCO Visual Question Answering (VQA) real images 1.0 open ended\\", \\"Metric\\": \\"BLEU-1\\", \\"Score\\": \\"65.1\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Question Generation\\", \\"Dataset\\": \\"VQA v2 test-std\\", \\"Metric\\": \\"overall\\", \\"Score\\": \\"80.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Question Generation\\", \\"Dataset\\": \\"VQA v2 test-std\\", \\"Metric\\": \\"overall\\", \\"Score\\": \\"70.7\\"}} ]"},{"Context":"Unsupervised Scene Adaptation with Memory Regularization in vivo We consider the unsupervised scene adaptation problem of learning from both labeled source data and unlabeled target data. Existing methods focus on minoring the inter-domain gap between the source and target domains. However, the intra-domain knowledge and inherent uncertainty learned by the network are under-explored. In this paper, we propose an orthogonal method, called memory regularization in vivo to exploit the intradomain knowledge and regularize the model training. Specifically, we refer to the segmentation model itself as the memory module, and minor the discrepancy of the two classifiers, i.e., the primary classifier and the auxiliary classifier, to reduce the prediction inconsistency. Without extra parameters, the proposed method is complementary to most existing domain adaptation methods and could generally improve the performance of existing methods. Albeit simple, we verify the effectiveness of memory regularization on two synthetic-to-real benchmarks: GTA5 \u2192 Cityscapes and SYNTHIA \u2192 Cityscapes, yielding +11.1% and +11.3% mIoU improvement over the baseline model, respectively. Besides, a similar +12.0% mIoU improvement is observed on the cross-city benchmark: Cityscapes \u2192 Oxford RobotCar. We mainly evaluate the proposed method on the two unsupervised scene adaption settings, i.e., GTA5 Table 1: Ablation study of the memory regularization on both clas- sifiers, i.e., the auxiliary classifier and the primary classifier, in the Stage-I training. The result suggests that the memory regularization helps both classifiers, especially the auxiliary classifier. The final results of the full model combine the results of both classifiers, and therefore improve the performance further. without Lmr with Lmr Table 2: Ablation study of different losses in the Stage-I training. We gradually add the adversarial loss L adv and the memory regular- ization Lmr into consideration. mIoU Table 3: Ablation study of different losses in the Stage-II training. The result suggests that the memory regularization could prevent the model from overfitting to the noise in the pseudo labels. mIoU Table 4: Quantitative results on GTA5 \u2192 Cityscapes. We present pre-class IoU and mIoU. The best accuracy in every column is in bold. DRN - 26 DeepLabv2 DRN - 105","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"GTAV-to-Cityscapes Labels\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"48.3\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Synthetic-to-Real Translation\\", \\"Dataset\\": \\"GTAV-to-Cityscapes Labels\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"50.3\\"}} ]"},{"Context":"Predictability of Fixed-Job Priority Schedulers on Heterogeneous Multiprocessor Real-Time Systems The multiprocessor Fixed-Job Priority (FJP) scheduling of real-time systems is studied. An important property for the schedulability analysis, the predictability (regardless to the execution times), is studied for heterogeneous multiprocessor platforms. Our main contribution is to show that any FJP schedulers are predictable on unrelated platforms. A convenient consequence is the fact that any FJP schedulers are predictable on uniform multiprocessors.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Segatron: Segment-Aware Transformer for Language Modeling and Understanding Transformers are powerful for sequence modeling. Nearly all state-of-the-art language models and pre-trained language models are based on the Transformer architecture. However, it distinguishes sequential tokens only with the token position index. We hypothesize that better contextual representations can be generated from the Transformer with richer positional information. To verify this, we propose a segmentaware Transformer (Segatron), by replacing the original token position encoding with a combined position encoding of paragraph, sentence, and token. We first introduce the segmentaware mechanism to Transformer-XL, which is a popular Transformer-based language model with memory extension and relative position encoding. We find that our method can further improve the Transformer-XL base model and large model, achieving 17.1 perplexity on the WikiText-103 dataset. We further investigate the pre-training masked language modeling task with Segatron. Experimental results show that BERT pre-trained with Segatron (SegaBERT) can outperform BERT with vanilla Transformer on various NLP tasks, and outperforms RoBERTa on zero-shot sentence representation learning. Our code is available on GitHub. 1  Table 1: Comparison with Transformer-XL and competitive baseline results on WikiText-103. PPL Table 2: Ablation over the position encodings using Transformer-XL base architecture. PPL Table 2. From this table, we find that the PPL of Transformer-XL decreases from 24.35 to 24.07/22.51 after adding paragraph/sentence SegaBERT language modeling . 35 this table , we find that the PPL of Transformer - XL decreases Loss Segatron - XL 0 Transformer - XL Training Steps 5k 15k Loss BERT 10k 150 PPL 20k Table 3: Fair comparison on GLUE dev. The two base models are pre-trained in the same setting. For large models comparison, we choose the best of 3 BERT-large models: the original BERT, whole word masking BERT, and BERT without NSP task. Results of BERT-large (best of 3) are from Yang et al. (2019). \u2212 QQP CoLA RTE AVG SST - 2 MNLI QNLI MRPC STS - B Table 4: Results on","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-103\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"257M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-103\\", \\"Metric\\": \\"Test perplexity\\", \\"Score\\": \\"17.1\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"enwik8\\", \\"Metric\\": \\"Bit per Character (BPC)\\", \\"Score\\": \\"0.91\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"enwik8\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"277M\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-103\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"277M\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"WikiText-103\\", \\"Metric\\": \\"Test perplexity\\", \\"Score\\": \\"17.4\\"}} ]"},{"Context":"4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks In many robotics and VR/AR applications, 3D-videos are readily-available sources of input (a continuous sequence of depth images, or LIDAR scans). However, these 3D-videos are processed frame-by-frame either through 2D convnets or 3D perception algorithms in many cases. In this work, we propose 4-dimensional convolutional neural networks for spatio-temporal perception that can directly process such 3D-videos using high-dimensional convolutions. For this, we adopt sparse tensors [8, 9]  and propose the generalized sparse convolution which encompasses all discrete convolutions. To implement the generalized sparse convolution, we create an open-source auto-differentiation library for sparse tensors that provides extensive functions for highdimensional convolutional neural networks. 1  We create 4D spatio-temporal convolutional neural networks using the library and validate them on various 3D semantic segmentation benchmarks and proposed 4D datasets for 3D-video perception. To overcome challenges in the high-dimensional 4D space, we propose the hybrid kernel, a special case of the generalized sparse convolution, and the trilateral-stationary conditional random field that enforces spatio-temporal consistency in the 7D space-time-chroma space. Experimentally, we show that convolutional neural networks with only generalized sparse convolutions can outperform 2D or 2D-3D hybrid methods by a large margin. 2 Also, we show that on 3D-videos, 4D spatio-temporal convolutional neural networks are robust to noise, outperform 3D convolutional neural networks and are faster than the 3D counterpart in some cases. Next, we create multiple 4D datasets from 3D datasets that have temporal sequences and analyze each of the proposed components for ablation study For evaluation, we use the standard mean Intersection over Union (mIoU) and mean Accuracy (mAcc) for metrics following the previous works The dataset contains 3D scans of six floors of three different buildings The RueMonge 2014 dataset provides semantic labels fora multi-view 3D reconstruction of the Rue Mongue To create a 4D dataset, we crop the 3D reconstruction on-the-fly to generate a temporal sequence We use the Synthia dataset to create 3D video sequences Since the dataset is purely synthetic, we added various noise to the input point clouds to simulate noisy observations ScanNet & Stanford 3D Indoor The ScanNet and the Stanford Indoor datasets are one of the largest non-synthetic datasets, which make the datasets ideal test beds for 3D segmentation For all evaluation, we feed an Table 1: 3D Semantic Label Benchmark on ScanNet \u2020 [5] Method mIOU Table 1 : 3D Semantic Label Benchmark on ScanNet \u2020 [ 5 ] Table 2: Segmentation results on the 4D Synthia dataset Table 2 : Segmentation results on the 4D Synthia dataset mIOU mAcc Table 3: Segmentation results on the noisy Synthia 4D dataset Table 4 : Stanford Area 5 Test ( Fold #1 ) ( S3DIS ) [ 2 ] Building Road mAcc Pedestrian mIoU mIOU Lanemarking Car Vegetation Traffic Sign Table 3 : Segmentation results on the noisy Synthia 4D dataset Sidewalk Fence Traffic Light Pole Table 4: Stanford Area 5 Test (Fold #1) (S3DIS) [2] Table 4 : Stanford Area 5 Test ( Fold #1 ) ( S3DIS ) [ 2 ] Building Road mAcc Pedestrian mIoU mIOU Lanemarking Car Vegetation Traffic Sign Table 3 : Segmentation results on the noisy Synthia 4D dataset Sidewalk Fence","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS Area5\\", \\"Metric\\": \\"mAcc\\", \\"Score\\": \\"71.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS Area5\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"65.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"65.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ScanNet\\", \\"Metric\\": \\"3DIoU\\", \\"Score\\": \\"0.734\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Semantic Segmentation\\", \\"Dataset\\": \\"3DR2N2\\", \\"Metric\\":\\"mAcc\\", \\"Score\\": \\"89.3%\\"}} ]"},{"Context":"Path-Level Network Transformation for Efficient Architecture Search We introduce anew function-preserving transformation for efficient neural architecture search. This network transformation allows reusing previously trained networks and existing successful architectures that improves sample efficiency. We aim to address the limitation of current network transformation operations that can only perform layer-level architecture modifications, such as adding (pruning) filters or inserting (removing) a layer, which fails to change the topology of connection paths. Our proposed path-level transformation operations enable the meta-controller to modify the path topology of the given network while keeping the merits of reusing weights, and thus allow efficiently designing effective structures with complex path topologies like Inception models. We further propose a bidirectional treestructured reinforcement learning meta-controller to explore a simple yet highly expressive treestructured architecture space that can be viewed as a generalization of multi-branch architectures. We experimented on the image classification datasets with limited computational resources (about 200 GPU-hours), where we observed improved parameter efficiency and better test results (97.70% test accuracy on CIFAR-10 with 14.3M parameters and 74.6% top-1 accuracy on ImageNet in the mobile setting), demonstrating the effectiveness and transferability of our designed architectures. Specifically, we apply the proposed method described above to learn CNN cells on CIFAR-10 () for the image classification task and transfer the learned cell structures to ImageNet dataset) We use a standard data augmentation scheme (mirroring/shifting) that is widely used for this dataset and normalize the images using channel means and standard deviations for preprocessing Table 1. Test error rate (%) results of our best discovered architectures as well as state-of-the-art human-designed and automatically designed architectures on CIFAR-10. If \\"Reg\\" is checked, additional regularization techniques (e.g., Shake-Shake Auto are utilized when training the networks . designed and Cutout ( DeVries & Taylor , 2017 ) ) , along with a longer training schedule ( 600 epochs or 1800 epochs ) Test error Params Table 2. Top-1 (%) and Top-5 (%) classification error rate results on ImageNet in the M obile Setting (\u2264 600M multiply-add opera- tions). \\"\xd7+\\" denotes the number of multiply-add operations. Table 3. Start point network with identity mappings on CIFAR-10. 192 Feature map size 48 16 \xd7 16 [ identity mapping ] \xd74 Model architecture 192 32 \xd7 32 96","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"CIFAR-10 Image Classification\\", \\"Metric\\": \\"Params\\", \\"Score\\": \\"14.3M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"CIFAR-10 Image Classification\\", \\"Metric\\": \\"Percentage error\\", \\"Score\\": \\"2.30\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"86.1M\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"74.66%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"96.32%\\"}} ]"},{"Context":"Focusing and Polarization in Intuitionistic Logic A focused proof system provides a normal form to cut-free proofs that structures the application of invertible and non-invertible inference rules. The focused proof system of Andreoli for linear logic has been applied to both the proof search and the proof normalization approaches to computation. Various proof systems in literature exhibit characteristics of focusing to one degree or another. We present anew, focused proof system for intuitionistic logic, called LJF, and show how other proof systems can be mapped into the new system by inserting logical connectives that prematurely stop focusing. We also use LJF to design a focused proof system for classical logic. Our approach to the design and analysis of these systems is based on the completeness of focusing in linear logic and on the notion of polarity that appears in Girard\'s LC and LU proof systems.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"CharacterBERT: Reconciling ELMo and BERT for Word-Level Open-Vocabulary Representations From Characters Due to the compelling improvements brought by BERT, many recent representation models adopted the Transformer architecture as their main building block, consequently inheriting the wordpiece tokenization system despite it not being intrinsically linked to the notion of Transformers. While this system is thought to achieve a good balance between the flexibility of characters and the efficiency of full words, using predefined wordpiece vocabularies from the general domain is not always suitable, especially when building models for specialized domains (e.g., the medical domain). Moreover, adopting a wordpiece tokenization shifts the focus from the word level to the subword level, making the models conceptually more complex and arguably less convenient in practice. For these reasons, we propose CharacterBERT, anew variant of BERT that drops the wordpiece system altogether and uses a Character-CNN module instead to represent entire words by consulting their characters. We show that this new model improves the performance of BERT on a variety of medical domain tasks while at the same time producing robust, word-level, and open-vocabulary representations. 9  More specifically, we adapt these scripts to our needs. 10  We use gradient accumulation for larger batch sizes. We compare BERT and CharacterBERT on multiple medical tasks to evaluate the impact of using a Character-CNN module instead of wordpieces Given all the pre-trained models, the evaluation tasks, and a set of random seeds i \u2208 1..10: 1 We choose a pre-trained model, an evaluation task, and a random seed i then run 15 training epochs with batches of size 32 At each epoch, we evaluate the model on a validation set that is either given or computed as 20% of the training set After completing all training epochs, we load the best model and evaluate it on the test set Table 2: Statistics on pre-training corpora. 8 9 # documents # tokens Table 3: Number of examples of each evaluation task. ClinicalSTS","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"ChemProt\\", \\"Metric\\": \\"Micro F1\\", \\"Score\\": \\"73.44\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Natural Language Inference\\", \\"Dataset\\": \\"MedNLI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"84.95\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Similarity\\", \\"Dataset\\": \\"ClinicalSTS\\", \\"Metric\\": \\"Pearson Correlation\\", \\"Score\\": \\"85.62\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Drug\u2013drug Interaction Extraction\\", \\"Dataset\\": \\"DDI extraction 2013 corpus\\", \\"Metric\\": \\"Micro F1\\", \\"Score\\": \\"80.38\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Clinical Concept Extraction\\", \\"Dataset\\": \\"2010 i2b2/VA\\", \\"Metric\\": \\"Exact Span F1\\", \\"Score\\": \\"89.24\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-target regression\\", \\"Dataset\\": \\"USHCN-Daily\\", \\"Metric\\": \\"Micro F1\\", \\"Score\\": \\"84.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-target regression\\", \\"Dataset\\": \\"MIMIC-III\\", \\"Metric\\": \\"Micro F1\\", \\"Score\\": \\"82.75\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-target regression\\", \\"Dataset\\": \\"MIMIC-III\\", \\"Metric\\": \\"Micro F1\\", \\"Score\\": \\"80.44\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-target regression\\", \\"Dataset\\": \\"Multi-day Continuous metricFU\\", \\"Metric\\": \\"Micro F1\\", \\"Score\\": \\"83.03\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-target regression\\", \\"Dataset\\": \\"4.4\\", \\"Metric\\": \\"Micro F1\\", \\"Score\\": \\"82.81\\"}} ]"},{"Context":"As Time Goes By: Constraint Handling Rules A Survey of CHR Research from 1998 to 2007 Constraint Handling Rules (CHR) is a high-level programming language based on multiheaded multiset rewrite rules. Originally designed for writing user-defined constraint solvers, it is now recognized as an elegant general purpose language.CHR-related research has surged during the decade following the previous survey by Fr\xfchwirth (1998). Covering more than 180 publications, this new survey provides an overview of recent results in a wide range of research areas, from semantics and analysis to systems, extensions and applications.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"END-TO-END SPEECH RECOGNITION WITH ADAPTIVE COMPUTATION STEPS In this paper, we present Adaptive Computation Steps (ACS) algorithm, which enables end-to-end speech recognition models to dynamically decide how many frames should be processed to predict a linguistic output. The model that applies ACS algorithm follows the encoder-decoder framework, while unlike the attention-based models, it produces alignments independently at the encoder side using the correlation between adjacent frames. Thus, predictions can be made as soon as sufficient acoustic information is received, which makes the model applicable in online cases. Besides, a small change is made to the decoding stage of the encoder-decoder framework, which allows the prediction to exploit bidirectional contexts. We verify the ACS algorithm on a Mandarin speech corpus AIShell-1, and it achieves a 31.2% CER in the online occasion, compared to the 32.4% CER of the attention-based model. To fully demonstrate the advantage of ACS algorithm, offline experiments are conducted, in which our ACS model achieves an 18.7% CER, outperforming the attention-based counterpart with the CER of 22.0%.  Table 1. Character Error Rate (CER) on HMM-DNN and end-to- end models. The results of attention-based and ACS models were decoded using beam search algorithm with the width of 8. HMM - Hybrid Models Offline Character Models Online Character Models CER","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"AISHELL-1\\", \\"Metric\\": \\"Word Error Rate (WER)\\", \\"Score\\": \\"18.7\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"AISHdar\\", \\"Metric\\": \\"Word Error Rate (WER)\\", \\"Score\\": \\"2.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"AISHdar\\", \\"Metric\\": \\"Word Error Rate (WER)\\", \\"Score\\": \\"2\\"}} ]"},{"Context":"Bounded Underapproximations We show anew and constructive proof of the following language-theoretic result: for every context-free language L, there is a bounded context-free language L \u2286 L which has the same Parikh (commutative) image as L. Bounded languages, introduced by Ginsburg and Spanier, are subsets of regular languages of the form w * 1 w * 2 \xb7 \xb7 \xb7 w * k for some w1, . . . , wk \u2208 \u03a3 * . In particular bounded subsets of context-free languages have nice structural and decidability properties. Our proof proceeds in two parts. First, using Newton\'s iterations on the language semiring, we construct a context-free subset LN of L that can be represented as a sequence of substitutions on a linear language and has the same Parikh image as L. Second, we inductively construct a Parikh-equivalent bounded context-free subset of LN . We show two applications of this result in model checking: to underapproximate the reachable state space of multithreaded procedural programs and to underapproximate the reachable state space of recursive counter programs. The bounded language constructed above provides a decidable underapproximation for the original problems. By iterating the construction, we get a semi-algorithm for the original problems that constructs a sequence of underapproximations such that no two underapproximations of the sequence can be compared. This provides a progress guarantee: every word w \u2208 L is in some underapproximation of the sequence, and hence, a program bug is guaranteed to be found. In particular, we show that verification with bounded languages generalizes context-bounded reachability for multithreaded programs.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks Synthesizing high-quality images from text descriptions is a challenging problem in computer vision and has many practical applications. Samples generated by existing textto-image approaches can roughly reflect the meaning of the given descriptions, but they fail to contain necessary details and vivid object parts. In this paper, we propose Stacked Generative Adversarial Networks (StackGAN) to generate 256\xd7256 photo-realistic images conditioned on text descriptions. We decompose the hard problem into more manageable sub-problems through a sketch-refinement process. The Stage-I GAN sketches the primitive shape and colors of the object based on the given text description, yielding Stage-I low-resolution images. The Stage-II GAN takes Stage-I results and text descriptions as inputs, and generates high-resolution images with photo-realistic details. It is able to rectify defects in Stage-I results and add compelling details with the refinement process. To improve the diversity of the synthesized images and stabilize the training of the conditional-GAN, we introduce a novel Conditioning Augmentation technique that encourages smoothness in the latent conditioning manifold. Extensive experiments and comparisons with state-of-the-arts on benchmark datasets demonstrate that the proposed method achieves significant improvements on generating photo-realistic images conditioned on text descriptions. To validate our method, we conduct extensive quantitative and qualitative evaluations Since 80% of birds in this dataset have object-image size ratios of less than 0.5, as a pre-processing step, we crop all images to ensure that bounding boxes of birds have greater-than-0.75 object-image size ratios To show the generalization capability of our approach, a more challenging dataset, MS COCO is also utilized for evaluation Different from CUB and Oxford-102, the MS COCO dataset contains images with multiple objects and various backgrounds Each image in COCO has 5 descriptions, while 10 descriptions are provided by for every image in CUB and Oxford-102 datasets Evaluation metrics It is difficult to evaluate the performance of generative models (e.g., GAN) We choose a recently proposed numerical assessment approach \\"inception score\\" for quantitative evaluation, where x denotes one generated sample, and y is the label predicted by the Inception model In our experiments, we directly Table 1. Inception scores and average human ranks of our Stack- GAN, GAWWN [24], and GAN-INT-CLS [26] on CUB, Oxford- 102, and MS-COCO datasets. GAWWN Our StackGAN GAN - INT - CLS Table 1. Representative examples are compared in GAWWN Our StackGAN GAN - INT - CLS Table 2. Inception scores calculated with 30,000 samples gener- ated by different baseline models of our StackGAN. 256\xd7256 Stage - I GAN with different poses and viewpoints . wings and pointy beak This bird is completely red with black Inception score","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Text-to-Image Generation\\", \\"Dataset\\": \\"Oxford 102 Flowers\\", \\"Metric\\": \\"Inception score\\", \\"Score\\": \\"3.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Text-to-Image Generation\\", \\"Dataset\\": \\"CUB\\", \\"Metric\\": \\"Inception score\\", \\"Score\\": \\"3.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Text-to-Image Generation\\", \\"Dataset\\": \\"COCO\\", \\"Metric\\": \\"Inception score\\", \\"Score\\": \\"8.45\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"LSUN Bedroom 64 x 64\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"6.47\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"Oxford 102 Flowers\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"80.24\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CUB 128 x 128\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"2011.44\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CUB 128 x 128\\", \\"Metric\\": \\"Inception score\\", \\"Score\\": \\"3.78\\"}} ]"},{"Context":"Forming the COUNCIL Based Clusters in Securing Wireless Ad Hoc Networks In cluster-based routing protocol (CBRP), two-level hierarchical structure is successfully used to reduce over-flooding in wireless ad hoc networks. As it is vulnerable to a single point of failure , we propose anew adaptive distributed threshold scheme to replace the cluster head by a group of cluster heads within each cluster, called COUNCIL, and distribute the service of single cluster head to multiple cluster heads using (k,n) threshold secret sharing scheme. An ad hoc network formed by COUNCIL based clusters can work correctly when the number of compromised cluster heads is smaller thank. To implement this adaptive threshold scheme in wireless ad hoc netw orks, membership of the clusters should be defined in an adaptive way. In this paper, we mainly discuss our algorithm for forming COUNCIL based clusters using the concept of dominating set from graph theory.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Self-Supervised Monocular Scene Flow Estimation . Results of our monocular scene flow approach on the KITTI dataset [11]. Given two consecutive images (left), our method jointly predicts depth (middle) and scene flow (right). (x,z)-coordinates of 3D scene flow are visualized using an optical flow color coding.Scene flow estimation has been receiving increasing attention for 3D environment perception. Monocular scene flow estimation -obtaining 3D structure and 3D motion from two temporally consecutive images -is a highly illposed problem, and practical solutions are lacking to date. We propose a novel monocular scene flow method that yields competitive accuracy and real-time performance. By taking an inverse problem view, we design a single convolutional neural network (CNN) that successfully estimates depth and 3D motion simultaneously from a classical optical flow cost volume. We adopt self-supervised learning with 3D loss functions and occlusion reasoning to leverage unlabeled data. We validate our design choices, including the proxy loss and augmentation setup. Our model achieves state-of-the-art accuracy among unsupervised/self-supervised learning approaches to monocular scene flow, and yields competitive results for the optical flow and monocular depth estimation sub-tasks. Semi-supervised fine-tuning further improves the accuracy and yields promising results in real-time.  Table 1. Impact of geometric augmentations (Aug.) and CAM- Convs (CC.) D2 - all F1 - all Sq . Rel . SF1 - all Monocular scene flow Abs . Rel . Monocular depth D1 - all Table 2. Ablation study on the loss function: based on the Ba- sic 2D loss consisting of photometric and smoothness loss, the 3D point reconstruction loss (3D points) improves scene flow accu- racy, especially when discarding occluded pixels in the loss (Occ.). D2 - all F1 - all SF1 - all D1 - all Table 3. Single decoder vs. separate decoders: using a single decoder yields stable training and comparable accuracy on both tasks to models that target each individual task separately. 100 - D2 - all F1 - all SF1 - all D1 - all - Table 4. Monocular scene flow evaluation on KITTI Scene Flow Training: our self-supervised learning approach significantly out- performs","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Scene Flow Estimation\\", \\"Dataset\\": \\"KITTI 2015 Scene Flow Training\\", \\"Metric\\": \\"Runtime (s)\\", \\"Score\\": \\"0.09\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Scene Flow Estimation\\", \\"Dataset\\": \\"KITTI 2015 Scene Flow Training\\", \\"Metric\\": \\"D1-all\\", \\"Score\\": \\"31.25\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Scene Flow Estimation\\", \\"Dataset\\": \\"KITTI 2015 Scene Flow Training\\", \\"Metric\\": \\"D2-all\\", \\"Score\\": \\"34.86\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Scene Flow Estimation\\", \\"Dataset\\": \\"KITTI 2015 Scene Flow Training\\", \\"Metric\\": \\"Fl-all\\", \\"Score\\": \\"23.49\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Scene Flow Estimation\\", \\"Dataset\\": \\"KITTI 2015 Scene Flow Training\\", \\"Metric\\": \\"SF-all\\", \\"Score\\": \\"47.05\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Scene Flow Estimation\\", \\"Dataset\\": \\"KITTI 2015 Scene Flow Test\\", \\"Metric\\": \\"D1-all\\", \\"Score\\": \\"34.02\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Scene Flow Estimation\\", \\"Dataset\\": \\"KITTI 2015 Scene Flow Test\\", \\"Metric\\": \\"D2-all\\", \\"Score\\": \\"36.34\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Scene Flow Estimation\\", \\"Dataset\\": \\"KITTI 2015 Scene Flow Test\\", \\"Metric\\": \\"Fl-all\\", \\"Score\\": \\"23.54\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Scene Flow Estimation\\", \\"Dataset\\": \\"KITTI 2015 Scene Flow Test\\", \\"Metric\\": \\"Runtime (s)\\", \\"Score\\": \\"0.09\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Scene Flow Estimation\\", \\"Dataset\\": \\"KITTI 2015 Scene Flow Test\\", \\"Metric\\": \\"SF-all\\", \\"Score\\": \\"49.54\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Scene Flow Estimation\\", \\"Dataset\\": \\"KITTI 2015 Scene Flow Training\\", \\"Metric\\": \\"Runtime (s)\\", \\"Score\\": \\"0.05\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Scene Flow Estimation\\", \\"Dataset\\": \\"KITTI 2015 Scene Flow Training\\", \\"Metric\\": \\"D1-all\\", \\"Score\\": \\"26.81\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Scene Flow Estimation\\", \\"Dataset\\": \\"KITTI 2015 Scene Flow Training\\", \\"Metric\\": \\"D2-all\\", \\"Score\\": \\"60.97\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Scene Flow Estimation\\", \\"Dataset\\": \\"KITTI 2015 Scene Flow Training\\", \\"Metric\\": \\"Fl-all\\", \\"Score\\": \\"25.74\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Scene Flow Estimation\\", \\"Dataset\\": \\"KITTI 2015 Scene Flow Training\\", \\"Metric\\": \\"SF-all\\", \\"Score\\": \\"(>60.97)\\"}} ]"},{"Context":"0.5 Petabyte Simulation of a 45-Qubit Quantum Circuit Near-term quantum computers will soon reach sizes that are challenging to directly simulate, even when employing the most powerful supercomputers. Yet, the ability to simulate these early devices using classical computers is crucial for calibration, validation, and benchmarking. In order to make use of the full potential of systems featuring multi-and many-core processors, we use automatic code generation and optimization of compute kernels, which also enables performance portability. We apply a scheduling algorithm to quantum supremacy circuits in order to reduce the required communication and simulate a 45-qubit circuit on the Cori II supercomputer using 8, 192 nodes and 0.5 petabytes of memory. To our knowledge, this constitutes the largest quantum circuit simulation to this date. Our highly-tuned kernels in combination with the reduced communication requirements allow an improvement in time-to-solution over state-of-the-art simulations by more than an order of magnitude at every scale.\u2022 Applied computing \u2192 Physics; arXiv:1704.01127v2 [quant-ph]  Table 1: Re-scheduling of gates for depth-25 quantum supremacy circuits into clusters (using 30 local qubits). Clus- ters are built to contain k \u2264 k max qubits using a heuristic which tries to maximize the number of gates merged into one cluster. Clearly more than k max individual gates can be combined into one single cluster on average. These op- timizations take less than 3 seconds using Python and can be reused for all instance of the same size. 1000 of Gates of Qubits 58 Number Number of clusters k max = 3 82 73 98 Table 2: Results for all simulations carried out on Cori II. Circuit simulation time and speedup are given with respect to the depth-25 quantum supremacy circuit simulations per- formed in [5]. The comm.-column gives the percentage of circuit simulation time spent in communication and syn- chronization. {1024 , 2048 , 4096} nodes of Cori II","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Cartoon-To-Real Translation\\", \\"Dataset\\": \\"100 sleep nights of 8 caregivers\\", \\"Metric\\": \\"10%\\", \\"Score\\": \\"100\\"}}]","LLM prediction":"unanswerable"},{"Context":"An Improved Approximation Algorithm for the Column Subset Selection Problem * We consider the problem of selecting the \\"best\\" subset of exactly k columns from an m \xd7 n matrix A. In particular, we present and analyze a novel two-stage algorithm that runs in O(min{mn 2 , m 2 n}) time and returns as output an m \xd7 k matrix C consisting of exactly k columns of A. In the first stage (the randomized stage), the algorithm randomly selects \u0398(k log k) columns according to a judiciously-chosen probability distribution that depends on information in the top-k right singular subspace of A. In the second stage (the deterministic stage), the algorithm applies a deterministic column-selection procedure to select and return exactly k columns from the set of columns selected in the first stage. Let C be them \xd7 k matrix containing those k columns, let PC denote the projection matrix onto the span of those columns, and let A k denote the \\"best\\" rank-k approximation to the matrix A as computed with the singular value decomposition. Then, we prove that, with probability at least 0.8,","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Temporal Context Aggregation Network for Temporal Action Proposal Refinement Candidate Proposal Segment-Level Regression Output Frame-Level Regression Output Fused Output LGTE TBR Background Skiing Background Segment-Level Regression Start-Boundary Regression End-Boundary Regression Internal Context Starting Context Ending Context Encoded Feature Local Temporal Encoder Global Temporal Encoder Temporal action proposal generation aims to estimate temporal intervals of actions in untrimmed videos, which is a challenging yet important task in the video understanding field. The proposals generated by current methods still suffer from inaccurate temporal boundaries and inferior confidence used for retrieval owing to the lack of efficient temporal modeling and effective boundary context utilization. In this paper, we propose Temporal Context Aggregation Network (TCANet) to generate high-quality action proposals through \\"local and global\\" temporal context aggregation and complementary as well as progressive boundary refinement. Specifically, we first design a Local-Global Temporal Encoder (LGTE), which adopts the channel grouping strategy to efficiently encode both \\"local and global\\" temporal inter-dependencies. Furthermore, both the boundary and internal context of proposals are adopted for framelevel and segment-level boundary regressions, respectively. Temporal Boundary Regressor (TBR) is designed to combine these two regression granularities in an end-to-end fashion, which achieves the precise boundaries and reliable confidence of proposals through progressive refinement. Extensive experiments are conducted on three challenging datasets: HACS, ActivityNet-v1.3, and THUMOS-14, where TCANet can generate proposals with high precision and recall. By combining with the existing action classifier, TCANet can obtain remarkable temporal action detection performance compared with other methods. Not surprisingly, the proposed TCANet won the 1 st place in the CVPR 2020 -HACS challenge leaderboard on temporal action localization task. HACS is a large-scale dataset for temporal action detection In our experiments, we compare TCANet with the state-of-the-art method on all three datasets and performed ablation studies on HACS dataset Evaluation Metrics The learning rates on these two datasets are set to 0.0004 and 0.001, and the batch size is 16 for 10 epochs Table 1. Comparison with state-of-the-art methods on HACS. The results are measured by mAP(%) at different tIoU thresholds and average mAP(%). * indicates our implementation. Average Table 2. Comparison between our TCANet with other state-of- the-arts methods on ActivityNet-v1.3. The results are measured by mAP(%) at different tIoU thresholds and average mAP(%). For fair comparisons, we combined our proposals with video-level classification results from [41]. * indicates the reproduced results. Average Table 3. Comparison between our TCANet with other state-of-the- art methods on THUMOS14 dataset. The results are measured by mAP(%) at different tIoU thresholds. We combined our proposals with video-level classifier UntrimmedNet [34]. with video - level classifier UntrimmedNet [ 34 ] . Table 4. Comparison of our TCANet with other state-of-the-art methods on THUMOS14 dataset in terms of AR@AN. set to {0 . 5 , 0 . 75 , 0 . 95} , and we also test the average","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Temporal Action Localization\\", \\"Dataset\\": \\"ActivityNet-1.3\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"37.56\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Temporal Action Localization\\", \\"Dataset\\": \\"ActivityNet-1.3\\", \\"Metric\\": \\"mAP IOU@0.5\\", \\"Score\\": \\"54.33\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Temporal Action Localization\\", \\"Dataset\\": \\"ActivityNet-1.3\\", \\"Metric\\": \\"mAP IOU@0.75\\", \\"Score\\": \\"39.13\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Temporal Action Localization\\", \\"Dataset\\": \\"ActivityNet-1.3\\", \\"Metric\\": \\"mAP IOU@0.95\\", \\"Score\\": \\"8.41\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Temporal Action Proposal Generation\\", \\"Dataset\\": \\"ActivityNet-1.3\\", \\"Metric\\": \\"AR@100\\", \\"Score\\": \\"73.73\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Temporal Action Proposal Generation\\", \\"Dataset\\": \\"ActivityNet-1.3\\", \\"Metric\\": \\"AUC (val)\\", \\"Score\\": \\"65.72\\"}} ]"},{"Context":"Pyramidal Convolution: Rethinking Convolutional Neural Networks for Visual Recognition This work introduces pyramidal convolution (PyConv), which is capable of processing the input at multiple filter scales. PyConv contains a pyramid of kernels, where each level involves different types of filters with varying size and depth, which are able to capture different levels of details in the scene. On top of these improved recognition capabilities, PyConv is also efficient and, with our formulation, it does not increase the computational cost and parameters compared to standard convolution. Moreover, it is very flexible and extensible, providing a large space of potential network architectures for different applications. PyConv has the potential to impact nearly every computer vision task and, in this work, we present different architectures based on PyConv for four main tasks on visual recognition: image classification, video action classification/recognition, object detection and semantic image segmentation/parsing. Our approach shows significant improvements overall these core tasks in comparison with the baselines. For instance, on image recognition, our 50-layers network outperforms in terms of recognition performance on ImageNet dataset its counterpart baseline ResNet with 152 layers, while having 2.39 times less parameters, 2.52 times lower computational complexity and more than 3 times less layers. On image segmentation, our novel framework sets anew state-of-the-art on the challenging ADE20K benchmark for scene parsing. Code is available at: https://github.com/iduta/pyconv For image classification task we perform our experiments on the commonly used ImageNet dataset For image segmentation we use ADE20K benchmark, which is one of the most challenging datasets for image segmentation/parsing We present in the ablation experiments results of the proposed Py-Conv for image recognition task on the ImageNet dataset where, using the network with 50 layers, we vary the number of levels of PyConv The works,, besides using a strong computational architecture with many GPUs, take advantage of a large dataset of 3.5B images collected from Instagram (this dataset is not publicly available) Table 1. For direct comparison we place aside also the baseline architecture ResNet ReLU PyConv Networks for Image Classification Table 1: PyConvResNet and PyConvHGResNet. 3\xd73 max pool , s=2 ResNet - 50 7\xd77 , 64 , s=2 Table 2: ImageNet ablation experiments of PyConvResNet. top - 1 ( % ) top - 5 ( % ) params GFLOPs Table 3: Validation error rates comparison results of PyConv on ImageNet with other architectures. ResNet [ 7 ] by a large margin on all depths . For instance , our PyConvResNet improves the top - 1 Network PyConvHGResNet - 152 train top - 5 45 PyConvHGResNet - 152 val 25 ResNet - 152 val top - 1 PyConvHGResNet - 101 val ResNet - 50 train error PyConvResNet - 50 train PyConvHGResNet - 50 train network depth : 152 PyConvHGResNet - 101 train PyConvResNet - 152 train 90 ResNet - 152 train PyConvHGResNet -","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K val\\", \\"Metric\\": \\"Pixel Accuracy\\", \\"Score\\": \\"82.49\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K val\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"45.99\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K\\", \\"Metric\\": \\"Test Score\\", \\"Score\\": \\"56.52\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"45.99\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"42.3M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"81.49%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"95.72%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K val\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"45.3%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K\\", \\"Metric\\": \\"Test Score\\", \\"Score\\": \\"62.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"45.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K\\", \\"Metric\\": \\"Test Score\\", \\"Score\\": \\"56.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"44.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL Context\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"55.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL"},{"Context":"Cross-View Image Synthesis using Conditional GANs Learning to generate natural scenes has always been a challenging task in computer vision. It is even more painstaking when the generation is conditioned on images with drastically different views. This is mainly because understanding, corresponding, and transforming appearance and semantic information across the views is not trivial. In this paper, we attempt to solve the novel problem of cross-view image synthesis, aerial to street-view and vice versa, using conditional generative adversarial networks (cGAN). Two new architectures called Crossview Fork (X-Fork) and Crossview Sequential (X-Seq) are proposed to generate scenes with resolutions of 64\xd764 and 256\xd7256 pixels. X-Fork architecture has a single discriminator and a single generator. The generator hallucinates both the image and its semantic segmentation in the target view. X-Seq architecture utilizes two cGANs. The first one generates the target image which is subsequently fed to the second cGAN for generating its corresponding semantic segmentation map. The feedback from the second cGAN helps the first cGAN generate sharper images. Both of our proposed architectures learn to generate natural images as well as their semantic segmentation maps. The proposed methods show that they are able to capture and maintain the true semantics of objects in source and target views better than the traditional image-to-image translation method which considers only the visual appearance of the scene. Extensive qualitative and quantitative evaluations support the effectiveness of our frameworks, compared to two state of the art methods, for natural scene generation across drastically different views. For the experiments in this work, we use the cross-view image dataset provided by Vo et al. This dataset consists of more than one million pairs of street-view and overhead view images collected from 11 different cities in the US We call it Dayton Dataset The images in the original dataset have resolution of 354\xd7354 We also recruit the CVUSA dataset for direct comparison of our work with Zhai et al. This dataset consists of 35,532/8,884 train/test split of image pairs To do so, we take the first quarter of the ground level images and segmentations from the dataset and resize them to 256 \xd7 256 in our experiments Please see for some images from the CVUSA dataset The CVUSA dataset has annotated segmentation maps for ground view images, but for Dayton dataset such information is not available This network is pre-trained on outdoor scenes of the Cityscapes dataset and is Table 1: KL divergence scores between conditional and marginal probabilities (Inception Score). all 64\xd764 classes CVUSA Top - 5 256\xd7256 Top - 1 class - Table 2: Accuracies: Top-1 and Top-5. Accuracy ( % ) 64\xd764 CVUSA Top - 5 256\xd7256 Top - 1 - Methods Table 3: KL Divergence between model and data distributions. - Accuracy ( % ) 64\xd764 CVUSA Top - 5 256\xd7256 Top - 1 - Methods Table 3. As it can be seen, our proposed methods generate much better results than existing generative methods on both datasets. X-Fork generates images very similar to real distribution in all ex- - Accuracy ( % ) 64\xd764 CVUSA Top - 5 256\xd7256 Top - 1 - Methods Table 4: SSIM, PSNR and Sharpness Difference between real data and samples generated using different methods. SSIM PSNR 64\xd764 CVUSA Sharp Diff 256\xd7256 - Table 5: Evaluation Scores for segmentation maps. Per","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-View Image-to-Image Translation\\", \\"Dataset\\": \\"Ego2Top\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.2740\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-View Image-to-Image Translation\\", \\"Dataset\\": \\"Ego2Top\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.2738\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-View Image-to-Image Translation\\", \\"Dataset\\": \\"cvusa\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.4356\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-View Image-to-Image Translation\\", \\"Dataset\\": \\"cvusa\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.4231\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-View Image-to-Image Translation\\", \\"Dataset\\": \\"Dayton (256\xd7256) - ground-to-aerial\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.2725\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-View Image-to-Image Translation\\", \\"Dataset\\": \\"Dayton (256\xd7256) - aerial-to-ground\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.5031\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-View Image-to-Image Translation\\", \\"Dataset\\": \\"Dayton (256\xd7256) - aerial-to-ground\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.4963\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-View Image-to-Image Translation\\", \\"Dataset\\": \\"Dayton (64x64) - ground-to-aerial\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.3682\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-View Image-to-Image Translation\\", \\"Dataset\\": \\"Dayton (64x64) - ground-to-aerial\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.3663\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-View Image-to-Image Translation\\", \\"Dataset\\": \\"Dayton (64\xd764) - aerial-to-ground\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.5171\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-View Image-to-Image Translation\\", \\"Dataset\\": \\"Dayton (64\xd764) - aerial-to-ground\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.4921\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Cityscapes-to-Foggy Cityscapes\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"-8N\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Cityscapes-to-Foggy Cityscapes\\", \\"Metric\\": \\"Parameters\\", \\"Score\\": \\"65.6M\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Cityscapes-to-Photo\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"95.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Cityscapes-to-Photo\\", \\"Metric\\": \\"Per-pixel Accuracy\\", \\"Score\\": \\"96.5%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Cityscapes-to-Photo\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"65.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Cityscapes-to-Photo\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"63.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image-to-Image Translation\\","},{"Context":"DEEP CLUSTERING WITH A DYNAMIC AUTOENCODER: FROM RECONSTRUCTION TOWARDS CENTROIDS CONSTRUCTION A PREPRINT In unsupervised learning, there is no apparent straightforward cost function that can capture the significant factors of variations and similarities. Since natural systems have smooth dynamics, an opportunity is lost if an unsupervised objective function remains static during the training process. The absence of concrete supervision suggests that smooth dynamics should be integrated. Compared to classical static cost functions, dynamic objective functions allow to better make use of the gradual and uncertain knowledge acquired through pseudo-supervision. In this paper, we propose Dynamic Autoencoder (DynAE), a novel model for deep clustering that overcomes a clusteringreconstruction trade-off, by gradually and smoothly eliminating the reconstruction objective function in favor of a construction one. Experimental evaluations on benchmark datasets show that our approach achieves state-of-the-art results compared to the most relevant deep clustering methods. github.com/nairouz/DynAE We compare DynAE with several clustering algorithms on four famous datasets: MNIST-full, MNIST-test, USPS, and Fashion-MNIST \u2022 MNIST-full: A 10 classes dataset of 70000 samples \u2022 MNIST-test: A test subset of the MNIST-full dataset with 10000 data samples \u2022 USPS: A 10 classes dataset of 9298 samples \u2022 Fashion-MNIST: A 10 classes dataset of 70000 samples ACC and NMI are the most utilized evaluation metrics in the deep clustering literature Table 2: The ACC and NMI of different clustering approaches. Each category is separated from the other ones by a double horizontal line. -indicates that the program ran out of memory. Best method in bold, second best emphasized. ACC USPS MNIST - test Fashion - MNIST NMI MNIST - full - Table 3: The ACC and NMI of DEC*, IDEC* and DynAE. Best method in bold, second best emphasized. ACC USPS MNIST - test Fashion - MNIST NMI MNIST - full Table 4: The execution time (in seconds) of different deep clustering approaches. 13100 55 13000 49 USPS 15000 123000 890 110 640 120000 732 MNIST - test 349 Fashion - MNIST 857 MNIST - full Table 5: The execution time (in seconds) of DEC*, IDEC* and DynAE. 10840 USPS MNIST - test Fashion - MNIST MNIST - full","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"MNIST-full\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.987\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"MNIST-full\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"0.964\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"MNIST-test\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.987\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"MNIST-test\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"0.963\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"Fashion-MNIST\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.591\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"Fashion-MNIST\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"0.642\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"USPS\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.981\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"USPS\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"0.948\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"MNIST-full\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.965\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"MNIST-full\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"0.913\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"MNIST-test\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.967\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"MNIST-test\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"0.919\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"Fashion-MNIST\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.628\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"Fashion-MNIST\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"0.644\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"USPS\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.957\\"}}, { \\"LEADERBOARD\\": { "},{"Context":"LIPREADING USING TEMPORAL CONVOLUTIONAL NETWORKS Lip-reading has attracted a lot of research attention lately thanks to advances in deep learning. The current state-of-theart model for recognition of isolated words in-the-wild consists of a residual network and Bidirectional Gated Recurrent Unit (BGRU) layers. In this work, we address the limitations of this model and we propose changes which further improve its performance. Firstly, the BGRU layers are replaced with Temporal Convolutional Networks (TCN). Secondly, we greatly simplify the training procedure, which allows us to train the model in one single stage. Thirdly, we show that the current state-of-the-art methodology produces models that do not generalize well to variations on the sequence length, and we addresses this issue by proposing a variable-length augmentation. We present results on the largest publiclyavailable datasets for isolated word recognition in English and Mandarin, LRW and LRW1000, respectively. Our proposed model results in an absolute improvement of 1.2% and 3.2%, respectively, in these datasets which is the new state-of-the-art performance. Pre-processing: Each video sequence from the LRW dataset is processed by 1) doing face detection and face alignment, 2) aligning each frame to a reference mean face shape 3) cropping a fixed 96 \xd7 96 pixels wide ROI from the aligned face image so that the mouth region is always roughly centered on the image crop 4) transform the cropped image to gray level, as there does not seem to be a performance difference with respect to using RGB The mouth ROIs are pre-cropped in the LRW1000 dataset so there is no need for pre-processing Table 1: Comparison with state-of-the-art methods in the literature on the LRW and LRW-1000 datasets. Performance is in terms of classification accuracy (the higher the better). We also indicate the backbone employed, as some works either use higher-capacity networks, or use an ensemble of two networks. Networks marked with * use 2D convolutions except for the first being a 3D one. - LRW - 1000 ( Accuracy ) 4 - LRW ( Accuracy ) Table 2: Classification accuracy of different models on LRW when frames are randomly removed from the test sequences. The model in the first row is the same as the one in N = 0 N = 3 N = 4 N = 1 N = 2 N =5","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Lipreading\\", \\"Dataset\\": \\"Lip Reading in the Wild\\", \\"Metric\\": \\"Top-1 Accuracy\\", \\"Score\\": \\"85.30\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Lipreading\\", \\"Dataset\\": \\"CAS-VSR-W1k (LRW-1000)\\", \\"Metric\\": \\"Top-1 Accuracy\\", \\"Score\\": \\"41.4%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Lipreading\\", \\"Dataset\\": \\"Lip Reading in the Wild\\", \\"Metric\\": \\"Top-1 Accuracy\\", \\"Score\\": \\"83.34\\"}} ]"},{"Context":"Using the General Intensional Programming System (GIPSY) for Evaluation of Higher-Order Intensional Logic (HOIL) Expressions The General Intensional Programming System (GIPSY) has been built around the Lucid family of intensional programming languages that rely on the higher-order intensional logic (HOIL) to provide context-oriented multidimensional reasoning of intensional expressions. HOIL combines functional programming with various intensional logics to allow explicit context expressions to be evaluated as first-class values that can be passed as parameters to functions and return as results with an appropriate set of operators defined on contexts. GIPSY\'s frameworks are implemented in Java as a collection of replaceable components for the compilers of various Lucid dialects and the demand-driven eductive evaluation engine that can run distributively. GIPSY provides support for hybrid programming models that couple intensional and imperative languages fora variety of needs. Explicit context expressions limit the scope of evaluation of math expressions (effectively a Lucid program is a mathematics or physics expression constrained by the context) in tensor physics, regular math in multiple dimensions, etc., and for cyberforensic reasoning as one of the use-cases of interest. Thus, GIPSY is a support testbed for HOIL-based languages some of which enable such reasoning, as informal cyberforensic case analysis with event reconstruction. In this paper we discuss the GIPSY architecture, its evaluation engine and example use-cases.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"BERT-based Ensembles for Modeling Disclosure and Support in Conversational Social Media Text There is a growing interest in understanding how humans initiate and hold conversations. The affective understanding of conversations focuses on the problem of how speakers use emotions to react to a situation and to each other. In the CL-Aff Shared Task, the organizers released Get it #OffMyChest dataset, which contains Reddit comments from casual and confessional conversations, labeled for their disclosure and supportiveness characteristics. In this paper, we introduce a predictive ensemble model exploiting the finetuned contextualized word embeddings, RoBERTa and ALBERT. We show that our model outperforms the base models in all considered metrics, achieving an improvement of 3% in the F1 score. We further conduct statistical analysis and outline deeper insights into the given dataset while providing anew characterization of impact for the dataset. We further compare our ensemble model with four other ensemble models and show that our model performs the best among all the models in four out of five evaluation metrics using 10-fold cross validation We evaluate all the models on the following metrics: Accuracy, F1, Precision-1, Recall-1, and the mean of Accuracy and F1, denoted as Acc&F1 from hereon In this section, we provide a comprehensive statistical analysis of the dataset Get it #OffMyChest, which comprises of comments and parent posts from the subreddit /r/CasualConversations, and /r/OffMyChest We further propose new characterizations and outline semantic features for the given dataset Table 1. Label-averaged values for each metric for RoBERTa,ALBERT, and our best performing ensemble model. Accuracy Precision - 1 Recall - 1 F1 Acc&F1 Table 2. Label-wise values for each metric for our best performing ensemble model. 1 Recall - 1 F1 Acc&F1 Table 3. Weights assigned to each model in different Ensemble Models. Each cell contains a pair (x, y) where x denotes the weight assigned to RoBERTa and y denotes the weight assigned to ALBERT. dividual labels . Its performance on different labels is evaluated using the above Table 4. Label-averaged values for each metric for different ensemble models. F1 Acc&F1 Model / Metrics Accuracy Precision - 1 Recall - 1 Table 5. Weekday-wise label distribution of the labelled dataset. Support Emotional General Informational EmotionalSupport Weekday / Label Disclosure Table 6. The relationship between Labels and Impact, as represented by Pearson correlation coefficient, \u03c1. \u03c1 with Impact","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Text Classification\\", \\"Dataset\\": \\"AffCon 2020 Emotion Detection\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"0.558\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Dialogue Act Classification\\", \\"Dataset\\": \\"One-class CIFAR-10\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"94.4\\"}} ]"},{"Context":"Sub-Pixel Back-Projection Network For Lightweight Single Image Super-Resolution Convolutional neural network (CNN)-based methods have achieved great success for single-image superresolution (SISR). However, most models attempt to improve reconstruction accuracy while increasing the requirement of number of model parameters. To tackle this problem, in this paper, we study reducing the number of parameters and computational cost of CNN-based SISR methods while maintaining the accuracy of super-resolution reconstruction performance. To this end, we introduce a novel network architecture for SISR, which strikes a good trade-off between reconstruction quality and low computational complexity. Specifically, we propose an iterative back-projection architecture using sub-pixel convolution instead of deconvolution layers. We evaluate the performance of computational and reconstruction accuracy for our proposed model with extensive quantitative and qualitative evaluations. Experimental results reveal that our proposed method uses fewer parameters and reduces the computational cost while maintaining reconstruction accuracy against state-of-the-art SISR methods over well-known four SR benchmark datasets. 1 Code is available at https://github.com/supratikbanerjee/ SubPixel-BackProjection_SuperResolution. Each model was tested with four datasets, namely, Set5, Set14, BSDS100, and Urban100 Table 1: Quantitative Results on four datasets. The highest reconstruction accuracy is indicated in red and second highest reconstruction accuracy in blue. [\xd72 upscaling] Datasets Urban100 PSNR SSIM BSDS100 Set5 Set14 Table 1 : Quantitative Results on four datasets . The highest reconstruction accuracy is indicated in red and second highest Multi - Adds","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Set5 - 2x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"38.05\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Set5 - 2x upscaling\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.9606\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Urban100 - 2x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"32.07\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Urban100 - 2x upscaling\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.9277\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"BSDS100 - 2x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"32.21\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"BSDS100 - 2x upscaling\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.9001\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Set14 - 2x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"33.62\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Set14 - 2x upscaling\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.9178\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"BSD100 - 4x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"27.83\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Set5 - 4x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"30.40\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Set14 - 4x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"27.88\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Set14 - 4x upscaling\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.749\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Urban100 - 4x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"25.94\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Urban100 - 4x upscaling\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.756\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Ur"},{"Context":"GATED MECHANISM FOR ATTENTION BASED MULTIMODAL SENTIMENT ANALYSIS Multimodal sentiment analysis has recently gained popularity because of its relevance to social media posts, customer service calls and video blogs. In this paper, we address three aspects of multimodal sentiment analysis; 1. Cross modal interaction learning, i.e. how multiple modalities contribute to the sentiment, 2. Learning long-term dependencies in multimodal interactions and 3. Fusion of unimodal and cross modal cues. Out of these three, we find that learning cross modal interactions is beneficial for this problem. We perform experiments on two benchmark datasets, CMU Multimodal Opinion level Sentiment Intensity (CMU-MOSI) and CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI) corpus. Our approach on both these tasks yields accuracies of 83.9% and 81.1% respectively, which is 1.6% and 1.34% absolute improvement over current state-ofthe-art. We evaluated our system on two standard multimodal sentiment analysis datasets from CMU multimodal SDK 1, 1) CMU-MOSI: CMU Multimodal Opinion level Sentiment Intensity and; 2) CMU-MOSEI: CMU Multimodal Opinion Sentiment and Emotion Intensity Table 1: Comparison of performance of each step in the proposed model. Accuracy values are mentioned in the table CMU - MOSEI CMU - MOSI Table 2: Comparative results on CMU-MOSI and CMU-MOSEI multimodal sentiment analysis. ( * ) results are taken from Zadeh et al - ( 83 . 62 ) Sun et al [ 4 ] \xa6 ( 83 . 75 ) *","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Sentiment Analysis\\", \\"Dataset\\": \\"CMU-MOSEI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"81.14\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Sentiment Analysis\\", \\"Dataset\\": \\"MOSI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"83.91%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Sentiment Analysis\\", \\"Dataset\\": \\"MOSI\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"81.17\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Multimodal Sentiment Analysis\\", \\"Dataset\\": \\"MOSI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"85.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multimodal Sentiment Analysis\\", \\"Dataset\\": \\"MOSI\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.01\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multimodal Sentiment Analysis\\", \\"Dataset\\": \\"MOSI\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"83.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multimodal Sentiment Analysis\\", \\"Dataset\\": \\"MOSI\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.76\\"}} ]"},{"Context":"We propose a dynamical process for network evolution, aiming at explaining the emergence of the small world phenomenon, i.e., the statistical observation that any pair of individuals are linked by a short chain of acquaintances computable by a simple decentralized routing algorithm, known as greedy routing. Previously proposed dynamical processes enabled to demonstrate experimentally (by simulations) that the small world phenomenon can emerge from local dynamics. However, the analysis of greedy routing using the probability distributions arising from these dynamics is quite complex because of mutual dependencies. In contrast, our process enables complete formal analysis. It is based on the combination of two simple processes: a random walk process, and an harmonic forgetting process. Both processes reflect natural behaviors of the individuals, viewed as nodes in the network of inter-individual acquaintances. We prove that, in k-dimensional lattices, the combination of these two processes generates long-range links mutually independently distributed as a k-harmonic distribution. We analyze the performances of greedy routing at the stationary regime of our process, and prove that the expected number of steps for routing from any source to any target in any multidimensional lattice is a polylogarithmic function of the distance between the two nodes in the lattice. Up to our knowledge, these results are the first formal proof that navigability in small worlds can emerge from a dynamical process for network evolution. Our dynamical process can find practical applications to the design of spatial gossip and resource location protocols. . Additional supports from the ANR projects ALADDIN and ALPAGE, and from the COST Action 295 DYNAMO.\u2021 CNRS and University Paris 7. Email: Emmanuelle.Lebhar@liafa.jussieu.fr. Additional supports from the ANR project ALADDIN, and from the COST Action 295 DYNAMO.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Mode Seeking Generative Adversarial Networks for Diverse Image Synthesis Most conditional generation tasks expect diverse outputs given a single conditional context. However, conditional generative adversarial networks (cGANs) often focus on the prior conditional information and ignore the input noise vectors, which contribute to the output variations. Recent attempts to resolve the mode collapse issue for cGANs are usually task-specific and computationally expensive. In this work, we propose a simple yet effective regularization term to address the mode collapse issue for cGANs. The proposed method explicitly maximizes the ratio of the distance between generated images with respect to the corresponding latent codes, thus encouraging the generators to explore more minor modes during training. This mode seeking regularization term is readily applicable to various conditional generation tasks without imposing training overhead or modifying the original network structures. We validate the proposed algorithm on three conditional image synthesis tasks including categorical generation, image-toimage translation, and text-to-image synthesis with different baseline models. Both qualitative and quantitative results demonstrate the effectiveness of the proposed regularization method for improving diversity without loss of quality. * Equal contribution We evaluate the proposed regularization method through extensive quantitative and qualitative evaluation More implementation and evaluation details, please refer to the appendixes We conduct evaluations using the following metrics To evaluate the quality of the generated images, we use FID to measure the distance between the generated distribution and the real one through features extracted by Inception Network To evaluate diversity, we employ LPIPS following These metrics evaluate the extent of mode missing of generative models We calculate the bin-proportions of the training samples and the synthesized samples to evaluate the difference between the generated distribution and the real data distribution For evaluation, we randomly generate N images fora given conditional context on various tasks More evaluation details of one trial are presented as follows For NDB and JSD, we employ all the training samples for clustering and choose K = 20 bins for facades, and K = 50 bins for Table 1: NDB and JSD results on the CIFAR-10 dataset. automobile deer horse frog airplane bird cat truck ship dog Table 2: FID results on the CIFAR-10 dataset. DCGAN MSGAN Table 3: Quantitative results on the facades and maps dataset. Datasets Facades Maps BicycleGAN [ 35 ] MSGAN Pix2Pix [ 11 ] Table 4: Quantitative results of the Yosemite (Summer Winter) and the Cat Dog dataset. Datasets Cat2Dog Dog2Cat Summer2Winter DRIT [ 15 ] MSGAN Winter2Summer Table 5: Quantitative results on the CUB-200-2011 dataset. We conduct experiments in two settings: 1) Conditioned on text descriptions, where every description can be mapped to different text codes. 2) Conditioned on text codes, where the text codes are fixed so that their effects are excluded. Conditioned on text codes Conditioned on text descriptions MSGAN StackGAN++ [ 32 ] Table 6: Quantitative results with different \u03bb ms on the facades dataset. 1 3 Table 7:","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Unsupervised Image-To-Image Translation\\", \\"Dataset\\": \\"CelebA-HQ\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"33.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Unsupervised Image-To-Image Translation\\", \\"Dataset\\": \\"AFHQ\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"61.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"28.73\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"12.30\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Inception score\\", \\"Score\\": \\"8.25\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"12.89\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Inception score\\", \\"Score\\": \\"8.21\\"}} ]"},{"Context":"FABRICATION OF MINIATURIZED VARIABLE-FOCUS LENS USING LIQUID FILLING TECHNIQUE This paper describes a simple method for fabricating a variable-focus lens by using PDMS (polydimethylsiloxane) and filling with liquid for the variable-focus lens. The lens diameter of 2-mm was designed in this experiment and expected to reach the focal length in the range of 3 ~ 12 mm. The theoretical value between the liquid volume and the lens contact angle at different focal lengths were simulated and measured.  Table 1 List of symbols. 3 , and","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Kvasir-SEG: A Segmented Polyp Dataset Pixel-wise image segmentation is a highly demanding task in medical-image analysis. In practice, it is difficult to find annotated medical images with corresponding segmentation masks. In this paper, we present Kvasir-SEG: an open-access dataset of gastrointestinal polyp images and corresponding segmentation masks, manually annotated by a medical doctor and then verified by an experienced gastroenterologist. Moreover, we also generated the bounding boxes of the polyp regions with the help of segmentation masks. We demonstrate the use of our dataset with a traditional segmentation approach and a modern deep-learning based Convolutional Neural Network (CNN) approach. The dataset will be of value for researchers to reproduce results and compare methods. By adding segmentation masks to the Kvasir dataset, which only provide frame-wise annotations, we enable multimedia and computer vision researchers to contribute in the field of polyp segmentation and automatic analysis of colonoscopy images. The Kvasir-SEG dataset is based on the previous Kvasir dataset, which is the first multi-class dataset for gastrointestinal (GI) tract disease detection and classification The original Kvasir dataset comprises 8,000 GI tract images from 8 classes where each class consists of 1000 images We replaced the 13 images from the polyp class with new images to improve the quality of the dataset A more detailed explanation about each image classes, the data collection procedure and the dataset details can be found in The Kvasir dataset was used for the Multimedia for Medicine Challenge (the Medico Task) in 2017 and 2018 at the MediaEval Benchmarking Initiative for Multimedia Evaluation 1 to develop and compare methods to reach clinical level performance on multiclass classification of endoscopic findings in the large bowel However, the dataset was limited to frame classification only, due to only a frame-wise annotations trained their model on the CVC-ClinicDB, and Table 1: Quantitative performance of ResUNet model on Kvasir-SEG dataset. Dice coefficient Mean IoU Loss","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Medical Image Segmentation\\", \\"Dataset\\": \\"Kvasir-SEG\\", \\"Metric\\": \\"mean Dice\\", \\"Score\\": \\"0.7877\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Polyp Segmentation\\", \\"Dataset\\": \\"Kvasir-SEG\\", \\"Metric\\": \\"DSC\\", \\"Score\\": \\"0.7877\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Medical Image Segmentation\\", \\"Dataset\\": \\"Kvasir-SEG\\", \\"Metric\\": \\"FPS\\", \\"Score\\": \\"69.59\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Medical Image Segmentation\\", \\"Dataset\\": \\"Kvasir-SEG\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"0.7800\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Medical Image Segmentation\\", \\"Dataset\\": \\"Kvasir-SEG\\", \\"Metric\\":\\"mean Dice\\", \\"Score\\": \\"0.8576\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Medical Image Segmentation\\", \\"Dataset\\": \\"Endotect Polyp Segmentation\\", \\"Metric\\": \\"DSC\\", \\"Score\\": \\"0.7870\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Medical Image Segmentation\\", \\"Dataset\\": \\"Endotect Polyp Segmentation\\", \\"Metric\\": \\"FPS\\", \\"Score\\": \\"70.23\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Medical Image Segmentation\\", \\"Dataset\\": \\"Endotect Polyp Segmentation\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"0.701\\"}} ]"},{"Context":"COMPLEX TRANSFORMER: A FRAMEWORK FOR MODELING COMPLEX-VALUED SEQUENCE While deep learning has received a surge of interest in a variety of fields in recent years, major deep learning models barely use complex numbers. However, speech, signal and audio data are naturally complex-valued after Fourier Transform, and studies have shown a potentially richer representation of complex nets. In this paper, we propose a Complex Transformer, which incorporates the transformer model as a backbone for sequence modeling; we also develop attention and encoder-decoder network operating for complex input. The model achieves state-of-the-art performance on the MusicNet dataset and an In-phase Quadrature (IQ) signal dataset. The GitHub implementation to reproduce the experimental results is available at https://github.com/ muqiaoy/dl_signal. Index Terms-Deep learning, transformer network, sequence modeling, complex-valued deep neural network  Table 1. Experimental results for automatic music transcrip- tion. Model # Parameters APS (%) tion . Table 1 . Experimental results for automatic music transcrip - APS ( % ) # Parameters Table 2. Experimental results for In-phase Quadrature (IQ) data. Model Accuracy (%) data . Accuracy ( % ) Experimental results for In - phase Quadrature ( IQ ) Model Table 2 . Table 3. Experimental results (in loss) for sequence genera- tion. Model MusicNet IQ dataset tion . IQ dataset Table 3 . Experimental results ( in loss ) for sequence genera - MusicNet","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Music Transcription\\", \\"Dataset\\": \\"MusicNet\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"74.22\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Music Transcription\\", \\"Dataset\\": \\"MusicNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"11.61M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Music Transcription\\", \\"Dataset\\": \\"MusicNet\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"71.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Music Transcription\\", \\"Dataset\\": \\"MusicNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"9.79M\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"80.8%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"95.1%\\"}} ]"},{"Context":"Bit Error Rate Performance Analysis on Modulation Techniques of Wideband Code Division Multiple Access In the beginning of 21 st century there has been a dramatic shift in the market dynamics of telecommunication services. The transmission from base station to mobile or downlink transmission using M-ary Quadrature Amplitude modulation (QAM) and Quadrature phase shift keying (QPSK) modulation schemes are considered in Wideband-Code Division Multiple Access (W-CDMA) system. We have done the performance analysis of these modulation techniques when the system is subjected to Additive White Gaussian Noise (AWGN) and multipath Rayleigh fading are considered in the channel. The research has been performed by using MATLAB 7.6 for simulation and evaluation of Bit Error Rate (BER) and Signal-To-Noise Ratio (SNR) for W-CDMA system models. It is shows that the analysis of Quadrature phases shift key and 16-ary Quadrature Amplitude modulations which are being used in wideband code division multiple access system, Therefore, the system could go for more suitable modulation technique to suit the channel quality, thus we can deliver the optimum and efficient data rate to mobile terminal.  No ) 4481 Simulation result for evaluation on BER vs . SNR Noise 7520 Signal to 15615 11334","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Multi-Shift de Bruijn Sequence A (non-circular) de Bruijn sequence w of order n is a word such that every word of length n appears exactly once in was a factor. In this paper, we generalize the concept to a multi-shift setting: a m-shift de Bruijn sequence of order n is a word such that every word of length n appears exactly once in was a factor that starts at an index im + 1 for some integer i \u2265 0. We show the number of the m-shift de Bruijn sequences of order n is an !a (m\u2212n)(a n \u22121) for 1 \u2264 n \u2264 m and is (a m !) a n\u2212m for 1 \u2264 m \u2264 n, where a is the size of the alphabet. We provide two algorithms for generating a multi-shift de Bruijn sequence. The multi-shift de Bruijn sequence is important in solving the Frobenius problem in a free monoid.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Ideal Stabilization We define and explore the concept of ideal stabilization. The program is ideally stabilizing if its every state is legitimate. Ideal stabilization allows the specification designer to prescribe with arbitrary degree of precision not only the fault-free program behavior but also its recovery operation. Specifications mayor may not mention all possible states. We identify approaches to designing ideal stabilization to both kinds of specifications. For the first kind, we state the necessary condition for an ideally stabilizing solution. On the basis of this condition we prove that there is no ideally stabilizing solution to the leader election problem. We illustrate the utility of the concept by providing examples of well-known programs and proving them ideally stabilizing. Specifically, we prove ideal stabilization of the conflict manager, the alternator, the propagation of information with feedback and the alternating bit protocol. \u22c6","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Abstraction and Refinement in Static Model-Checking interpretation is a general methodology for building static analyses of programs. It was introduced by P. and R. Cousot in [3]. We present, in this paper, an application of a generic abstract interpretation to domain of model-checking. Dynamic checking are usually easier to use, because the concept are established and wide well know. But they are usually limited to systems whose states space is finite. In another part, certain faults cannot be detected dynamically, even by keeping track of the history of the states space.Indeed, the classical problem of finding the right test cases is far from trivial and limit the abilities of dynamic checkers further. Static checking have the advantage that they work on a more abstract level than dynamic checker and can verify system properties for all inputs. Problem, it is hard to guarantee that a violation of a modeled property corresponds to a fault in the concrete system. We propose an approach, in which we generate counter-examples dynamically using the abstract interpretation techniques. a)","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Simple Baselines for Human Pose Estimation and Tracking There has been significant progress on pose estimation and increasing interests on pose tracking in recent years. At the same time, the overall algorithm and system complexity increases as well, making the algorithm analysis and comparison more difficult. This work provides simple and effective baseline methods. They are helpful for inspiring and evaluating new ideas for the field. State-of-the-art results are achieved on challenging benchmarks. The code will be available at https://github. com/leoxiaobin/pose.pytorch.  Table 2. Ablation study of our method on COCO val2017 dataset. Those settings used in comparison are in bold. For example, (a, e, f) compares backbones. #Deconv . Layers Deconv . Kernel Size AP Table 3. Comparison with Hourglass [22] and CPN [6] on COCO val2017 dataset. Their results are cited from [6]. OHKM means Online Hard Keypoints Mining. 2 . Kernel size . Methods ( a , c , d ) show that a smaller kernel size gives a marginally performance . Methods ( a , e , f ) show steady improvement by using deeper Input Size AP Table 4. Comparisons on COCO test-dev dataset. Top: methods in the literature, trained only on COCO training dataset. Middle: results submitted to COCO test-dev leaderboard [9], which have either extra training data (*) or models ensamled ( + ). Bottom: our single model results, trained only on COCO training dataset. split","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Pose Estimation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"73.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Pose Estimation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"91.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Pose Estimation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"81.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Pose Estimation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"80\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Pose Estimation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"70.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Pose Estimation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AR\\", \\"Score\\": \\"79\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO\\", \\"Metric\\": \\"Validation AP\\", \\"Score\\": \\"72.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-challenge\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"74.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-challenge\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"90.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-challenge\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"80.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-challenge\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"87.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-challenge\\", \\"Metric\\": \\"AR\\", \\"Score\\": \\"80.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-challenge\\", \\"Metric\\": \\"AR50\\", \\"Score\\": \\"95.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-challenge\\", \\"Metric\\": \\"AR75\\", \\"Score\\": \\"86.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-challenge\\", \\"Metric\\": \\"ARL\\", \\"Score\\": \\"82.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-challenge\\", \\"Metric\\": \\"ARM\\", \\"Score\\": \\"75.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"92.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"84.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"82.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"73.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AR\\", \\"Score\\": \\"81.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AR50\\", \\"Score\\": \\"95.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AR75\\", \\"Score\\": \\"88.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"ARL\\", \\"Score\\": \\"87.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"ARM\\", \\"Score\\": \\"77.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"91.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"81.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"80.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"70.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Keypoint Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AR\\", \\"Score\\": \\"79.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Pose Tracking\\", \\"Dataset\\": \\"PoseTrack2017\\", \\"Metric\\": \\"MOTA\\", \\"Score\\": \\"57.81\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Pose Tracking\\", \\"Dataset\\": \\"PoseTrack2017\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"74.57\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Pose Tracking\\", \\"Dataset\\": \\"PoseTrack2018\\", \\"Metric\\": \\"MOTA\\", \\"Score\\": \\"61.37\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Pose Tracking\\", \\"Dataset\\": \\"PoseTrack2018\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"74.03\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Pose Tracking\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"68.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Pose Tracking\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"70.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Pose Tracking\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"66.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Pose Tracking\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"22.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Pose Tracking\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"42.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Pose Tracking\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"65.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Pose Tracking\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"43.3\\"}},"},{"Context":"Patent Classification by Fine-Tuning BERT Language Model In this work we focus on fine-tuning a pre-trained BERT model and applying it to patent classification. When applied to large datasets of over two millions patents, our approach outperforms the state of the art by an approach using CNN with word embeddings. In addition, we focus on patent claims without other parts in patent documents. Our contributions include: (1) anew state-of-the-art result based on pretrained BERT model and fine-tuning for patent classification, (2) a large dataset USPTO-3M at the CPC subclass level with SQL statements that can be used by future researchers, (3) showing that patent claims alone are sufficient for classification task, in contrast to conventional wisdom.  Table 1: Patent Classification Performance Top 1 Top 5 O ( % ) N / A Precision Recall < 74 F1 < 35 < 45","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Multi-Label Text Classification\\", \\"Dataset\\": \\"USPTO-3M\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"66.83%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"USPS\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"45.0%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"USPS\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"43.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"USPS\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"38.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"USPS\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"40.4%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"USPS\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"40.4%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"USPS\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"40.2%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"arstrial\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"44.51\\"}}, { \\"LEADERBOARD\\": { "},{"Context":"Multilingual Models for Compositional Distributed Semantics We present a novel technique for learning semantic representations, which extends the distributional hypothesis to multilingual data and joint-space embeddings. Our models leverage parallel data and learn to strongly align the embeddings of semantically equivalent sentences, while maintaining sufficient distance between those of dissimilar sentences. The models do not rely on word alignments or any syntactic information and are successfully applied to a number of diverse languages. We extend our approach to learn semantic representations at the document level, too. We evaluate these models on two cross-lingual document classification tasks, outperforming the prior state of the art. Through qualitative analysis and the study of pivoting effects we demonstrate that our representations are semantically plausible and can capture semantic relationships across languages without parallel data. First, we replicate the cross-lingual document classification task of, learning distributed representations on the Europarl corpus and evaluating on documents from the Reuters RCV1/RCV2 corpora Subsequently, we design a multi-label classification task using the TED corpus, both for training and evaluating The use of a wider range of languages in the second experiments allows us to better evaluate our models\' capabilities in learning a shared multilingual semantic representation Here we describe our experiments on the TED corpus, which enables us to scale up to multilingual learning Consisting of a large number of relatively short and parallel documents, this corpus allows us to evaluate the performance of the DOC model described in \xa73.2 We use the training data of the corpus to learn distributed representations across 12 languages In the single mode, vectors are learnt from a single language pair (en-X), while in the joint mode vectorlearning is performed on all parallel Table 1: Classification accuracy for training on English and German with 1000 labeled examples on the RCV corpus. Cross-lingual compositional representations (ADD, BI and their multilingual extensions), I-Matrix (Klementiev et al., 2012) translated (MT) and glossed (Glossed) word baselines, and the majority class baseline. The baseline results are from Klementiev et al. (2012). dim = 40 dim = 128 en \u2192 de de \u2192 en Table 2: F1-scores for the TED document classification task for individual languages. Results are re- ported for both directions (training on English, evaluating on L2 and vice versa). Bold indicates best result, underline best result amongst the vector-based systems. L2 \u2192 en Language en \u2192 L2 Training Rom \' n Russian Turkish Pt - Br Pt - Br Roman . Russian Turkish Test Language Setting Languages Arabic German Spanish French Italian Dutch Polish Table 3: F1-scores for TED corpus document classification results when training and testing","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-Lingual Document Classification\\", \\"Dataset\\": \\"Reuters RCV1/RCV2 English-to-German\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"88.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-Lingual Document Classification\\", \\"Dataset\\": \\"Reuters RCV1/RCV2 German-to-English\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"79.2\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Text Classification\\", \\"Dataset\\": \\"R7\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"71.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Text Classification\\", \\"Dataset\\": \\"R7\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"71.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Text Classification\\", \\"Dataset\\": \\"ROUGE-L\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"85.3\\"}} ]"},{"Context":"Digging Into Self-Supervised Monocular Depth Estimation Per-pixel ground-truth depth data is challenging to acquire at scale. To overcome this limitation, self-supervised learning has emerged as a promising alternative for training models to perform monocular depth estimation. In this paper, we propose a set of improvements, which together result in both quantitatively and qualitatively improved depth maps compared to competing self-supervised methods.Research on self-supervised monocular training usually explores increasingly complex architectures, loss functions, and image formation models, all of which have recently helped to close the gap with fully-supervised methods. We show that a surprisingly simple model, and associated design choices, lead to superior predictions. In particular, we propose (i) a minimum reprojection loss, designed to robustly handle occlusions, (ii) a full-resolution multi-scale sampling method that reduces visual artifacts, and (iii) an auto-masking loss to ignore training pixels that violate camera motion assumptions. We demonstrate the effectiveness of each component in isolation, and show high quality, state-of-the-art results on the KITTI benchmark. We evaluate our models, named Monodepth2, on the KITTI 2015 stereo dataset, to allow comparison with previously published monocular methods In Section A of the supplementary material we show odometry evaluation on KITTI In we evaluate our pose estimation network following the protocol in In order to evaluate our two-frame model on the five-frame test sequences, we make separate predictions for each of the four frame-to-frame transformation for each set of five frames and combine them to form local trajectories Baseline methods were evaluated using their provided disparity files, which were either available publicly or from private communication with the authors Additional Evaluation D.1 Improved Ground Truth As mentioned in the main paper, the evaluation method introduced by Eigen for KITTI uses the reprojected LI-DAR points but does not handle occlusions, moving objects, or the fact that the car is moving introduced a set of high quality depth maps for the Table 1. Quantitative results. Com- parison of our method to existing methods on KITTI 2015 [13] using the Eigen split. Best results in each category are in bold; second best are underlined. underlined . methods on KITTI 2015 [ 13 ] using category are in bold ; second best are the Eigen split . Table 1 . Quantitative results . parison - Table 2. Ablation. Results for different variants of our model (Monodepth2) with monocular training on KITTI 2015 [13] using the Eigen split. (a) The baseline model, with none of our contributions, performs poorly. The addition of our minimum reprojection, auto-masking and full-res multi-scale components, significantly improves performance. (b) Even without ImageNet pretrained weights, our much simpler model brings large improvements above the baseline -see also Table 1. (c) If we train with the full Eigen dataset (instead of the subset introduced for monocular training by [76]) our improvement over","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Monocular Depth Estimation\\", \\"Dataset\\": \\"KITTI Eigen split\\", \\"Metric\\": \\"absolute relative error\\", \\"Score\\": \\"0.106\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Monocular Depth Estimation\\", \\"Dataset\\": \\"KITTI Eigen split\\", \\"Metric\\": \\"absolute relative error\\", \\"Score\\": \\"0.133\\"}} ]"},{"Context":"On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units Deep feedforward neural networks with piecewise linear activations are currently producing the state-of-the-art results in several public datasets (e.g., CIFAR-10, CIFAR-100, MNIST, and SVHN). The combination of deep learning models and piecewise linear activation functions allows for the estimation of exponentially complex functions with the use of a large number of subnetworks specialized in the classification of similar input examples. During the training process, these subnetworks avoid overfitting with an implicit regularization scheme based on the fact that they must share their parameters with other subnetworks. Using this framework, we have made an empirical observation that can improve even more the performance of such models. We notice that these models assume a balanced initial distribution of data points with respect to the domain of the piecewise linear activation function. If that assumption is violated, then the piecewise linear activation units can degenerate into purely linear activation units, which can result in a significant reduction of their capacity to learn complex functions. Furthermore, as the number of model layers increases, this unbalanced initial distribution makes the model ill-conditioned. Therefore, we propose the introduction of batch normalisation units into deep feedforward neural networks with piecewise linear activations, which drives a more balanced use of these activation units, where each region of the activation function is trained with a relatively large proportion of training samples. Also, this batch normalisation promotes the pre-conditioning of very deep learning models. We show that by introducing maxout and batch normalisation units to the network in network model results in a model that produces classification results that are better than or comparable to the current state of the art in CIFAR-10, CIFAR-100, MNIST, and SVHN datasets. We evaluate our proposed method on four common deep learning benchmarks: CIFAR-10, CIFAR-100, MNIST and SVHN The CIFAR-10 [8] dataset contains 60000 32x32 RGB images of 10 classes of common visual objects (e.g., animals, vehicles, etc.), where 50000 images are for training and the rest 10000 for testing The MNIST dataset is a standard benchmark for comparing learning methods Finally, the Street View House Number (SVHN) dataset is a real-word digit dataset with over 600000 32x32 RGB images containing images of house numbers (i.e., digits 0-9) The dataset is partitioned into training, test and extra sets, where the extra 530000 images are less difficult samples to be used as extra training data For each of these datasets, we validate our algorithm using the same training and validation splitting described by Goodfellow et al Moreover, we do not perform data augmentation for any of these datasets and only compare our MIM model","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"MNIST\\", \\"Metric\\": \\"Percentage error\\", \\"Score\\": \\"0.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"70.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"SVHN\\", \\"Metric\\": \\"Percentage error\\", \\"Score\\": \\"2.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"91.5\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-100\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"84.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"94.8\\"}} ]"},{"Context":"ConsNet: Learning Consistency Graph for Zero-Shot Human-Object Interaction Detection Human-Object Interaction Detection, Graph Neural Networks, Zero- Shot Learning ACM Reference Format We consider the problem of Human-Object Interaction (HOI) Detection, which aims to locate and recognize HOI instances in the form of \u27e8\u210e , , \u27e9 in images. Most existing works treat HOIs as individual interaction categories, thus cannot handle the problem of long-tail distribution and polysemy of action labels. We argue that multi-level consistencies among objects, actions and interactions are strong cues for generating semantic representations of rare or previously unseen HOIs. Leveraging the compositional and relational peculiarities of HOI labels, we propose ConsNet, a knowledge-aware framework that explicitly encodes the relations among objects, actions and interactions into an undirected graph called consistency graph, and exploits Graph Attention Networks (GATs) to propagate knowledge among HOI categories as well as their constituents. Our model takes visual features of candidate human-object pairs and word embeddings of HOI labels as inputs, maps them into visual-semantic joint embedding space and obtains detection results by measuring their similarities. We extensively evaluate our model on the challenging V-COCO and HICO-DET datasets, and results validate that our approach outperforms stateof-the-arts under both fully-supervised and zero-shot settings. Code is available at https://github.com/yeliudev/ConsNet. In this section, we evaluate the proposed method on the challenging V-COCO and HICO-DET datasets We first evaluate our method under the fully-supervised settings on both of the datasets, following by zero-shot settings on HICO-DET dataset An extensive ablation study is also reported after the evaluations V-COCO is a subset of MS-COCO 2014 dataset, it has 2,533 images for training, 2,867 images for validation and 4,946 images for testing HICO-DET is another large-scale HOI detection dataset that extends annotations of HICO from image-level to instancelevel We follow the standard evaluation metric introduced by Chao et al Table 1: Role Detection results on V-COCO dataset under fully-supervised settings. mAP Table 2: HOI Detection results on HICO-DET dataset un- der fully-supervised settings. R and H represent ResNet and Hourglass respectively. Non - Rare Rare Full Table 3: HOI Detection results on HICO-DET dataset under zero-shot settings. UC, UO and UA denote unseen action- object combination, unseen object and unseen action scenar- ios respectively. UO 12 . 74\xb10 . 34 16 . 99\xb11 . 67 19 . 81\xb10 . 32 11 . 31\xb11 . 03 Unseen 12 . 45\xb10 . 16 Seen 20 . 51\xb10 . 62 Full Table 4: Ablation study results on HICO-DET dataset under fully-supervised settings. \u2205 means predicting HOI labels us- ing visual embedding network directly. Non - Rare Rare Full","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Human-Object Interaction Detection\\", \\"Dataset\\": \\"HICO-DET\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"25.94\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Human-Object Interaction Detection\\", \\"Dataset\\": \\"HICO-DET\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"22.15\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Human-Object Interaction Detection\\", \\"Dataset\\": \\"HICO-DET\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"87.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Human-Object Interaction Detection\\", \\"Dataset\\": \\"V-COCO\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"44.2\\"}} ]"},{"Context":"Generalised sequential crossover of words and languages In this paper, we propose anew operation, Generalised Sequential Crossover (GSCO) of words, which in some sense an abstract model of crossing over of the chromosomes in the living organisms. We extend GSCO over language L iteratively (GSCO * (L) as well as iterated GSCO over two languages GSCO * (L1, L2)). Our study reveals that GSCO * (L) is subclass of regular languages for any L. We compare the different classes of GSCO languages with the prominent sub-regular classes.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Optimal Iris Fuzzy Sketches Fuzzy sketches, introduced as a link between biometry and cryptography, area way of handling biometric data matching as an error correction issue. We focus hereon iris biometrics and look for the best error-correcting code in that respect. We show that two-dimensional iterative min-sum decoding leads to results near the theoretical limits. In particular, we experiment our techniques on the Iris Challenge Evaluation (ICE) database and validate our findings.  Table 1: Theoretical limits on ICE database Theoretical limits on ICE database Best theoretical FRR","PWC Annotation":"unanswerable","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Iris-View Image-to-Image Translation\\", \\"Dataset\\": \\"cvusa\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.82\\"}} ]"},{"Context":"SimCSE: Simple Contrastive Learning of Sentence Embeddings This paper presents SimCSE, a simple contrastive learning framework that greatly advances the state-of-the-art sentence embeddings. We first describe an unsupervised approach, which takes an input sentence and predicts itself in a contrastive objective, with only standard dropout used as noise. This simple method works surprisingly well, performing on par with previous supervised counterparts. We hypothesize that dropout acts as minimal data augmentation and removing it leads to a representation collapse. Then, we draw inspiration from the recent success of learning sentence embeddings from natural language inference (NLI) datasets and incorporate annotated pairs from NLI datasets into contrastive learning by using \\"entailment\\" pairs as positives and \\"contradiction\\" pairs as hard negatives. We evaluate SimCSE on standard semantic textual similarity (STS) tasks, and our unsupervised and supervised models using BERT base achieve an average of 74.5% and 81.6% Spearman\'s correlation respectively, a 7.9 and 4.6 points improvement compared to previous best results. We also show that contrastive learning theoretically regularizes pretrained embeddings\' anisotropic space to be more uniform, and it better aligns positive pairs when supervised signals are available. 1 1) with different datasets and compare the results in (for a fair comparison, we also run experiments with the same # of training pairs) We find that most of these models using supervised datasets outperform our unsupervised approach, showing a clear benefit from supervised signals Among all the options, using entailment pairs from the NLI (SNLI + MNLI) datasets perform the best We think this is reasonable, as the NLI datasets consist of high-quality and crowd-sourced pairs, and human annotators are expected to write the hypotheses manually based on the premises, and 3 Though our final model only takes entailment pairs as positives, here we also try neutral and contradiction pairs 4 https://www.quora.com/q/quoradata/ 5 ParaNMT is automatically constructed by machine translation systems and we should not call it a supervised dataset, although it even underperforms our unsupervised SimCSE Contradiction as hard negatives Finally, we further take the advantage of the NLI Table 2: Comparison of different data augmentations on STS-B development set (Spearman\'s correlation). Crop k%: randomly crop and keep a continuous span with 100-k% of the length; word deletion k%: ran- domly delete k% words; delete one word: randomly delete one word; MLM k%: use BERT base to replace k% of words. All of them include the standard 10% dropout (except \\"w/o dropout\\"). 10% 20% 30% Data augmentation STS - B Table 3: Comparison of different unsupervised ob- jectives. Results are Spearman\'s correlation on the STS-B development set using BERT base , trained on 1- million pairs from Wikipedia. The two columns denote whether we use one encoder f \u03b8 or two independent en- coders f \u03b81 and f \u03b82 (\\"dual-encoder\\"). Next 3 sentences: randomly sample one from the next 3 sentences. Delete one word: delete one word randomly (see 1 f \u03b8 Table 4: Effects of different dropout probabilities p","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Textual Similarity\\", \\"Dataset\\": \\"STS Benchmark\\", \\"Metric\\": \\"Spearman Correlation\\", \\"Score\\": \\"0.867\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Textual Similarity\\", \\"Dataset\\": \\"SICK\\", \\"Metric\\": \\"Spearman Correlation\\", \\"Score\\": \\"0.8195\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Textual Similarity\\", \\"Dataset\\": \\"STS12\\", \\"Metric\\": \\"Spearman Correlation\\", \\"Score\\": \\"0.7746\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Textual Similarity\\", \\"Dataset\\": \\"STS13\\", \\"Metric\\": \\"Spearman Correlation\\", \\"Score\\": \\"0.8727\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Textual Similarity\\", \\"Dataset\\": \\"STS14\\", \\"Metric\\": \\"Spearman Correlation\\", \\"Score\\": \\"0.8236\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Textual Similarity\\", \\"Dataset\\": \\"STS16\\", \\"Metric\\": \\"Spearman Correlation\\", \\"Score\\": \\"0.8393\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Textual Similarity\\", \\"Dataset\\": \\"STS15\\", \\"Metric\\": \\"Spearman Correlation\\", \\"Score\\": \\"0.8666\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Textual Similarity\\", \\"Dataset\\": \\"STS Benchmark\\", \\"Metric\\": \\"Spearman Correlation\\", \\"Score\\": \\"0.6921\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Textual Similarity\\", \\"Dataset\\": \\"SICK\\", \\"Metric\\": \\"Spearman Correlation\\", \\"Score\\": \\"0.6425\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Textual Similarity\\", \\"Dataset\\": \\"MRPC\\", \\"Metric\\": \\"Spearman Correlation\\", \\"Score\\": \\"0.5677\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Textual Similarity\\", \\"Dataset\\": \\"STS\\", \\"Metric\\": \\"Spearman Correlation\\", \\"Score\\": \\"0.4904\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Textual Similarity\\", \\"Dataset\\": \\"STS\\", \\"Metric\\": \\"Spearman Correlation\\", \\"Score\\": \\"0.6121\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Textual Similarity\\", \\"Dataset\\": \\"STS\\", \\"Metric\\": \\"Spearman Correlation\\", \\"Score\\": \\"0.7011\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Textual Similarity\\", \\"Dataset\\": \\"MR"},{"Context":"DDRprog: A CLEVR Differentiable Dynamic Reasoning Programmer We present a novel Dynamic Differentiable Reasoning (DDR) framework for jointly learning branching programs and the functions composing them; this resolves a significant nondifferentiability inhibiting recent dynamic architectures. We apply our framework to two settings in two highly compact and data efficient architectures: DDRprog for CLEVR Visual Question Answering and DDRstack for reverse Polish notation expression evaluation. DDRprog uses a recurrent controller to jointly predict and execute modular neural programs that directly correspond to the underlying question logic; it explicitly forks subprocesses to handle logical branching. By effectively leveraging additional structural supervision, we achieve a large improvement over previous approaches in subtask consistency and a small improvement in overall accuracy. We further demonstrate the benefits of structural supervision in the RPN setting: the inclusion of a stack assumption in DDRstack allows our approach to generalize to long expressions where an LSTM fails the task. Recall that the loss is evaluated on the predicted answers to all n subproblems corresponding to the outputs of each OP function Table 1. Accuracy on all CLEVR question types for baselines and competitive models. The Human baseline is from the original CLEVR work. * denotes additional program supervision. SA refers to stacked spatial attention (Yang et al., 2015) . Integer dropping the learning rate to 1e - 5 for the last few epochs to Discussion training and for model selection during validation , but not We train on a single GTX 1080 TI and Overall Exist Query Epochs Model Compare Count Table 5. ResNetFeaturizer Table 6 . CNN 3 \xd7 224 \xd7 224 Table 5 . ResNetFeaturizer Output Size Table 7. Hyperparameter details for DDRprog. Only the learning rate and model size were coarsely cross validated due to hardware limitations: hyperparameter are not optimal. 2 3 Architecture 64","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Question Answering\\", \\"Dataset\\": \\"CLEVR\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"98.3\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Question Answering\\", \\"Dataset\\": \\"CLEVR-Humans\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"67.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Question Answering\\", \\"Dataset\\": \\"CLEVR\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"99.7\\"}} ]"},{"Context":"MINA: Multilevel Knowledge-Guided Attention for Modeling Electrocardiography Signals Electrocardiography (ECG) signals are commonly used to diagnose various cardiac abnormalities. Recently, deep learning models showed initial success on modeling ECG data, however they are mostly black-box, thus lack interpretability needed for clinical usage. In this work, we propose MultIlevel kNowledge-guided Attention networks (MINA) that predict heart diseases from ECG signals with intuitive explanation aligned with medical knowledge. By extracting multilevel (beat-, rhythm-and frequency-level) domain knowledge features separately, MINA combines the medical knowledge and ECG data via a multilevel attention model, making the learned models highly interpretable. Our experiments showed MINA achieved PR-AUC 0.9436 (outperforming the best baseline by 5.51%) in real world ECG dataset. Finally, MINA also demonstrated robust performance and strong interpretability against signal distortion and noise contamination. In this section, we first describe the dataset used for the experiments, followed by the description of the baseline models Table 2: Data profile of PhysioNet Challenge 2017 dataset Mean StDev Min # of points Median # recording","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Atrial Fibrillation Detection\\", \\"Dataset\\": \\"PhysioNet Challenge 2017\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"0.8342\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Atrial Fibrillation Detection\\", \\"Dataset\\": \\"PhysioNet Challenge 2017\\", \\"Metric\\": \\"PR-AUC\\", \\"Score\\": \\"0.9436\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Atrial Fibrillation Detection\\", \\"Dataset\\": \\"PhysioNet Challenge 2017\\", \\"Metric\\": \\"ROC-AUC\\", \\"Score\\": \\"0.9488\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Medical Image Generation\\", \\"Dataset\\": \\"Automatic Cardiac Diagnosis Challenge (ACDC)\\", \\"Metric\\": \\"Dice\\", \\"Score\\": \\"0.9336\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Medical Image Generation\\", \\"Dataset\\": \\"Automatic Cardiac Diagnosis Challenge (ACDC)\\", \\"Metric\\": \\"Grad Det-Jac\\", \\"Score\\": \\"0.9336\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Medical Image Generation\\", \\"Dataset\\": \\"Automatic Cardiac Diagnosis Challenge (ACDC)\\", \\"Metric\\": \\"Hausdorff Distance (mm)\\", \\"Score\\": \\"2.77\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Medical Image Generation\\", \\"Dataset\\": \\"Automatic Cardiac Diagnosis Challenge (ACDC)\\", \\"Metric\\": \\"Hausdorff Distance (mm)\\", \\"Score\\": \\"60.94\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Medical Image Generation\\", \\"Dataset\\": \\"Automatic Cardiac Diagnosis Challenge (ACDC)\\", \\"Metric\\": \\"Hausdorff Distance (mm)\\", \\"Score\\": \\"89.71\\"}} ]"},{"Context":"From Random Graph to Small World by Wandering","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Free-Form Image Inpainting with Gated Convolution : Free-form image inpainting results by our system built on gated convolution. Each triad shows original image, free-form input and our result from left to right. The system supports free-form mask and guidance like user sketch. It helps user remove distracting objects, modify image layouts and edit faces in images.We present a generative image inpainting system to complete images with free-form mask and guidance. The system is based on gated convolutions learned from millions of images without additional labelling efforts. The proposed gated convolution solves the issue of vanilla convolution that treats all input pixels as valid ones, generalizes partial convolution by providing a learnable dynamic feature selection mechanism for each channel at each spatial location across all layers. Moreover, as free-form masks may appear anywhere in images with any shape, global and local GANs designed fora single rectangular mask are not applicable. Thus, we also present a patch-based GAN loss, named SN-PatchGAN, by applying spectral-normalized discriminator on dense image patches. SN-PatchGAN is simple in formulation, fast and stable in training. Results on automatic image inpainting and user-guided extension demonstrate that our system generates higher-quality and more flexible results than previous methods. Our system helps user quickly remove distracting objects, modify image layouts, clear watermarks and edit faces. Code, demo and models are available at: https://github.com/JiahuiYu/ generative_inpainting.  Table 2: Results of mean 1 error and mean 2 error on val- idation images of Places2 with both rectangle masks and free-form masks. Both PartialConv* and ours are trained on same random combination of rectangle and free-form masks. No edge guidance is utilized in training/inference to ensure fair comparison. * denotes our implementation within the same framework due to unavailability of official implementation and models. 2 err . rectangular mask 1 err . free - form mask","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Inpainting\\", \\"Dataset\\": \\"Places2 val\\", \\"Metric\\": \\"free-form mask l1 err\\", \\"Score\\": \\"9.1%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Inpainting\\", \\"Dataset\\": \\"Places2 val\\", \\"Metric\\": \\"free-form mask l2 err\\", \\"Score\\": \\"1.6%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Inpainting\\", \\"Dataset\\": \\"Places2 val\\", \\"Metric\\": \\"rect mask l1 error\\", \\"Score\\": \\"8.6%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Inpainting\\", \\"Dataset\\": \\"Places2 val\\", \\"Metric\\": \\"rect mask l2 err\\", \\"Score\\": \\"2.0%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Inpainting\\", \\"Dataset\\": \\"Paris StreetView\\", \\"Metric\\": \\"10-20% Mask PSNR\\", \\"Score\\": \\"28.73\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Inpainting\\", \\"Dataset\\": \\"Paris StreetView\\", \\"Metric\\": \\"20-30% Mask PSNR\\", \\"Score\\": \\"26.16\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Inpainting\\", \\"Dataset\\": \\"Paris StreetView\\", \\"Metric\\": \\"30-40% Mask PSNR\\", \\"Score\\": \\"24.26\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Inpainting\\", \\"Dataset\\": \\"Paris StreetView\\", \\"Metric\\": \\"40-50% Mask PSNR\\", \\"Score\\": \\"22.62\\"}} ]"},{"Context":"Building One-Shot Semi-supervised (BOSS) Learning up to Fully Supervised Performance Reaching the performance of fully supervised learning with unlabeled data and only labeling one sample per class might be ideal for deep learning applications. We demonstrate for the first time the potential for building one-shot semi-supervised (BOSS) learning on Cifar-10 and SVHN up to attain test accuracies that are comparable to fully supervised learning. Our method combines class prototype refining, class balancing, and self-training. A good prototype choice is essential and we propose a technique for obtaining iconic examples. In addition, we demonstrate that class balancing methods substantially improve accuracy results in semi-supervised learning to levels that allow self-training to reach the level of fully supervised learning performance. Rigorous empirical evaluations provide evidence that labeling large datasets is not necessary for training deep neural networks. We made our code available at https://github.com/lnsmith54/BOSS to facilitate replication and for use with future real-world applications.  Table 1. Class accuracies. One-shot semi-supervised average (of 2 runs) class accuracies for Cifar-10 test data with the FixMatch model, that was trained on sets of manually chosen prototypes for each class. Prototype set 6 was modified from set 2 and prototype set 7 was modified from set 4 (i.e., prototype refining). deer horse Mean auto frog airplane bird cat truck ship dog Table 2. Main results. BOSS methods are compared using five sets of class prototypes (i.e., 1 prototype per class) for Cifar-10, plus two sets from prototype refining. The FixMatch column shows test accuracies (average and standard deviation of 4 runs) for the original FixMatch code on the prototype sets. The next four columns gives the accuracy results for the class balance methods (see text for a description of class balance methods). Results for the PyTorch reimplementation of FixMatch and modified with the BOSS methods are shown in brackets","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"cifar-10, 10 Labels\\", \\"Metric\\": \\"Accuracy (Test)\\", \\"Score\\": \\"95.1\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"CIFAR-10, 4000 Labels\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.13\\"}} ]"},{"Context":"On the Self-stabilization of Mobile Robots in Graphs On the Self-stabilization of Mobile Robots in Graphs Sur l\'Auto-stabilisation de Robots Mobiles dans un Graphe Self-stabilization is a versatile technique to withstand any transient fault in a distributed system. Mobile robots (or agents) are one of the emerging trends in distributed computing as they mimic autonomous biologic entities. The contribution of this paper is threefold. First, we present anew model for studying mobile entities in networks subject to transient faults. Our model differs from the classical robot model because robots have constraints about the paths they are allowed to follow, and from the classical agent model because the number of agents remains fixed throughout the execution of the protocol. Second, in this model, we study the possibility of designing self-stabilizing algorithms when those algorithms are run by mobile robots (or agents) evolving on a graph. We concentrate on the core building blocks of robot and agents problems: naming and leader election. Not surprisingly, when no constraints are given on the network graph topology and local execution model, both problems are impossible to solve. Finally, using minimal hypothesis with respect to impossibility results, we provide deterministic and probabilistic solutions to both problems, and show equivalence of these problems by an algorithmic reduction mechanism.L\'auto-stabilisation est une technique g\xe9n\xe9rique pour tol\xe9rer toute d\xe9faillance transitoire dans un syst\xe8me distribu\xe9. Les robots (ou agents) mobiles constituent l\'un des mod\xe8les\xe9mergents de l\'informatique distribu\xe9e du fait de leur ressemblance avec les entit\xe9s biologiques autonomes. La contribution de cet article est triple. D\'abord, nous pr\xe9sentons un nouveau mod\xe8le pour l\'\xe9tude des entit\xe9s mobiles dans des r\xe9seaux sujets\xe0 des d\xe9faillances transitoires. Notre mod\xe8le diff\xe8re du mod\xe8le classique des robots car les robots ont des contraintes sur les chemins qu\'ils peuvent emprunter, et du mod\xe8le classique des agents mobiles car le nombre d\'agents reste fixe pendant toute la dur\xe9e de l\'ex\xe9cution du protocole. Ensuite, dans ce mod\xe8le, nous\xe9tudions la possibilit\xe9 de l\'existence d\'algorithmes auto-stabilisants quand ces algorithmes sont ex\xe9cut\xe9s par des robots mobiles\xe9voluant dans un graphe. Nous nous concentrons sur les briques de bases des syst\xe8mes\xe0 base d\'agents et de robots : le nomage et l\'\xe9lection d\'un chef. Conform\xe9ment\xe0 l\'intuition, quand aucune contrainte n\'est faite sur le r\xe9seau et les param\xe8tres de l\'ex\xe9cution, les deux probl\xe8mes sont impossibles\xe0 r\xe9soudre. Enfin, quand les hypoth\xe8ses minimales pour r\xe9soudre ces deux probl\xe8mes sont disponibles, nous proposons des solutions d\xe9terministes et probabilistes pour les deux probl\xe8mes, et montrons que ces deux probl\xe8mes sont\xe9quivalents au moyen d\'une r\xe9duction algorithmique.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"DCNAS: Densely Connected Neural Architecture Search for Semantic Image Segmentation Existing NAS methods for dense image prediction tasks usually compromise on restricted search space or search on proxy task to meet the achievable computational demands. To allow as wide as possible network architectures and avoid the gap between realistic and proxy setting, we propose a novel Densely Connected NAS (DCNAS) framework, which directly searches the optimal network structures for the multi-scale representations of visual information, over a large-scale target dataset without proxy. Specifically, by connecting cells with each other using learnable weights, we introduce a densely connected search space to cover an abundance of mainstream network designs. Moreover, by combining both path-level and channel-level sampling strategies, we design a fusion module and mixture layer to reduce the memory consumption of ample search space, hence favoring the proxyless searching. Compared with contemporary works, experiments reveal that the proxyless searching scheme is capable of bridging the gap between searching and training environments. Further, DC-NAS achieves new state-of-the-art performances on public semantic image segmentation benchmarks, including 84.3% on Cityscapes, and 86.9% on PASCAL VOC 2012. We also retain leading performances when evaluating the architecture on the more challenging ADE20K and PASCAL-Context dataset. To evaluate DCNAS comprehensively, we first verify the effect of the proxyless searching paradigm by measuring the correlation of the performance between the searching and training environments Secondly, we quantitatively demonstrate the superiority of DCNAS on several broadly used benchmarks according to corresponding evaluation metrics Table 1. Comparisons with state of the arts. The table presents the comparison results of mIoU ( % ) \u2191 FLOPs ( G ) \u03c4 \u2191 \u03c1 \u2191 GPU Days Table 2. Performance on Cityscapes. The table summarizes the performance on Cityscapes testing dataset. Validation: Models trained with both train-fine and val-fine parts. ImageNet: The backbones of model trained on ImageNet. Coarse: Models that exploit extra datas in Cityscapes with coarse annotation. \u2020 : Adopts the well labeled Mapillary Vistas [45] dataset. mIoU ( % ) Table 3. Performance on PASCAL VOC 2012. The table presents per-class semantic segmentation results on the PASCAL VOC 2012 test dataset. Our method advances the new state-of-the-art with mIoU 86.9%. - Methods mIoU Pascal Context ADE20K Pix - Acc mIoU 60 - cls mIoU 59 - cls - Table 2 presents the comparison results of our method and several state-of-the-art methods. Without - Methods mIoU","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K val\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"47.12\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"83.6%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL Context\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"55.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL VOC 2012 test\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"86.9%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"ADE20K val\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"86.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"85.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL Context\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"83.9\\"}} ]"},{"Context":"The Heap Lambda Machine This paper introduces anew machine architecture for evaluating lambda expressions using the normalorder reduction, which guarantees that every lambda expression will be evaluated if the expression has its normal form and the system has enough memory. The architecture considered here operates using heap memory only. Lambda expressions are represented as graphs, and all algorithms used in the processing unit of this machine are non-recursive.ZU064-05-FPR heap 9 September 2018 12:33 2 A. SalikhmetovThe memory manager in our machine consists of a single register and three commands only. Taking into account the similarity of our memory allocator and heap-based dynamic memory allocators, we have decided to refer this machine to as the Heap Lambda Machine. Worth mentioning here is also the fact that careful design of the processing unit algorithms allowed us to avoid using garbage collection.The purpose of this paper is to describe the architecture of our machine and to demonstrate all vital parts of the emulator. In order to evaluate lambda expression in the memory, the machine walks through the expression tree and looks for nodes that can be reduced","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Meta-Learned Confidence for Few-shot Learning Transductive inference is an effective means of tackling the data deficiency problem in few-shot learning settings. A popular transductive inference technique for few-shot metric-based approaches, is to update the prototype of each class with the mean of the most confident query examples, or confidence-weighted average of all the query samples. However, a caveat here is that the model confidence maybe unreliable, which may lead to incorrect predictions. To tackle this issue, we propose to meta-learn the confidence for each query sample, to assign optimal weights to unlabeled queries such that they improve the model\'s transductive inference performance on unseen tasks. We achieve this by meta-learning an input-adaptive distance metric over a task distribution under various model and data perturbations, which will enforce consistency on the model predictions under diverse uncertainties for unseen tasks. Moreover, we additionally suggest a regularization which explicitly enforces the consistency on the predictions across the different dimensions of a high-dimensional embedding vector. We validate our few-shot learning model with meta-learned confidence on four benchmark datasets, on which it largely outperforms strong recent baselines and obtains new state-of-the-art results. Further application on semi-supervised few-shot learning tasks also yields significant performance improvements over the baselines. The source code of our algorithm is available at https://github.com/seongmin-kye/MCT.Preprint. Under review. Dataset We validate our method on four popular benchmark datasets for few-shot classification Please seethe Section A.1 of the appendix regarding the detailed information for each of the datasets For our full models, we evaluate the expectation over task distribution p(\u03c4 ) via Monte-Carlo (MC) approximation with a single sample during training to obtain the learning objective, where we set \u03bb = 0.5 which we found with a validation set We validate our method on four benckmark datasets for few-shot classification This dataset consists of a subset of 100 classes sampled from the ImageNet dataset This dataset is another subset of ImageNet, that consists of 779, 165 images of 84 \xd7 84 pixels collected from 608 classes Table 1: Average classification performance over 1000 randomly generated episodes, with 95% confidence Inductive Backbone 58 . 56\xb10 . 39 63 . 85\xb10 . 48 75 . 53\xb10 . 80 64 . 49\xb10 . 64 78 . 63\xb10 . 46 76 . 65\xb10 . 38 79 . 44\xb10 . 34 82 . 15\xb10 . 45 61 . 20\xb11 . 80 59 . 63\xb10 . 52 79 . 01\xb10 . 13 76 . 36\xb10 . 10 62 . 64\xb10 . 61 65 . 34\xb10 . 63 5 - shot 76 . 34\xb10 . 48 61 . 26\xb10 . 20 69 . 86\xb10 . 65 81 . 63\xb10 . 44 61 . 65\xb10 . 15 miniImageNet 55 . 51\xb10 . 86 1 - shot Table 2: Average classification performance on CIFAR-FS and FC100. Table 4: Semi-supervised few-shot classification performance. We consider 5-way classification on miniIm- 5 - shot mini tiered w / D","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"Mini-ImageNet - 1-Shot Learning\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"78.55%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"Mini-Imagenet 5-way (1-shot)\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"78.55\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"OMNIGLOT - 5-Shot, 20-way\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"99.35%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"OMNIGLOT - 1-Shot, 20-way\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"99.65%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"OMNIGLOT - 1-Shot, 5-way\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"99.39%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"OMNIGLOT - 1-Shot, 5-way\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"98.20%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"OMNIGLOT - 1-Shot, 20-way\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"98.52%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"OMNIGLOT - 1-Shot, 20-way\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"98."},{"Context":"A computational method for bounding the probability of reconstruction on trees For a tree Markov random field non-reconstruction is said to hold if as the depth of the tree goes to infinity the information that atypical configuration at the leaves gives about the value at the root goes to zero. The distribution of the measure at the root conditioned on atypical boundary can be computed using a distributional recurrence. However the exact computation is not feasible because the support of the distribution grows exponentially with the depth.In this work, we introduce a notion of a survey of a distribution over probability vectors which is a succinct representation of the true distribution. We show that a survey of the distribution of the measure at the root can be constructed by an efficient recursive algorithm. The key properties of surveys are that the size does not grow with the depth, they can be constructed recursively, and they still provide a good bound for the distance between the true conditional distribution and the unconditional distribution at the root. This approach applies to a large class of Markov random field models including randomly generated ones. As an application we show bounds on the reconstruction threshold for the Potts model on small-degree trees.  Table 1: The Kesten-Stigum upper bound on the non-reconstruction threshold and the values of \u03bb up to which non-reconstruction has been shown in d Theorem 12","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Powers of layers for image-to-image translation We propose a simple architecture to address unpaired image-to-image translation tasks: style or class transfer, denoising, deblurring, deblocking, etc. We start from an image autoencoder architecture with fixed weights. For each task we learn a residual block operating in the latent space, which is iteratively called until the target domain is reached. A specific training schedule is required to alleviate the exponentiation effect of the iterations. At test time, it offers several advantages: the number of weight parameters is limited and the compositional design allows one to modulate the strength of the transformation with the number of iterations. This is useful, for instance, when the type or amount of noise to suppress is not known in advance. Experimentally, we provide proofs of concepts showing the interest of our method for many transformations. The performance of our model is comparable or better than CycleGAN with significantly fewer parameters.Generative adversarial networks (GANs) [13] is a framework where two networks, a generator and a discriminator, are learned together in a zero-sum game fashion. The generator learns to produce more and more realistic images wrt. the training dataset with real images. The discriminator learns to discriminate better and better between real data and generated images. GANs are used in many tasks such as domain adaptation, style transfer, inpainting and talking head generation [3,24,33,44]. We report results for 6 of the 8 unpaired image-to-image translation tasks introduced in the CycleGAN paper (the two remaining ones lead to the same conclusions) and we used the datasets from the website The FID measures the similarity between two datasets of images, we use it to compare the target dataset with the transformed dataset Table 2: PSNR on Urban-100. Comparison between our choice (PoL) and independent blocks. independent Gaussian noise ( std 30 ) POL Gaussian blur ( sigma 4 ) Table 3: Comparison between different maximum number of compositions. We report the most adapted metric on Urban-100: PSNR for the Gaussian noise and blur, NIQE for deblocking. NIQE ( lower=better ) JPEG ( quality=25 ) PSNR ( higher=better ) Gaussian noise ( std 30 ) Gaussian blur ( \u03c3=4 ) Table 4: PSNR on Urban-100 [17] -Gaussian noise (std=30). Comparison between augmentation steps during the warm-up phase. The augmentation step is to the number of epochs performed with the same number of compositions (1 epoch corresponds to 800 backward passes). 1 augmentation step 2 4 16 8 ntr Table 6: Comparison between our approach (PoL) and CycleGAN. We three tasks, all computed with the Urban-100 dataset: PSNR (higher is better) with different amount of","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"photo2vangogh\\", \\"Metric\\": \\"Frechet Inception Distance\\", \\"Score\\": \\"152.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"photo2vangogh\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"15.9M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"zebra2horse\\", \\"Metric\\": \\"Frechet Inception Distance\\", \\"Score\\": \\"112.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"zebra2horse\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"15.9M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"horse2zebra\\", \\"Metric\\": \\"Frechet Inception Distance\\", \\"Score\\": \\"53.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"horse2zebra\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"15.9M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"vangogh2photo\\", \\"Metric\\": \\"Frechet Inception Distance\\", \\"Score\\": \\"134.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"vangogh2photo\\", \\"Metric\\": \\"Number of Params\\", \\"Score\\": \\"15.9M\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Urban100\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"21.12\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Paris Street\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"23.25\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Paris Street\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.89\\"}} ]"},{"Context":"Oracle Based Active Set Algorithm for Scalable Elastic Net Subspace Clustering State-of-the-art subspace clustering methods are based on expressing each data point as a linear combination of other data points while regularizing the matrix of coefficients with \u2113 1 , \u2113 2 or nuclear norms. \u2113 1 regularization is guaranteed to give a subspace-preserving affinity (i.e., there are no connections between points from different subspaces) under broad theoretical conditions, but the clusters may not be connected. \u2113 2 and nuclear norm regularization often improve connectivity, but give a subspace-preserving affinity only for independent subspaces. Mixed \u2113 1 , \u2113 2 and nuclear norm regularizations offer a balance between the subspacepreserving and connectedness properties, but this comes at the cost of increased computational complexity. This paper studies the geometry of the elastic net regularizer (a mixture of the \u2113 1 and \u2113 2 norms) and uses it to derive a provably correct and scalable active set method for finding the optimal coefficients. Our geometric analysis also provides a theoretical justification and a geometric interpretation for the balance between the connectedness (due to \u2113 2 regularization) and subspace-preserving (due to \u2113 1 regularization) properties for elastic net subspace clustering. Our experiments show that the proposed active set method not only achieves state-of-the-art clustering performance, but also efficiently handles large-scale datasets. We test our method on the four datasets presented in The Coil-100 dataset contains 7,200 grayscale images of 100 different objects The PIE dataset contains images of the faces of 68 people taken under 13 different poses, 43 different illuminations, and 4 different expressions The MNIST dataset contains 70,000 images of handwritten digits 0-9 Table 1. Dataset information. ORGEN ( w . SPAMS ) 100 1 ] ; and ( b , c ) N = 100 , 000 and \u03bb \u2208 [ 0 . 05 , 0 . 999 ] . 700 \u2212 2 \u2212 1 n ( #groups ) GPSR ( a ) Running time versus N N 0 1 100 RFSS 2 entries #Nonzero 200 3 ORGEN ( w . RFSS ) 300 400 1024 600 ( b ) Running time versus \u03bb Running ( sec ) \u03bb D ( ambient dim . ) Table 2. Performance of different clustering algorithms. The running time includes the time for computing the affinity matrix and for performing spectral clustering. The sparsity is the number of nonzero coefficients in each representation cj averaged over j = 1, \xb7 \xb7 \xb7 , N . The value \\"M\\" means that the memory limit of 16GB was exceeded,","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"MNIST-full\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.976\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"MNIST-full\\", \\"Metric\\": \\"NMI\\", \\"Score\\": \\"0.937\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"coil-100\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.6924\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Clustering\\", \\"Dataset\\": \\"Extended Yale-BNIST\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.706\\"}} ]"},{"Context":"CurveLane-NAS: Unifying Lane-Sensitive Architecture Search and Adaptive Point Blending We address the curve lane detection problem which poses more realistic challenges than conventional lane detection for better facilitating modern assisted/autonomous driving systems. Current handdesigned lane detection methods are not robust enough to capture the curve lanes especially the remote parts due to the lack of modeling both long-range contextual information and detailed curve trajectory. In this paper, we propose a novel lane-sensitive architecture search framework named CurveLane-NAS to automatically capture both long-ranged coherent and accurate short-range curve information. It consists of three search modules: a) a feature fusion search module to find a better fusion of the local and global context for multi-level hierarchy features; b) an elastic backbone search module to explore an efficient feature extractor with good semantics and latency; c) an adaptive point blending module to search a multi-level post-processing refinement strategy to combine multi-scale head prediction. Furthermore, we also steer forward to release a more challenging benchmark named CurveLanes for addressing the most difficult curve lanes. It consists of 150K images with 680K labels. 3 Experiments on the new CurveLanes show that the SOTA lane detection methods suffer substantial performance drop while our model can still reach an 80+% F1-score. Extensive experiments on traditional lane benchmarks such as CULane also demonstrate the superiority of our CurveLane-NAS, e.g. achieving anew SOTA 74.8% F1-score on CULane. We conduct neural architecture search on two large lane detection datasets: the CULane, and the new CurveLanes dataset Evaluation metrics Evaluation metrics is important since it is also the target of our architecture search We follow the literature and use the corresponding evaluation metrics for each particular dataset Following the official implementation of the evaluation, we compute the intersection-over-union (IoU) between GT labels and predictions, where each lane has 30 pixel width The F1 measure is used as the evaluation metric: F 1 = 2\xd7P recision\xd7Recall P recision+Recall , where P recision = T PT P +F P and Recall = T PT P +F N We also use the official metric as the evaluation metrics: Accuracy = N pred N GT , where where N pred is the number of correctly predicted lane points and N GT is the number of ground-truth lane points We found that fora large dataset Table 2. Comparison of F1-measure of the state-of-the-art models on CULane test set. CurveLane-S, CurveLane-M, and CurveLane-L are the searched architectures of our method. Our method outperforms the SOTA models by a large margin with a small computational overhead. 1998 2359 Searched SCNN R101 1640 ENet 1990 SCNN [ 20 ] SAD [ 11 ] SAD PointLane [ 6 ] CurveLane - S CurveLane - M CurveLane - L 2817 2052 1746 Table 3. Comparison of different algorithms on the new dataset CurveLanes. CurveLane-S, CurveLane-M, and CurveLane-L are the searched architectures of our method. The SOTA methods such as SCNN and SAD suffer substantial performance drop (20%\u02dc30% F1 score). FLOPS ( G ) Precision Recall F1 Table 4. Ablative study with the F1-measure on the CULane dataset. CurveLane S to L denote our searched backbone architectures. The performance of models combined with all the modules are listed in the final column.","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Lane Detection\\", \\"Dataset\\": \\"CULane\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"74.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Lane Detection\\", \\"Dataset\\": \\"CULane\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"73.5\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Lane Detection\\", \\"Dataset\\": \\"CULane\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"74.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Lane Detection\\", \\"Dataset\\": \\"CULane\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"84.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Lane Detection\\", \\"Dataset\\": \\"CULane\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"95.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Lane Detection\\", \\"Dataset\\": \\"CULane\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"94.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Lane Detection\\", \\"Dataset\\": \\"CULane\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"90.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Lane Detection\\", \\"Dataset\\": \\"CULane\\", \\"Metric\\": \\"F1 score\\", \\"Score\\": \\"96.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Lane Detection\\", \\"Dataset\\": \\"CULane\\", \\"Metric\\": \\"F1 score"},{"Context":"Graph-based Reduction of Program Verification Conditions Increasing the automaticity of proofs in deductive verification of C programs is a challenging task. When applied to industrial C programs known heuristics to generate simpler verification conditions are not efficient enough. This is mainly due to their size and a high number of irrelevant hypotheses.This work presents a strategy to reduce program verification conditions by selecting their relevant hypotheses. The relevance of a hypothesis is determined by the combination of a syntactic analysis and two graph traversals. The first graph is labeled by constants and the second one by the predicates in the axioms. The approach is applied on a benchmark arising in industrial program verification.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Learning to Reconstruct 3D Human Pose and Shape via Model-fitting in the Loop Model-based human pose estimation is currently approached through two different paradigms. Optimizationbased methods fit a parametric body model to 2D observations in an iterative manner, leading to accurate imagemodel alignments, but are often slow and sensitive to the initialization. In contrast, regression-based methods, that use a deep network to directly estimate the model parameters from pixels, tend to provide reasonable, but not pixel accurate, results while requiring huge amounts of supervision. In this work, instead of investigating which approach is better, our key insight is that the two paradigms can form a strong collaboration. A reasonable, directly regressed estimate from the network can initialize the iterative optimization making the fitting faster and more accurate. Similarly, a pixel accurate fit from iterative optimization can act as strong supervision for the network. This is the core of our proposed approach SPIN (SMPL oPtimization IN the loop). The deep network initializes an iterative optimization routine that fits the body model to 2D joints within the training loop, and the fitted estimate is subsequently used to supervise the network. Our approach is self-improving by nature, since better network estimates can lead the optimization to better solutions, while more accurate optimization fits provide better supervision for the network. We demonstrate the effectiveness of our approach in different settings, where 3D ground truth is scarce, or not available, and we consistently outperform the state-of-the-art model-based pose estimation approaches by significant margins. The project website with videos, results, and code can be found at https://seas.upenn.edu/\u02dcnkolot/projects/spin. Here we give a quick description of the datasets we use for training and evaluation We train using the first three datasets (no training data from 3DPW), while similarly to, we also incorporate training data with 2D annotations from other datasets, i.e., LSP-Extended, MPII, and COCO For the different settings we investigate, e.g., training with/without in the loop update, or training with/without 3D ground truth), we train a single model per setting and we use it to report results on all datasets, without fine-tuning on each particular dataset Moreover, we clarify, that we always evaluate the network\\"s output Also, since different datasets often use different error metrics to report results, we use the metrics that are more often met in the literature for each dataset tocols, e.g.,, we use subjects S1, S5, S6, S7, S8 for training and we evaluate on subjects S9 and S11 MPI-INF-3DHP: It is a dataset captured Table 1: Evaluation on the 3DPW dataset. The numbers are mean reconstruction errors in mm. The model-based supervision alone (Ours -static fits) outperforms similar architectures trained on the same ([15, 17]) or more data ([3, 16]). Incorporating the fitting in the loop (Ours -in the loop) further improves performance. Rec . Error Table 2: Evaluation on foreground-background and six-part seg- mentation on the LSP test set. The numbers are accuracies and f1 Part Seg . FB Seg . acc . f1 Table 4: Evaluation on the MPI-INF-3DHP dataset. The compar- ison is under different metrics before (left) and after (right) rigid alignment. Our approach outperforms the previous baselines. (For PCK and AUC, higher is better, while for MPJPE, lower is better). PCK AUC MPJPE PCK AUC MPJPE Rigid Alignment Absolute -","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"MPI-INF-3DHP\\", \\"Metric\\": \\"3DPCK\\", \\"Score\\": \\"92.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"MPI-INF-3DHP\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"55.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"MPI-INF-3DHP\\", \\"Metric\\": \\"MJPE\\", \\"Score\\": \\"67.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3D Poses in the Wild Challenge\\", \\"Metric\\": \\"MPJAE\\", \\"Score\\": \\"25.42\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3D Poses in the Wild Challenge\\", \\"Metric\\": \\"MPJPE\\", \\"Score\\": \\"102.56\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3DPW\\", \\"Metric\\": \\"MPJPE\\", \\"Score\\": \\"96.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3DPW\\", \\"Metric\\": \\"MPVPE\\", \\"Score\\": \\"116.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3DPW\\", \\"Metric\\": \\"PA-MPJPE\\", \\"Score\\": \\"59.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3DPW\\", \\"Metric\\": \\"acceleration error\\", \\"Score\\": \\"29.8\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3D Poses in the Wild Challenge\\", \\"Metric\\": \\"MPJAE\\", \\"Score\\": \\"19.69\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3D Poses in the Wild Challenge\\", \\"Metric\\": \\"MPJPE\\", \\"Score\\": \\"83.15\\"}} ]"},{"Context":"TRANSFORMER-BASED ACOUSTIC MODELING FOR HYBRID SPEECH RECOGNITION We propose and evaluate transformer-based acoustic models (AMs) for hybrid speech recognition. Several modeling choices are discussed in this work, including various positional embedding methods and an iterated loss to enable training deep transformers. We also present a preliminary study of using limited right context in transformer models, which makes it possible for streaming applications. We demonstrate that on the widely used Librispeech benchmark, our transformer-based AM outperforms the best published hybrid result by 19% to 26% relative when the standard n-gram language model (LM) is used. Combined with neural network LM for rescoring, our proposed approach achieves state-of-the-art results on Librispeech. Our findings are also confirmed on a much larger internal dataset. To evaluate the effectiveness of the proposed transformer-based acoustic model, we first perform experiments on the Librispeech corpus This corpus contains about 960 hours of read speech data for training, and 4 development and test sets ({dev, test} -{clean,other}), where other sets are more acoustic challenging ing, the best checkpoints for test-clean and test-other are selected separately on the corresponding development sets 4 Finally, we perform a large scale experiment on one of our internal tasks, English video ASR 3 test sets are used for evaluation purpose: an 8.5-hour curated set of carefully select very clean videos, an 19-hour clean set and a 18.6-hour noisy set For our initial evaluation purpose, both training and test sets are segmented into maximum 10 second segments Table 1: Effect of Positional Embeddings (PE) for Transformer. PE test-clean test-other None 3.11 6.94 Sinusoid 3.13 6.67 Frame Stacking 3.04 6.64 Convolution 2.87 6.46 test - clean test - other Table 1 : Effect of Positional Embeddings ( PE ) for Transformer . Table 2: Architecture comparison on the Librispeech benchmark Model Arch #Params (M) test-clean test-other BLSTM (800,5) 79 3.11 7.44 Trf-FS (768,12) 91 3.04 6.64 vggBLSTM (800,5) 95 2.99 6.95 vggTrf. (768,12) 93 2.87 6.46 vggBLSTM (1000,6) 163 2.86 6.63 vggTrf. (768, 20) 149 2.77 6.10 CE losses are calculated separately . These additional CE losses are test - clean test - other Table 2 : Architecture comparison on the Librispeech benchmark Table 3: Using iterated loss to train deep transformer models. Model Arch Iter Loss test-clean test-other vggTrf. (768, 12) N 2.87 6.46 (Params: 93M) Y 2.77 6.10 vggTrf. (512, 24) N not converged (Params: 81M) Y","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"LibriSpeech test-clean\\", \\"Metric\\": \\"Word Error Rate (WER)\\", \\"Score\\": \\"2.26\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"LibriSpeech test-other\\", \\"Metric\\": \\"Word Error Rate (WER)\\", \\"Score\\": \\"4.85\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"LibriSpeech test-clean\\", \\"Metric\\": \\"Word Error Rate (WER)\\", \\"Score\\": \\"1.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Speech Recognition\\", \\"Dataset\\": \\"LibriSpeech test-other\\", \\"Metric\\": \\"Word Error Rate (WER)\\", \\"Score\\": \\"16.5\\"}} ]"},{"Context":"EVOLVING MULTIALGEBRAS UNIFY ALL USUAL SEQUENTIAL COMPUTATION MODELS It is well-known that Abstract State Machines (ASMs) can simulate \\"stepby-step\\" any type of machines (Turing machines, RAMs, etc.). We aim to overcome two facts: 1) simulation is not identification, 2) the ASMs simulating machines of some type do not constitute a natural class among all ASMs. We modify Gurevich\'s notion of ASM to that of EMA (\\"Evolving MultiAlgebra\\") by replacing the program (which is a syntactic object) by a semantic object: a functional which has to be very simply definable over the static part of the ASM. We prove that very natural classes of EMAs correspond via \\"literal identifications\\" to slight extensions of the usual machine models and also to grammar models. Though we modify these models, we keep their computation approach: only some contingencies are modified. Thus, EMAs appear as the mathematical model unifying all kinds of sequential computation paradigms.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"DEEP GRAPH LIBRARY: A GRAPH-CENTRIC, HIGHLY- PERFORMANT PACKAGE FOR GRAPH NEURAL NET- WORKS Advancing research in the emerging field of deep graph learning requires new tools to support tensor computation over graphs. In this paper, we present the design principles and implementation of Deep Graph Library (DGL) 1 . DGL distills the computational patterns of GNNs into a few generalized sparse tensor operations suitable for extensive parallelization. By advocating graph as the central programming abstraction, DGL can perform optimizations transparently. By cautiously adopting a framework-neutral design, DGL allows users to easily port and leverage the existing components across multiple deep learning frameworks. Our evaluation shows that DGL significantly outperforms other popular GNN-oriented frameworks in both speed and memory consumption over a variety of benchmarks and has little overhead for small scale workloads.  Table 2: The categorized number of lines of codes (LoC) need to change when porting a GNN layer in DGL from PyTorch to TensorFlow. Code comments are excluded. Total II Change / Total III Change Type Table 3: Epoch running time in seconds (full graph training). OOM means out-of-memory. Link Prediction Node Classification 4 OOM PyG over DGL - PT Model DGL GraphNets over DGL - TF 8 CPU GPU PyG Table 4: Epoch running time in seconds for mini- batch training using neighbor sampling (NS) and cluster sampling (CS). Link Prediction Node Classification PyG over DGL - PT GraphNets over DGL - TF DGL Model PyG","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Cora\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"83.98%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Drug-targeting\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"71.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Drug- Moderate val\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"80.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Coauthor CS\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"94.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Coauthor Physics\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"94.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Cora\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"84.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Cora\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"80.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"CiteSeer with Public Split: fixed 20 nodes per class\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"73.3\\"}}, { "},{"Context":"Improving Performance of Cluster Based Routing Protocol using Cross-Layer Design The main goal of routing protocol is to efficiency delivers data from source to destination. All routing protocols are the same in this goal, but the way they adopt to achieve it is different, so routing strategy has an egregious role on the performance of an ad hoc network. Most of routing protocols proposed for ad hoc networks have a flat structure. These protocols expand the control overhead packets to discover or maintain a route. On the other hand a number of hierarchical-based routing protocols have been developed, mostly are based on layered design. These protocols improve network performances especially when the network size grows up since details about remote portion of network can be handled in an aggregate manner. Although, there is another approach to design a protocol called cross-layer design. Using this approach information can exchange between different layer of protocol stack, result in optimizing network performances.In this paper, we intend to exert cross-layer design to optimize Cluster Based Routing Protocol (Cross-CBRP). Using NS-2 network simulator we evaluate rate of cluster head changes, throughput and packet delivery ratio. Comparisons denote that Cross-CBRP has better performances with respect to the original CBRP.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Detail-revealing Deep Video Super-resolution Previous CNN-based video super-resolution approaches need to align multiple frames to the reference. In this paper, we show that proper frame alignment and motion compensation is crucial for achieving high quality results. We accordingly propose a \\"sub-pixel motion compensation\\" (SPMC) layer in a CNN framework. Analysis and experiments show the suitability of this layer in video SR. The final end-to-end, scalable CNN framework effectively incorporates the SPMC layer and fuses multiple frames to reveal image details. Our implementation can generate visually and quantitatively high-quality results, superior to current state-of-the-arts, without the need of parameter tuning. To our knowledge, there is no such publicly available video dataset that is large enough to train our deep networks Table 1. Performance of baseline models DF - 0up Ours DF - Bic Table 1 . Performance of baseline models BW Table 2. Comparison with video SR methods (PSNR/SSIM) VSRNet Table 2 . Comparison with video SR methods ( PSNR / SSIM ) VSRnet Bicubic VESPCN Ours ( F3 ) Ours ( F5 ) BayesSR DESR Table 3. Comparison with image SR methods (PSNR/SSIM) - SRCNN Ours ( F1 ) FSRCNN VDSR Ours ( F3 ) Table 3 . Comparison with image SR methods ( PSNR / SSIM )","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Set5 - 4x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"30.96\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Set5 - 4x upscaling\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.87\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Set14 - 4x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"27.57\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Super-Resolution\\", \\"Dataset\\": \\"Set14 - 4x upscaling\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.76\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\"Vid4 - 4x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"25.88\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\"Vid4 - 4x upscaling\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.774\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\"Vid4 - 4x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"27.16\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\"Vid4 - 4x upscaling\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.75\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\"Vid4 - 2x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"31.10\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\"Vid4 - 2x upscaling\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.88\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\"Set5 - 2x upscaling\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"37.94\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\"Set5 - 2x upscaling\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.96\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Super-Resolution\\", \\"Dataset\\": \\""},{"Context":"Enhancing VAEs for Collaborative Filtering: Flexible Priors & Gating Mechanisms Neural network based models for collaborative filtering have started to gain attention recently. One branch of research is based on using deep generative models to model user preferences where variational autoencoders were shown to produce state-of-the-art results. However, there are some potentially problematic characteristics of the current variational autoencoder for CF. The first is the too simplistic prior that VAEs incorporate for learning the latent representations of user preference. The other is the model\\"s inability to learn deeper representations with more than one hidden layer for each network. Our goal is to incorporate appropriate techniques to mitigate the aforementioned problems of variational autoencoder CF and further improve the recommendation performance. Our work is the first to apply flexible priors to collaborative filtering and show that simple priors (in original VAEs) maybe too restrictive to fully model user preferences and setting a more flexible prior gives significant gains. We experiment with the VampPrior, originally proposed for image generation, to examine the effect of flexible priors in CF. We also show that VampPriors coupled with gating mechanisms outperform SOTA results including the Variational Autoencoder for Collaborative Filtering by meaningful margins on 2 popular benchmark datasets (MovieLens & Netflix). Experiments were conducted to evaluate the effect of flexible priors, hierarchical stochastic units and gating mechanisms in the context of collaborative filtering Table 1: Results for MovieLens 20M and Netflix dataset. Standard errors are around 0.002 for ML-20M and 0.001 for Netflix. NDCG@100 Recall@20 Recall@50 Table 2: Comparison of performance between Gated and Un- Gated for models of different depth 3 . The model with better performance (1 Layer vs 2 Layers) is marked in bold. No - Gate Gated","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Recommendation Systems\\", \\"Dataset\\": \\"MovieLens 20M\\", \\"Metric\\": \\"Recall@20\\", \\"Score\\": \\"0.41308\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Recommendation Systems\\", \\"Dataset\\": \\"MovieLens 20M\\", \\"Metric\\": \\"Recall@50\\", \\"Score\\": \\"0.55109\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Recommendation Systems\\", \\"Dataset\\": \\"MovieLens 20M\\", \\"Metric\\": \\"nDCG@100\\", \\"Score\\": \\"0.44522\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Recommendation Systems\\", \\"Dataset\\": \\"Netflix\\", \\"Metric\\": \\"Recall@20\\", \\"Score\\": \\"0.37678\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Recommendation Systems\\", \\"Dataset\\": \\"Netflix\\", \\"Metric\\": \\"Recall@50\\", \\"Score\\": \\"0.46252\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Recommendation Systems\\", \\"Dataset\\": \\"Netflix\\", \\"Metric\\": \\"nDCG@100\\", \\"Score\\": \\"0.40861\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Recommendation Systems\\", \\"Dataset\\": \\"MovieLens 20M\\", \\"Metric\\": \\"Recall@20\\", \\"Score\\": \\"0.4325\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Recommendation Systems\\", \\"Dataset\\": \\"MovieLens 20M\\", \\"Metric\\": \\"Recall@20\\", \\"Score\\": \\"0.42\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Recommendation Systems\\", \\"Dataset\\": \\"MovieLens 20M\\", \\"Metric\\": \\"nDCG@20\\", \\"Score\\": \\"0.43\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Recommendation Systems\\", \\"Dataset\\": \\"MovieLens 20M\\", \\"Metric\\": \\"Recall@20\\", \\"Score\\": \\"0.42\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Recommendation Systems\\", \\"Dataset\\": \\"MovieLens 20M\\", \\"Metric\\": \\"Recall@20\\", \\"Score\\": \\"0.56\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Recommendation Systems\\", \\"Dataset\\": \\"MovieLens 20M\\", \\"Metric\\": \\"nDCG@20\\", \\"Score\\": \\"0.434\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Recommendation Systems\\", \\"Dataset\\": \\"Net"},{"Context":"Back-tracing Representative Points for Voting-based 3D Object Detection in Point Clouds 3D object detection in point clouds is a challenging vision task that benefits various applications for understanding the 3D visual world. Lots of recent research focuses on how to exploit end-to-end trainable Hough voting for generating object proposals. However, the current voting strategy can only receive partial votes from the surfaces of potential objects together with severe outlier votes from the cluttered backgrounds, which hampers full utilization of the information from the input point clouds. Inspired by the back-tracing strategy in the conventional Hough voting methods, in this work, we introduce anew 3D object detection method, named as Back-tracing Representative Points Network (BRNet), which generatively back-traces the representative points from the vote centers and also revisits complementary seed points around these generated points, so as to better capture the fine local structural features surrounding the potential objects from the raw point clouds. Therefore, this bottom-up and then top-down strategy in our BR-Net enforces mutual consistency between the predicted vote centers and the raw surface points and thus achieves more reliable and flexible object localization and class prediction results. Our BRNet is simple but effective, which significantly outperforms the state-of-the-art methods on two large-scale point cloud datasets, ScanNet V2 (+7.5% in terms of mAP@0.50) and SUN RGB-D (+4.7% in terms of mAP@0.50), while it is still lightweight and efficient. Code will be available at https  Table 1. 3D object detection results on the ScanNet V2 validation set(left) and the SUN RGB-D V1 validation set(right). Evaluation metric is average precision with 3D IOU thresholds as 0.25 and 0.50. *Note for fair comparison, we report the results of H3DNet on the ScanNet V2 dataset under both 1 and 4 PointNet++ backbones (BB) settings. While we only report the result of H3DNet with 4 PointNet++ backbones (BB) on the SUN RGB-D dataset, as the work [41] only reports the result under this setting. - mAP@0 . 50 Input H3DNet ( 1BB ) * [ 41 ] 3D object detection results on the ScanNet V2 validation set . mAP@0 . 25 - Table 2. 3D object detection results on the ScanNet V2 validation set. The evaluation metric is the average precision with 3D IOU threshold as 0.50. *Note that for H3DNet only the per-category results with 4 PointNet++ backbones are","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"ScanNetV2\\", \\"Metric\\": \\"mAP@0.25\\", \\"Score\\": \\"66.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"ScanNetV2\\", \\"Metric\\": \\"mAP@0.5\\", \\"Score\\": \\"50.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"SUN-RGBD val\\", \\"Metric\\": \\"mAP@0.25\\", \\"Score\\": \\"61.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"SUN-RGBD val\\", \\"Metric\\": \\"mAP@0.5\\", \\"Score\\": \\"43.7\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"S3DIS\\", \\"Metric\\":\\"mAP@0.25\\", \\"Score\\": \\"67.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"S3DIS\\", \\"Metric\\":\\"mAP@0.5\\", \\"Score\\": \\"48.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"SUN-RGBD val\\", \\"Metric\\":\\"mAP@0.25\\", \\"Score\\": \\"60.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Object Detection\\", \\"Dataset\\": \\"SUN-RGBD val\\", \\"Metric\\":\\"mAP@0.5\\", \\"Score\\": \\"39.0\\"}} ]"},{"Context":"A Multiprocessor Communication Architecture For High Speed Networks Over the years, communication speed of networks has increased from a few Kbps to several Mbps, as also the bandwidth demand, Communication Protocols, however have not improved to that extent. With the advent of Wavelength Division Multiplexing (WDM), it is now possible to \\"tune\\" protocols to current and future demands. The purpose of this paper is to evolve a High Speed Network architecture, which will cater to the needs of bandwidth-consuming applications, such as voice, video and high definition image transmission.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Semi-Supervised Semantic Segmentation with Pixel-Level Contrastive Learning from a Class-wise Memory Bank This work presents a novel approach for semi-supervised semantic segmentation, i.e., per-pixel classification problem assuming that only a small set of the available data is labeled. We propose a novel representation learning module based on contrastive learning. This module enforces the segmentation network to yield similar pixel-level feature representations for same-class samples across the whole dataset. To achieve this, we maintain a memory bank continuously updated with feature vectors from labeled data. These features are selected based on their quality and relevance for the contrastive learning. In an end-to-end training, the features from both labeled and unlabeled data are optimized to be similar to same-class samples from the memory bank. Our approach outperforms the current stateof-the-art for semi-supervised semantic segmentation and semi-supervised domain adaptation on well-known public benchmarks, with larger improvements on the most challenging scenarios, i.e., less available labeled data. This section describes the datasets and implementation details used in the evaluation of the presented work It is areal urban scene dataset composed of 2975 training and 500 validation samples, with 19 semantic classes It is a natural scenes dataset with 21 semantic classes The dataset has 10582 and 1449 images for training and validation respectively It is a synthetic dataset captured from a video game with realistic urban-like scenarios with 24966 images in total The original dataset provides 33 different categories but, following, we only use the 19 classes that are shared with Cityscapes The evaluation is done on the Cityscapes data, since it provides more complex scenes compared to Pascal VOC Table 1. Strong and weak data augmentation set-ups Architecture : Deeplabv3+ with ResNet - 50 backbone Architecture : Deeplabv2 with ResNet - 101 backbone Weak 1 / 4 Parameter 1 / 8 Table 1 . Strong and weak data augmentation set - ups 1 / 30 Strong FS Table 3. Performance (Mean IoU) for the Pascal VOC val set for different labeled-unlabeled ratios and, in parentheses, the differ- ence w.r.t. the corresponding fully supervised (FS) result. Architecture : Deeplabv3+ with ResNet - 50 backbone Architecture : Deeplabv2 with ResNet - 101 backbone 1 / 4 1 / 20 1 / 8 1 / 30 FS 1 / 50 Table 4. Mean IoU in Cityscapes val set. Central columns evaluate the semi-supervised domain adaptation task (GTA5 \u2192 Cityscapes). The last column evaluates a semi-supervised setting in Cityscapes (no adaptation). Different labeled-unlabeled ratios for Cityscapes are compared. All methods use ImageNet pre- trained","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes 100 samples labeled\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"64.9%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes 100 samples labeled\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"59.4%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes 25% labeled\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"71.6%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes 25% labeled\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"65.9%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Semantic Segmentation\\", \\"Dataset\\": \\"Pascal VOC 2012 5% labeled\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"70.0%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Semantic Segmentation\\", \\"Dataset\\": \\"Pascal VOC 2012 12.5% labeled\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"71.6%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes 12.5% labeled\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"70.0%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes 12.5% labeled\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"64.4%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Semantic Segmentation\\", \\"Dataset\\": \\"Pascal VOC 2012 2% labeled\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"67.9%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Semantic Segmentation\\", \\"Dataset\\": \\"Pascal VOC 2012 1% labeled\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"59.52%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes 100 samples labeled\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"51.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes 50% labeled\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"51.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes 25% labeled\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"63.87%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes 25% labeled\\", \\"Metric\\": \\"Validation mIoU\\", \\"Score\\": \\"69.57%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Semantic Segmentation\\", \'Data"},{"Context":"Compact Trilinear Interaction for Visual Question Answering In Visual Question Answering (VQA), answers have a great correlation with question meaning and visual contents. Thus, to selectively utilize image, question and answer information, we propose a novel trilinear interaction model which simultaneously learns high level associations between these three inputs. In addition, to overcome the interaction complexity, we introduce a multimodal tensor-based PARALIND decomposition which efficiently parameterizes trilinear interaction between the three inputs. Moreover, knowledge distillation is first time applied in Free-form Opened-ended VQA. It is not only for reducing the computational cost and required memory but also for transferring knowledge from trilinear interaction model to bilinear interaction model. The extensive experiments on benchmarking datasets TDIUC, VQA-2.0, and Visual7W show that the proposed compact trilinear interaction model achieves state-of-the-art results when using a single model on all three datasets. The source code is available at https://github.com/aioz-ai/ICCV19_ Dataset We conduct the experiments on three benchmarking VQA datasets that are Visual7W for the MC VQA, VQA-2.0 and TDIUC for the FFOE VQA We use training set to train and validation set to evaluate in all mentioned datasets when conducting ablation study In all experiments, the learning rate is set to 10 Evaluation Metrics We follow the literature in which the evaluation metrics for each VQA task are different For FFOE VQA, the single accuracy, which is a standard VQA accuracy (Acc), is applied for both TDIUC and VQA-2.0 datasets In addition, due to the imbalance in the question types of TDIUC dataset, follow, we also report four other metrics that compensate for the skewed question-type distribution For MC VQA, we follow the evaluation metric (Acc-MC) proposed by in which the performance is measured by the portion of correct answers selected by the VQA model from the candidate answer set Table 1. Overall performance of the proposal and the baselines BAN2, SAN in different evaluation metrics on TDIUC validation set. The performance is shown with and without considering Ab- surd question category. BAN2-CTI and SAN-CTI are student models trained under our proposed CTI teacher model. Acc Ari - N Har Har - N Ari Models Evaluation metrics Table 2. Performance (Acc) of the proposal and the baselines BAN2, SAN for each question-type on TDIUC validation set. BAN2-CTI and SAN-CTI are student models trained under our compact trilinear interaction teacher model. SAN SAN - CTI [ 43 ] [ 18 ] BAN2 BAN2 - CTI Table 3. Performance of the proposal and baselines BAN2, SAN in VQA-2.0 validation set and test-dev set. BAN2-CTI and SAN- CTI are student models trained under proposed teacher model. Validation Accuracy Test - dev Table 4. The performance (Acc-MC) and the number of parameters of the proposed","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Question Answering\\", \\"Dataset\\": \\"VQA v2 test-dev\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"67.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Question Answering\\", \\"Dataset\\": \\"TDIUC\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"87\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Question Answering\\", \\"Dataset\\": \\"Visual7W\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"72.3\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Question Answering\\", \\"Dataset\\": \\"VQA v2 test-dev\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"68.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Question Answering\\", \\"Dataset\\": \\"VQA v2 test-std\\", \\"Metric\\": \\"overall\\", \\"Score\\": \\"70.3\\"}} ]"},{"Context":"Semantic Segmentation for Real Point Cloud Scenes via Bilateral Augmentation and Adaptive Fusion Given the prominence of current 3D sensors, a finegrained analysis on the basic point cloud data is worthy of further investigation. Particularly, real point cloud scenes can intuitively capture complex surroundings in the real world, but due to 3D data\'s raw nature, it is very challenging for machine perception. In this work, we concentrate on the essential visual task, semantic segmentation, for largescale point cloud data collected in reality. On the one hand, to reduce the ambiguity in nearby points, we augment their local context by fully utilizing both geometric and semantic features in a bilateral structure. On the other hand, we comprehensively interpret the distinctness of the points from multiple resolutions and represent the feature map following an adaptive fusion method at point-level for accurate semantic segmentation. Further, we provide specific ablation studies and intuitive visualizations to validate our key modules. By comparing with state-of-the-art networks on three different benchmarks, we demonstrate the effectiveness of our network. Datasets: In this work, we are targeting the semantic segmentation of real point cloud scenes \u2022 S3DIS: Stanford Large-Scale 3D Indoor Spaces (S3DIS) dataset is collected from indoor working environments In general, there are six sub-areas in the dataset, each containing \u223c50 different rooms We adopt a 6-fold strategy for evaluation Overall, this dataset contains more than four billion points manually marked in eight semantic classes In particular, the dataset has two test sets for online evaluation: the full test set (i.e., semantic-8) has 15 scenes with over 2 billion points, while its subset (i.e., reduced-8) has four selected scenes with \u223c0.1 billion sampled points Particularly, 11 of the 22 sequences are provided with labels, while the results of the other ten sequences (over 20k scans) are for online evaluation Training Settings: We train for 100 epochs on a single GeForce RTX 2080Ti GPU with a batch size between 4 to Table 1: Semantic segmentation (6-fold cross-validation) results (%) on the S3DIS dataset [2]. (mAcc: average class accuracy, OA: overall accuracy, mIoU: mean Intersection-over-Union. \\"-\\" indicates unknown result.) 2018 2017 indicates unknown result . ) 2020 mIoU OA mAcc average class accuracy , Table 1 : Semantic segmentation ( 6 - fold cross - validation ) results ( mAcc : Table 2: Semantic segmentation (semantic-8) results (%) on the Semantic3D dataset [14]. natural scape scanning vegetation artefacts mIoU cars OA high man - made low buildings hard terrain Table 3: Semantic segmentation (single-scan) results (%) on the SemanticKITTI dataset [4]. sidewalk parking other - vehicle other - ground bicycle truck vegetation traffic - sign trunk pole building mIoU motorcycle bicyclist road car person motorcyclist terrain fence Table 6: Complexity analysis of different semantic segmentation networks on SemanticKITTI. (\\"-\\" indicates the unknown result.) networks on SemanticKITTI . ( \\" - \\" indicates the","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS Area5\\", \\"Metric\\": \\"mAcc\\", \\"Score\\": \\"73.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS Area5\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"65.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS Area5\\", \\"Metric\\": \\"oAcc\\", \\"Score\\": \\"88.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Semantic3D\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"75.4%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Semantic3D\\", \\"Metric\\": \\"oAcc\\", \\"Score\\": \\"94.9%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"72.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS\\", \\"Metric\\": \\"mAcc\\", \\"Score\\": \\"83.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS\\", \\"Metric\\": \\"oAcc\\", \\"Score\\": \\"88.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Semantic Segmentation\\", \\"Dataset\\": \\"SemanticKITTI\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"59.9%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS Area5\\", \\"Metric\\":\\"mAcc\\", \\"Score\\": \\"68.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS Area5\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"61.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS Area5\\", \\"Metric\\": \\"oAcc\\", \\"Score\\": \\"87.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"68.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS\\", \\"Metric\\":\\"mAcc\\", \\"Score\\": \\"78.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS\\", \\"Metric\\": \\"oAcc\\", \\"Score\\": \\"87.9\\"}} ]"},{"Context":"Communication-optimal parallel and sequential QR and LU factorizations: theory and practice We present parallel and sequential dense QR factorization algorithms that are both optimal (up to polylogarithmic factors) in the amount of communication they perform, and just as stable as Householder QR. Our first algorithm, Tall Skinny QR (TSQR), factors m \xd7 n matrices in a one-dimensional (1-D) block cyclic row layout, and is optimized form n. Our second algorithm, CAQR (Communication-Avoiding QR), factors general rectangular matrices distributed in a two-dimensional block cyclic layout. It invokes TSQR for each block column factorization.The new algorithms are superior in both theory and practice. We have extended known lower bounds on communication for sequential and parallel matrix multiplication to provide latency lower bounds, and show these bounds apply to the LU and QR decompositions. We not only show that our QR algorithms attain these lower bounds (up to polylogarithmic factors), but that existing LAPACK and ScaLAPACK algorithms perform asymptotically more communication. We also point out recent LU algorithms in the literature that attain at least some of these lower bounds.Both TSQR and CAQR have asymptotically lower latency cost in the parallel case, and asymptotically lower latency and bandwidth costs in the sequential case. In practice, we have implemented parallel TSQR on several machines, with speedups of up to 6.7\xd7 on 16 processors of a Pentium III cluster, and up to 4\xd7 on 32 processors of a BlueGene/L. We have also implemented sequential TSQR on a laptop for matrices that do not fit in DRAM, so that slow memory is disk. Our out-of-DRAM implementation was as little as 2\xd7 slower than the predicted runtime as though DRAM were infinite.We have also modeled the performance of our parallel CAQR algorithm, yielding predicted speedups over ScaLAPACK\'s PDGEQRF of up to 9.7\xd7 on an IBM Power5, up to 22.9\xd7 on a model Petascale machine, and up to 5.3\xd7 on a model of the Grid.  Table 1: Performance models of parallel TSQR and ScaLAPACK\'s parallel QR factorization PDGEQRF on an m\xd7n matrix with P processors, along with lower bounds on the number of flops, words, and messages. We assume m/P \u2265 n. Everything (messages, words, and flops) is counted along the critical path. The boldface part of the table highlights TSQR\'s improvement over ScaLAPACK. \\" P Lower bound PDGEQRF TSQR \u0398 n Table 2: Performance models of parallel CAQR and ScaLAPACK\'s parallel QR factorization PDGEQRF on a m \xd7 n matrix with P processors, along with lower bounds on the number of flops, words, and messages. The matrix is stored in a 2-D P r \xd7 P c block cyclic layout with square b \xd7 b blocks. We choose b, P r , and P c optimally and independently for each algorithm. We assume m \u2265 n. Everything (messages, words, and flops) is counted along the","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"FoveaBox: Beyound Anchor-Based Object Detection We present FoveaBox, an accurate, flexible, and completely anchor-free framework for object detection. While almost all state-of-the-art object detectors utilize predefined anchors to enumerate possible locations, scales and aspect ratios for the search of the objects, their performance and generalization ability are also limited to the design of anchors. Instead, FoveaBox directly learns the object existing possibility and the bounding box coordinates without anchor reference. This is achieved by: (a) predicting category-sensitive semantic maps for the object existing possibility, and (b) producing category-agnostic bounding box for each position that potentially contains an object. The scales of target boxes are naturally associated with feature pyramid representations. In FoveaBox, an instance is assigned to adjacent feature levels to make the model more accurate.We demonstrate its effectiveness on standard benchmarks and report extensive experimental analysis. Without bells and whistles, FoveaBox achieves state-of-the-art single model performance on the standard COCO and Pascal VOC object detection benchmark. More importantly, FoveaBox avoids all computation and hyper-parameters related to anchor boxes, which are often sensitive to the final detection performance. We believe the simple and effective approach will serve as a solid baseline and help ease future research for object detection. The code has been made publicly available at https://github.com/taokong/FoveaBox. Index Terms-Object detection, anchor free, foveabox. For our main results, we report COCO AP on the test-dev split, which has no public labels and requires use of the evaluation server For Pascal VOC, all models are trained on trainval2007 and trainval2012, and evaluated on test2007 subset, following common practice, we conducted additional experiments on Pascal VOC object detection dataset This dataset covers 20 object categories, and the performance is measured by mean average precision (mAP) at IoU = 0.5 All variants are trained on VOC2007 trainval and VOC2012 trainval, and tested on VOC2007 test dataset","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"58.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"41.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"51.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"43.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"22.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"38.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"57.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"40.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"38.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"40.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"52.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"42.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"19.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"38\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"55.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"37.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"50.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"39.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"18.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO minival\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"36.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"63.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"47.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"55.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"46.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"26.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"43.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"42.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"61.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"45.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"46.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"24.9\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"PASCAL VOC 2007\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"82.6%\\"}} ]"},{"Context":"Learning multiple visual domains with residual adapters There is a growing interest in learning data representations that work well for many different types of problems and data. In this paper, we look in particular at the task of learning a single visual representation that can be successfully utilized in the analysis of very different types of images, from dog breeds to stop signs and digits. Inspired by recent work on learning networks that predict the parameters of another, we develop a tunable deep network architecture that, by means of adapter residual modules, can be steered on the fly to diverse visual domains. Our method achieves a high degree of parameter sharing while maintaining or even improving the accuracy of domain-specific representations. We also introduce the Visual Decathlon Challenge, a benchmark that evaluates the ability of representations to capture simultaneously ten very different visual domains and measures their ability to perform well uniformly. In this section we evaluate our method quantitatively against several baselines (section 5.1), investigate the ability of the proposed techniques to learn models for ten very diverse visual domains Table 1: Multiple-domain networks. The figure reports the (top-1) classification accuracy (%) of different models on the decathlon tasks and final decathlon score (S). ImageNet is used to prime the network in every case, except for the networks trained from scratch. The model size is the number of parameters w.r.t. the baseline ResNet. The fully-finetuned model, written blue, is used as a baseline to compute the decathlon score. 2515 2118 2503 2643 544 1363 1826 Airc . Flwr OGlt 26k DPed GTSR 30k SVHN 40k 50k C100 70k 9k 7k DTD mean 4k 2k UCF #par . ImNet Table 2: Pairwise forgetting. Each pair of numbers report the top-1 accuracy (%) on the old task (ImageNet) and a new target task after the network is fully finetuned on the latter. We also show the performance of LwF when it is finetuned on the new task with a high and low learning","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Continual Learning\\", \\"Dataset\\": \\"visual domain decathlon (10 tasks)\\", \\"Metric\\": \\"decathlon discipline (Score)\\", \\"Score\\": \\"3131\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Continual Learning\\", \\"Dataset\\": \\"visual domain decathlon (10 tasks)\\", \\"Metric\\": \\"decathlon discipline (Score)\\", \\"Score\\": \\"2643\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Continual Learning\\", \\"Dataset\\": \\"visual domain decathlon (10 tasks)\\", \\"Metric\\": \\"decathlon discipline (Score)\\", \\"Score\\": \\"2621\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Continual Learning\\", \\"Dataset\\": \\"visual domain decathlon (10 tasks)\\", \\"Metric\\": \\"decathlon discipline (Score)\\", \\"Score\\": \\"2503\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Continual Learning\\", \\"Dataset\\": \\"visual domain decathlon (10 tasks)\\", \\"Metric\\": \\"decathlon discipline (Score)\\", \\"Score\\": \\"2118\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"STL-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"94.41\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"STL-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"88.80\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"STL-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"87.36\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"STL-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"74.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"STL-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"91.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Stanford Cars\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"96.32%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Stanford Cars\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"32.76%\\"}}, {"},{"Context":"Optimal and Cut-free Tableaux for Propositional Dynamic Logic with Converse We give an optimal (exptime), sound and complete tableaubased algorithm for deciding satisfiability for propositional dynamic logic with converse (CPDL) which does not require the use of analytic cut. Our main contribution is a sound method to combine our previous optimal method for tracking least fix-points in PDL with our previous optimal method for handling converse in the description logic ALCI. The extension is non-trivial as the two methods cannot be combined naively. We give sufficient details to enable an implementation by others. Our OCaml implementation seems to be the first theorem prover for CPDL.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Syntax-Enhanced Neural Machine Translation with Syntax-Aware Word Representations Syntax has been demonstrated highly effective in neural machine translation (NMT). Previous NMT models integrate syntax by representing 1-best tree outputs from a welltrained parsing system, e.g., the representative Tree-RNN and Tree-Linearization methods, which may suffer from error propagation. In this work, we propose a novel method to integrate source-side syntax implicitly for NMT. The basic idea is to use the intermediate hidden representations of a well-trained end-to-end dependency parser, which are referred to as syntax-aware word representations (SAWRs). Then, we simply concatenate such SAWRs with ordinary word embeddings to enhance basic NMT models. The method can be straightforwardly integrated into the widelyused sequence-to-sequence (Seq2Seq) NMT models. We start with a representative RNNbased Seq2Seq baseline system, and test the effectiveness of our proposed method on two benchmark datasets of the Chinese-English and English-Vietnamese translation tasks, respectively. Experimental results show that the proposed approach is able to bring significant BLEU score improvements on the two datasets compared with the baseline, 1.74 points for Chinese-English translation and 0.80 point for English-Vietnamese translation, respectively. In addition, the approach also outperforms the explicit Tree-RNN and Tree-Linearization methods.  Previous Work 38 . 83 / +1 . 74 34 . 30 / +2 . 59 38 . 41 / +1 . 32 MT05 MT06 Average / \u2206 MT03 MT04 Table 3: The influence of fine-tuning parser parameters in the SAWR system. MT05 Average MT06 MT03 MT04 Table 4: Ensemble performances, where the Hybrid model denotes SAWR + Tree-RNN + Tree-Linearization. 42 . 27 / +1 . 03 42 . 60 / +1 . 36 42 . 18 / +0 . 94 MT05 MT06 Average / \u2206 MT03 MT04 Table 5: Final results based on the transformer. Only the SAWR results are significantly better (p < 0.05). 41 . 42 / +0 . 68 41 . 78 / +1 . 04 MT05 MT06 Average / \u2206 MT03 MT04","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"IWSLT2015 English-Vietnamese\\", \\"Metric\\": \\"BLEU\\", \\"Score\\": \\"29.09\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Dependency Parsing\\", \\"Dataset\\": \\"Penn Treebank\\", \\"Metric\\": \\"LAS\\", \\"Score\\": \\"90.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Dependency Parsing\\", \\"Dataset\\": \\"Penn Treebank\\", \\"Metric\\": \\"UAS\\", \\"Score\\": \\"94.9\\"}} ]"},{"Context":"From Causality Semantics to Duration Timed Models The interleaving semantics is not compatible with both action refinement and durational actions. Since many true concurrency semantics are congruent w.r.t. action refinement, notably the causality and the maximality ones [Cos93,Gla90], this has challenged us to study the dense time behavior -where the actions are of arbitrary fixed durationwithin the causality semantics of Da Costa [Cos93].We extend the causal transition systems with the clocks and the timed constraints, and thus we obtain an over class of timed automata where the actions need not to be atomic. We define areal time extension of the formal description technique CSP, called duration-CSP, by attributing the duration to actions. We give the operational timed causal semantics of duration-CSP as well as its denotational semantics over the class of timed causal transition systems. Afterwards, we prove that the two semantics are equivalent. Finally we extend the duration-CSP language with a refinement operator \u03c1 -that allows to replace an action with a process -and prove that it preserves the timed causal bisimulation.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"DFNets: Spectral CNNs for Graphs with Feedback-Looped Filters We propose a novel spectral convolutional neural network (CNN) model on graph structured data, namely Distributed Feedback-Looped Networks (DFNets). This model is incorporated with a robust class of spectral graph filters, called feedbacklooped filters, to provide better localization on vertices, while still attaining fast convergence and linear memory requirements. Theoretically, feedback-looped filters can guarantee convergence w.r.t. a specified error bound, and be applied universally to any graph without knowing its structure. Furthermore, the propagation rule of this model can diversify features from the preceding layers to produce strong gradient flows. We have evaluated our model using two benchmark tasks: semi-supervised document classification on citation networks and semi-supervised entity classification on a knowledge graph. The experimental results show that our model considerably outperforms the state-of-the-art methods in both benchmark tasks overall datasets. We evaluate our models on two benchmark tasks: (1) semi-supervised document classification in citation networks, and (2) semi-supervised entity classification in a knowledge graph Datasets We use three citation network datasets Cora, Citeseer, and Pubmed for semi-supervised document classification, and one dataset NELL for semi-supervised entity classification We evaluate our feedback-looped filters using three different spectral CNN models: (i) DFNet: a densely connected spectral CNN with feedback-looped filters, (ii) DFNet-ATT: a self-attention based densely connected spectral CNN with feedback-looped filters, and (iii) DF-ATT: a self-attention based spectral CNN model with feedback-looped filters.: Hyperparameter settings for citation network datasets We use the same data splitting for each dataset as in Yang et al. summarizes the hyperparameter settings for citation network datasets The same hyperparameters are applied to the NELL dataset except for L2 regularization (i.e., 9e-2 for DFNet and DFnet-ATT, and 9e-4 for DF-ATT) The parameters p = 5, q = 3 Table 2: Dataset statistics. %Labeled Nodes contains dataset statistics [ 33 ] . Table 3: Hyperparameter settings for citation network datasets. \u03bb cut Dropout Table 4. We can see that our feedback-looped filters perform best, no matter whether or not the dense architecture is used. - - Table 4: Accuracy (%) averaged over 10 runs (* was obtained using a different data splitting in - - Table 5: Accuracy (%) averaged over 10 runs. Cora dataset . Citeseer It shows that feedback - looped filters improve The experimental results are presented in table 5 . Cora Pubmed Table 6: Accuracy (%) averaged over 10 runs on the Cora dataset. Table 6 : Accuracy ( % ) averaged over 10 runs on the Cora dataset . 2 . LNet GCN Training Split DFNet GAT AdaLNet Chebyshev Table 7: Accuracy (%) averaged over 10 runs on the Citeseer dataset. Table 7 : Accuracy","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Citeseer\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"74.7%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Pubmed\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"85.2%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Cora\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"86%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"NELL\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"68.8%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Citeseer\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"73.5%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Pubmed\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"82.6%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Cora\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"82.3%\\"}} ]"},{"Context":"Modeling of a Reconfigurable OFDM IP Block Family For an RF System Simulator The idea of design domain specific Mother Model of IP block family as abase of modeling of system integration is presented here. A common reconfigurable Mother Model for ten different standardized digital OFDM transmitters has been developed. By means of a set of parameters, the mother model can be reconfigured to any of the ten selected standards. So far the applicability of the proposed reconfiguration and analog-digital co-modeling methods have been proved by modeling the function of the digital parts of three, 802.11a, ADSL and DRM, transmitters in an RF system simulator. The model is intended to be used as signal source template in RF system simulations. The concept is not restricted to signal sources, it can be applied to any IP block development.The idea of the Mother Model will be applied in other design domains to prove that in certain application areas, OFDM transceivers in this case, the design process can progress simultaneously in different design domainsmixed signal, system and RTL-architectural -without the need of high-level synthesis. Only the Mother Models of three design domains are needed to be formally proved to function as specified.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"A Secure Wireless Routing Protocol Using Enhanced Chain Signatures We propose a routing protocol for wireless networks. Wireless routing protocols allow hosts within a network to have some knowledge of the topology in order to know when to forward a packet (via broadcast) and when to drop it. Since a routing protocol forms the backbone of a network, it is a lucrative target for many attacks, all of which attempt to disrupt network traffic by corrupting routing tables of neighboring routers using false updates. Secure routing protocols designed for wired networks (such as S-BGP) are not scalable in an ad-hoc wireless environment because of two main drawbacks: (1) the need to maintain knowledge about all immediate neighbors (which requires a discovery protocol), and (2) the need to transmit the same update several times, one for each neighbor. Although information about neighbors is readily available in a fairly static and wired network, such information is often not updated or available in an ad-hoc wireless network with mobile devices. Our protocol is a variant of S-BGP called SS-BGP and allows a single broadcast for routing updates without having the need to be aware of every neighboring router. The protocol is based on a novel authentication primitive called Enhanced Chain Signatures (ECS).","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Cutting a Convex Polyhedron Out of a Sphere \u22c6 Given a convex polyhedron P of n vertices inside a sphere Q, we give an O(n 3 )-time algorithm that cuts P out of Q by using guillotine cuts and has cutting cost O(log 2 n) times the optimal.The problem of cutting a convex polygon P out of apiece of planar material Q (P is already drawn on Q) with minimum total cutting length is a well studied problem in computational geometry. The problem was first introduced by Overmars and Welzl in 1985 [13] but has been extensively studied in the last decades [2-5, 8, 9, 11, 13-15]  with several variations, such as P and Q are convex or non-convex polygons, Q is a circle, and the cuts are line cuts or ray cuts. This type of cutting problems have many industrial applications such as in metal sheet cutting, paper cutting, furniture manufacturing, ceramic industries, fabrication, ornaments, and leather industries. Some of their variations also fall under stock cutting problems [4].If Q is another convex polygon with m edges, this problem with line cuts has been approached in various ways [3-6, 9, 10, 13, 14]. If the cuts are allowed only along the edges of P , Overmars and Welzl [13] proposed an O(n 3 + m)-time algorithm for this problem with optimal cutting length, where n is the number of edges of P . The problem is more difficult if the cuts are more general, i.e., they are not restricted to touch only the edges of P . In that case, Bhadury and Chandrasekaran showed that the problem has optimal solutions that lie in the algebraic extension of the input data field [4], and due to this algebraic nature of this problem, an approximation scheme is the best that one can achieve [4]. They also gave an approximation scheme with pseudo-polynomial running time [4].After the indication of Bhadury and Chandrasekaran [4] to the hardness of the problem, many people have given polynomial time approximation algorithms. Dumitrescu proposed an O(log n)-approximation algorithm with O(mn+n log n) running time [9,10]. Then, Daescu and Luo [6] gave the first constant factor approximation algorithm with ratio 2.5 + ||Q||/||P ||, where ||P || and ||Q|| are the \u22c6 An earlier version appeared in Proc. WALCOM 2010, LNCS, Springer, 2010","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Buffer Management Algorithm Design and Implementation Based on Network Processors To solve the parameter sensitive issue of the traditional RED (random early detection) algorithm, an adaptive buffer management algorithm called PAFD (packet adaptive fair dropping) is proposed. This algorithm supports DiffServ (differentiated services) model of QoS (quality of service). In this algorithm, both of fairness and throughput are considered. The smooth buffer occupancy rate function is adopted to adjust the parameters. By implementing buffer management and packet scheduling on Intel IXP2400, the viability of QoS mechanisms on NPs (network processors) is verified. The simulation shows that the PAFD smoothes the flow curve, and achieves better balance between fairness and network throughput. It also demonstrates that this algorithm meets the requirements of fast data packet processing, and the hardware resource utilization of NPs is higher.Florida. He has been involved in theoretical works on control theory and on parallel simulation algorithms development for real-time applications in the past several years. In the same periods, he has also participated in several industry supported projects on real-time data processing and microprocessor-based control system designs. Currently, his research interests are in the security related issues and performance improvement of computer networks.Deng Pan received his Ph.D. and M.S.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Toward Scalable Neural Dialogue State Tracking Model The latency in the current neural based dialogue state tracking models prohibits them from being used efficiently for deployment in production systems, albeit their highly accurate performance. This paper proposes anew scalable and accurate neural dialogue state tracking model, based on the recently proposed Global-Local Self-Attention encoder (GLAD) model by Zhong et al. (2018) which uses global modules to share parameters between estimators for different types (called slots) of dialogue states, and uses local modules to learn slot-specific features. By using only one recurrent networks with global conditioning, compared to (1 + # slots) recurrent networks with global and local conditioning used in the GLAD model, our proposed model reduces the latency in training and inference times by 35% on average, while preserving performance of belief state tracking, by 97.38% on turn request and 88.51% on joint goal and accuracy. Evaluation on Multi-domain dataset (Multi-WoZ) also demonstrates that our model outperforms GLAD on turn inform and joint goal accuracy. In this section, we evaluate the proposed encoder for the task of dialogue state tracking om single and multi-domain dialogue state tracking Wizard of oz (WoZ) restaurant reservation dataset is chosen for single-domain, and the performance is compared with the recent neural belief tracking models Moreover, we also evaluate on recen;t proposed multi-domain dataset, Multi-WoZ, which consists of seven domains, i.e The evaluation metric is based on joint goal and turn-level request and joint goal tracking accuracy Multi-Domain: shows the evauation on Multi-Woz dataset which consists of 10k dialogues Table 2: Time complexity for each batch of turn, and train and test epoch on WoZ dataset. Each batch contains 50 turns. All numbers are in second. 76 Test ( sec . ) Turn Train ( sec . ) Table 3: Performance on Multi-Domain dataset, Multi-WoZ (Budzianowski et al., 2018). 76 Test ( sec . ) Turn Train ( sec . )","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Dialogue State Tracking\\", \\"Dataset\\": \\"Wizard-of-Oz\\", \\"Metric\\": \\"Joint\\", \\"Score\\": \\"88.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Dialogue State Tracking\\", \\"Dataset\\": \\"Wizard-of-Oz\\", \\"Metric\\": \\"Request\\", \\"Score\\": \\"97.4\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Dialogue State Tracking\\", \\"Dataset\\": \\"Multi-Domain\\", \\"Metric\\": \\"MOTA\\", \\"Score\\": \\"83.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Dialogue State Tracking\\", \\"Dataset\\": \\"Multi-Domain\\", \\"Metric\\": \\"MOTP\\", \\"Score\\": \\"83.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Dialogue State Tracking\\", \\"Dataset\\": \\"Multi-Domain\\", \\"Metric\\": \\"MOTP\\", \\"Score\\": \\"83.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Dialogue State Tracking\\", \\"Dataset\\": \\"Multi-Domain\\", \\"Metric\\": \\"MOTP\\", \\"Score\\": \\"80.0\\"}} ]"},{"Context":"Reading documents on mobile devices is challenging. Not only are screens small and difficult to read, but also navigating an environment using limited visual attention can be difficult and potentially dangerous. Reading content aloud using text-tospeech (TTS) processing can mitigate these problems, but only for content that does not include rich visual information. In this paper, we introduce anew technique, SeeReader, that combines TTS with automatic content recognition and document presentation control that allows users to listen to documents while also being notified of important visual content. Together, these services allow users to read rich documents on mobile devices while maintaining awareness of their visual environment. We ran a within subjects, dual-task study as a preliminary evaluation of the core features of the SeeReader interface","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"SkeleMotion: A New Representation of Skeleton Joint Sequences Based on Motion Information for 3D Action Recognition Due to the availability of large-scale skeleton datasets, 3D human action recognition has recently called the attention of computer vision community. Many works have focused on encoding skeleton data as skeleton image representations based on spatial structure of the skeleton joints, in which the temporal dynamics of the sequence is encoded as variations in columns and the spatial structure of each frame is represented as rows of a matrix. To further improve such representations, we introduce a novel skeleton image representation to be used as input of Convolutional Neural Networks (CNNs), named SkeleMotion. The proposed approach encodes the temporal dynamics by explicitly computing the magnitude and orientation values of the skeleton joints. Different temporal scales are employed to compute motion values to aggregate more temporal dynamics to the representation making it able to capture longrange joint interactions involved in actions as well as filtering noisy motion values. Experimental results demonstrate the effectiveness of the proposed representation on 3D action recognition outperforming the state-of-the-art on NTU RGB+D 120 dataset. To isolate only the contribution brought by SkeleMotion to the action recognition problem, all other representations were tested on the same datasets with the same split of training and testing data and using the same CNN The NTU RGB+D 60 is publicly available 3D action recognition dataset The dataset provides four different data information: (i) RGB frames; (ii) depth maps; (iii) 395 infrared sequences; and (iv) skeleton joints There are two different evaluation protocols: cross-subject, which split the 40 subjects into training and testing; and cross-view, which uses samples from one camera for testing and the other two for training The performance is evaluated by computing the average recognition across all classes The NTU RGB+D 120 is a large-scale 3D action recognition dataset captured under various environmental conditions As in NTU RGB+D 60, the dataset provides RGB frames, depth maps, infrared sequences and skeleton joints There are two different evaluation protocols: Table 1. Action recognition accuracy (%) results on a subset of NTU RGB+D 60 [25] dataset by applying temporal scale aggre- gation (TSA) on our SkeleMotion representation. Three Temporal Scales Acc . ( % ) Magnitude Orientation Table 2. Action recognition accuracy (%) results on NTU RGB+D 60 [25] dataset. Results for the baselines were obtained running each method implementation. Cross - view Acc . ( % ) subject Table 3. Comparison between late and early fusion techniques on NTU RGB+D 60 [25] dataset. Acc . ( % ) Cross - subject Cross - view Table 4. Action recognition accuracy (%) results on NTU RGB+D 120 [15] dataset. Results for literature methods were obtained from [15]. Cross - setup Acc . ( % ) Cross - subject","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D 120\\", \\"Metric\\": \\"Accuracy (Cross-Setup)\\", \\"Score\\": \\"66.9%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D 120\\", \\"Metric\\": \\"Accuracy (Cross-Subject)\\", \\"Score\\": \\"67.7%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D 120\\", \\"Metric\\": \\"Accuracy (Cross-Setup)\\", \\"Score\\": \\"63.0%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D 120\\", \\"Metric\\": \\"Accuracy (Cross-Subject)\\", \\"Score\\": \\"62.9%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (CS)\\", \\"Score\\": \\"76.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (CV)\\", \\"Score\\": \\"84.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D 120\\", \\"Metric\\": \\"Accuracy (Cross-Setup)\\", \\"Score\\": \\"66.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D 120\\", \\"Metric\\": \\"Accuracy (Cross-Subject)\\", \\"Score\\": \\"67.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (CS)\\", \\"Score\\": \\"76.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (CV)\\", \\"Score\\": \\"84.7\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D 120\\", \\"Metric\\": \\"Accuracy (Cross-Setup)\\", \\"Score\\": \\"88.4%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D 120\\", \\"Metric\\": \\"Accuracy (Cross-Subject)\\", \\"Score\\": \\"86.9%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (CS)\\", \\"Score\\": \\"90.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (CV)\\", \\"Score\\": \\"96.3\\"}} ]"},{"Context":"Meta-DETR: Few-Shot Object Detection via Unified Image-Level Meta-Learning Few-shot object detection aims at detecting novel objects with only a few annotated examples. Prior works have proved meta-learning a promising solution, and most of them essentially address detection by meta-learning over regions for their classification and location fine-tuning. However, these methods substantially rely on initially welllocated region proposals, which are usually hard to obtain under the few-shot settings. This paper presents a novel meta-detector framework, namely Meta-DETR, which eliminates region-wise prediction and instead meta-learns object localization and classification at image level in a unified and complementary manner. Specifically, it first encodes both support and query images into category-specific features and then feeds them into a category-agnostic decoder to directly generate predictions for specific categories. To facilitate meta-learning with deep networks, we design a simple but effective Semantic Alignment Mechanism (SAM), which aligns high-level and low-level feature semantics to improve the generalization of meta-learned representations. Experiments over multiple few-shot object detection benchmarks show that Meta-DETR outperforms state-of-the-art methods by large margins. Concretely, two widely used few-shot object detection benchmarks are evaluated in our experiments We use trainval 07+12 for training and perform evaluations on test 07 Mean average precision (mAP) at IoU threshold 0.5 is used as the evaluation metric Results are averaged over 10 randomly sampled support datasets MS COCO is a more challenging object detection dataset, which contains 80 categories including those 20 categories in Pascal VOC We adopt the 20 shared categories as novel categories, and adopt the remaining 60 categories in MS COCO dataset as base categories We use train 2017 for training, and perform evaluations on val 2017 Standard evaluation metrics for MS COCO are adopted Results are averaged over 5 randomly sampled support datasets For Pascal VOC, mean average precision (mAP) at IoU threshold 0.5 is used as the evaluation metric Evaluation with Multiple Repeated Runs To address this issue, following and, our results, as reported Table 1. Few-shot detection performance (mAP@0.5) on Pascal VOC test 07 set for novel categories. Results are averaged over multiple repeated runs with different randomly sampled support datasets. \u2020 indicates results are re-evaluated using official codes for multiple runs since original results are evaluated with a single run. since original results are evaluated with a single run . 1 2 3 Novel 5 Split 3 \u2020 indicates results are re - evaluated using official codes for multiple runs Base 10 Table 2. Few-shot detection performance (mAP@0.5) for base and novel categories on category split 1 of Pascal VOC. Results are averaged over multiple runs. \u2020 indicates re-evaluated results. since original results are evaluated with a single run . Novel \u2020 indicates results are re - evaluated using official codes for multiple runs Table 1 . Few - shot detection performance ( mAP@0 . 5 ) on Pascal VOC test 07 set","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Object Detection\\", \\"Dataset\\": \\"MS-COCO (30-shot)\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"22.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Object Detection\\", \\"Dataset\\": \\"MS-COCO (30-shot)\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"21.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Object Detection\\", \\"Dataset\\": \\"MS-COCO (10-shot)\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"17.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Object Detection\\", \\"Dataset\\": \\"MS-COCO (10-shot)\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"16.7\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Few-Shot Object Detection\\", \\"Dataset\\": \\"MS-COCO (30-shot)\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"9.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Few-Shot Object Detection\\", \\"Dataset\\": \\"MS-COCO (10-shot)\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"5.6\\"}} ]"},{"Context":"Forecasting directional movements of stock prices for intraday trading using LSTM and random forests We employ both random forests and LSTM networks (more precisely CuDNNLSTM) as training methodologies to analyze their effectiveness in forecasting out-of-sample directional movements of constituent stocks of the S&P 500 from January 1993 till December 2018 for intraday trading. We introduce a multi-feature setting consisting not only of the returns with respect to the closing prices, but also with respect to the opening prices and intraday returns. As trading strategy, we use Krauss et al. (2017) and Fischer & Krauss (2018) as benchmark and, on each trading day, buy the 10 stocks with the highest probability and sell short the 10 stocks with the lowest probability to outperform the market in terms of intraday returns -all with equal monetary weight. Our empirical results show that the multi-feature setting provides a daily return, prior to transaction costs, of 0.64% using LSTM networks, and 0.54% using random forests. Hence we outperform the single-feature setting in Fischer & Krauss (2018) and Krauss et al. (2017) consisting only of the daily returns with respect to the closing prices, having corresponding daily returns of 0.41% and of 0.39% with respect to LSTM and random forests, respectively. 1 We follow the procedure of and divide the dataset consisting of 29 years starting from January 1990 till December 2018, using a 4-year window and 1-year stride, where each study period is divided into a training period of approximately 756 days (\u2248 3 years) and a trading period of approximately 252 days (\u2248 1 year) Table 2: Average performance metrics of the simulations before transaction cost 3 - Feature LSTM RF IntraDay 1 - Feature NextDay Index SP500 Table 3: Average performance metrics of the simulations after transaction cost 3 - Feature LSTM RF IntraDay 1 - Feature Table 2 : Average performance metrics of the simulations before transaction cost NextDay Index SP500","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Stock Market Prediction\\", \\"Dataset\\": \\"S&P 500\\", \\"Metric\\": \\"Average daily returns\\", \\"Score\\": \\"0.635%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Inspec\\", \\"Dataset\\": \\"NYU Corpus\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.942\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Inspec\\", \\"Dataset\\": \\"STL-10\\", \\"Metric\\": \\"Average Accuracy\\", \\"Score\\": \\"0.863\\"}} ]"},{"Context":"YOLACT++ Better Real-time Instance Segmentation We present a simple, fully-convolutional model for real-time (> 30 fps) instance segmentation that achieves competitive results on MS COCO evaluated on a single Titan Xp, which is significantly faster than any previous state-of-the-art approach. Moreover, we obtain this result after training on only one GPU. We accomplish this by breaking instance segmentation into two parallel subtasks: (1) generating a set of prototype masks and (2) predicting per-instance mask coefficients. Then we produce instance masks by linearly combining the prototypes with the mask coefficients. We find that because this process doesn\'t depend on repooling, this approach produces very high-quality masks and exhibits temporal stability for free. Furthermore, we analyze the emergent behavior of our prototypes and show they learn to localize instances on their own in a translation variant manner, despite being fully-convolutional. We also propose Fast NMS, a drop-in 12 ms faster replacement for standard NMS that only has a marginal performance penalty. Finally, by incorporating deformable convolutions into the backbone network, optimizing the prediction head with better anchor scales and aspect ratios, and adding a novel fast mask re-scoring branch, our YOLACT++ model can achieve 34.1 mAP on MS COCO at 33.5 fps, which is fairly close to the state-of-the-art approaches while still running at real-time.  S AP 50 AP L FPS Time M 75 AP YOLACT FPS Time AP AP mask AP bbox FPS Time Table 1. In addition to our base 550 \xd7 550 image size model, we train 400 \xd7 400 (YOLACT-400) and 700 \xd7 700 (YOLACT-700) models, adjusting the anchor scales accordingly (s x = s 550 /550 * x). Lowering the image size results in a large decrease in performance, demonstrating that instance segmenta- tion naturally demands larger images. Then, raising the image size decreases speed significantly but also increases performance, as expected. In addition to our base backbone of ResNet-101 With the proposed enhancements , YOLACT++ obtains a huge high speed . In particular , our YOLACT++ - ResNet - 50 model runs mAP r FPS Time Method mAP S AP 50 \xb7 FPS Time L M 75 AP FPS Time AP Table 7. With these two upgrades for object detection,","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Instance Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"53.8%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Instance Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"36.9%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Instance Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"55.1%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Instance Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"36.8%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Instance Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"11.9%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Instance Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"mask AP\\", \\"Score\\": \\"34.6%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Real-time Instance Segmentation\\", \\"Dataset\\": \\"MSCOCO\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"53.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Real-time Instance Segmentation\\", \\"Dataset\\": \\"MSCOCO\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"36.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Real-time Instance Segmentation\\", \\"Dataset\\": \\"MSCOCO\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"55.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Real-time Instance Segmentation\\", \\"Dataset\\": \\"MSCOCO\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"36.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Real-time Instance Segmentation\\", \\"Dataset\\": \\"MSCOCO\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"11.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Real-time Instance Segmentation\\", \\"Dataset\\": \\"MSCOCO\\", \\"Metric\\": \\"Frame (fps)\\", \\"Score\\": \\"27.3 (Titan Xp)\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Real-time Instance Segmentation\\", \\"Dataset\\": \\"MSCOCO\\", \\"Metric\\": \\"mask AP\\", \\"Score\\": \\"34.6\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Instance Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"62.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Instance Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"43.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Instance Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"54.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Instance Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"43.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Instance Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"25.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Instance Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\":\\"mask AP\\", \\"Score\\": \\"40.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Real-time Instance Segmentation\\", \\"Dataset\\": \\"MSCOCO\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"61.4%\\"}}, { "},{"Context":"DEEP ENSEMBLES FOR LOW-DATA TRANSFER LEARNING In the low-data regime, it is difficult to train good supervised models from scratch. Instead practitioners turn to pre-trained models, leveraging transfer learning. Ensembling is an empirically and theoretically appealing way to construct powerful predictive models, but the predominant approach of training multiple deep networks with different random initialisations collides with the need for transfer via pre-trained weights. In this work, we study different ways of creating ensembles from pre-trained models. We show that the nature of pre-training itself is a performant source of diversity, and propose a practical algorithm that efficiently identifies a subset of pre-trained models for any downstream dataset. The approach is simple: Use nearest-neighbour accuracy to rank pre-trained models, fine-tune the best ones with a small hyperparameter sweep, and greedily construct an ensemble to minimise validation cross-entropy. When evaluated together with strong baselines on 19 different downstream tasks (the Visual Task Adaptation Benchmark), this achieves state-of-the-art performance at a much lower inference budget, even when selecting from over 2,000 pre-trained models. We also assess our ensembles on ImageNet variants and show improved robustness to distribution shift. We evaluate our models on the Visual Task Adaptation Benchmark : 19 diverse downstream classification tasks, split into \'natural\', \'specialised\' and \'structured\' categories For the resultant ensemble, we retrain constituent models on the full 1000 data points, and evaluate it on the test data While ImageNet does not match our low-data regime of interest, previous work and additional datasets allow us to conveniently measure robustness and uncertainty metrics Table 1: Test accuracy of our best ensembles against reproduced baselines from Kolesnikov et al. (2019) [ * ]. For each dataset, we take the median of three independent runs. Rows show the average over datasets. Bootstrapped confidence intervals at the 95% level. The source of diversity for ensem- bles is shown: U = upstream (during pre-training) and C = combined (pre-training and fine-tuning). Specialised VTAB 1K Structured Natural Table 2: Upstream diversity gives better ensembles. Test accuracy of different ensembles. For each dataset, we take the median of three independent runs. Rows show the average over datasets. Bootstrapped confidence intervals at the 95% level. The source of diversity is noted as: D = down- stream (during fine-tuning), U = upstream (during pre-training) and C = combined (both). Specialised VTAB 1K Structured Natural Table 3: Ablations. Test accuracy of different ensembles. For each dataset, we take the median of three independent","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"VTAB-1k\\", \\"Metric\\": \\"Top-1 Accuracy\\", \\"Score\\": \\"77.6\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"STL-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"71.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"STL-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"69.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"STL-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"68.19\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"STL-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"63.13\\"}} ]"},{"Context":"Analyse des suites al\xe9atoires engendr\xe9es par des automates cellulaires et applications\xe0 la cryptographie On s\'int\xe9resse aux interactions entre la cryptologie et les automates cellulaires. Il a\xe9t\xe9 montr\xe9 r\xe9cemment qu\'il n\'existe pas de r\xe8gle\xe9l\xe9mentaire d\'automate cellulaire non-lin\xe9aire robuste\xe0 la corr\xe9lation. Ce r\xe9sultat limite fortement l\'usage d\'automates cellulaires pour la construction de suites pseudo-al\xe9atoires servant de cl\xe9s utilisables en cryptographie\xe0 cl\xe9 secr\xe8te. De plus, pour de tels m\xe9canismes de g\xe9n\xe9ration de suites pseudo-al\xe9atoires, Meier et Staffelbach ont propos\xe9 une technique de cryptanalyse efficace. Cependant, des pistes subsistent pour construire des automates cellulaires susceptibles d\'engendrer de bonnes suites pseudo-al\xe9atoires, que nous\xe9voquerons\xe0 la fin de cet article.Abstract : This paper considers interactions between cellular automata and cryptology. It is known that non-linear elementary rule which is correlation-immune don\'t exist. This results limits the use of cellular automata as pseudo-random generators suitable for cryptographic applications. In addition, for this kind of pseudo-random generators, a successful cryptanalysis was proposed by Meier and Staffelbach. However, other ways to design cellular automata capable to generate good pseudo-random sequences remain and will be discussed in the end of this article.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Chain-Based Representations for Solid and Physical Modeling In this paper we show that the (co)chain complex associated with a decomposition of the computational domain, commonly called a mesh in computational science and engineering, can be represented by a block-bidiagonal matrix that we call the Hasse matrix. Moreover, we show that topology-preserving mesh refinements, produced by the action of (the simplest) Euler operators, can be reduced to multilinear transformations of the Hasse matrix representing the complex. Our main result is anew representation of the (co)chain complex underlying field computations, a representation that provides new insights into the transformations induced by local mesh refinements. Our approach is based on first principles and is general in that it applies to most representational domains that can be characterized as cell complexes, without any restrictions on their type, dimension, codimension, orientability, manifoldness, connectedness.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"LiteSeg: A Novel Lightweight ConvNet for Semantic Segmentation Semantic image segmentation plays a pivotal role in many vision applications including autonomous driving and medical image analysis. Most of the former approaches move towards enhancing the performance in terms of accuracy with a little awareness of computational efficiency. In this paper, we introduce LiteSeg, a lightweight architecture for semantic image segmentation. In this work, we explore anew deeper version of Atrous Spatial Pyramid Pooling module (ASPP) and apply short and long residual connections, and depthwise separable convolution, resulting in a faster and efficient model. LiteSeg architecture is introduced and tested with multiple backbone networks as Darknet19, MobileNet, and ShuffleNet to provide multiple trade-offs between accuracy and computational cost. The proposed model LiteSeg, with MobileNetV2 as a backbone network, achieves an accuracy of 67.81% mean intersection over union at 161 frames per second with 640 \xd7 360 resolution on the Cityscapes dataset.Index Terms-semantic image segmentation, atrous spatial pyramid pooling, encoder decoder, and depthwise separable convolution. In our evaluation of the proposed method, the effectiveness of LiteSeg with different backbone networks is empirically tested and the results are compared with the lightweight state-of-the-art architectures on Cityscapes dataset The Cityscapes dataset is a large-scale dataset for semantic understanding of urban scenes","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Category mIoU\\", \\"Score\\": \\"88.29\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"GFlops\\", \\"Score\\": \\"103.09\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"70.75%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Category mIoU\\", \\"Score\\": \\"86.79\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"GFlops\\", \\"Score\\": \\"4.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"67.81%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Category mIoU\\", \\"Score\\": \\"85.39\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"GFlops\\", \\"Score\\": \\"2.75\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"65.17%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Real-Time Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"67.8%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"69.8%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"75.7%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"73.0%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"68.0%\\"}} ]"},{"Context":"OPTIMIZATION OF A CLASSICAL STAMPING PROGRESSION BY MODAL CORRECTION OF ANISOTROPY EARS This work is a development from the INETFORSMEP European project. It was proposed to realize a global optimization of a deep drawing industrial progression (made of several stages) fora cup manufacture. The objectives of the process were the thickness decrease and the geometrical parameters (especially the height). This paper completes this previous work in the aim of mastering the contour defect. From the optimal configuration, we are looking for minimizing the needed material and the number of forming operations. Our action is focused on the appearance of undesirable undulations (ears) located in the rim of the cups during forming, due to non-uniform crystallographic texture. These undulations can cause a significant amount of scrap, productivity loss and undesired cost during manufacture. In this paper, this phenomenon causes the use of five forming operations for the cup manufacture. The focus is to cut down from five to two forming stages by defining an optimal blank (size and shape). The advantage is to reduce the cost of the tool manufacturing and to minimize the needed material (by suppressing the part flange). The envisaged approach consists in defining a particular description of the ears\' part by modal decomposition and then simulating several blank shapes and sizes generated by discrete cosine transformation (DCT). The use of a numerical simulation for the forming operation and the design of experiment technique allows to find mathematical links between the ears\' formation and the DCT coefficients. An optimization is then possible by using mathematical links. This original approach leads to reduce the ears\' amplitude by ten, with only fifteen numerical experiments. Moreover, we have downsized the number of forming stages from five to two with minimal material use.  Table 1. Numerical parameters of the finite element simulation. Process parameters Shell ( 4 nodes ) 7 3m / s Rigid surface table 1 . 1428 Table 3: variation range of each DCT coefficient s High value Low value Initial value 115 . 5mm 118 . 5mm D : nominal diameter 117mm Table 4: Central composite experimental design. < - target values each simulated part . All these results are presented in table 4 . - 1 . 35E+00 Profile 12 Profile 13 Profile 14 L1 - 1 . 24E+00 L2 L3 - 1 . 22E+00 L4 L5 1 . 39E+00 1 . 28E+00 1 . 82E - 01 Profile 10 1 . 52E+00 Profile 11 - 1 . 12E+00 1 . 34E+00 blank with particular D , A1 and A2 values . The result was a file of points from the bottom contour . Table 5: Optimal configuration and modal","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"3D MRI brain tumor segmentation using autoencoder regularization Automated segmentation of brain tumors from 3D magnetic resonance images (MRIs) is necessary for the diagnosis, monitoring, and treatment planning of the disease. Manual delineation practices require anatomical knowledge, are expensive, time consuming and can be inaccurate due to human error. Here, we describe a semantic segmentation network for tumor subregion segmentation from 3D MRIs based on encoder-decoder architecture. Due to a limited training dataset size, a variational auto-encoder branch is added to reconstruct the input image itself in order to regularize the shared decoder and impose additional constraints on its layers. The current approach won 1st place in the BraTS 2018 challenge.  Table 1. VAE decoder branch structure, where GN stands for group normalization (with group size of 8), Conv -3x3x3 convolution, Conv1 -1x1x1 convolution, AddId - addition of identity/skip connection, UpLinear -3D linear spatial upsampling, Dense -fully connected layer - fully connected layer 256x20x24x16 256x1 128x1 32x160x192x128 128x40x48x32 64x80x96x64 Ops Repeat Table 1 . VAE decoder branch structure , where GN stands for group normalization Table 2. BraTS 2018 validation dataset results. Mean Dice and Hausdorff measure- ments of the proposed segmentation method. EN -enhancing tumor core, WT -whole tumor, TC -tumor core. Hausdorff ( mm ) Dice WT ET TC Table 3. BraTS 2018 testing dataset results. Mean Dice and Hausdorff measurements of the proposed segmentation method. EN -enhancing tumor core, WT -whole tumor, TC -tumor core. Hausdorff ( mm ) Dice WT ET TC","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Brain Tumor Segmentation\\", \\"Dataset\\": \\"BRATS 2018\\", \\"Metric\\": \\"Dice Score\\", \\"Score\\": \\"0.87049\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Medical Image Segmentation\\", \\"Dataset\\": \\"TCIA Pancreas-CT\\", \\"Metric\\": \\"Dice Score\\", \\"Score\\": \\"0.84\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Medical Image Segmentation\\", \\"Dataset\\": \\"CT-150\\", \\"Metric\\": \\"Dice Score\\", \\"Score\\": \\"0.88\\"}} ]"},{"Context":"Video Classification with FineCoarse Networks A rich representation of the information in video data can be realized by means of frequency analysis. Fine motion details from the boundaries of moving regions are characterized by high frequencies in the spatio-temporal domain. Meanwhile, lower frequencies are encoded with coarse information containing substantial redundancy, which causes low efficiency for those video models that take as input raw RGB frames. In this work, we propose a Motion Band-pass Module (MBPM) for separating the fine-grained information from coarse information in raw video data. By representing the coarse information with low resolution, we can increase the efficiency of video data processing. By embedding the MBPM into a two-pathway CNN architecture, we define a FineCoarse network. The efficiency of the FineCoarse network is determined by avoiding the redundancy in the feature space processed by the two pathways: one operates on downsampled features of low-resolution data, while the other operates on the fine-grained motion information captured by the MBPM. The proposed FineCoarse network outperforms many recent video processing models on Kinetics400, UCF101 and HMDB51. Furthermore, our approach achieves the state-of-the-art with 57.0% top-1 accuracy on Something-Something V1. In this section, we first introduce the datasets and implementation details Datasets We evaluate our approach on Something-Something V1, Kinetics400, UCF101 and HMDB51 Since Something-Something is widely used for evaluating temporal modeling efficiency, we mainly evaluate FineCoarse networks on this dataset As for other datasets, we utilize the sparse sampling strategy as shown in where a video is equally divided into N segments, and we randomly sample 3 consecutive frames in each segment to constitute a video clip of length T =3N Table 2: Ablation Studies for FineCoarse Networks on Something-Something V1. We show top-1 and top-5 prediction accuracy (%), as well as computational complexity measured in GFLOPs for a single crop & single clip. GFLOPs Top - 5 Top - 1 Table 3: Ablation study on the spatio-temporal input size (width 2 \xd7time) of the two pathways in FineCoarse network. GFLOPs ( % ) Input size for Fine Top - 5 for Coarse Top - 1 Table 4: Comparison results on Something-Something V1. \\"N/A\\" indicates the numbers are not available. + refers to averaging the predictions from different models. - Top - 1 ( % ) Top - 5 ( % ) Table 5: Comparison results on Kinetics400. We report the inference cost of multiple \\"views\\" (spatial crops \xd7 temporal clips). - FLOPs ( % ) Top - 5 Top - 1 Table 6: Comparison results on HMDB51 and UCF101. We report","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"77.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@5\\", \\"Score\\": \\"93.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"Something-Something V1\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"57.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"Something-Something V1\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"83.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"UCF101\\", \\"Metric\\": \\"3-fold Accuracy\\", \\"Score\\": \\"97.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"HMDB-51\\", \\"Metric\\": \\"Average accuracy of 3 splits\\", \\"Score\\": \\"77.6\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"75.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"Something-Something V1\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"49.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"Something-Something V1\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"46.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"Something-Something V1\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"84.5\\"}} ]"},{"Context":"Transformer Tracking Correlation acts as a critical role in the tracking field, especially in recent popular Siamese-based trackers. The correlation operation is a simple fusion manner to consider the similarity between the template and the search region. However, the correlation operation itself is a local linear matching process, leading to lose semantic information and fall into local optimum easily, which maybe the bottleneck of designing high-accuracy tracking algorithms. Is there any better feature fusion method than correlation? To address this issue, inspired by Transformer, this work presents a novel attention-based feature fusion network, which effectively combines the template and search region features solely using attention. Specifically, the proposed method includes an ego-context augment module based on self-attention and a cross-feature augment module based on cross-attention. Finally, we present a Transformer tracking (named TransT) method based on the Siamese-like feature extraction backbone, the designed attention-based fusion mechanism, and the classification and regression head. Experiments show that our TransT achieves very promising results on six challenging datasets, especially on largescale LaSOT, TrackingNet, and GOT-10k benchmarks. Our tracker runs at approximatively 50 fps on GPU. Code and models are available at https://github.com/chenxindlut/TransT. We report the detailed comparison results on the large-scale LaSOT, Track-ingNet, and GOT-10k datasets in LaSOT is a recent large-scale dataset with high-quality annotations, which contains 1400 challenging videos: 1120 for training and 280 for testing We follow the one-pass evaluation (Success and Precision) to compare different tracking algorithms on the LaSOT test set reports an attribute-based evaluation of representative stateof-the-art algorithms, illustrating that the TransT performs much better than other competing trackers on all attributes TrackingNet is a large-scale tracking dataset, which covers diverse object classes and scenes We submit our tracker\'s outputs to the official online evaluation server, and report the Success (AUC) and Precision (P and P N orm ) results in The GOT-10k dataset contains 10k sequences for training and 180 for testing We evaluate our tracker on some commonly used smallscale datasets, including NFS, OTB2015, and UAV123 We evaluate the proposed tracker on the 30 fps Table 1. State-of-the-art comparison on TrackingNet, LaSOT, and GOT-10k. The best two results are shown in red and blue fonts. SR TrackingNet [ 30 ] GOT - 10k [ 19 ] LaSOT [ 14 ] - Source Table 2. Ablation study on TrackingNet, LaSOT, and GOT-10k. The best results are shown in the red font. PNorm P 19 ] SR0 . 5 AO SR0 . 75 AUC Table 1. TransT- GOT denotes training with only the GOT-10k traning set. PNorm P 19 ] SR0 . 5 AO SR0 . 75 AUC Table 3. Comparison with correlation on TrackingNet, LaSOT, and GOT-10k. The best results are shown in the red font. \u221a \u221a","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Object Tracking\\", \\"Dataset\\": \\"LaSOT\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"64.9\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Object Tracking\\", \\"Dataset\\": \\"TrackingNet\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"81.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Object Tracking\\", \\"Dataset\\": \\"TrackingNet\\", \\"Metric\\": \\"Normalized Precision\\", \\"Score\\": \\"85.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Object Tracking\\", \\"Dataset\\": \\"TrackingNet\\", \\"Metric\\": \\"Precision\\", \\"Score\\": \\"80.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Object Tracking\\", \\"Dataset\\": \\"LaSOT\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"64.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Object Tracking\\", \\"Dataset\\": \\"GOT-10k\\", \\"Metric\\": \\"Average Overlap\\", \\"Score\\": \\"64.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Object Tracking\\", \\"Dataset\\": \\"GOT-10k\\", \\"Metric\\": \\"Success Rate 0.5\\", \\"Score\\": \\"72.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Video Object Segmentation\\", \\"Dataset\\": \\"DAVIS 2017 (test-dev-dev)\\", \\"Metric\\":"},{"Context":"Benchmark for Generic Product Detection: A Low Data Baseline for Dense Object Detection Object detection in densely packed scenes is anew area where standard object detectors fail to train well . Dense object detectors like RetinaNet (Lin et al., 2017) trained on large and dense datasets show great performance. We train a standard object detector on a small, normally packed dataset with data augmentation techniques. This dataset is 265 times smaller than the standard dataset, in terms of number of annotations. This low data baseline achieves satisfactory results (mAP=0.56) at standard IoU of 0.5. We also create a varied benchmark for generic SKU product detection by providing full annotations for multiple public datasets. It can be accessed at this URL. We hope that this benchmark helps in building robust detectors that perform reliably across different settings in the wild. The denseness of the datasets depends on two factors SKU110K is by far one of the most dense datasets for object detection An analysis of the denseness of other datasets in the current benchmark is shown in Table 1: Details of the datasets in the benchmark. # represents the count. Object sizes (Mean and Standard Deviation) are relative to the image size. Average Image size is shown in Megapixels Object Size Avg Img Size ( Std ) ( Mean ) Table 3: Details of Holoselecta dataset. # represents the count. Average size of the entire image is shown in megapixels 208 30 #Images 24 Avg Img Size Type of Images Table 4: Statistics of trainset. # represents the count. Num- ber of Annotations is denoted by #Anns #Images #Obj / Img #Anns Table 5: Performance of our Faster-RCNN across different general product datasets. * denotes results obtained using the trained model given at URL as is. - AR 300","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"COCO 2017\\", \\"Metric\\": \\"Mean mAP\\", \\"Score\\": \\"3153\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"SKU-110K\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"0.846\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"SKU-110K\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"0.74\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"SKU-110K\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"0.63\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"SKU-110K\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"0.82\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"SKU-110K\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"0.73\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Object Detection\\", \\"Dataset\\": \\"SKU-110K\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"0.54\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Object Detection\\", \\"Dataset\\": \\"SKU-110K\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"33.3\\"}}, { "},{"Context":"Deep Diving into BitTorrent Locality [Please cite the IEEE INFOCOM\'11 version of this paper] A substantial amount of work has recently gone into localizing BitTorrent traffic within an ISP in order to avoid excessive and oftentimes unnecessary transit costs. Several architectures and systems have been proposed and the initial results from specific ISPs and a few torrents have been encouraging. In this work we attempt to deepen and scale our understanding of locality and its potential. Looking at specific ISPs, we consider tens of thousands of concurrent torrents, and thus capture ISP-wide implications that cannot be appreciated by looking at only a handful of torrents. Secondly, we go beyond individual case studies and present results for the top 100 ISPs in terms of number of users represented in our dataset of up to 40K torrents involving more than 3.9M concurrent peers and more than 20M in the course of a day spread in 11K ASes. We develop scalable methodologies that permit us to process this huge dataset and answer questions such as: \\"what is the minimum and the maximum transit traffic reduction across hundreds of ISPs? \\", \\"what are the win-win boundaries for ISPs and their users? \\", \\"what is the maximum amount of transit traffic that can be localized without requiring finegrained control of inter-AS overlay connections? \\", \\"what is the impact to transit traffic from upgrades of residential broadband speeds? \\". Some points worth noting: The largest torrent has approximately 60K clients in all three datasets Looking at the number of peers and torrents per ISP we see that mn40K has bigger values which is expected since it is a much bigger dataset than the other two and thus contains more and bigger ISPs (notice that in the numbers for mn40K are per snapshot, whereas for the other two are aggregates over a day, i.e., totals from 24 snapshots) If not otherwise stated, our default dataset will be mn40K Seeder/leecher ratios: In dataset pb600 we know exactly if a peer is seeder or leacher but in mn40K and mn3K we do not have this information Then we made a client in our dataset a seeder with probability equal to the seeder/leecher ratio of its torrent We validated this technique with the dataset pb600 obtaining minor variation compared to real seeder distributions Table 1: Torrent sets collected in the period Aug-Oct 2009. For mn40K we collected three ver- sions, with one week in between them. We actu- ally crawled 100K torrents but only around 40K had peers. For mn3K and pb600 we repeated the crawl every hour for one day. The #IPs and #ISPs for mn40K are per snapshot, whereas for mn3K and pb600 are daily totals. pb600 |V ( T ) | |V ( A ) | mn40k 10 Table 2: Results for ISPs EU1-EU3, US1-US3, under different demographic and speed datasets ( a ) Transit traffic reduction under mn40K and Ookla speeds . Degradation LOIF Strict median QoS Locality under mn40K and Ookla speeds . Table 3: Live torrent characteristics Figure 6 : Comparision between LOIF and Local Percentage of Seed Local Remote","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Study of first-order thermal \u03a3\u2206 architecture for convective accelerometers This paper presents the study of an original closed-loop conditioning approach for fully-integrated convective inertial sensors. The method is applied to an accelerometer manufactured on a standard CMOS technology using an auto-aligned bulk etching step. Using the thermal behavior of the sensor as a summing function, a first order sigma-delta modulator is built. This \\"electrophysical\\" modulator realizes an analog-to-digital conversion of the signal. Besides the feedback scheme should improve the sensor performance.I.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection Mechanical devices such as engines, vehicles, aircrafts, etc., are typically instrumented with numerous sensors to capture the behavior and health of the machine. However, there are often external factors or variables which are not captured by sensors leading to time-series which are inherently unpredictable. For instance, manual controls and/or unmonitored environmental conditions or load may lead to inherently unpredictable time-series. Detecting anomalies in such scenarios becomes challenging using standard approaches based on mathematical models that rely on stationarity, or prediction models that utilize prediction errors to detect anomalies. We propose a Long Short Term Memory Networks based Encoder-Decoder scheme for Anomaly Detection (EncDec-AD) that learns to reconstruct \'normal\' time-series behavior, and thereafter uses reconstruction error to detect anomalies. We experiment with three publicly available quasi predictable time-series datasets: power demand, space shuttle, and ECG, and two realworld engine datasets with both predictive and unpredictable behavior. We show that EncDec-AD is robust and can detect anomalies from predictable, unpredictable, periodic, aperiodic, and quasi-periodic time-series. Further, we show that EncDec-AD is able to detect anomalies from short time-series (length as small as 30) as well as long time-series (length as large as 500). We consider four real-world datasets: power demand, space shuttle valve, ECG, and engine (see) The first three are taken from whereas the engine dataset is a proprietary one encountered in a real-life project The engine dataset contains data for two different applications: Engine-P where the time-series is quasi-predictable, Engine-NP where the time-series is unpredictable, for reasons such as mentioned earlier shows the performance of EncDec-AD on all the datasets Power demand dataset contains one univariate time-series with 35, 040 readings for power demand recorded over a period of one year Space shuttle dataset contains periodic sequences with 1000 points per cycle, and 15 such cycles Engine dataset contains readings for 12 sensors such as coolant temperature, torque, accelerator (control variable), etc ECG dataset contains quasi-periodic time-series (duration of a cycle varies from one instance to another) For our experiment, we use the first channel from qtdb/sel102 dataset where the time-series contains Table 1. Nature of datasets. N , Nn and Na is no. of original se- quences, normal subsequences and anomalous subsequences, re- spectively. spectively . \u221e Quasi - periodic Nn 12 Aperiodic 45 F \u03b2 - score Periodicity Dimensions Periodic 240 P 1 \u03b2 R 200 215 20 TPR / FPR Table 2. F \u03b2 -scores and positive likelihood ratios (TPR/FPR). spectively . \u221e Quasi - periodic Nn 12 Aperiodic 45 F \u03b2 - score Periodicity Dimensions Periodic 240 P 1 \u03b2 R 200 215 20 TPR / FPR","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Classification\\", \\"Dataset\\": \\"Physionet 2017 Atrial Fibrillation\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.719\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Outlier Detection\\", \\"Dataset\\": \\"ECG5000\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.934\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Anomaly Detection\\", \\"Dataset\\": \\"Automatic Misogynistic Identification\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"0.83\\"}} ]"},{"Context":"Coupled Generative Adversarial Networks We propose coupled generative adversarial network (CoGAN) for learning a joint distribution of multi-domain images. In contrast to the existing approaches, which require tuples of corresponding images in different domains in the training set, CoGAN can learn a joint distribution without any tuple of corresponding images. It can learn a joint distribution with just samples drawn from the marginal distributions. This is achieved by enforcing a weight-sharing constraint that limits the network capacity and favors a joint distribution solution over a product of marginal distributions one. We apply CoGAN to several joint distribution learning tasks, including learning a joint distribution of color and depth images, and learning a joint distribution of face images with different attributes. For each task it successfully learns the joint distribution without any tuple of corresponding images. We also demonstrate its applications to domain adaptation and image transformation. In,,, and, we show several example images of the training images used for the pair image generation tasks in the experiment section.,, and contain the statistics of the training datasets for the experiments Table 1: Unsupervised domain adaptation performance comparison. The table reported classification accuracies achieved by competing algorithms. to USPS to MNIST [ 20 ] [ 19 ] [ 18 ] [ 17 ] CoGAN Table 3: The table shows the performance of pair generation of digits and corresponding edge images (Task A) with different CoGAN weight-sharing configurations. The results were the average pixel agreement ratios over 10000 images over 5 trials. Avg . pixel agreement ratio 5 5 , 4 , 3 , 2 5 , 4 , 3 Weight - sharing layers in the generative models 5 , 4 Table 4: The table shows the performance of pair generation of digits and corresponding negative images (Task B) with different CoGAN weight-sharing configurations. The results were the average pixel agreement ratios over 10000 images over 5 trials. Avg . pixel agreement ratio 5 5 , 4 , 3 , 2 5 ,","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Cityscapes Photo-to-Labels\\", \\"Metric\\": \\"Class IOU\\", \\"Score\\": \\"0.08\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Cityscapes Photo-to-Labels\\", \\"Metric\\": \\"Per-class Accuracy\\", \\"Score\\": \\"11%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Cityscapes Photo-to-Labels\\", \\"Metric\\": \\"Per-pixel Accuracy\\", \\"Score\\": \\"45%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Cityscapes Labels-to-Photo\\", \\"Metric\\": \\"Class IOU\\", \\"Score\\": \\"0.06\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Cityscapes Labels-to-Photo\\", \\"Metric\\": \\"Per-class Accuracy\\", \\"Score\\": \\"10%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Cityscapes Labels-to-Photo\\", \\"Metric\\": \\"Per-pixel Accuracy\\", \\"Score\\": \\"40%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"SYNTHIA-to-Cityscapes\\", \\"Metric\\":\\"mIoU (13 classes)\\", \\"Score\\": \\"42.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Synthetic-to-Real Translation\\", \\"Dataset\\": \\"GTAV-to-Cityscapes Labels\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"44.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Domain Adaptation\\", \\"Dataset\\": \\"SYNSIG-to-Cityscapes\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"42.8\\"}} ]"},{"Context":"Compounding the Performance Improvements of Assembled Techniques in a Convolutional Neural Network . However, attempts to combine existing techniques to create a practical model are still uncommon. In this study, we carryout extensive experiments to validate that carefully assembling these techniques and applying them to basic CNN models (e.g., ResNet and MobileNet) can improve the accuracy and robustness of the models while minimizing the loss of throughput. Our proposed assembled ResNet-50 shows improvements in top-1 accuracy from 76.3% to 82.78%, mCE from 76.0% to 48.9% and mFR from 57.7% to 32.3% on ILSVRC2012 validation set. With these improvements, inference throughput only decreases from 536 to 312. To verify the performance improvement in transfer learning, fine grained classification and image retrieval tasks were tested on several public datasets and showed that the improvement to backbone network performance boosted transfer learning performance significantly. Our approach achieved 1st place in the iFood Competition Fine-Grained Visual Recognition at CVPR 2019 1 , and the source code and trained models will be made publicly available 2 . Top-1 The top-1 is a measure of classification accuracy on the ILSVRC2012 validation dataset The validation dataset consists of 50,000 images of 1,000 classes Table 1. Summary of key results. Top-1 is ILSVRC2012 top-1 validation accuracy. mCE is mean corruption error and mFR is mean flip rate (Lower is better.) 312 536 mFR Top - 1 - mCE Table 2. Result of channel attention with different configurations. R50 is a simple notation for ResNet-50. r is the reduction ratio of SK in the Fuse operation. The piecewise learning rate decay is used in these experiments. 466 402 326 536 382 r SK Top - 1 Table 3. Results for downsampling with anti-aliasing. The perfor- mance of the model was tested with different configurations for downsampling with anti-aliasing. The piecewise learning rate de- cay is used in these experiments. 422 456 536 483 Strided Conv Top - 1 Table 6. Performance comparison of stacking network tweaks. By stacking the ResNet-D, Selective Kernel (SK), BigLittleNet (BL) and downsampling with anti-aliasing (AA), we have steadily improved the ResNet-50","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet ReaL\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"88.65%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet ReaL\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"87.82%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"84.2%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Oxford 102 Flowers\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"98.9%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"SOP\\", \\"Metric\\": \\"Recall@1\\", \\"Score\\": \\"85.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"FGVC Aircraft\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"92.4%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Food-101\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"92.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Stanford Cars\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"94.4%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Oxford-IIIT Pets\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"94.3%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Oxford-IIIT Pets\\", \\"Metric\\": \\"Top-1 Error Rate\\", \\"Score\\": \\"5.7%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"57.3M\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"80.1%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"95.1%\\"}} ]"},{"Context":"Modeling Multi-Point Transport Protocol in P2P Networks Traditional end-to-end congestion control mechanisms assume data transferring happens between each pair user. In contrast, in a P2P network, many peers may locally keep a copy of a specific data object. If the path between a pair of peers is congested, the requesting peer who wants to download data will switch to another peer in its neighbor peer list to fetch the data instead of decreasing the download rate from the current peer. Thus, it is critical to study the performance in multi-point-to-multi-point (M2M) transport protocol in a P2P network. In this paper, we build a mathematical model for identifying the key parameters for the M2M transport protocol and also the relationships among these parameters. Finally, we conduct simulation experiments to validate our model.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Automatic Generation of Proof Tactics for Finite-Valued Logics * A number of flexible tactic-based logical frameworks are nowadays available that can implement a wide range of mathematical theories using a common higher-order metalanguage. Used as proof assistants, one of the advantages of such powerful systems resides in their responsiveness to extensibility of their reasoning capabilities, being designed over rule-based programming languages that allow the user to build her own \'programs to construct proofs\' -the so-called proof tactics.The present contribution discusses the implementation of an algorithm that generates sound and complete tableau systems fora very inclusive class of sufficiently expressive finite-valued propositional logics, and then illustrates some of the challenges and difficulties related to the algorithmic formation of automated theorem proving tactics for such logics. The procedure on whose implementation we will report is based on a generalized notion of analyticity of proof systems that is intended to guarantee termination of the corresponding automated tactics on what concerns theoremhood in our targeted logics.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"WDRN : A Wavelet Decomposed RelightNet for Image Relighting The task of recalibrating the illumination settings in an image to a target configuration is known as relighting. Relighting techniques have potential applications in digital photography, gaming industry and in augmented reality. In this paper, we address the one-to-one relighting problem where an image at a target illumination settings is predicted given an input image with specific illumination conditions. To this end, we propose a wavelet decomposed RelightNet called WDRN which is a novel encoder-decoder network employing wavelet based decomposition followed by convolution layers under a muti-resolution framework. We also propose a novel loss function called gray loss that ensures efficient learning of gradient in illumination along different directions of the ground truth image giving rise to visually superior relit images. The proposed solution won the first position in the relighting challenge event in advances in image manipulation (AIM) 2020 workshop which proves its effectiveness measured in terms of a Mean Perceptual Score which in turn is measured using SSIM and a Learned Perceptual Image Patch Similarity score. The dataset used in the experiments is the Virtual Image Dataset for Illumination Transfer (VIDIT) The dataset contains 390 different scenes which is captured at 40 different illumination settings (8 azimuthal angles and five different colour temperatures 2500K, 4500K etc.) with a total of 15, 600 images For the experiments as part of the challenge, we used 390 image pairs from the dataset, where the input image has a fixed illumination setting \u03b8 1 =North, T 1 = 6500K and the target is set at a different illumination setting \u03b8 2 = East, T 2 = 4500K In addition to the standard evaluation metrics like peak signal to noise ratio (PSNR) and SSIM, the performance of the proposed WDRN is evaluated using rather new perceptual metrics like Learned Perceptual Image Patch Similarity (LPIPS) and mean perceptual score (MPS) Table 1. Performance comparison of WDRN with competing entries in scene relight- ing and illumination estimation challenge, track-1 one-to-one relighting at AIM 2020 workshop. The MPS, used to determine the final ranking, is computed following Eq. (6). 13s 6s MPS SSIM PSNR LPIPS Run - time Table 2. Ablation study of wavelet domain network MPS Table 2 . Ablation study of wavelet domain network SSIM PSNR LPIPS Table 3. Ablation study of wavelet decomposition levels MPS SSIM PSNR Table 3 . Ablation study of wavelet decomposition levels LPIPS","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Relighting\\", \\"Dataset\\": \\"VIDIT\u201920 validation set\\", \\"Metric\\": \\"LPIPS\\", \\"Score\\": \\"0.2771\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Relighting\\", \\"Dataset\\": \\"VIDIT\u201920 validation set\\", \\"Metric\\": \\"MPS\\", \\"Score\\": \\"0.6935\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Relighting\\", \\"Dataset\\": \\"VIDIT\u201920 validation set\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"17.45\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Relighting\\", \\"Dataset\\": \\"VIDIT\u201920 validation set\\", \\"Metric\\": \\"Runtime(s)\\", \\"Score\\": \\"0.05\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Relighting\\", \\"Dataset\\": \\"VIDIT\u201920 validation set\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.6642\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Relighting\\", \\"Dataset\\": \\"VIDIT\u201920 validation set\\", \\"Metric\\": \\"LPIPS\\", \\"Score\\": \\"0.3712\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Relighting\\", \\"Dataset\\": \\"VIDIT\u201920 validation set\\", \\"Metric\\": \\"MPS\\", \\"Score\\": \\"0.5992\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Relighting\\", \\"Dataset\\": \\"VIDIT\u201920 validation set\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"17.20\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Relighting\\", \\"Dataset\\": \\"VIDIT\u201920 validation set\\", \\"Metric\\": \\"Runtime(s)\\", \\"Score\\": \\"0.0058\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Relighting\\", \\"Dataset\\": \\"VIDIT\u201920 validation set\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.5696\\"}} ]"},{"Context":"Rewarding Smatch: Transition-Based AMR Parsing with Reinforcement Learning Our work involves enriching the Stack-LSTM transition-based AMR parser (Ballesteros and Al-Onaizan, 2017) by augmenting training with Policy Learning and rewarding the Smatch score of sampled graphs. In addition, we also combined several AMR-to-text alignments with an attention mechanism and we supplemented the parser with pre-processed concept identification, named entities and contextualized embeddings. We achieve a highly competitive performance that is comparable to the best published results. We show an in-depth study ablating each of the new components of the parser. We start by reimplementing BO 5 and we train models with the most recent dataset (LDC2017T10) 6 All our experiments use beam 10 for decoding and they are the best (when evaluated in the development set) of 5 different random seeds 5 BO reported results on the 2014 dataset Table 1: Results, including comparison with the best systems, in the LDC2017T10 test set (aka AMR 2.0). Results highlighted Concepts Smatch Negations Wikification Experiment Named Entities Id SRL Rentrancies Unlabeled No WSD","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"AMR Parsing\\", \\"Dataset\\": \\"LDC2017T10\\", \\"Metric\\": \\"Smatch\\", \\"Score\\": \\"73.4\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"AMR Parsing\\", \\"Dataset\\": \\"LDC2017T10\\", \\"Metric\\": \\"Smatch\\", \\"Score\\": \\"71.3\\"}} ]"},{"Context":"Computer-aided assessment of physical rehabilitation entails evaluation of patient performance in completing prescribed rehabilitation exercises, based on processing movement data captured with a sensory system. Despite the essential role of rehabilitation assessment toward improved patient outcomes and reduced healthcare costs, existing approaches lack versatility, robustness, and practical relevance. In this paper, we propose a deep learning-based framework for automated assessment of the quality of physical rehabilitation exercises. The main components of the framework are metrics for quantifying movement performance, scoring functions for mapping the performance metrics into numerical scores of movement quality, and deep neural network models for generating quality scores of input movements via supervised learning. The proposed performance metric is defined based on the log-likelihood of a Gaussian mixture model, and encodes low-dimensional data representation obtained with a deep autoencoder network. The proposed deep spatio-temporal neural network arranges data into temporal pyramids, and exploits the spatial characteristics of human movements by using sub-networks to process joint displacements of individual body parts. The presented framework is validated using a dataset often rehabilitation exercises. The significance of this work is that it is the first that implements deep neural networks for assessment of rehabilitation performance. For validation of the presented framework, we created the UI-PRMD dataset The dataset consists of skeletal data collected from 10 healthy subjects A detailed description of the UI-PRMD dataset is provided in","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Action Quality Assessment\\", \\"Dataset\\": \\"UI-PRMD\\", \\"Metric\\": \\"Average mean absolute error\\", \\"Score\\": \\"0.0253\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Quality Assessment\\", \\"Dataset\\": \\"KIMORE\\", \\"Metric\\": \\"Average mean absolute error\\", \\"Score\\": \\"0.0379\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Surgical tool detection\\", \\"Dataset\\": \\"U-Detnamese Representation-based\\", \\"Metric\\": \\"2-Class Accuracy\\", \\"Score\\": \\"0.304\\"}} ]"},{"Context":"Using Similarity Measures to Select Pretraining Data for NER Word vectors and Language Models (LMs) pretrained on a large amount of unlabelled data can dramatically improve various Natural Language Processing (NLP) tasks. However, the measure and impact of similarity between pretraining data and target task data are left to intuition. We propose three cost-effective measures to quantify different aspects of similarity between source pretraining and target task data. We demonstrate that these measures are good predictors of the usefulness of pretrained models for Named Entity Recognition (NER) over 30 data pairs. Results also suggest that pretrained LMs are more effective and more predictable than pretrained word vectors, but pretrained word vectors are better when pretraining data is dissimilar. Micro average F 1 score is used to evaluate the performance of the tagger The supervised model used for NER is the same BiLSTM-CRF model mentioned above, and we follow the approach proposed by to incorporate the pretrained LMs Table 2: List of the target NER data sets and their specifications. Size is shown in number of tokens. biology and chemistry experi - Physics . Protein , Science , Material Sciences and Protocols Description taxa , Abstract Protein , DNA , RNA , Cell line and Cell type terial ( including corpora , physical materials ) Entity Types Person , Organization , Location , Miscellany Process ( including methods , equipment ) , Task and Ma - Adverse Drug Event , Disease , Drug , Finding , Symp - which is a forum where con - Newswire Biomacromolecular sequence , Entrez gene , Biological vice , Location , Method , Reagent , Speed , Tempera - Table 3: Similarity between source and target data sets (left), and the effectiveness of word vectors and LMs pretrained using different sources for NER (right). Lower PPL or WVV values indicate higher similarity between","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"WetLab\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"79.62\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"JNLPBA\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"74.29\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Drug\u2013drug Interaction Extraction\\", \\"Dataset\\": \\"DDI extraction 2013 corpus\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"0.8255\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Drug\u2013drug Interaction Extraction\\", \\"Dataset\\": \\"DDI extraction 2013 corpus\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"0.805\\"}} ]"},{"Context":"COINDUCTIVE FORMAL REASONING IN EXACT REAL ARITHMETIC In this article we present a method for formally proving the correctness of the lazy algorithms for computing homographic and quadratic transformations -of which field operations are special cases-on a representation of real numbers by coinductive streams. The algorithms work on coinductive stream of M\xf6bius maps and form the basis of the Edalat-Potts exact real arithmetic. We use the machinery of the Coq proof assistant for the coinductive types to present the formalisation. The formalised algorithms are only partially productive, i.e., they do not output provably infinite streams for all possible inputs. We show how to deal with this partiality in the presence of syntactic restrictions posed by the constructive type theory of Coq. Furthermore we show that the type theoretic techniques that we develop are compatible with the semantics of the algorithms as continuous maps on real numbers. The resulting Coq formalisation is available for public download.  Table 1: Various phases of the formalisation. 4596 lines 2099 lines ( percentage of total ) Length 62 K ( 12 . 9% )","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Haptic Sensing for MEMS with Application for Cantilever and Casimir Effect This paper presents an implementation of the Cosserat theory into haptic sensing technologies for real-time simulation of microstructures. Cosserat theory is chosen instead of the classical theory of elasticity fora better representation of stress, especially in the nonlinear regime. The use of Cosserat theory leads to a reduction of the complexity of the modelling and thus increases its capability for real time simulation which is indispensable for haptic technologies. The incorporation of Cosserat theory into haptic sensing technology enables the designer to simulate in real-time the components in a virtual reality environment (VRE) which can enable virtual manufacturing and prototyping. The software tool created as a result of this methodology demonstrates the feasibility of the proposed model. As test demonstrators, a cantilever microbeam and microbridge undergoing bending in VRE are presented.I.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Delaunay Triangulations in Linear Time? (Part I) * We present anew and simple randomized algorithm for constructing the Delaunay triangulation using nearest-neighbor graphs for point location. Under suitable assumptions, it runs in linear expected time for points in the plane with polynomially bounded spread, i.e., if the ratio between the largest and smallest pointwise distance is polynomially bounded. This also holds for point sets with bounded spread in higher dimensions as long as the expected complexity of the Delaunay triangulation of a sample of the points is linear in the sample size. * This was originally part of a manuscript containing further material now in [5]. For the problem at hand, we found an algorithm avoiding the use of the history of the construnction [6].","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Using Mobilize Power Management IP for Dynamic & Static Power Reduction in SoC at 130 nm At 130 nm and 90 nm, power consumption (both dynamic and static) has become a barrier in the roadmap for SoC designs targeting battery powered, mobile applications. This paper presents the results of dynamic and static power reduction achieved implementing Tensilica\'s 32-bit Xtensa microprocessor core, using Virtual Silicon\'s Power Management IP. Independent voltage islands are created using Virtual Silicon\'s VIP PowerSaver standard cells by using voltage level shifting cells and voltage isolation cells to implement power islands. The VIP PowerSaver standard cells are characterized at 1.2V, 1.0V and 0.8V, to accommodate voltage scaling. Power islands can also be turned off completely. Designers can significantly lower both the dynamic power and the quiescent or leakage power of their SoC designs, with very little impact on speed or area using Virtual Silicon\'s VIP Gate Bias standard cells.  Table 1: Leakage vs. Process 1 . 00E - 05 Proceedings of the Design , Automation and Test in Europe Conference and Exhibition ( DATE \' 05 ) 0 90nm FF 125C - 0 Current","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting Many real-world applications require the prediction of long sequence time-series, such as electricity consumption planning. Long sequence time-series forecasting (LSTF) demands a high prediction capacity of the model, which is the ability to capture precise long-range dependency coupling between output and input efficiently. Recent studies have shown the potential of Transformer to increase the prediction capacity. However, there are several severe issues with Transformer that prevent it from being directly applicable to LSTF, including quadratic time complexity, high memory usage, and inherent limitation of the encoder-decoder architecture. To address these issues, we design an efficient transformer-based model for LSTF, named Informer, with three distinctive characteristics: (i) a ProbSparse self-attention mechanism, which achieves O(L log L) in time complexity and memory usage, and has comparable performance on sequences\' dependency alignment. (ii) the self-attention distilling highlights dominating attention by halving cascading layer input, and efficiently handles extreme long input sequences. (iii) the generative style decoder, while conceptually simple, predicts the long time-series sequences atone forward operation rather than a step-by-step way, which drastically improves the inference speed of long-sequence predictions. Extensive experiments on four large-scale datasets demonstrate that Informer significantly outperforms existing methods and provides anew solution to the LSTF problem. We extensively perform experiments on four datasets, including 2 collected real-world datasets for LSTF and 2 public benchmark datasets To explore the granularity on the LSTF problem, we create separate datasets as {ETTh 1 , ETTh 2 } for 1-hourlevel and ETTm 1 for 15-minute-level Due to the missing data, we convert the dataset into hourly consumption of 2 years and set \'MT 320\' as the target value Weather 4 : This dataset contains local climatological data for nearly 1,600 U.S To better explore the ProbSparse selfattention\'s performance in our proposed Informer, we incorporate the canonical self-attention variant (Informer \u2020 ), the efficient variant Reformer and the most related work LogSparse self-attention in the experiments Setup: The input of each dataset is zero-mean normalized and summarize the univariate/multivariate evaluation results of all the methods on 4 datasets Note that we preserves 10% validation data for each dataset, so all the experiments Table 1: Univariate long sequence time-series forecasting results on four datasets (five cases). LogTrans Reformer LSTMa Informer DeepAR ARIMA Informer \u2020 MSE MAE Prophet Table 2: Multivariate long sequence time-series forecasting results on four datasets (five cases). Table 3: Ablation study of the ProbSparse self-attention mechanism. LogTrans Informer Figure 4 : The parameter sensitivity of three components in Informer . L / 2 - scale Dependency ( b ) Sampling Factor . 48 1440 Encoder Input ( horizon=48 ) 2880 - Informer , factor c=8 ( a ) Input length . 168 720 336 Prolong Input Length ( L x , L token ) 624 Informer , factor c=10 L / 4 - scale Dependency Encoder Input Length ( L x ) Encoder Input ( horizon=168 ) MSE L - scale Dependency Informer , factor c=3 Table 5: Ablation study of the self-attention distilling. 960 720 Prediction length 336 1200 480","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (168)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.389\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (168)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.232\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (168)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.595\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (168)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"2.800\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (168)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.346\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (168)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.183\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (168)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.504\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (168)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.396\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (336)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.387\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (336)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.222\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (336)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.593\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (336)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.468\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (48)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.314\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (48)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.155\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (48)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.474\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (48)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"3.190\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (24)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.247\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (24)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.098\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (24)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.284\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (24)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.108\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (48)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.319\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (48)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.158\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (48)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.424\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (48)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.175\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (336)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.417\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (336)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.263\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (336)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.738\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (336)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"2.753\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (720)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.435\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (720)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.269\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (720)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.766\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh1 (720)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.659\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (720)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.431\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (720)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.277\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (720)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"1.044\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (720)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"2.878\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (24)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.240\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (24)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.093\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (24)\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.455\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Forecasting\\", \\"Dataset\\": \\"ETTh2 (24)\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"3.554\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Sequential Image Classification\\", \\"Dataset\\": \\"Sequential CIFAR-10\\", \\"Metric\\": \\"Unpermuted Accuracy\\", \\"Score\\": \\"73.2\\"}} ]"},{"Context":"Dual Variational Generation for Low Shot Heterogeneous Face Recognition Heterogeneous Face Recognition (HFR) is a challenging issue because of the large domain discrepancy and alack of heterogeneous data. This paper considers HFR as a dual generation problem, and proposes a novel Dual Variational Generation (DVG) framework. It generates large-scale new paired heterogeneous images with the same identity from noise, for the sake of reducing the domain gap of HFR. Specifically, we first introduce a dual variational autoencoder to represent a joint distribution of paired heterogeneous images. Then, in order to ensure the identity consistency of the generated paired heterogeneous images, we impose a distribution alignment in the latent space and a pairwise identity preserving in the image space. Moreover, the HFR network reduces the domain discrepancy by constraining the pairwise feature distances between the generated paired heterogeneous images. Extensive experiments on four HFR databases show that our method can significantly improve state-of-the-art results. The related code is available at https://github.com/BradyFU/DVG.Recently, the great progress of high-quality face synthesis [38,5,33,39] has made \\"recognition via generation\\" possible. TP- GAN [16]  and CAPG- GAN [13]  introduce face synthesis to improve the quantitative performance of large pose face recognition. For HFR, [32] proposes a two-path model to synthesize VIS images from NIR images.[36] utilizes a GAN based multi-stream feature fusion technique to generate VIS images from polarimetric thermal faces. However, all these methods are * Equal Contribution  Table 1: Experimental analyses on the CASIA NIR-VIS 2.0 database. The backbone is LightCNN-9. FID MD Rank - 1 Table 2: Comparisons with other state-of-the-art deep HFR methods on the CASIA NIR-VIS 2.0, the Oulu-CASIA NIR-VIS, the BUAA-VisNir and the IIIT-D Viewed Sketch databases. DVR VisNir databases , respectively Further , when backbone DVG IDR Method - state - of - the - art methods . We first employ LightCNN - 9 as the backbone to perform DVG , which 10 5 WCNN 10 4 10 1 False Positive Rate 10 2 - Rank - 1 FAR=0 . 1% ( c ) BUAA - VisNir ROC IIIT - D Viewed Sketch Oulu - CASIA NIR - VIS BUAA - VisNir FAR=1% 10 0 ( b ) Oulu - CASIA NIR - VIS ROC","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"Oulu-CASIA NIR-VIS\\", \\"Metric\\": \\"TAR @ FAR=0.001\\", \\"Score\\": \\"92.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"Oulu-CASIA NIR-VIS\\", \\"Metric\\": \\"TAR @ FAR=0.01\\", \\"Score\\": \\"98.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"IIIT-D Viewed Sketch\\", \\"Metric\\": \\"TAR @ FAR=0.01\\", \\"Score\\": \\"97.86\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"CASIA NIR-VIS 2.0\\", \\"Metric\\": \\"TAR @ FAR=0.001\\", \\"Score\\": \\"99.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"BUAA-VisNir\\", \\"Metric\\": \\"TAR @ FAR=0.001\\", \\"Score\\": \\"97.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"BUAA-VisNir\\", \\"Metric\\": \\"TAR @ FAR=0.01\\", \\"Score\\": \\"98.5\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"Oulu-CASIA NIR-VIS\\", \\"Metric\\": \\"TAR @ FAR=0.001\\", \\"Score\\": \\"84.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"Oulu-CASIA NIR-VIS\\", \\"Metric\\": \\"TAR @ FAR=0.01\\", \\"Score\\": \\"97.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"CASIA NIR-VIS 2.0\\", \\"Metric\\": \\"TAR @ FAR=0.001\\", \\"Score\\": \\"99.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"BUAA-VisNir\\", \\"Metric\\": \\"TAR @ FAR=0.001\\", \\"Score\\": \\"96.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"BUAA-VisNir\\", \\"Metric\\": \\"TAR @ FAR=0.01\\", \\"Score\\": \\"98.5\\"}} ]"},{"Context":"Action Quality Assessment Across Multiple Actions Can learning to measure the quality of an action help in measuring the quality of other actions? If so, can consolidated samples from multiple actions help improve the performance of current approaches? In this paper, we carryout experiments to see if knowledge transfer is possible in the action quality assessment (AQA) setting. Experiments are carried out on our newly released AQA dataset (http: //rtis.oit.unlv.edu/datasets.html) consisting of 1106 action samples from seven actions with quality as measured by expert human judges. Our experimental results show that there is utility in learning a single model across multiple actions. To the best of our knowledge, there are only two publicly available AQA datasets and they have limited number of samples for each individual activity This is partly due to the extra effort required to collect samples as compared to an action recognition dataset In case of action recognition dataset compilation, an annotator might go to video hosting website such as YouTube and run a search query on names of actions While in compiling an AQA dataset, annotator has to mark starting and ending frames of a sample, and note down execution score, difficulty level, final score, etc Additionally, field experts are required to evaluate and score AQA data samples which can be quite difficult in many domains These factors limit dataset size To fill this data void, we introduce Action Quality Assessment 7 (AQA-7) dataset (), comprising samples from seven actions: {singles diving-10m platform, gymnastic vault, big air skiing, big Table 1: Characteristics of AQA-7 dataset. Avg . Seq . Len . 1 8 - 50 2 # Samples Score Range Table 2: All-Action vs. Single-Action models. Performance evaluation of single-action and all-action models in terms of action-wise and average Spearman\'s rank correlation (higher is better). First two frameworks simply average features to aggregate them and use SVR as the regression module. The bottom two frameworks use LSTM to aggregate features and use a fully-connected layer as the regression module. Our approach can be directly compared with single-action C3D-LSTM [16], since both have the same architecture. C3D - SVR [ 16 ] C3D - LSTM [ 16 ] oarding Snowb - Gymvault Skiing Sync . Dive 3m Diving Dive 10m Avg . Corr . - Table 3: Zero-shot AQA. Performance comparison of randomly-initialized model, single-action models (for e.g., first row shows the results of training on diving action measuring the quality","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Action Quality Assessment\\", \\"Dataset\\": \\"AQA-7\\", \\"Metric\\": \\"Spearman Correlation\\", \\"Score\\": \\"69.37%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Quality Assessment\\", \\"Dataset\\": \\"AQA-7\\", \\"Metric\\": \\"Spearman Correlation\\", \\"Score\\": \\"64.78%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Quality Assessment\\", \\"Dataset\\": \\"AQA-7\\", \\"Metric\\": \\"Spearman Correlation\\", \\"Score\\": \\"61.65%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"UCF101\\", \\"Metric\\": \\"3-fold Accuracy\\", \\"Score\\": \\"97.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"HMDB-51\\", \\"Metric\\": \\"Average accuracy of 3 splits\\", \\"Score\\": \\"71.5\\"}} ]"},{"Context":"Distributed Representations of Sentences and Documents Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, \\"powerful,\\" \\"strong\\" and \\"Paris\\" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-ofwords models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks. For sentiment analysis, we use two datasets: Stanford sentiment treebank dataset and IMDB dataset Documents in these datasets differ significantly in lengths: We also test our method on an information retrieval task, where the goal is to decide if a document should be retrieved given a query Dataset: This dataset was first proposed by and subsequently extended by as a benchmark for sentiment analysis The dataset consists of three sets: 8544 sentences for training, 2210 sentences for test and 1101 sentences for validation (or development) Every sentence in the dataset has a label which goes from very negative to very positive in the scale from 0.0 to 1.0 The dataset comes with detailed labels for sentences, and subphrases in the same scale In total, there are 239,232 labeled phrases in the dataset The dataset can be downloaded at: http://nlp.Stanford.edu/sentiment/ We learn the word vectors and paragraph vectors using 75,000 training documents Table 1. The performance of our method compared to other ap- proaches on the Stanford Sentiment Treebank dataset. The error rates of other methods are reported in (Socher et al., 2013b). ( Socher et al . , 2013b ) grained ) Error rate Negative ) ( Fine - ( Positive /","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"WikiQA\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"0.5976\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"WikiQA\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.6058\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"WikiQA\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"0.5110\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"WikiQA\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.5160\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"QASent\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"0.6762\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"QASent\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.7514\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"QASent\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"0.5213\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Question Answering\\", \\"Dataset\\": \\"QASent\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.6023\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Text Classification\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy (10 classes)\\", \\"Score\\": \\"-\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Text Classification\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy (2 classes)\\", \\"Score\\": \\"92.58\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"55.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"90.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"88.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"IMDb\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"75.4\\"}}, { \\"LEADERBOARD\\":"},{"Context":"Robust Lexical Features for Improved Neural Network Named-Entity Recognition Neural network approaches to Named-Entity Recognition reduce the need for carefully handcrafted features. While some features do remain in state-of-the-art systems, lexical features have been mostly discarded, with the exception of gazetteers. In this work, we show that this is unfair: lexical features are actually quite useful. We propose to embed words and entity types into a lowdimensional vector space we train from annotated data produced by distant supervision thanks to Wikipedia. From this, we compute -offline -a feature vector representing each word. When used with a vanilla recurrent neural network model, this representation yields substantial improvements. We establish anew state-of-the-art F1 score of 87.95 on ONTONOTES 5.0, while matching state-of-the-art performance with a F1 score of 91.73 on the over-studied CONLL-2003   dataset.This work is licensed under a Creative Commons Attribution 4.0 International License. License details: provides an overview of the two datasets For both datasets, we convert the IOB encoding to BILOU, since found the latter to perform better The four entity types are fairly evenly distributed, and the train/dev/test datasets present a similar type distribution This dataset is annotated with 18 entity types, and is much larger than CONLL Table 1: Topmost similar entity types to a few single-word mentions (left table) and non-entity words (right table directed in Sim Table 2: Statistics of the CONLL-2003 and ONTONOTES 5.0 datasets. #tok stands for the number of tokens, and #ent indicates the number of named-entities gold annotated. Dev #ent CONLL - 2003","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"CoNLL 2003 (English)\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"91.73\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"Ontonotes v5 (English)\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"87.95\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"CoNLL 2003 (English)\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"84.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"CoNLL 2003 (English)\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"82.0\\"}} ]"},{"Context":"On Distributed Model Checking of MSO on Graphs We consider distributed model-checking of Monadic Second-Order logic (MSO) on graphs which constitute the topology of communication networks. The graph is thus both the structure being checked and the system on which the distributed computation is performed. We prove that MSO can be distributively model-checked with only a constant number of messages sent over each link for planar networks with bounded diameter, as well as for networks with bounded degree and bounded treelength. The distributed algorithms rely on nontrivial transformations of linear time sequential algorithms for tree decompositions of bounded tree-width graphs.In the sequel, we present distributed algorithms to model-check MSO over classes of networks of bounded tree-width. These algorithms are obtained by transforming the centralized linear time algorithm presented in the previous section into distributed ones, which admit low complexity bounds. The challenge lies in two aspects. First, an ordered tree decomposition could be distributively constructed, with only O(1) messages sent over each link. Second, the constructed tree decomposition should be distributively stored in a suitable way, so that the tree automaton obtained from the MSO sentence, can be ran over the rooted labeled tree transformed from the ordered tree decomposition, in a bottom-up way, still with only O(1) messages sent over each link.We consider a message passing model of computation [AW04], based on a communication network whose topology is given by a graph G = (V, E) of diameter \u2206, where E denotes the set of bidirectional communication links between nodes. From now on, we restrict our attention to finite connected graphs.Unless specified explicitly, we assume in this paper that the distributed system is asynchronous and has no failure. The nodes have a unique identifier","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"AN APPLICATION OF THE FEFERMAN-VAUGHT THEOREM TO AUTOMATA AND LOGICS FOR WORDS OVER AN INFINITE ALPHABET We show that a special case of the Feferman-Vaught composition theorem gives rise to a natural notion of automata for finite words over an infinite alphabet, with good closure and decidability properties, as well as several logical characterizations. We also consider a slight extension of the Feferman-Vaught formalism which allows to express more relations between component values (such as equality), and prove related decidability results. From this result we get new classes of decidable logics for words over an infinite alphabet.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Communications Law The ABC of Digital Business Ecosystems Subject: Legal foundations for network-based economies The European Commission has the power to inspire, initiate and sponsor huge transnational projects to an extent impossible for most other entities. These projects can address universal themes and develop well-being models that are valuable across a diversity of societies and economies.It is a universal fact that SMEs in all countries provide a substantial proportion of total employment, and conduct much of a nation\'s innovative activity. Yet these smaller companies struggle in global markets on afar from level playing field, where large companies have distinct advantages.To redress this imbalance the Commission saw it as a priority to improve the trading capability of the Small and Medium-sized Enterprises (SMEs), and perceived digital platforms as the modern means to this end. They considered that the best operational model fora vibrant Web2.0-based Internet services industry would be by analogy to well-performing biological ecosystems.Open Source Software is adopted in the DBE 1 /OPAALS 2 projects as the best support for sustainability of such complex electronic webs, since it minimises interoperability problems, enables code access for cheaper in-house modification or development of systems, and reduces both capital and operating expenditure. al.respond to the new conditions 3 . Less healthy scenarios are where a dominant effectively produces a monoculture. If such a species is then taken out of the eco-equation, and there are no tail species to provide resilience to changed conditions, the ecosystem may fail.For industrial communities, if one accepts the analogy to biological ecosystems, the presence of super-dominants 4 can be regarded as a configuration that impacts all other \'business species\'. Digital Business Ecosystems (DBE) and its sister project OPAALS are major initiatives which, together with their satellite work groups, focus on the health of the European SMEs -the \'business tail\' -in the new knowledge-based economy that we are experiencing growing up around us.A key observation is that when living in a marketplace alongside dominant firms, self-organisation by other firms is more difficult to achieve. The current Internet use models fail to support local autonomy for the firm [Dini 2008], and the so-called sharing/cooperation zones on the internet are homogenised in the direction of the interests of the dominant participants. Thus, conformity rather than diversity results 5 . This effectively centralised model further promotes the possibility of single points of failure 6 , and more importantly single points of control from centralised servers. So an ecosystem-oriented approach necessitates a fully distributed peer-to-peer 7 networking model [Briscoe 2007b], which would avoid single points of control and so be immune to single points of failure, as shown in Figure 1.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Searching Beyond MobileNetV3 The evolution of MobileNets has laid a solid foundation for neural network applications on mobile end. With the latest MobileNetV3, neural architecture search again claimed its supremacy in network design. Unfortunately, till today all mobile methods mainly focus on CPU latencies instead of GPU, the latter, however, is much preferred in practice for it has faster speed, lower overhead and less interference. Bearing the target hardware in mind, we propose the first Mobile GPU-Aware (MoGA) neural architecture search in order to be precisely tailored for real-world applications. Further, the ultimate objective to devise a mobile network lies in achieving better performance by maximizing the utilization of bounded resources. Urging higher capability while restraining time consumption is not reconcilable. We alleviate the tension by weighted evolution techniques. Moreover, we encourage increasing the number of parameters for higher representational power. With 200\xd7 fewer GPU days than MnasNet, we obtain a series of models that outperform MobileNetV3 under the similar latency constraints, i.e., MoGA-A achieves 75.9% top-1 accuracy on ImageNet, MoGA-B meets 75.5% which costs only 0.5 ms more on mobile GPU. MoGA-C best attests GPU-awareness by reaching 75.3% and being slower on CPU but faster on GPU. The models and test code are made publicly here 12 .  Table 2: The architecture of MoGA-A. Note t, c, s refer to expansion rate, output channel size and stride respectively. SE for squeeze-and-excitation, NL for non-linearity. k for the number of categories. Input Ops s t Table 3: Comparison of mobile models on ImageNet. : Our reimplementation. Numbers within the parentheses are reported by its authors, same for below. \u2020 : Based on its published code. \u2021 : Samsung Galaxy S8. * : Samsung Note8. - Latc ( % ) Top - 5 ( M ) Top - 1 ( ms ) Table 3. Apart from the mobile framework we use, CPUs and GPUs differ on inherent microarchitectures, which puts hardware-specific requirements a must for the design of neu- ral architectures. 0 500 FBNet 1000 2000","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"5.1M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"75.9%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"92.8%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"75.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"MACs\\", \\"Score\\": \\"325M\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Params\\", \\"Score\\": \\"4.0M\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top-1 Error Rate\\", \\"Score\\": \\"24.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"75.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"MACs\\", \\"Score\\": \\"238M\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Params\\", \\"Score\\": \\"5.5M\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neu"},{"Context":"UPSNet: A Unified Panoptic Segmentation Network In this paper, we propose a unified panoptic segmentation network (UPSNet) for tackling the newly proposed panoptic segmentation task. On top of a single backbone residual network, we first design a deformable convolution based semantic segmentation head and a Mask R-CNN style instance segmentation head which solve these two subtasks simultaneously. More importantly, we introduce a parameter-free panoptic head which solves the panoptic segmentation via pixel-wise classification. It first leverages the logits from the previous two heads and then innovatively expands the representation for enabling prediction of an extra unknown class which helps better resolve the conflicts between semantic and instance segmentation. Additionally, it handles the challenge caused by the varying number of instances and permits back propagation to the bottom modules in an end-to-end manner. Extensive experimental results on Cityscapes, COCO and our internal dataset demonstrate that our UPSNet achieves stateof-the-art performance with much faster inference. In this section, we present the experimental results on COCO, Cityscapes and our internal dataset Our Dataset We also use an internal dataset which is similar to Cityscapes and consists of 10235 training, 1139 validation and 1186 test images of ego-centric driving scenarios Our dataset consists of 10 and 17 classes for thing (e.g., car, bus) and stuff (e.g., building, road) respectively Experimental Setup For all datasets, we report results on the validation set To evaluate the performance, we adopt panoptic quality (PQ), recognition quality (RQ) and semantic quality (SQ) as the metrics We set the learning rate and weight decay as 0.02 and 0.0001 for all datasets For our dataset, we train for 36K iterations and apply the same learning rate decay at 24K and 32K iterations For PSPNet, we use \\"poly\' learning rate schedule as in and train 220K, 18K and 76K on COCO, Cityscapes and our dataset with Table 1: Panoptic segmentation results on COCO. Super- scripts Th and St stand for thing and stuff. \'-\' means inap- plicable. mIoU PQ - SQ RQ AP Table 2: Panoptic segmentation results on MS-COCO 2018 test-dev. The top 3 rows contain results of top 3 models taken from the official leadboard. PQ SQ RQ Table 3: Panoptic segmentation results on Cityscapes. \'- COCO\' means the model is pretrained on COCO. \'-101\' means the model uses ResNet-101 as the backbone. Unless specified, all models use ResNet-50 as the backbone and are pretrained on ImageNet. mIoU PQ - SQ RQ AP PQ Th Table 4: Panoptic segmentation results on our dataset. mIoU PQ SQ RQ AP Table 6: Ablation study on COCO dataset. \'Pano.\', \'Loss Bal.\', \'Unk.\' and \'ICA\' stand for training with panoptic loss, loss balance, unknown prediction and instance class assign- ment respectively. PQ St Seg . Th GT","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"PQ\\", \\"Score\\": \\"46.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"PQst\\", \\"Score\\": \\"36.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"PQth\\", \\"Score\\": \\"53.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Indian Driving Dataset\\", \\"Metric\\": \\"PQ\\", \\"Score\\": \\"47.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"39.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"PQ\\", \\"Score\\": \\"61.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"PQst\\", \\"Score\\": \\"64.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"PQth\\", \\"Score\\": \\"57.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"79.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"37.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"PQ\\", \\"Score\\": \\"60.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"PQst\\", \\"Score\\": \\"63.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"PQth\\", \\"Score\\": \\"57.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"77.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"33.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"PQ\\", \\"Score\\": \\"59.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"PQst\\", \\"Score\\": \\"62.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"PQth\\", \\"Score\\": \\"54.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"75.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"KITTI Panoptic Segmentation\\", \\"Metric\\": \\"PQ\\", \\"Score\\": \\"39.9\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"PQ\\", \\"Score\\": \\"48.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"PQst\\", \\"Score\\": \\"37.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"PQth\\", \\"Score\\": \\"55.5\\"}} ]"},{"Context":"SESAME: Semantic Editing of Scenes by Adding, Manipulating or Erasing Objects input labe Fig. 1. We assess SESAME on three tasks (a) image editing with free form semantic drawings (first row) (b) semantic layout driven semantic editing (second row) (c) layout to image generation with SESAME discriminator (third row)Abstract. Recent advances in image generation gave rise to powerful tools for semantic image editing. However, existing approaches can either operate on a single image or require an abundance of additional information. They are not capable of handling the complete set of editing operations, that is addition, manipulation or removal of semantic concepts. To address these limitations, we propose SESAME, a novel generator-discriminator pair for Semantic Editing of Scenes by Adding, Manipulating or Erasing objects. In our setup, the user provides the semantic labels of the areas to be edited and the generator synthesizes the corresponding pixels. In contrast to previous methods that employ a discriminator that trivially concatenates semantics and image as an input, the SESAME discriminator is composed of two input streams that arXiv:2004.04977v2 [cs.CV] 8 Oct 2020 2 E. Ntavelis et al.independently process the image and its semantics, using the latter to manipulate the results of the former. We evaluate our model on a diverse set of datasets and report state-of-the-art performance on two tasks: (a) image manipulation and (b) image generation conditioned on semantic labels. require the whole semantics while we use only the semantics of the box -In order to quantify the performance of our network we follow the data preparation and evaluation steps of Hong et al ., for generating and removing objects based on a given semantic layout Datasets The dataset contains 3,000 street-level view images of 50 different cities in Europe for the training set and 500 images for the validation set The whole dataset is used for the generation task For manipulation, following Hong et al ., we experiment on a subset of the ADE20K dataset comprised of bedroom scenes In total we consider 49 semantic categories for training and evaluation -Flickr-Landscapes Datasets Similar to SPADE, we first scrapped 200,000 images from flickr with only landscape constraint After post-processing, our curated dataset consists of 7367 training and 500 validation images with their corresponding segmentation for 17 different semantic classes The user Table 1. Addition Results for Cityscapes and ADE20k dataset. We ablate on the Generator and Discriminator architecture as well as the semantic availability. For the SSIM, accuracy and mIoU higher is better, while for FID, lower is better. FID ADE20k Labels SSIM accu mIoU SSIM accu mIoU Cityscapes Table 2. Removal results for Cityscapes and ADE20k datasets. For the SSIM, accuracy and mIoU higher is better, while for FID, lower is better. ADE20k accu\u2191 Cityscapes SSIM\u2191 accu\u2191 mIoU\u2191 FID\u2193 SSIM\u2191 mIoU\u2191 FID\u2193 Table 3. Comparison in number of parameters Parameters in millions while for FID , lower is better ADE20k Discriminator mIoU accu FID mIoU accu FID Generator Discriminator Cityscapes Table 3 . Comparison in number of parameters Table 5. User Study Results: Which image is the most photorealistic? The first study invited the users to choose between Hong et al . User Study II Discriminator : SESAME PatchGAN User Study","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Cityscapes Labels-to-Photo\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"54.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Cityscapes Labels-to-Photo\\", \\"Metric\\": \\"Per-pixel Accuracy\\", \\"Score\\": \\"82.5%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"Cityscapes Labels-to-Photo\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"66\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"ADE20K Labels-to-Photos\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"85.5%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"ADE20K Labels-to-Photos\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"31.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"ADE20K Labels-to-Photos\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"49\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"Binarized MNIST\\", \\"Metric\\": \\"nats\\", \\"Score\\": \\"8.250\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Density Estimation\\", \\"Dataset\\": \\"UCF101\\", \\"Metric\\": \\"Log-ll-auto-100k\\", \\"Score\\": \\"11.94\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Density Estimation\\", \\"Dataset\\": \\"UCF101\\", \\"Metric\\": \\"Log-ll-auto-100k\\", \\"Score\\": \\"8.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Density Estimation\\", \\"Dataset\\": \\"UCF101\\", \\"Metric\\": \\"Log-ll-auto-100k\\", \\"Score\\": \\"93.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Density Estimation\\", \\"Dataset\\": \\"UCF101\\", \\"Metric\\":\\"mean Dice\\", \\"Score\\": \\"0.80\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Density Estimation\\", \\"Dataset\\": \\"NYU Depth v2\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"0.76\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Density Estimation\\", \\"Dataset\\": \\"ScanNetV2\\", \'Metric"},{"Context":"Note on Maximal Bisection above Tight Lower Bound Ina graph G = (V, E), a bisection (X, Y ) is a partition of V into sets X and Y such that |X| \u2264 |Y | \u2264 |X|+1. The size of (X, Y ) is the number of edges between X and Y . In the Max Bisection problem we are given a graph G = (V, E) and are required to find a bisection of maximum size. It is not hard to see that \u2308|E|/2\u2309 is a tight lower bound on the maximum size of a bisection of G.We study parameterized complexity of the following parameterized problem called Max Bisection above Tight Lower Bound (Max-Bisec-ATLB): decide whether a graph G = (V, E) has a bisection of size at least \u2308|E|/2\u2309 + k, where k is the parameter. We show that this parameterized problem has a kernel with O(k 2 ) vertices and O(k 3 ) edges, i.e., every instance of Max-Bisec-ATLB is equivalent to an instance of Max-Bisec-ATLB on a graph with at most O(k 2 ) vertices and O(k 3 ) edges.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Influence of Memory Hierarchies on Predictability for Time Constrained Embedded Software*","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Multi-granularity Generator for Temporal Action Proposal Temporal action proposal generation is an important task, aiming to localize the video segments containing human actions in an untrimmed video. In this paper, we propose a multi-granularity generator (MGG) to perform the temporal action proposal from different granularity perspectives, relying on the video visual features equipped with the position embedding information. First, we propose to use a bilinear matching model to exploit the rich local information within the video sequence. Afterwards, two components, namely segment proposal producer (SPP) and frame actionness producer (FAP), are combined to perform the task of temporal action proposal at two distinct granularities. SPP considers the whole video in the form of feature pyramid and generates segment proposals from one coarse perspective, while FAP carries out a finer actionness evaluation for each video frame. Our proposed MGG can be trained in an end-to-end fashion. By temporally adjusting the segment proposals with fine-grained frame actionness information, MGG achieves the superior performance over state-of-the-art methods on the public THUMOS-14 and ActivityNet-1.3 datasets. Moreover, we employ existing action classifiers to perform the classification of the proposals generated by MGG, leading to significant improvements compared against the competing methods for the video detection task. The whole dataset consists of 19,994 videos with 200 classes annotated, with 50% for training, 25% for validation, and the rest 25% for testing., SST, TURN, BSN, TAG, and CTAP on THUMOS-14 in terms of AR@AN Table 1: Performance comparisons with DAPs [10], SCNN- prop - Table 2: Performance comparisons with TCN [9], MSRA [46], Prop-SSAD [25], CTAP [13], and BSN [26] on the validation and testing splits of ActivityNet-1.3. MSRA Prop - SSAD BSN MGG TCN CTAP Table 3: Ablation studies on the validation set of ActivityNet-1.3 in terms of AUC and AR@AN. AUC ( val ) @80 @50 @100 @30 Table 4: Recall rates of MGG-U and MGG on generated proposals of different temporal extents on the validation set of ActivityNet-1.3, where AN and tIoU thresholds are set to 100 and 0.75, respectively. 0 - 5s 10 - 15s 40 - 45s 5 - 10s 35 - 40s 15 - 20s 25 - 30s Table 5: Performance comparisons of the two-stage TBA on the validation set of ActivityNet-1.3 in both end-to-end training and stagewise training manners. Stage II Stagewise End - to - end Table","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"THUMOS\u201914\\", \\"Metric\\": \\"mAP@0.3\\", \\"Score\\": \\"53.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"THUMOS\u201914\\", \\"Metric\\": \\"mAP@0.4\\", \\"Score\\": \\"46.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"THUMOS\u201914\\", \\"Metric\\": \\"mAP@0.5\\", \\"Score\\": \\"37.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Temporal Action Proposal Generation\\", \\"Dataset\\": \\"ActivityNet-1.3\\", \\"Metric\\": \\"AR@100\\", \\"Score\\": \\"74.54\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Temporal Action Proposal Generation\\", \\"Dataset\\": \\"ActivityNet-1.3\\", \\"Metric\\": \\"AUC (val)\\", \\"Score\\": \\"66.43\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Temporal Action Proposal Generation\\", \\"Dataset\\": \\"ActivityNet-1.3\\", \\"Metric\\": \\"Average Accuracy\\", \\"Score\\": \\"73.17\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Temporal Action Proposal Generation\\", \\"Dataset\\": \\"ActivityNet-1.3\\", \\"Metric\\": \\"Average Accuracy\\", \\"Score\\": \\"65.72\\"}} ]"},{"Context":"AtlasNet: A Papier-M\xe2ch\xe9 Approach to Learning 3D Surface Generation . Given input as either a 2D image or a 3D point cloud (a), we automatically generate a corresponding 3D mesh (b) and its atlas parameterization (c). We can use the recovered mesh and atlas to apply texture to the output shape (d) as well as 3D print the results (e).We introduce a method for learning to generate the surface of 3D shapes. Our approach represents a 3D shape as a collection of parametric surface elements and, in contrast to methods generating voxel grids or point clouds, naturally infers a surface representation of the shape. Beyond its novelty, our new shape generation framework, AtlasNet, comes with significant advantages, such as improved precision and generalization capabilities, and the possibility to generate a shape of arbitrary resolution without memory issues. We demonstrate these benefits and compare to strong baselines on the ShapeNet benchmark for two applications: (i) autoencoding shapes, and (ii) single-view reconstruction from a still image. We also provide results showing its potential for other applications, such as morphing, parametrization, super-resolution, matching, and co-segmentation.  Table 1. 3D reconstruction. Comparison of our approach against a point-generation baseline (\\"CD\\" -Chamfer distance, multiplied by 10 3 , computed on 2500 points; \\"Metro\\" values are multiplied by 10). Note that our approach can be directly evaluated by Metro while the baseline requires performing PSR - CD Metro Table 2. Generalization across object categories. Comparison of our approach with varying number of patches against the point- generating baseline to generate a specific category when training on all other ShapeNet categories. Chamfer distance is reported, multi- plied by 10 3 , computed on 2500 points. Notice that our approach with 125 patches out-performs all baselines when generalizing to the new category. For reference, we also show performance when we train over all categories. Points Ours 125 patches baseline 1 patch Table 3. Single-View Reconstruction (per category). The mean is taken category-wise. The Chamfer Distance reported is computed on 1024 points, after","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Point Cloud Completion\\", \\"Dataset\\": \\"Completion3D\\", \\"Metric\\": \\"Chamfer Distance\\", \\"Score\\": \\"17.77\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Shape Reconstruction\\", \\"Dataset\\": \\"Pix3D\\", \\"Metric\\": \\"CD\\", \\"Score\\": \\"0.125\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Shape Reconstruction\\", \\"Dataset\\": \\"Pix3D\\", \\"Metric\\": \\"EMD\\", \\"Score\\": \\"0.128\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Shape Reconstruction\\", \\"Dataset\\": \\"Pix3D\\", \\"Metric\\": \\"IoU\\", \\"Score\\": \\"N/A\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Reconstruction\\", \\"Dataset\\": \\"Data3DR2N2\\", \\"Metric\\": \\"3DIoU\\", \\"Score\\": \\"0.575\\"}} ]"},{"Context":"Succinct Geometric Indexes Supporting Point Location Queries We propose to design data structures called succinct geometric indexes of negligible space (more precisely, o(n) bits) that, by taking advantage of then points in the data set permuted and stored elsewhere as a sequence, to support geometric queries in optimal time. Our first and main result is a succinct geometric index that can answer point location queries, a fundamental problem in computational geometry, on planar triangulations in O(lg n) time 3 . We also design three variants of this index. The first supports point location using lg n + 2 \u221a lg n + O(lg 1/4 n) point-line comparisons.The second supports point location in o(lg n) time when the coordinates are integers bounded by U . The last variant can answer point location in O(H + 1) expected time, where H is the entropy of the query distribution. These results match the query efficiency of previous point location structures that use O(n) words or O(n lg n) bits, while saving drastic amounts of space. We then generalize our succinct geometric index to planar subdivisions, and design indexes for other types of queries. Finally, we apply our techniques to design the first implicit data structures that support point location in O(lg 2 n) time.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Decoupled Spatial-Temporal Attention Network for Skeleton-Based Action Recognition Dynamic skeletal data, represented as the 2D/3D coordinates of human joints, has been widely studied for human action recognition due to its high-level semantic information and environmental robustness. However, previous methods heavily rely on designing handcrafted traversal rules or graph topologies to draw dependencies between the joints, which are limited in performance and generalizability. In this work, we present a novel decoupled spatial-temporal attention network (DSTA-Net) for skeleton-based action recognition. It involves solely the attention blocks, allowing for modeling spatial-temporal dependencies between joints without the requirement of knowing their positions or mutual connections. Specifically, to meet the specific requirements of the skeletal data, three techniques are proposed for building attention blocks, namely, spatial-temporal attention decoupling, decoupled position encoding and spatial global regularization. Besides, from the data aspect, we introduce a skeletal data decoupling technique to emphasize the specific characteristics of space/time and different motion scales, resulting in a more comprehensive understanding of the human actions. To test the effectiveness of the proposed method, extensive experiments are conducted on four challenging datasets for skeleton-based gesture and action recognition, namely, SHREC, DHG, NTU-60 and NTU-120, where DSTA-Net achieves state-of-the-art performance on all of them. To verify the generalization of the model, we use two datasets for hand gesture recognition (DHG and SHREC) and two datasets for human action recognition (NTU-60 and NTU-120) Then, we evaluate our model on all four datasets to compare with the state-of-the-art methods DHG: DHG dataset contains 2800 video sequences of 14 hand gestures performed 5 times by 20 subjects It uses the leave-one-subject-out cross-validation strategy for evaluation SHREC: SHREC dataset contains 2800 gesture sequences performed 1 and 10 times by 28 participants in two ways like the DHG dataset This dataset is used for the competition of SHREC\'17 in conjunction with the Euro-graphics 3DOR\'2017 Workshop NTU-60: NTU-60 is a most widely used in-door-captured action recognition dataset, which contains 56,000 action clips in 60 action classes This dataset provides 25 joints for each subject in the skeleton sequences Table 1. Ablation studies for architectures of the model on the SHREC dataset. ST-ATT-c denotes the spatial temporal attention networks with attention type c introduced in Accuracy Table 2. Ablation studies for feature fusion on the SHREC dataset. Spatial-temporal denotes the raw data, i.e., the joint coordinates. Other types of features are introduced in Sec. 3.6. Accuracy Table 3. Recognition accuracy comparison of our method and state-of-the-art methods on SHREC dataset and DHG dataset. DHG 14 gestures Year SHREC 28 gestures Table 4. Recognition accuracy comparison of our method and state-of-the-art methods on NTU-60 dataset. CS and CV denote the cross-subject and cross-view benchmarks, respectively. CS ( % ) CV ( % ) Table 5. Recognition accuracy comparison of our method and state-of-the-art methods on NTU-120 dataset. CS and CE denote the cross-subject and cross-setup benchmarks, respectively. CE ( % ) CS ( % )","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D 120\\", \\"Metric\\": \\"Accuracy (Cross-Setup)\\", \\"Score\\": \\"89.0 %\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D 120\\", \\"Metric\\": \\"Accuracy (Cross-Subject)\\", \\"Score\\": \\"86.6%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (CS)\\", \\"Score\\": \\"91.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (CV)\\", \\"Score\\": \\"96.4\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (CS)\\", \\"Score\\": \\"92.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Skeleton Based Action Recognition\\", \\"Dataset\\": \\"NTU RGB+D\\", \\"Metric\\": \\"Accuracy (CV)\\", \\"Score\\": \\"96.1\\"}} ]"},{"Context":"LAMBDANETWORKS: MODELING LONG-RANGE INTERACTIONS WITHOUT ATTENTION We present lambda layers -an alternative framework to self-attention -for capturing long-range interactions between an input and structured contextual information (e.g. a pixel surrounded by other pixels). Lambda layers capture such interactions by transforming available contexts into linear functions, termed lambdas, and applying these linear functions to each input separately. Similar to linear attention, lambda layers bypass expensive attention maps, but in contrast, they model both content and position-based interactions which enables their application to large structured inputs such as images. The resulting neural network architectures, LambdaNetworks, significantly outperform their convolutional and attentional counterparts on ImageNet classification, COCO object detection and COCO instance segmentation, while being more computationally efficient. Additionally, we design LambdaResNets, a family of hybrid architectures across different scales, that considerably improves the speed-accuracy tradeoff of image classification models. LambdaResNets reach excellent accuracies on ImageNet while being 3.2 -4.4x faster than the popular EfficientNets on modern machine learning accelerators. When training with an additional 130M pseudo-labeled images, LambdaResNets achieve up to a 9.5x speed-up over the corresponding Efficient-Net checkpoints 1 . In subsequent experiments, we evaluate lambda layers on standard computer vision benchmarks: ImageNet classification (Deng et al., 2009), COCO object detection and instance segmentation Table 3: Comparison of the lambda layer and attention mechanisms on ImageNet classification with a ResNet50 architecture. The lambda layer strongly outperforms attention alternatives at a fraction of the parameter cost. All models are trained in mostly similar setups (see Appendix E.2) and we include the reported improvements compared to the convolution baseline in parentheses. See Appendix B.4 for a description of the |u| hyperparameter. \u2020 Our implementation. top - 1 Params ( M ) Table 4: The lambda layer reaches higher ImageNet accuracies while being faster and more memory-efficient than self-attention alternatives. Memory is reported assuming full precision for a batch of 128 inputs using default hyperparameters. The memory cost for storing the lambdas matches the memory cost of activations in the rest of the network and is therefore ignored. b: batch size, h: number of heads/queries, n: input length, m: context length, k: query/key depth, l: number of layers.","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"42M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"84.3%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"35M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"84.0%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"78.9M\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"80.72%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"93.52%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"83.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"83.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"83.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"84.9M\\"}}]"},{"Context":"ACE: Adaptive Confusion Energy for Natural World Data Distribution With the development of deep learning, standard classification problems have achieved good results. However, conventional classification problems are often too idealistic. Most data in the natural world usually have imbalanced distribution and fine-grained characteristics. Recently, many state-of-the-art approaches tend to focus on one or another separately, but rarely on both. In this paper, we introduce a novel and adaptive batch-wise regularization based on the proposed Adaptive Confusion Energy (ACE) to flexibly address the nature world distribution, which usually involves fine-grained and long-tailed properties at the same time. ACE increases the difficulty of the training process and further alleviates the overfitting problem. Through the datasets with the technical issue in fine-grained (CUB, CAR, AIR) and long-tailed (ImageNet-LT), or comprehensive issues (CUB-LT, iNaturalist), the result shows that the ACE is not only competitive to some state-ofthe-art on performance but also demonstrates the effectiveness of training. We conduct extensive experiments to evaluate our approach on three balanced benchmark FGVC datasets, imbalanced datasets, and the natural world distribution dataset We first evaluate the effectiveness of the proposed approach on three standard fine-grained visual classification datasets, namely, CUB-200-2011, Stanford Cars, and FGVC-Aircraft The class distribution of the three datasets is nearly balanced, which can be used to measure the proposed method\'s performance only in the fine-grained scenario with the adaptive matrix\xc2 approximating identity matrix Compared with other datasets for the large-scale visual classification task, these three FGVC datasets have fewer training data for each category Next, we go through the experiments on the imbalanced datasets, ImageNet-LT The former is a long-tailed distribution with a low fine-grained factor, confirming whether the proposed approach will adjust on the purely imbalanced dataset The latter is a fine-grained dataset that also has a long-tailed property Finally, we then focus on the natural world Table 1. Head-to-head comparisons of the confusion energy scenarios on the standard FGVC datasets CUB-200-2011 (CUB), Stanford Cars (Cars), and FGVC-Aircraft (Aircraft). Model CUB ResNet - 50 CAR ResNeXt - 50 AIR DenseNet - 161 ResNeXt - 101 Table 2. Compare the results with the typical state-of-the-art. The CNN backbone is ResNet-50. CUB CAR AIR Table 3. Following the approach (Kang et al., 2020) on ImageNet- LT, the proposed ACE gains a significant improvement. Total Median Few Many Table 4. The comparison with some recent stat-of-the-art works Total Median Few Many on the iNaturalist 2018 .","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"FGVC Aircraft\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"93.5%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Stanford Cars\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"94.8%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"CUB-200-2011\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"89.2%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CUB-200-2011\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"89.6%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"iNaturalist\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"75.3%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"CUB-200-2011\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"96%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"FGVC Aircraft\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"94.5%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Stanford Cars\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.63%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"CUB-200-2011\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"88.1%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"FGVC Aircraft\\", \\"Metric\\": "},{"Context":"CommunityGAN: Community Detection with Generative Adversarial Nets Community detection refers to the task of discovering groups of vertices sharing similar properties or functions so as to understand the network data. With the recent development of deep learning, graph representation learning techniques are also utilized for community detection. However, the communities can only be inferred by applying clustering algorithms based on learned vertex embeddings. These general cluster algorithms like K-means and Gaussian Mixture Model cannot output much overlapped communities, which have been proved to be very common in many real-world networks. In this paper, we propose CommunityGAN, a novel community detection framework that jointly solves overlapping community detection and graph representation learning. First, unlike the embedding of conventional graph representation learning algorithms where the vector entry values have no specific meanings, the embedding of CommunityGAN indicates the membership strength of vertices to communities. Second, a specifically designed Generative Adversarial Net (GAN) is adopted to optimize such embedding. Through the minimax competition between the motif-level generator and discriminator, both of them can alternatively and iteratively boost their performance and finally output a better community structure. Extensive experiments on synthetic data and real-world tasks demonstrate that CommunityGAN achieves substantial community detection performance gains over the state-of-the-art methods. In this section, in order to evaluate the effectiveness of Commu-nityGAN, we conduct a series of experiments based on synthetic datasets The The availability of ground-truth communities allows us to quantitatively evaluate the performance of community detection algorithms Table 2: The occurrence probability of cliques for vertices sampled from all vertices or from one community. R: from all vertices. C: from one community. Dataset 3 - Clique C 2 - Clique 4 - Clique Table 4: Synthetic Graphs statistics. V : number of vertices, E: number of edges, C: number of communities, A: average number of community memberships per vertex, P: percent- age of communities that have overlapping with others 100% age of communities that have overlapping with others A Table 4 : Synthetic Graphs statistics . V : number of vertices , Table 4. We can see that the percentages of overlapped communities (denoted by P) are all 100%, indicating that all the communities overlap more or less with others. Besides, with the decrease of \u03b2 1 and \u03b2 2 , the average number of community memberships per vertex (denoted by A) increases, which means the density of","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Community Detection\\", \\"Dataset\\": \\"Amazon\\", \\"Metric\\": \\"F1-score\\", \\"Score\\": \\"0.091\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Community Detection\\", \\"Dataset\\": \\"DBLP\\", \\"Metric\\": \\"F1-Score\\", \\"Score\\": \\"0.153\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Community Detection\\", \\"Dataset\\": \\"Commons\\", \\"Metric\\": \\"Evg F1\\", \\"Score\\": \\"Commons\\"}} ]"},{"Context":"Adaptive Dynamics of Realistic Small-World Networks Continuing in the steps of Jon Kleinberg\'s and others celebrated work on decentralized search in small-world networks, we conduct an experimental analysis of a dynamic algorithm that produces small-world networks. We find that the algorithm adapts robustly to a wide variety of situations in realistic geographic networks with synthetic test data and with real world data, even when vertices are uneven and non-homogeneously distributed.We investigate the same algorithm in the case where some vertices are more popular destinations for searches than others, for example obeying power-laws. We find that the algorithm adapts and adjusts the networks according to the distributions, leading to improved performance. The ability of the dynamic process to adapt and create small worlds in such diverse settings suggests a possible mechanism by which such networks appear in nature.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Cross-lingual Entity Alignment with Incidental Supervision Much research effort has been put to multilingual knowledge graph (KG) embedding methods to address the entity alignment task, which seeks to match entities in different languagespecific KGs that refer to the same real-world object. Such methods are often hindered by the insufficiency of seed alignment provided between KGs. Therefore, we propose an incidentally supervised model, JEANS , which jointly represents multilingual KGs and text corpora in a shared embedding scheme, and seeks to improve entity alignment with incidental supervision signals from text. JEANS first deploys an entity grounding process to combine each KG with the monolingual text corpus. Then, two learning processes are conducted: (i) an embedding learning process to encode the KG and text of each language in one embedding space, and (ii) a selflearning based alignment learning process to iteratively induce the matching of entities and that of lexemes between embeddings. Experiments on benchmark datasets show that JEANS leads to promising improvement on entity alignment with incidental supervision, and significantly outperforms state-of-the-art methods that solely rely on internal information of KGs. 1 In this section, we evaluate JEANS on two benchmark datasets for cross-lingual entity alignment, and compare against a wide selection of recent baseline methods Table 1: Entity alignment results. Baselines are separated in accord with the three groups described in Section 4.1. \u2020 indicates results obtained from (Sun et al., 2020a), and \u2021 indicates those from (Pei et al., 2019b). Results of KECG, GCN-JE, MMR, HMAN, KDCoE and NAEA are from original papers. Hyphens denote not available. MRR were not reported by GCN-JE, MMR and HMAN. Top results (incl. w/ and w/o seed lexicon) are boldfaced. Note that results by GCN-JE, GMN and HMAN are reported only for the versions where the extra cross-lingual alignment information (such as machine translation) is removed, so as to conduct fair comparison with all the rest models that are trained using only the alignment labels in the benchmark training sets. \u2212 \u2212 Table 2: The ablation study results for components of JEANS based on DBP15k En\u2212F r and DBP15k En\u2212Ja . Note that the additional seed lexicon is not","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Alignment\\", \\"Dataset\\": \\"DBP15k zh-en\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.719\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Entity Alignment\\", \\"Dataset\\": \\"DBP15k zh-en\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"83.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Entity Alignment\\", \\"Dataset\\": \\"DBP15k zh-en\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"83.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Entity Alignment\\", \\"Dataset\\": \\"dbp15k ja-en\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"80.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Entity Alignment\\", \\"Dataset\\": \\"dbp15k fr-en\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"8370\\"}} ]"},{"Context":"Unsupervised Learning using Pretrained CNN and Associative Memory Bank Deep Convolutional features extracted from a comprehensive labeled dataset, contain substantial representations which could be effectively used in anew domain. Despite the fact that generic features achieved good results in many visual tasks, fine-tuning is required for pretrained deep CNN models to be more effective and provide state-of-the-art performance. Fine tuning using the backpropagation algorithm in a supervised setting, is a time and resource consuming process. In this paper, we present anew architecture and an approach for unsupervised object recognition that addresses the above mentioned problem with fine tuning associated with pretrained CNN-based supervised deep learning approaches while allowing automated feature extraction. Unlike existing works, our approach is applicable to general object recognition tasks. It uses a pretrained (on a related domain) CNN model for automated feature extraction pipelined with a Hopfield network based associative memory bank for storing patterns for classification purposes. The use of associative memory bank in our framework allows eliminating backpropagation while providing competitive performance on an unseen dataset. The experiments focus on three popular object classification datasets: Caltech101, Caltech256, and CIFAR-10 We start with the details of these datasets and then we contrast the results obtained using our framework with the state-of-the-art The images in the dataset vary in the degree of shape and scale 1000 images from each class have been randomly selected creating a test dataset of 10000 images and the remaining were used for training We first evaluate the performance of our framework with respect to the number of core patterns The results shown in are based on the Caltech101, Caltech256, and CIFAR-10 datasets from ResNet-50 and VGG-16 models It also showed similar behavior on Caltech256 and CIFAR-10 datasets but relatively more stable after increasing initially The confusion matrix for CIFAR-10 dataset is shown in Since Caltech101 and Caltech256 datasets have a large number of categories compared to the CIFAR-10 dataset, instead of computing the confusion","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"Caltech-256 5-way (1-shot)\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"74.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Few-Shot Image Classification\\", \\"Dataset\\": \\"CIFAR100 5-way (1-shot)\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"89.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"83.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Caltech-101\\", \\"Metric\\": \\"Top-1 Error Rate\\", \\"Score\\": \\"91.00%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"Caltech-256, 1024 Labels\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"77.40%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"Caltech-101, 202 Labels\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"91.00%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"CIFAR-10, 40 Labels\\", \\"Metric\\": \\"Percentage error\\", \\"Score\\": \\"16.90\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"Caltech-256\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"77.40%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"Caltech-101\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"91.00%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Percentage correct\\", \\"Score\\": \\"74.9\\"}} ]"},{"Context":"GRAPH WAVELET NEURAL NETWORK We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed. To evaluate the proposed GWNN, we apply GWNN on semi-supervised node classification, and conduct experiments on three benchmark datasets, namely, Cora, Citeseer and Pubmed In the three citation network datasets, nodes represent documents and edges are citation links Details of these datasets are demonstrated in Following the experimental setup of GCN (Kipf & Welling, 2017), we fetch 20 labeled nodes per class in each dataset to train the model We train a two-layer graph wavelet neural network with 16 hidden units, and prediction accuracy is evaluated on a test set of 1000 labeled samples The partition of datasets is the same as GCN (Kipf & Welling, 2017) with an additional validation set of 500 labeled samples to determine hyper-parameters Table 1. Here, the label rate denotes the proportion of labeled nodes used for training. Following the experimental setup of GCN (Kipf & Welling, 2017), we fetch 20 labeled nodes per class in each dataset to train the model. Table 1 : The Statistics of Datasets Label Rate Table 1: The Statistics of Datasets Table 1 : The Statistics of Datasets Label Rate Table 2: Results of Detaching Feature Transformation from Convolution Citeseer Table 2 : Results of Detaching Feature Transformation from Convolution Cora Pubmed Table 3: Results of Node Classification Citeseer 81 . 7\xb10 . 5% 78 . 8\xb10 . 3% Table 3 : Results of Node Classification Cora Pubmed - Table 4: Statistics of wavelet transform and Fourier transform on Cora Transform Matrix Projected Signal Statistical Property 205 , 774 wavelet transform Number of Non - zero Elements Fourier transform Table 4 : Statistics of wavelet transform and Fourier","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Citeseer\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"71.7%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Pubmed\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"79.1%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Cora\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"81.6%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Citeseer\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"71.2%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Pubmed\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"83.5%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"Cora\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"84.3%\\"}} ]"},{"Context":"A Novel Bi-hemispheric Discrepancy Model for EEG Emotion Recognition The neuroscience study [1] has revealed the discrepancy of emotion expression between left and right hemispheres of human brain. Inspired by this study, in this paper, we propose a novel bi-hemispheric discrepancy model (BiHDM) to learn the asymmetric differences between two hemispheres for electroencephalograph (EEG) emotion recognition. Concretely, we first employ four directed recurrent neural networks (RNNs) based on two spatial orientations to traverse electrode signals on two separate brain regions, which enables the model to obtain the deep representations of all the EEG electrodes\' signals while keeping the intrinsic spatial dependence. Then we design a pairwise subnetwork to capture the discrepancy information between two hemispheres and extract higher-level features for final classification. Besides, in order to reduce the domain shift between training and testing data, we use a domain discriminator that adversarially induces the overall feature learning module to generate emotion-related but domain-invariant feature, which can further promote EEG emotion recognition. We conduct experiments on three public EEG emotional datasets, and the experiments show that the new state-of-the-art results can be achieved. To evaluate the proposed BiHDM model, in this section, we will conduct experiments on three public EEG emotional datasets All the three datasets were collected when the participants satin front of a monitor comfortably and watched emotional video clips The detailed information of these datasets are described as follows: (1) SEED SEED dataset contains 15 subjects, and each subject has three sessions SEED-IV dataset also contains 15 subjects, and each subject has three sessions MPED dataset contains 30 subjects and each subject has one session To evaluate the proposed BiHDM model adequately, we design two kinds of experiments including the subject-dependent and subject-independent ones Thus the sizes d \xd7 N of the input sample X tare 5 \xd7 62, 5 \xd7 62 and 1 \xd7 62 for these three datasets, respectively The mean accuracy (ACC) and standard deviation (STD) are used as the final evaluation metrics for all the subjects in","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"EEG\\", \\"Dataset\\": \\"SEED-IV\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"74.35\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Emotion Recognition\\", \\"Dataset\\": \\"MPED\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"40.34\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Emotion Recognition\\", \\"Dataset\\": \\"SEED-IV\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"56.61\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Emotion Recognition\\", \\"Dataset\\": \\"SEED-IV\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"79.37\\"}} ]"},{"Context":"Automated Synthesis of Assertion Monitors using Visual Specifications properties plays a significant role in assertion-based verification. We present here a methodology to synthesize assertion monitors from visual specifications given in CESC (Clocked Event Sequence Chart). CESC is a visual language designed for specifying system level interactions involving single and multiple clock domains. It has well-defined graphical and textual syntax and formal semantics based on synchronous language paradigm enabling formal analysis of specifications. In this paper we provide an overview of CESC language with few illustrative examples. The algorithm for automated synthesis of assertion monitors from CESC specifications is described. A few examples from standard bus protocols (OCP-IP and AMBA) are presented to demonstrate the application of monitor synthesis algorithm.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"SiamVGG: Visual Tracking using Deeper Siamese Networks Recently, we have seen a rapid development of Deep Neural Network (DNN) based visual tracking solutions. Some trackers combine the DNN-based solutions with Discriminative Correlation Filters (DCF) to extract semantic features and successfully deliver the state-of-the-art tracking accuracy. However, these solutions are highly compute-intensive, which require long processing time, resulting unsecured real-time performance. To deliver both high accuracy and reliable real-time performance, we propose a novel tracker called SiamVGG 1 . It combines a Convolutional Neural Network (CNN) backbone and a cross-correlation operator, and takes advantage of the features from exemplary images for more accurate object tracking. The architecture of SiamVGG is customized from VGG-16, with the parameters shared by both exemplary images and desired input video frames. We demonstrate the proposed SiamVGG on OTB-2013/50/100 and VOT 2015/2016/2017 datasets with the state-ofthe-art accuracy while maintaining a decent real-time performance of 50 FPS running on a GTX 1080Ti. Our design can achieve 2% higher Expected Average Overlap (EAO) compared to the ECO [1] and C-COT [2] in VOT2017 Challenge. In this section, we first start an ablation study of our proposed SiamVGG on OTB100 dataset and then we demonstrate our approach in six different public datasets with the state-of-the-art performance Thus, we introduce the Youtube-BB dataset including more than 100,000 videos annotated once in every 30 frames for more training material By combining these two datasets in a particular ratio, the performance of our design has improved from 0.637 to 0.654 (AUC of success plots for OPE) in OTB-100 Table 1. The backbone architecture of SiamVGG\'s. All the convolutional layers are integrated with ReLU except the last one working for generating outputs. \'MP\' stands for the maxpooling layer. The channel map indicates the number of output and input channels using the format outputchannel \xd7 inputchannel. 57 \xd7 57 125 \xd7 125 Stride Chan . Map 25 \xd7 25 28 \xd7 28 22 \xd7 22 127 \xd7 127 123 \xd7 123 23 \xd7 23 26 \xd7 26 Activation Size 24 \xd7 24 21 \xd7 21 For Exemplar 61 \xd7 61 59 \xd7 59 11 \xd7 11 Kernel Size Table 2. AUC value for recently published real-time trackers using Siamese networks. Datas highlighted in red , blue, and green color stand for the first, second, and third place of each benchmarks, respectively. OTB - 2013 OTB - 50 OTB - 100 - Table 3. We compare our tracker to top 10 trackers","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Object Tracking\\", \\"Dataset\\": \\"OTB-2013\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.665\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Object Tracking\\", \\"Dataset\\": \\"OTB-50\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.61\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Object Tracking\\", \\"Dataset\\": \\"OTB-2015\\", \\"Metric\\": \\"AUC\\", \\"Score\\": \\"0.654\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Object Tracking\\", \\"Dataset\\": \\"VOT2016\\", \\"Metric\\": \\"Expected Average Overlap (EAO)\\", \\"Score\\": \\"0.351\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Visual Object Tracking\\", \\"Dataset\\": \\"VOT2017\\", \\"Metric\\": \\"Expected Average Overlap (EAO)\\", \\"Score\\": \\"0.286\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Visual Object Tracking\\", \\"Dataset\\": \\"VOT2017/18\\", \\"Metric\\": \\"Expected Average Overlap (EAO)\\", \\"Score\\": \\"0.337\\"}} ]"},{"Context":"Dilated SpineNet for Semantic Segmentation Scale-permuted networks have shown promising results on object bounding box detection and instance segmentation. Scale permutation and cross-scale fusion of features enable the network to capture multi-scale semantics while preserving spatial resolution. In this work, we evaluate this meta-architecture design on semantic segmentationanother vision task that benefits from high spatial resolution and multi-scale feature fusion at different network stages. By further leveraging dilated convolution operations, we propose SpineNet-Seg, a network discovered by NAS that is searched from the DeepLabv3 system. SpineNet-Seg is designed with a better scale-permuted network topology with customized dilation ratios per block on a semantic segmentation task. SpineNet-Seg models outperform the DeepLabv3/v3+ baselines at all model scales on multiple popular benchmarks in speed and accuracy. In particular, our SpineNet-S143+ model achieves the new state-ofthe-art on the popular Cityscapes benchmark at 83.04% mIoU and attained strong performance on the PASCAL VOC2012 benchmark at 85.56% mIoU. SpineNet-Seg models also show promising results on a challenging Street View segmentation dataset. Code and checkpoints will be opensourced.semantic segmentation as the pixel-wise classification task benefits from detailed spatial information and aggregation of features from multiple scales.To solve these problems, researches have proposed better network operations and architecture designs. The dilated convolution operator [29,48,3,4,5,6] is one of the most popular methods that overcome the challenge of preserving feature resolution. The \'convolution with holes\' design allows the network to use upsampled convolution kernels to extract abstract semantics without reducing feature resolution. Recently, scale-permuted networks discovered by neural architecture search (NAS) [14,13] have shown promising results on the task of object detection. Scale permutation for the intermediate building blocks enables the network to capture strong semantics and retain high feature resolution throughout network stages. Cross-scale feature fusion aggregates multi-scale semantics that helps the network to recognize objects at different scales. We evaluate our Spinenet-Seg models on the PASCAL VOC2012 benchmark, the Cityscapes benchmark and a challenging large-scale Street View dataset For pretraining, we use ImageNet and COCO datasets Search dataset is important since the evaluation signals influence the quality of the searched architectures For instance, performance on the PASCAL VOC2012 dataset depends heavily on the quality of the pretrained checkpoint, hence it is difficult to use for NAS that trains proxty tasks from scratch We decide to use COCO dataset since it is diverse, and unlike Cityscapes it has significantly smaller images Training proxy tasks from scratch using the COCO dataset usually converges, and eval signals can be used as stable rewards to update the NAS controller Table 1. A performance comparison of the original DeepLabv3+ ResNet-50 backbone that downsamples at the end of each stage and our modified ResNet-S50 backbone that downsamples at the beginning of each stage. Results are reported with the DeepLabv3+ system on the PASCAL VOC2012 val dataset. mIoU Table 2. Learned network configurations for the SpineNet-S49 architecture. We show the detailed configurations for each block for the search space components described in Section 3.1. BP: block permutation. CC: cross-scale connection. LA: level adjust- ment. DR: dilation ratio. FD: feature dimension. {3\xd7L as ResNet - 50 / 101 / 152 S50 ) , while we refer to the original DeepLabv3+ backbones L beginning of each stage . This saves proposes to downsample the features at the end of each net - the effect of such a modification is shown in Tab . 1 . We 9\xd7L We take two 30% of the computa -","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"83.04%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL VOC 2012 val\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"85.64%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"82.6%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL VOC 2012 test\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"89.2%\\"}} ]"},{"Context":"Weakly-and Semi-Supervised Panoptic Segmentation We present a weakly supervised model that jointly performs both semantic-and instance-segmentation -a particularly relevant problem given the substantial cost of obtaining pixel-perfect annotation for these tasks. In contrast to many popular instance segmentation approaches based on object detectors, our method does not predict any overlapping instances. Moreover, we are able to segment both \\"thing\\" and \\"stuff\\" classes, and thus explain all the pixels in the image. \\"Thing\\" classes are weakly-supervised with bounding boxes, and \\"stuff\\" with image-level tags. We obtain state-of-the-art results on Pascal VOC, for both full and weak supervision (which achieves about 95% of fullysupervised performance). Furthermore, we present the first weakly-supervised results on Cityscapes for both semantic-and instance-segmentation. Finally, we use our weakly supervised framework to analyse the relationship between annotation quality and predictive performance, which is of interest to dataset creators. Datasets and weak supervision We evaluate on two standard segmentation datasets, Pascal VOC and Cityscapes Following common practice on this dataset, we utilise additional images from the SBD dataset to obtain a training set of 10582 images We evaluate on the validation set, of 1449 images, as the evaluation server is not available for instance segmentation However, we increased the threshold to 50% to obtain higher precision on this more cluttered dataset Moreover, our fullysupervised instance segmentation model outperforms all previous work on this dataset Table 1. Comparison of semantic segmentation performance to recent methods using only weak, bounding-box supervision on Pascal VOC. Note that [12] and [11] use the less accurate VGG network, whilst we and [43] use ResNet-101. \\"FS%\\" denotes the percentage of fully-supervised performance. With COCO annotations Without COCO annotations Validation set FS% IoU ( full ) IoU ( weak ) Test set - Table 2. Comparison of instance segmentation performance to recent (fully-and weakly- supervised) methods on the VOC 2012 validation set. Weakly supervised without COCO Weakly supervised with COCO Fully supervised without COCO Fully supervised with COCO - PQ vol Method - AP r Table 3. Semantic-and instance-segmentation performance on Pascal VOC with varying lev- els of supervision from the Pascal and COCO datasets. The former is measured by the IoU, and latter by the AP r vol and PQ. PQ vol Dataset COCO IoU AP r Table 4. Semantic segmentation","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"28.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"PQ\\", \\"Score\\": \\"53.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"PQst\\", \\"Score\\": \\"62.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"PQth\\", \\"Score\\": \\"42.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Panoptic Segmentation\\", \\"Dataset\\": \\"Cityscapes val\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"79.8\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"81.3%\\"}} ]"},{"Context":"Bilevel Online Adaptation for Out-of-Domain Human Mesh Reconstruction This paper considers anew problem of adapting a pretrained model of human mesh reconstruction to out-ofdomain streaming videos. However, most previous methods based on the parametric SMPL model [36] underperform in new domains with unexpected, domain-specific attributes, such as camera parameters, lengths of bones, backgrounds, and occlusions. Our general idea is to dynamically finetune the source model on test video streams with additional temporal constraints, such that it can mitigate the domain gaps without over-fitting the 2D information of individual test frames. A subsequent challenge is how to avoid conflicts between the 2D and temporal constraints. We propose to tackle this problem using anew training algorithm named Bilevel Online Adaptation (BOA), which divides the optimization process of overall multi-objective into two steps of weight probe and weight update in a training iteration. We demonstrate that BOA leads to state-of-the-art results on two human mesh reconstruction benchmarks 1 . * Equal contribution \u2020 Corresponding authors: Yunbo Wang, Bingbing Ni 1 The project website with code, supplementary materials and video results is at https://sites.google.com/view/humanmeshboa Domain Gap Camera Height (m) Bone Length (m) Focal Length (pixel) Datasets We use the Human3.6M dataset for training the source model and learn to adapt the model to the 3DHP and 3DPW datasets presents the statistics of typical domain gaps among these datasets \u2022 3DHP is the test split of the MPI-INF-3DHP dataset Evaluation metrics Following previous works, we evaluate our model in terms of Mean Per Joint Position Error (MPJPE), Procrustes-Aligned MPJPE (PA-MPJPE), and the Percentage of Correct Keypoints (PCK) with a threshold of 150mm on 3DHP presents atypical showcase of mesh reconstruction on the challenging 3DPW dataset Table 1. Typical domain gaps among datasets in terms of focal length, bone length, camera distance, and camera height [57]. Human3 . 6M dataset and take 3DPW and 3DHP as test sets . 3DPW 3DHP We first train the base model M on the collected Focal len . ( pixel ) H3 . 6M Table 2. Results on 3DPW, including end-to-end approaches (top) and those fine-tuned on the target domain (middle). Figure 4 . A qualitative comparison of mesh reconstruction on 3DPW streaming data . We zoom in on the limbs for better visualization . - PA - MPJPE VIBE MPJPE Table 3. Different protocols of pre-processing the 3DPW data by SPIN does not require access to the training set . In addition , we do PA - MPJPE PCK Method MPJPE Table 4. Results on 3DHP. All models but BOA are trained on the training split of MPI-INF-3DHP, while BOA","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3DPW\\", \\"Metric\\": \\"MPJPE\\", \\"Score\\": \\"77.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3DPW\\", \\"Metric\\": \\"PA-MPJPE\\", \\"Score\\": \\"49.5\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3DPW\\", \\"Metric\\": \\"MPJPE\\", \\"Score\\": \\"69.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3DPW\\", \\"Metric\\": \\"MPVPE\\", \\"Score\\": \\"82.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3DPW\\", \\"Metric\\": \\"PA-MPJPE\\", \\"Score\\": \\"67.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"3DPW\\", \\"Metric\\": \\"acceleration error\\", \\"Score\\": \\"6.8\\"}} ]"},{"Context":"LFFD: A Light and Fast Face Detector for Edge Devices Face detection, as a fundamental technology for various applications, is always deployed on edge devices which have limited memory storage and low computing power. This paper introduces a Light and Fast Face Detector (LFFD) for edge devices. The proposed method is anchorfree and belongs to the one-stage category. Specifically, we rethink the importance of receptive field (RF) and effective receptive field (ERF) in the background of face detection. Essentially, the RFs of neurons in a certain layer are distributed regularly in the input image and theses RFs are natural \\"anchors\\". Combining RF \\"anchors\\" and appropriate RF strides, the proposed method can detect a large range of continuous face scales with 100% coverage in theory. The insightful understanding of relations between ERF and face scales motivates an efficient backbone for onestage detection. The backbone is characterized by eight detection branches and common layers, resulting in efficient computation. Comprehensive and extensive experiments on popular benchmarks: WIDER FACE and FDDB are conducted. A new evaluation schema is proposed for application-oriented scenarios. Under the new schema, the proposed method can achieve superior accuracy (WIDER FACE Val/Test -Easy: 0.910/0.896, Medium: 0.881/0.865, Hard: 0.780/0.770; FDDB -discontinuous: 0.973, continuous: 0.724). Multiple hardware platforms are introduced to evaluate the running efficiency. The proposed method can obtain fast inference speed ( NVIDIA TITAN Xp: 131.45 FPS at 640\xd7480; NVIDIA TX2: 136.99 PFS at 160\xd7120; Raspberry Pi 3 Model B+: 8.44 FPS at 160\xd7120) with model size of 9 MB. Firstly, anew evaluation schema is proposed and the evaluation results on benchmarks are presented In this subsection, anew evaluation schema is described at the beginning SIO is proposed to reform the evaluation procedure for real-world applications The conventional evaluation procedure involves some tricky means, such as flips and image pyramids, for achieving higher accuracy We evaluate all methods on two benchmarks: FDDB and WDIER FACE FDDB dataset We show final evaluation results of LFFD on FDDB against above five methods in WIDER FACE dataset Table 1. Accuracy of the top-5 methods on validation set of WIDER FACE. Method Easy Subset Medium Hard","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Face Detection\\", \\"Dataset\\": \\"FDDB\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"0.973\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Detection\\", \\"Dataset\\": \\"WIDER Face (Hard)\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"0.770\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Detection\\", \\"Dataset\\": \\"WIDER Face (Medium)\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"0.865\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Detection\\", \\"Dataset\\": \\"WIDER Face (Easy)\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"0.896\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Face Detection\\", \\"Dataset\\": \\"FDDB\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"0.901\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Detection\\", \\"Dataset\\": \\"WIDER Face (Hard)\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"0.876\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Detection\\", \\"Dataset\\": \\"WIDER Face (Medium)\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"0.931\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Detection\\", \\"Dataset\\": \\"WIDER Face (Easy)\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"0.943\\"}} ]"},{"Context":"Analytical correlation of routing table length index and routing path length index in hierarchical routing model In Kleinrock and Kamoun\'s paper, the inverse relation of routing table length index and routing path length index in hierarchical routing model is illustrated. In this paper we give the analytical correlation of routing table length index and routing path length index in hierarchical routing model.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Student-Teacher Feature Pyramid Matching for Unsupervised Anomaly Detection Anomaly detection is a challenging task and usually formulated as an unsupervised learning problem for the unexpectedness of anomalies. This paper proposes a simple yet powerful approach to this issue, which is implemented in the student-teacher framework for its advantages but substantially extends it in terms of both accuracy and efficiency. Given a strong model pre-trained on image classification as the teacher, we distill the knowledge into a single student network with the identical architecture to learn the distribution of anomaly-free images and this one-step transfer preserves the crucial clues as much as possible. Moreover, we integrate the multi-scale feature matching strategy into the framework, and this hierarchical feature alignment enables the student network to receive a mixture of multi-level knowledge from the feature pyramid under better supervision, thus allowing to detect anomalies of various sizes. The difference between feature pyramids generated by the two networks serves as a scoring function indicating the probability of anomaly occurring. Due to such operations, our approach achieves accurate and fast pixel-level anomaly detection. Very competitive results are delivered on three major benchmarks, significantly superior to the state of the art ones. In addition, it makes inferences at a very high speed (with 100 FPS for images of the size at 256\xd7256), at least dozens of times faster than the latest counterparts. To evaluate the effectiveness of our method, we first conduct experiments on the MVTec Anomaly Detection (MVTec-AD) dataset Our method is then applied to the ShanghaiTech Campus (STC) dataset for unsupervised anomaly pixel-level detection and the CIFAR-10 dataset for one-class classification To strike a balance between detection accuracy and efficiency, we resize all images in the MVTec-AD and STC datasets to 256\xd7256 For instance, flipped metal nut in the MvTec-AD dataset is regraded as anomalous product Evaluation Metrics Our method is first evaluated on the MVTec-AD dataset, which is specifically created to benchmark algorithms for unsupervised detection of anomalous regions This makes the MVTec-AD dataset more challenging than those previously used in the literature (e.g., MNIST and CIFAR-10) where anomalous images come from other different categories Pixel-precise anomaly detection on the MvTec-AD dataset We further evaluate our method for pixel-level anomaly detection on the STC dataset This dataset is originally created Table 1. Image-level anomaly detection on the MvTec-AD dataset. The performance is measured by average AUC-ROC across 15 cat- egories. The best results are highlighted by boldface. Results for all approaches except ours are quoted from [11]. Ours SPADE Geom GANomaly ITAE 2 - AE Table 2. Pixel-precise anomaly detection on the MvTec-AD dataset. The performance is measured by the pixel-level AUC- ROC for each category. The best results are highlighted in bold- face. Results for all approaches except ours are quoted from Ours SPADE CNN - Dict SSIM - AE AnoGAN Table 3. Pixel-level anomaly detection on the MvTec-AD dataset. The performance is measured by the normalized area under the Per- Region-Overlap (PRO) curve up to an average false positive rate (FPR) of 30% for each category. The best results are highlighted in boldface. Results for all approaches except ours are quoted from STAD Ours K - means SPADE CNN","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Anomaly Detection\\", \\"Dataset\\": \\"MVTec AD\\", \\"Metric\\": \\"Detection AUROC\\", \\"Score\\": \\"95.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Anomaly Detection\\", \\"Dataset\\": \\"MVTec AD\\", \\"Metric\\": \\"Segmentation AUROC\\", \\"Score\\": \\"97.0\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Anomaly Detection\\", \\"Dataset\\": \\"MVTec AD\\", \\"Metric\\": \\"Detection AUROC\\", \\"Score\\": \\"95.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Anomaly Detection\\", \\"Dataset\\": \\"MVTec AD\\", \\"Metric\\": \\"Segmentation AUROC\\", \\"Score\\": \\"95.9\\"}} ]"},{"Context":"Unsupervised Training for 3D Morphable Model Regression We present a method for training a regression network from image pixels to 3D morphable model coordinates using only unlabeled photographs. The training loss is based on features from a facial recognition network, computed onthe-fly by rendering the predicted faces with a differentiable renderer. To make training from features feasible and avoid network fooling effects, we introduce three objectives: a batch distribution loss that encourages the output distribution to match the distribution of the morphable model, a loopback loss that ensures the network can correctly reinterpret its own output, and a multi-view identity loss that compares the features of the predicted 3D face and the input photograph from multiple viewing angles. We train a regression network using these objectives, a set of unlabeled photographs, and the morphable model itself, and demonstrate state-of-the-art results. nition network [25] into identity parameters for the Basel 2017 Morphable Face Model [8].to-image autoencoder with a fixed, morphable-model-based decoder and an image-based loss [28]. This paper presents a method for training a regression network that removes both the need for supervised training data and the reliance on inverse rendering to reproduce image pixels. Instead, the network learns to minimize a loss based on the facial identity features produced by a face recognition network such as VGG-Face [17] or Google\'s FaceNet [25]. These features are robust to pose, expression, lighting, and even non-photorealistic inputs. We exploit this 1 arXiv:1806.06098v1 [cs.CV] We then evaluate our method quantitatively by comparing reconstruction error against scanned 3D face geometry (Sec Results on the MoFA-Test dataset Table 1. Mean Error on MICC Dataset using point-to-plane dis- tance after ICP alignment of video-averaged outputs with isotropic scale estimation. Our errors lower on average and in variance, both within individual subjects and as conditions change. Mean Cooperative Std . Outdoor Indoor Mean Std . Table 2. Earth mover\'s distance between distributions of VGG- Face \u03c6( t) similarity and distributions of same and different iden- tities on LFW. A low distance for \\"Same\\" means the similarity scores between a photo and its associated 3D rendering are close to the scores of same identity photos in LFW, while a low distance for \\"Diff.\\" means the scores are close to the scores of different identity photos. ters were fixed for all renderings . Same Diff . MICC MoFA - T Figure 5 . Distributions of cosine similarity between VGG - Face LFW Table 3. Identity Clustering Recall using VGG-Face distances on MoFA-Test","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"3D Face Reconstruction\\", \\"Dataset\\": \\"Florence\\", \\"Metric\\": \\"Average 3D Error\\", \\"Score\\": \\"1.50\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Human Pose Estimation\\", \\"Dataset\\": \\"Human3.6M\\", \\"Metric\\": \\"Average MPJPE (mm)\\", \\"Score\\": \\"65.6\\"}} ]"},{"Context":"Unsupervised Image-to-Image Translation Networks Unsupervised image-to-image translation aims at learning a joint distribution of images in different domains by using images from the marginal distributions in individual domains. Since there exists an infinite set of joint distributions that can arrive the given marginal distributions, one could infer nothing about the joint distribution from the marginal distributions without additional assumptions. To address the problem, we make a shared-latent space assumption and propose an unsupervised image-to-image translation framework based on Coupled GANs. We compare the proposed framework with competing approaches and present high quality image translation results on various challenging unsupervised image translation tasks, including street scene image translation, animal image translation, and face image translation. We also apply the proposed framework to domain adaptation and achieve state-of-the-art performance on benchmark datasets. Code and additional results are available in https://github.com/mingyuliutw/unit. We used the map dataset (visualized in), which contained corresponding pairs of images in two domains (satellite image and map) useful for quantitative evaluation We did not evaluate the translation from maps to images since the translation was multi-modal, which was difficult to construct a proper evaluation metric In, we showed several example results achieved by applying the proposed framework to translate images between the synthetic images in the SYNTHIA dataset and the real images in the Cityscape dataset We used the images of Husky, German Shepherd, Corgi, Samoyed, and Old English Sheep dogs in the ImageNet dataset to learn to translate dog images between different breeds We also used the images of house cat, tiger, lion, cougar, leopard, jaguar, and cheetah in the ImageNet dataset to learn to translate cat images between different species We used the CelebA dataset for attribute-based face images translation Each face image in the dataset Table 2: Unsupervised domain adaptation performance. The reported numbers are classification accuracies. DTN [ 26 ] SA [ 4 ] DANN [ 5 ] CoGAN UNIT ( proposed )","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Image-To-Image Translation\\", \\"Dataset\\": \\"Freiburg Forest Dataset\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"9.42\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Unsupervised Image-To-Image Translation\\", \\"Dataset\\": \\"Edge-to-Shoes\\", \\"Metric\\": \\"Diversity\\", \\"Score\\": \\"0.011\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Unsupervised Image-To-Image Translation\\", \\"Dataset\\": \\"Edge-to-Shoes\\", \\"Metric\\": \\"Quality\\", \\"Score\\": \\"37.4%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Unsupervised Image-To-Image Translation\\", \\"Dataset\\": \\"Cats-and-Dogs\\", \\"Metric\\": \\"CIS\\", \\"Score\\": \\"0.115\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Unsupervised Image-To-Image Translation\\", \\"Dataset\\": \\"Cats-and-Dogs\\", \\"Metric\\": \\"IS\\", \\"Score\\": \\"0.826\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Unsupervised Image-To-Image Translation\\", \\"Dataset\\": \\"EPFL NIR-VIS\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"15.33\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Unsupervised Image-To-Image Translation\\", \\"Dataset\\": \\"Edge-to-Handbags\\", \\"Metric\\": \\"Diversity\\", \\"Score\\": \\"0.023\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Unsupervised Image-To-Image Translation\\", \\"Dataset\\": \\"Edge-to-Handbags\\", \\"Metric\\": \\"Quality\\", \\"Score\\": \\"37.3%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"GTAV-to-Cityscapes Labels\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"43.2\\"}} ]"},{"Context":"FASTER EXPONENTIALS OF POWER SERIES We describe anew algorithm for computing exp f where f is a power series in C x . If M (n) denotes the cost of multiplying polynomials of degree n, the new algorithm costs (2.1666 . . . + o(1))M (n) to compute exp f to order n. This improves on the previous best result, namely (2.333 . . . + o(1))M (n).","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Mockingbird: Defending Against Deep-Learning-Based Website Fingerprinting Attacks with Adversarial Traces Website Fingerprinting (WF) is a type of traffic analysis attack that enables a local passive eavesdropper to infer the victim\'s activity even when the traffic is protected by encryption, a VPN, or an anonymity system like Tor. Leveraging a deep-learning classifier, a WF attacker can gain over 98% accuracy on Tor traffic. Existing WF defenses are either very expensive in terms of bandwidth and latency overheads (e.g. two-to-three times as large or slow) or ineffective against the latest attacks. In this paper, we explore a novel defense, Mockingbird, based on the idea of adversarial examples that have been shown to undermine machine-learning classifiers in other domains. Since the attacker gets to design his classifier based on the defense design, we first demonstrate that at least one technique for generating adversarial-example based traces fails to protect against an attacker using adversarial training for robust classification. We then propose Mockingbird, a technique for generating traces that resists adversarial training by moving randomly in the space of viable traces and not following more predictable gradients. The technique drops the accuracy of the state-of-the-art attack hardened with adversarial training from 98% to as low as 29% while incurring only 56% bandwidth overhead. The attack accuracy is generally lower than state-of-the-art defenses, and much lower when considering Top-2 accuracy, while incurring lower overheads inmost settings. In our experiments, we use burst sequences for both FD and HD datasets Full-Duplex (FD) : We use the FD traffic traces provided by Sirinam et al.Their dataset has 95 classes with 1000 instances each We also use the FD openworld (OW) dataset from Sirinam et al We process the OW dataset as well Half-Duplex (HD) : We use the HD dataset provided by Sirinam et al. This dataset contains 100 sites which are also from top 100 sites in Alexa.com [1], with 900 instances for each class We preprocess this dataset in the same way we processed FD dataset We also process OW dataset We use both of these HD closed-world (CW) and OW datasets for our HD evaluations In order to use these datasets for our defense, further preprocessing is required before we can use those in our models In consequence, we must determine an ideal size of input Table 1: Dataset Split: Adv Set & Detector Set. FD: Full-Duplex, HD: Half-Duplex, NC: Number of Classes, NI: Number of Instances, CW: Closed-World, OW: Open-World. Bandwidth 40 , 000 Adv Set A Total Case I OW Overhead Case II 40 , 716 ( NC \xd7 N I ) HD FD Table 2: The Evaluation of the Mockingbird against DF, AWF, CUMUL, k-FP, and k-NN Attacks & Comparison against WTF-PAD and W-T Defenses. S\xd7I: Sites\xd7Instances, BWO: Bandwidth Overhead, FD: Full-Duplex, HD: Half-Duplex. iterations . Bandwidth Case I k - NN [ 38 ] \u03b1 =7 DF [ 36 ] \u03b1 =5 k - FP [ 15 ] ( b ) Case II Number of Iterations 100 200 300 500 ( a ) Case I CUMUL [ 26 ] AWF [ 34 ] Overhead BWO Table 3: Top-2 Accuracy of DF Attack against Mocking- bird and W-T. FD: Full-duplex, HD: Half-Duplex. DF [","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Website Fingerprinting Defense\\", \\"Dataset\\": \\"Website Traffic Data on Tor\\", \\"Metric\\": \\"Accuracy (%)\\", \\"Score\\": \\"42\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Adversarial Defense\\", \\"Dataset\\": \\"ImageNet (non-targeted PGD, max perturbation=4)\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"7.0%\\"}} ]"},{"Context":"GRDN:Grouped Residual Dense Network for Real Image Denoising and GAN-based Real-world Noise Modeling Recent research on image denoising has progressed with the development of deep learning architectures, especially convolutional neural networks. However, real-world image denoising is still very challenging because it is not possible to obtain ideal pairs of ground-truth images and real-world noisy images. Owing to the recent release of benchmark datasets, the interest of the image denoising community is now moving toward the real-world denoising problem. In this paper, we propose a grouped residual dense network (GRDN), which is an extended and generalized architecture of the state-of-the-art residual dense network (RDN). The core part of RDN is defined as grouped residual dense block (GRDB) and used as a building module of GRDN. We experimentally show that the image denoising performance can be significantly improved by cascading GRDBs. In addition to the network architecture design, we also develop anew generative adversarial network-based real-world noise modeling method. We demonstrate the superiority of the proposed methods by achieving the highest score in terms of both the peak signal-to-noise ratio and the structural similarity in the NTIRE2019 Real Image Denoising Challenge -Track 2:sRGB. We used the training and validation images of NTIRE 2019 Real Image Denoising Challenge, which is a subset of SIDD dataset Let ChDB denote the dataset we used for our experiment Because the ground-truth images of the test dataset are not publicly available, we report the performance of image denoising models using the validation dataset in this Section Table 1: Comparison of image denoising models. Table 2: Performance comparison on the test dataset of NTIRE 2019 Real Image Denoising Challenge - Track2:sRGB. in the electronic version . ( b ) PSNR SSIM","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Color Image Denoising\\", \\"Dataset\\": \\"NTIRE 2019 Real Image Denoising Challenge (sRGB)\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"39.931743\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Color Image Denoising\\", \\"Dataset\\": \\"NTIRE 2019 Real Image Denoising Challenge (sRGB)\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.973589\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Denoising\\", \\"Dataset\\": \\"SIDD\\", \\"Metric\\": \\"PSNR (sRGB)\\", \\"Score\\": \\"39.28\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Denoising\\", \\"Dataset\\": \\"SIDD\\", \\"Metric\\": \\"SSIM (sRGB)\\", \\"Score\\": \\"0.956\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Denoising\\", \\"Dataset\\": \\"DND\\", \\"Metric\\": \\"PSNR (sRGB)\\", \\"Score\\": \\"39.38\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Denoising\\", \\"Dataset\\": \\"DND\\", \\"Metric\\": \\"SSIM (sRGB)\\", \\"Score\\": \\"0.952\\"}} ]"},{"Context":"ZHAI, WU: CLASSIFICATION IS A STRONG BASELINE FOR DEEP METRIC LEARNING Classification is a Strong Baseline for Deep Metric Learning Deep metric learning aims to learn a function mapping image pixels to embedding feature vectors that model the similarity between images. Two major applications of metric learning are content-based image retrieval and face verification. For the retrieval tasks, the majority of current state-of-the-art (SOTA) approaches are triplet-based nonparametric training. For the face verification tasks, however, recent SOTA approaches have adopted classification-based parametric training. In this paper, we look into the effectiveness of classification based approaches on image retrieval datasets. We evaluate on several standard retrieval datasets such as CAR-196, CUB-200-2011, Stanford Online  Product, and  In-Shop datasets for image retrieval and clustering, and establish that our classification-based approach is competitive across different feature dimensions and base feature networks. We further provide insights into the performance effects of subsampling classes for scalable classification-based training, and the effects of binarization, enabling efficient storage and computation for practical applications. We follow the same evaluation protocol commonly used in image retrieval tasks with the standard train/test split on four datasets: CARS-196, CUB-200-2011, Stanford Online Products (SOP), and In-shop Clothes Retrieval Finally in Section 4.6, we show that our method outperforms state-of-the-art methods on several retrieval datasets Table 1: Recall@K and NMI across standard retrieval tasks. All methods are trained using GoogleNet for a fair comparison. - 1 100 2 CUB - 200 4 SOP CARS - 196 8 NMI - 10 Table 2: Recall@K and NMI across standard retrieval tasks. All methods are trained using BNInception for a fair comparison - 1 100 2 CUB - 200 4 SOP CARS - 196 8 NMI 10 Table 3: Recall@K and NMI across standard retrieval tasks. All methods are trained using ResNet50 for a fair comparison BNInception for a fair comparison 1 100 2 CUB - 200 4 SOP CARS - 196 8 Table 2 : Recall@K and NMI across standard retrieval tasks . All methods are trained using NMI 10 Table 5: Recall@K on Stanford Online Products (SOP) and In-Shop. R -ResNet, G - GoogleNet, B -BNInception, \u2020 refers to refers to additional attention parameters, LMCL * is","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"SOP\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"79.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"CUB-200-2011\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"65.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"CARS196\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"89.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"In-Shop\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"89.4\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"SOP\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"84.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"In-Shop\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"91.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"CUB-200-2011\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"74.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"CARS196\\", \\"Metric\\": \\"R@1\\", \\"Score\\": \\"91.5\\"}} ]"},{"Context":"Action Recognition with Trajectory-Pooled Deep-Convolutional Descriptors Visual features are of vital importance for human action understanding in videos. This paper presents anew video representation, called trajectory-pooled deepconvolutional descriptor (TDD), which shares the merits of both hand-crafted features [31] and deep-learned features [24]. Specifically, we utilize deep architectures to learn discriminative convolutional feature maps, and conduct trajectory-constrained pooling to aggregate these convolutional features into effective descriptors. To enhance the robustness of TDDs, we design two normalization methods to transform convolutional feature maps, namely spatiotemporal normalization and channel normalization. The advantages of our features come from (i) TDDs are automatically learned and contain high discriminative capacity compared with those hand-crafted features; (ii) TDDs take account of the intrinsic characteristics of temporal dimension and introduce the strategies of trajectoryconstrained sampling and pooling for aggregating deeplearned features. We conduct experiments on two challenging datasets: HMDB51 and UCF101. Experimental results show that TDDs outperform previous hand-crafted features [31] and deep-learned features [24]. Our method also achieves superior performance to the state of the art on these datasets 1 . In this section, we first present the details of datasets and their evaluation scheme In order to verify the effectiveness of TDDs, we conduct experiments on two public large datasets, namely HMDB51 and UCF101 The HMDB51 dataset is a large collection of realistic videos from various sources, including movies and web videos The dataset is composed of 6, 766 video clips from 51 action categories, with each category containing at least 100 clips Our experiments follow the original evaluation scheme using three different training/testing splits The UCF101 dataset contains 101 action classes and there are at least 100 video clips for each class The whole dataset contains 13, 320 video clips, which are divided into 25 groups for each action category We follow the evaluation scheme of the THUMOS13 challenge and adopt the three training/testing splits for evaluation As UCF101 is larger than HMDB51, we use the UCF101 dataset to train Table 1. ConvNet Architectures. We use similar architectures to two-stream ConvNets 1 / 16 1 / 4 1 / 8 Table 3. Performance of TDD on the HMDB51 dataset and UCF101 dataset. We compare our proposed TDD with iDT features Table 2. The performance of different layers of spatial nets and temporal nets on the HMDB51 dataset. conv5 conv4 conv3 conv2 conv1 Spatial ConvNets Temporal ConvNets","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"UCF101\\", \\"Metric\\": \\"3-fold Accuracy\\", \\"Score\\": \\"91.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"HMDB-51\\", \\"Metric\\": \\"Average accuracy of 3 splits\\", \\"Score\\": \\"65.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Activity Recognition In Videos\\", \\"Dataset\\": \\"DogCentric\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"76.6\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"UCF101\\", \\"Metric\\": \\"3-fold Accuracy\\", \\"Score\\": \\"94.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"HMDB-51\\", \\"Metric\\": \\"Average accuracy of 3 splits\\", \\"Score\\": \\"71.5\\"}} ]"},{"Context":"Learning by cheating Vision-based urban driving is hard. The autonomous system needs to learn to perceive the world and act in it. We show that this challenging learning problem can be simplified by decomposing it into two stages. We first train an agent that has access to privileged information. This privileged agent cheats by observing the ground-truth layout of the environment and the positions of all traffic participants. In the second stage, the privileged agent acts as a teacher that trains a purely vision-based sensorimotor agent. The resulting sensorimotor agent does not have access to any privileged information and does not cheat. This two-stage training procedure is counter-intuitive at first, but has a number of important advantages that we analyze and empirically demonstrate. We use the presented approach to train a vision-based autonomous driving system that substantially outperforms the state of the art on the CARLA benchmark and the recent NoCrash benchmark. Our approach achieves, for the first time, 100% success rate on all tasks in the original CARLA benchmark, sets anew record on the NoCrash benchmark, and reduces the frequency of infractions by an order of magnitude compared to the prior state of the art.  Table 1: Ablation study on the CoRL2017 bench- mark (CARLA 0.9.5, \\"navigation\\" condition, test town, test weather). Two key advantages of the presented decomposition -white-box supervision and on-policy trajectories -each substantially im- prove performance and together achieve 100% success rate on the benchmark. on - policy Table 2: Comparison of the success rate of the presented approach (LBC) to the state of the art on the original CARLA benchmark (CoRL2017) in the test town. (The supplement provides results on the training town.) LBC \u2020 denotes our agent trained and evaluated on CARLA 0.9.6. All other agents were evaluated on CARLA 0.8 and 0.9.5. Our approach outperforms all prior work and achieves 100% success rate on all routes in the full-generalization setting (test town, test weather). test train CIL [ 6 ] 100 LBC \u2020 CAL [ 22 ] CILRS [ 7 ] MP [ 8 ] LBC CIRL [ 14 ]","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Autonomous Driving\\", \\"Dataset\\": \\"CARLA Leaderboard\\", \\"Metric\\": \\"Driving Score\\", \\"Score\\": \\"8.94\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Vehicle Re-Identification\\", \\"Dataset\\": \\"CARPK\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"6.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Vehicle Re-Identification\\", \\"Dataset\\": \\"CARPK\\", \\"Metric\\": \\"RMSE\\", \\"Score\\": \\"57.55\\"}} ]"},{"Context":"Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation Neural machine translation (NMT) aims at solving machine translation (MT) problems using neural networks and has exhibited promising results in recent years. However, most of the existing NMT models are shallow and there is still a performance gap between a single NMT model and the best conventional MT system. In this work, we introduce anew type of linear connections, named fastforward connections, based on deep Long Short-Term Memory (LSTM) networks, and an interleaved bi-directional architecture for stacking the LSTM layers. Fast-forward connections play an essential role in propagating the gradients and building a deep topology of depth 16. On the WMT\'14 Englishto-French task, we achieve BLEU=37.7 with a single attention model, which outperforms the corresponding single shallow model by 6.2 BLEU points. This is the first time that a single NMT model achieves state-of-the-art performance and outperforms the best conventional model by 0.7 BLEU points. We can still achieve BLEU=36.3 even without using an attention mechanism. After special handling of unknown words and model ensembling, we obtain the best score reported to date on this task with BLEU=40.4. Our models are also validated on the more difficult WMT\'14 English-to-German task. We evaluate our method mainly on the widely used WMT\'14 English-to-French translation task Table 2: The effect of F-F. We list the BLEU scores of Deep-Att with and without F-F. Because of the param- eter exploding problem, we can not list the model per- formance of larger depth without F-F. For n e = 1 and n d = 1, F-F connections only contribute to the represen- tation at interface part (see Eq. 7). d BLEU ne Table 3: BLEU scores with different LSTM layer width in Deep-Att. After using two times larger LSTM layer width of 1024, we can only obtain BLEU score of 33.8. It is still behind the corresponding Deep-Att with F-F. d BLEU ne Table 4: The effect of the interleaved bi-directional en- coder. We list the BLEU scores of our largest Deep-Att and Deep-ED models. The encoder term Bi denotes that the interleaved bi-directional encoder is used. Uni de- notes a model where all LSTM layers work in forward","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-French\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"39.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-French\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"35.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-German\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"20.7\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-French\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"35.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-French\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"31.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2016 English-Romanian\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"27.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-German\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"33.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-German\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"30.4\\"}} ]"},{"Context":"The C Object System * Using C as a High-Level Object-Oriented Language The C Object System (COS) is a small C library which implements high-level concepts available in CLOS, OBJECTIVE-C and other object-oriented programming languages: uniform object model (class, metaclass and property-metaclass), generic functions, multi-methods, delegation, properties, exceptions, contracts and closures. COS relies on the programmable capabilities of the C programming language to extend its syntax and to implement the aforementioned concepts as first-class objects. COS aims at satisfying several general principles like simplicity, extensibility, reusability, efficiency and portability which are rarely met in a single programming language. Its design is tuned to provide efficient and portable implementation of message multi-dispatch and message multi-forwarding which are the heart of code extensibility and reusability. With COS features in hand, software should become as flexible and extensible as with scripting languages and as efficient and portable as expected with C programming. Likewise, COS concepts should significantly simplify adaptive and aspect-oriented programming as well as distributed and service-oriented computing.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Overlapping Multi-hop Clustering for Wireless Sensor Networks Clustering is a standard approach for achieving efficient and scalable performance in wireless sensor networks. Traditionally, clustering algorithms aim at generating a number of disjoint clusters that satisfy some criteria. In this paper, we formulate a novel clustering problem that aims at generating overlapping multi-hop clusters. Overlapping clusters are useful in many sensor network applications, including inter-cluster routing, node localization, and time synchronization protocols. We also propose a randomized, distributed multi-hop clustering algorithm (KOCA) for solving the overlapping clustering problem. KOCA aims at generating connected overlapping clusters that cover the entire sensor network with a specific average overlapping degree. Through analysis and simulation experiments we show how to select the different values of the parameters to achieve the clustering process objectives. Moreover, the results show that KOCA produces approximately equal-sized clusters, which allows distributing the load evenly over different clusters. In addition, KOCA is scalable; the clustering formation terminates in a constant time regardless of the network size.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Neural Architecture Search with Bayesian Optimisation and Optimal Transport Bayesian Optimisation (BO) refers to a class of methods for global optimisation of a function f which is only accessible via point evaluations. It is typically used in settings where f is expensive to evaluate. A common use case for BO in machine learning is model selection, where it is not possible to analytically model the generalisation performance of a statistical model, and we resort to noisy and expensive training and validation procedures to choose the best model. Conventional BO methods have focused on Euclidean and categorical domains, which, in the context of model selection, only permits tuning scalar hyper-parameters of machine learning algorithms. However, with the surge of interest in deep learning, there is an increasing demand to tune neural network architectures. In this work, we develop NASBOT, a Gaussian process based BO framework for neural architecture search. To accomplish this, we develop a distance metric in the space of neural network architectures which can be computed efficiently via an optimal transport program. This distance might be of independent interest to the deep learning community as it may find applications outside of BO. We demonstrate that NASBOT outperforms other alternatives for architecture search in several cross validation based model selection tasks on multi-layer perceptrons and convolutional neural networks.While there are several approaches to BO, those based on Gaussian processes (GP) [35] are most common in the BO literature. In its most unadorned form, a BO algorithm operates sequentially, starting at time 0 with a GP prior for f ; at time t, it incorporates results of evaluations from 1, . . . , t\u22121 in the form of a posterior for f . It then uses this posterior to construct an acquisition function \u03d5 t , where \u03d5 t (x) is a measure of the value of evaluating fat x at time t if our goal is to maximise f . Our RAND implementation, operates in exactly the same way as NASBOT, except that the EA procedure is fed a random sample from Unif(0, 1) instead of the GP acquisition each time it evaluates an architecture Datasets: We use the following datasets: blog feedback, indoor location, slice localisation, naval propulsion, protein tertiary structure, news popularity, Cifar10 Experimental Set up: Each method is executed in an asynchronously parallel setup of 2-4 GPUs, That is, it can evaluate multiple models in parallel, with each model on a single GPU When the evaluation of one model finishes, the methods can incorporate the result and immediately re-deploy the next job without waiting for the others to finish For the blog, indoor, slice, naval and protein datasets we use 2 GeForce GTX 970 (4GB) GPUs and a computational budget of 8 hours for each method For the news popularity dataset we use 4 GeForce GTX 980 (6GB) Table 3: The first row gives the number of samples N and the dimensionality D of each dataset in the form Method ( 54K , 385 ) ( 12K , 17 ) 150K iters ( 46K , 9 ) ( 60K , 3K ) ( 40K , 61 ) Cifar10 ( 21K , 529 ) Protein ( 60K , 281 ) Slice Naval News Indoor Blog","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"NAS-Bench-201, ImageNet-16-120\\", \\"Metric\\": \\"Accuracy (Test)\\", \\"Score\\": \\"46.37\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"NAS-Bench-201, ImageNet-16-120\\", \\"Metric\\": \\"Search time (s)\\", \\"Score\\": \\"75600\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"75.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"MACs\\", \\"Score\\": \\"597M\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Params\\", \\"Score\\": \\"5.3M\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top-1 Error Rate\\", \\"Score\\": \\"24.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Search Time (GPU days)\\", \\"Score\\": \\"0.25\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Neural Architecture Search\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Top-1 Error Rate\\", \\"Score\\": \\"2.39%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Node Classification\\", \\"Dataset\\": \\"PPI\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"99.09\\"}}, { \\"LEADERBOARD\\": "},{"Context":"Devil in the Details: Towards Accurate Single and Multiple Human Parsing Human parsing has received considerable interest due to its wide application potentials. Nevertheless, it is still unclear how to develop an accurate human parsing system in an efficient and elegant way. In this paper, we identify several useful properties, including feature resolution, global context information and edge details, and perform rigorous analyses to reveal how to leverage them to benefit the human parsing task. The advantages of these useful properties finally result in a simple yet effective Context Embedding with Edge Perceiving (CE2P) framework for single human parsing. Our CE2P is end-to-end trainable and can be easily adopted for conducting multiple human parsing. Benefiting the superiority of CE2P, we won the 1st places on all three human parsing tracks in the 2nd Look into Person (LIP) Challenge. Without any bells and whistles, we achieved 56.50% (mIoU), 45.31% (mean AP r ) and 33.34% (AP p 0.5 ) in Track 1, Track 2 and Track 5, which outperform the state-of-the-arts more than 2.06%, 3.81% and 1.87%, respectively. We hope our CE2P will serve as a solid baseline and help ease future research in single/multiple human parsing. Global Context Embedding Module To evaluate the effectiveness of each module, we first conduct experiments by introducing a global context embedding module Comparison with State-of-the-Arts We evaluate the performance of CE2P on the validation dataset of LIP and compare it to other state-of-the-art approaches Table 1: Comparison of CE2P in various module settings on the validation set of LIP. The results are obtained without left-right flipping except for the last row. \'B\' means baseline model. \'G\', \'H\' and \'E\' denote global context, high resolution and edge perceiving module, respectively. ( CE2P ) al . 2018b ) , i . e . \\" Poly \\" learning rate policy with base learning dress l - leg pants scarf r - leg glove socks j - suits glasses r - arm mIoU coat hair face l - arm skirt u - cloth hat l - shoe r - shoe bkg Table 2: Comparison of performance on the validation set of LIP with state-of-arts methods. to the input size . The results are shown in Tab . 1 , and we can mean acc . mIoU pixel acc . Table 3: Comparison of the performance on the test set","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"LIP val\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"53.10%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"LIP val\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"65.3\\"}} ]"},{"Context":"Towards an Embedding of Graph Transformation in Intuitionistic Linear Logic Linear logics have been shown to be able to embed both rewriting-based approaches and process calculi in a single, declarative framework. In this paper we are exploring the embedding of double-pushout graph transformations into quantified linear logic, leading to a Curry-Howard style isomorphism between graphs / transformations and formulas / proof terms. With linear implication representing rules and reachability of graphs, and the tensor modelling parallel composition of graphs / transformations, we obtain a language able to encode graph transformation systems and their computations as well as reason about their properties.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Information Hiding Using Improper Frame Padding Hiding information in network traffic may lead to leakage of confidential information. In this paper we introduce anew steganographic system: the PadSteg (Padding Steganography). To authors\' best knowledge it is the first information hiding solution which represents interprotocol steganography i.e. usage of relation between two or more protocols from the TCP/IP stack to enable secret communication. PadSteg utilizes ARP and TCP protocols together with an Etherleak vulnerability (improper Ethernet frame padding) to facilitate secret communication for hidden groups in LANs (Local Area Networks). Basing on real network traces we confirm that PadSteg is feasible in today\'s networks and we estimate what steganographic bandwidth is achievable while limiting the chance of disclosure. We also point at possible countermeasures against PadSteg.  Table 1. The traffic was captured with the aid of Dumpcap which is part of the Wireshark sniffer ver. 1.3.3 (www.wireshark.org). The sources of traffic were ordinary computer devices placed in several university laboratories and employees\' ones but also peripherals, servers and network equipment. To analyze the captured traffic and calculate statistics TShark (which is also part of Wireshark) was utilized. Statistics were calculated per day, and average results are presented. protocol TCP Others 8 , 945 , 403 Friday UPPER LAYER PROTCOLS AFFECTED WITH ETHERNET ARP ICMP","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Quality Aware Network for Set to Set Recognition This paper targets on the problem of set to set recognition, which learns the metric between two image sets. Images in each set belong to the same identity. Since images in a set can be complementary, they hopefully lead to higher accuracy in practical applications. However, the quality of each sample cannot be guaranteed, and samples with poor quality will hurt the metric. In this paper, the quality aware network (QAN) is proposed to confront this problem, where the quality of each sample can be automatically learned although such information is not explicitly provided in the training stage. The network has two branches, where the first branch extracts appearance feature embedding for each sample and the other branch predicts quality score for each sample. Features and quality scores of all samples in a set are then aggregated to generate the final feature embedding. We show that the two branches can be trained in an end-to-end manner given only the set-level identity annotation. Analysis on gradient spread of this mechanism indicates that the quality learned by the network is beneficial to set-to-set recognition and simplifies the distribution that the network needs to fit. Experiments on both face verification and person re-identification show advantages of the proposed QAN. The source code and network structure can be downloaded at GitHub 1 Based on above knowledge, we evaluate QAN on two human re-identification benchmarks and two unconstrained face verification benchmarks Results of evaluation obeying \\"10-fold cross validation\\" on PRID2011 and iLIDS-VID are shown in and Benefiting from the large scale training dataset, our CNN+AvePool and CNN+Min(cos) baselines are close to or even better than the state-of-the-art On PRID2011 dataset, QAN increase top-1 matching rate by 11.1% and 29.4% compared with CNN+AvePool and CNN+Min(cos) On iLIDS-VID dataset, inherent noise is much more than that in PRID2011, which significantly influence the accuracy of CNN+Min(cos) since operator \\"Min(cos)\\" is more sensitive than \\"AvePool\\" to noisy samples However, QAN achieves more gain on this noisy dataset Based on these two experiments, QAN significantly outperforms two baselines on both datasets The performance gain is more significant on noisy iLIDS-VID dataset, which meets the expectation and proves QAN\'s ability to deal with images of poor quality To prevent our Table 1. Comparison of QAN, AvePool, Min(cos) and other state-of-the-art methods on PRID2011, where the number repre- sents the cumulative matching rate in CMC curve. CMC5 CMC20 CMC1 90 70 CMC10 95 97 Table 2. Comparison of QAN, AvePool, Min(cos) and other human re-identification methods on iLIDS-VID, where the num- ber represents the cumulative matching rate on CMC curve. PRID2011 CMC5 CMC20 58 CMC1 91 iLIDS - VID CMC10 84 96 Table 3. Cross-dataset performance of QAN on PRID2011, where the number represents the cumulative accuracy on CMC curve. iLIDS - VID 57 CMC5 CMC20 69 28 CMC1 81 CMC10 PRID2011 Table 4. Cross-dataset performance of QAN on iLIDS-VID, where the number represents the cumulative accuracy on CMC curve. iLIDS - VID 57 CMC5 CMC20 69 28 CMC1 81 CMC10 PRID2011 Table 5. Average accuracy and AUC of QAN on YouTube Face dataset, compared with baselines and other state-of-the-arts. - %","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"YouTube Faces DB\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"96.17%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"PRID2011\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"94.07%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"PRID2011\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"93.70%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"PRID2011\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"93.27%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"PRID2011\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"87.27%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"PRID2011\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"93.17%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"PRID2011\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"83.14%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"PRID2011\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"80.026\\"}}, { \\"LEADERBOARD\\": { "},{"Context":"Symbolic model checking of tense logics on rational Kripke models We introduce the class of rational Kripke models and study symbolic model checking of the basic tense logic Kt and some extensions of it in models from that class. Rational Kripke models are based on (generally infinite) rational graphs, with vertices labeled by the words in some regular language and transitions recognized by asynchronous two-head finite automata, also known as rational transducers. Every atomic proposition in a rational Kripke model is evaluated in a regular set of states. We show that every formula of Kt has an effectively computable regular extension in every rational Kripke model, and therefore local model checking and global model checking of Kt in rational Kripke models are decidable. These results are lifted to a number of extensions of Kt. We study and partly determine the complexity of the model checking procedures.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"RECON: Relation Extraction using Knowledge Graph Context in a Graph Neural Network In this paper, we present a novel method named RECON, that automatically identifies relations in a sentence (sentential relation extraction) and aligns to a knowledge graph (KG). RECON uses a graph neural network to learn representations of both the sentence as well as facts stored in a KG, improving the overall extraction quality. These facts, including entity attributes (label, alias, description, instance-of) and factual triples, have not been collectively used in the state of the art methods. We evaluate the effect of various forms of representing the KG context on the performance of RECON. The empirical evaluation on two standard relation extraction datasets shows that RECON significantly outperforms all state of the art methods on NYT Freebase and Wikidata datasets. ACM Reference Format:  Table 1: Comparison of RECON and sentential RE models on the Wikidata dataset. Best values are in bold. Each time a KG context is added in a graph neural network, the per- formance has increased, resulting in a significant RECON outperformance against all sentential RE baselines. P R Macro Micro F1 Table 2: Comparison of RECON against baselines (sentential and multi-instance) on the NYT Freebase dataset. Best val- ues are in bold. RECON continues to significantly outper- form sentential RE baselines and also surpasses the perfor- mance of state of the art multi-instance RE approach. Sentential Precision @30% @10% Table 3: The McNemar\'s test for statistical significance on the results of both datasets. It can be observed that each of the improvement in the RECON configurations is statisti- cally significant independent of the underlying KG. Freebase Wikidata 3699 Statistic p - value Contingency 4417 Table 4: RECON-EAC performance on Wikidata Dataset.","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Relationship Extraction (Distant Supervised)\\", \\"Dataset\\": \\"New York Times Corpus\\", \\"Metric\\": \\"P@10%\\", \\"Score\\": \\"87.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Relationship Extraction (Distant Supervised)\\", \\"Dataset\\": \\"New York Times Corpus\\", \\"Metric\\": \\"P@30%\\", \\"Score\\": \\"74.1\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"WebNLG\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"28.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"NYT\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"42.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"NYT-single\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"49.5\\"}} ]"},{"Context":"An Accurate SER Estimation Method Based on Propagation Probability In this paper, we present an accurate but very fast soft error rate (SER) estimation technique for digital circuits based on error propagation probability (EPP) computation. Experiments results and comparison of the results with the random simulation technique show that our proposed method is on average within 6% of the random simulation method and four to five orders of magnitude faster.  Table 2. Our approach vs. random simulation 69510 79950 72800 15480 17220 23810 87230 SysT ISP 3133 %Dif 5270 3480 3405 SPT 1695 SimT 9648 12833 12951","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"M\xe9thode de calcul du rayonnement acoustique de structures complexes Dans l\'industrie automobile, pr\xe9dire le bruit rayonn\xe9 est une \xe9tape importante de la conception. Pour r\xe9soudre les probl\xe8mes acoustiques, il existe principalement deux familles de m\xe9thodes : les M\xe9thodes \xc9l\xe9ments Finis (FEM) et les M\xe9thodes \xc9l\xe9ments de Fronti\xe8res (BEM). Pour calculer le rayonnement acoustique en champ libre, on utilise g\xe9n\xe9ralement plut\xf4t les \xe9l\xe9ments de fronti\xe8res. N\xe9anmoins ces m\xe9thodes peuvent induire des singularit\xe9s, et sont par cons\xe9quent moins faciles \xe0 utiliser que les \xe9l\xe9ments finis qui eux sont plut\xf4t adapt\xe9s \xe0 l\'\xe9tude des milieux born\xe9s. La m\xe9thode d\xe9crite dans cet article, la SDM, permet de tirer avantage de ces deux m\xe9thodes en utilisant chacune l\xe0 o\xf9 elle est la plus performante. Une nouvelle m\xe9thode fond\xe9e sur \xe9l\xe9ments finis est \xe9galement pr\xe9sent\xe9e et permet de remplacer avantageusement les \xe9l\xe9ments de fronti\xe8re pour traiter le probl\xe8me ext\xe9rieur. L\'efficacit\xe9 de la SDM coupl\xe9e \xe0 cette nouvelle m\xe9thode est discut\xe9e.ABSTRACT. In the automotive industry, predicting noise during design cycle is a necessary step. Well-known methods exist to answer this issue in low frequency domain. Among these, Finite Element Methods, adapted to closed domains, are quite easy to implement whereas Boundary Element Methods are more adapted to infinite domains, but may induce singularity problems. In this article, the described method, the SDM, allows to use both methods in their best application domain. A new method is also presented to solve the SDM exterior problem.MOTS-CL\xc9S : SDM, FEM, BEM, rayonnement acoustique, structures \xe0 g\xe9om\xe9tries complexes, algorithme de clonage, sous structuration infinie.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"A finiteness structure on resource terms In our paper \\"Uniformity and the Taylor expansion of ordinary lambda-terms\\" (with Laurent Regnier), we studied a translation of lambda-terms as infinite linear combinations of resource lambda-terms, from a calculus similar to Boudol\'s lambda-calculus with resources and based on ideas coming from differential linear logic and differential lambda-calculus. The good properties of this translation wrt. beta-reduction were guaranteed by a coherence relation on resource terms: normalization is \\"linear and stable\\" (in the sense of the coherence space semantics of linear logic) wrt. this coherence relation. Such coherence properties are lost when one considers non-deterministic or algebraic extensions of the lambda-calculus (the algebraic lambda-calculus is an extension of the lambda-calculus where terms can be linearly combined). We introduce a \\"finiteness structure\\" on resource terms which induces a linearly topologized vector space structure on terms and prevents the appearance of infinite coefficients during reduction, in typed settings. * This work has been partly funded by the ANR project BLAN07-1 189926 Curry-Howard for Concurrency (CHOCO). 1 It is not really standard to consider dereliction as structural.The only infinite rule of LL is promotion. The potentially infinite duplicating power of contraction is not \\"located\\" in the contraction rule itself, but in the fact that, for being duplicable by contractions, a proof must be promoted first. This fact can be observed in denotational models but is not clear in the syntax because the structural rules have no other opponents but promotion 2 .The situation is quite different in differential LL (and, implicitly, in differential lambdacalculus and its variants), a system that we introduced recently (see [ER03,ER06b,EL09]). In this system, the \\"?\\" rules have exact dual rules: there is a cocontraction, a coweakening and a codereliction rules. These rules are logical versions of standard mathematical operations used in elementary differential calculus, whence the name of the system. So in differential LL we have structural and costructural rules and these rules interact in a completely symmetric and finite way, just as in the multiplicative and additive fragment. Promotion remains apart, as the only truly infinite rule of logic. This fact, which in LL could be observed only in denotational models, can be expressed syntactically in differential LL by means of the Taylor expansion of promotion rules.Resource lambda-calculus. This operation is more easily understood in the lambda-calculus (see [Tra08] for the connection between lambda-terms and nets in differential LL). Roughly speaking, the ordinary lambda-calculus correspond to the fragment of LL which contains the multiplicative, structural and promotion rules. But we can also consider a lambda-calculus corresponding to the multiplicative, structural and costructural rules: the resource calculus that we introduced in [ER08]. Similar calculi already existed in the literature, such as Boudol\'s calculi with multiplicities [Bou93] or with resources [BCL99], and also Kfoury\'s calculi [Kfo00], introduced with different motivations and with different semantic backgrounds. The intuition behind our calculus with resources is as follows.The first thing to say is that types should bethought of as (topological) vector spaces and not as domains. Consider then a term t : A \u21d2 B which should be seen as a function from A to B. Then imagine that it makes sense to compute the n-the derivative oft at the point 0 of the vector space A: it is a function t (n) (0) : A n \u2192 A, separately linear in each of its argument, and symmetric in the sense that t (n) (0)(s 1 , . . . , s n ) = t (n) (0)(s f (1) , . . . , sf (n) ) for any permutation f \u2208 Sn and any tuple (s 1 , . . . , s n ) \u2208 A n . In our resource calculus, we have an application construction which represents this operation. Given a term t (of type A \u21d2 B if we are in a typed setting) and a finite number s 1 , . . . , s n of terms (of type A), we can \\"apply\\" t to the multiset S = s 1 \xb7 \xb7 \xb7 s n (the multiset whose elements are s 1 , . . . , s n , taking multiplicities into account) and we denote with s S this operation. We take benefit of the intrinsic commutativity of multisets for implementing the symmetry of the n-th derivative. The other constructions of this calculus are standard: we have variables x, y, . . . and abstractions \u03bbx s. Redexes are terms of the shape \u03bbx s Sand x can have several free occurrences in s, which are all linear. When reducing this redex, one does not duplicate S. Instead, one splits it into as many pieces as there are occurrences of x in s, and since all these occurrences are linear, all these pieces should contain exactly one term. We do that in all possible ways and take the sum of all possible results. When the number of free occurrences of x in sand the size of S do not coincide, the result of this operation is 0.For this to make sense, one must have the possibility of adding terms, and this is compatible with the idea that types are vector spaces.Taylor expansion. Taylor expansion consists in replacing the ordinary application of lambda-calculus with this differential application of the resource calculus. If M : A \u21d2 B and N : A are terms, then the standard Taylor formula should be","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Incremental Topological Ordering and Strong Component Maintenance We present an on-line algorithm for maintaining a topological order of a directed acyclic graph as arcs are added, and detecting a cycle when one is created. Our algorithm takes O(m 1/2 ) amortized time per arc, where m is the total number of arcs. For sparse graphs, this bound improves the best previous bound by a logarithmic factor and is tight to within a constant factor fora natural class of algorithms that includes all the existing ones. Our main insight is that the bidirectional search method of previous algorithms does not require an ordered search, but can be more general. This allows us to avoid the use of heaps (priority queues) entirely. Instead, the deterministic version of our algorithm uses (approximate) median-finding. The randomized version of our algorithm avoids this complication, making it very simple. We extend our topological ordering algorithm to give the first detailed algorithm for maintaining the strong components of a directed graph, and a topological order of these components, as arcs are added. This extension also has an amortized time bound of O(m 1/2 ) per arc.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning In order to simulate human language capacity, natural language processing systems must be able to reason about the dynamics of everyday situations, including their possible causes and effects. Moreover, they should be able to generalise the acquired world knowledge to new languages, modulo cultural differences. Advances in machine reasoning and cross-lingual transfer depend on the availability of challenging evaluation benchmarks. Motivated by both demands, we introduce Cross-lingual Choice of Plausible Alternatives (XCOPA), a typologically diverse multilingual dataset for causal commonsense reasoning in 11 languages, which includes resource-poor languages like Eastern Apur\xedmac Quechua and Haitian Creole. We evaluate a range of state-of-the-art models on this novel dataset, revealing that the performance of current methods based on multilingual pretraining and zero-shot fine-tuning falls short compared to translation-based transfer. Finally, we propose strategies to adapt multilingual models to out-of-sample resource-lean languages where only a small corpus or a bilingual dictionary is available, and report substantial improvements over the random baseline. The XCOPA dataset is freely available at github.com/cambridgeltl/xcopa. arXiv:2005.00333v2 [cs.CL] 26 Oct 2020 14 github.com/huggingface/transformers 15 tfhub.dev/google/ universal-sentence-encoder-multilingual-large/ 3 We now benchmark a series of state-of-the-art models on XCOPA to provide baseline scores for future research, as well as to expose the challenging nature of the dataset Table 2: Indices of typological, genealogical, and areal diversity for the language samples of a set of NLU datasets. XQUAD XCOPA TyDiQA XNLI MLQA PAWS - X Table 3: Percentage of annotated labels in each language agreeing with the majority label. Note that the majority label is highly reliable, as we observed a 100% agreement with the development set labels in the original COPA. VI QU SW TH ID IT HT TA TR ZH ET Table 4: Different experimental setups for data sources. CO=COPA; SI=SIQA; ZS=Zero-Shot; TLV=Target Language Validation (Set). All XCOPA USE \u2229 MBERT \u2229 Table 4. We first compare our cross-lingual average XCOPA results in the best setup with the English COPA performance of the monolingual English BERT (Base) reported by Sap et al. (2019), namely 63 accuracy in COPA-only fine-tuning (+7%) and 80 after sequential SIQA + COPA fine-tuning (+17%). This contributes to recent suspicions (Cao et al.,","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Cross-Lingual Transfer\\", \\"Dataset\\": \\"XCOPA\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"76.05\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Common Sense Reasoning\\", \\"Dataset\\": \\"Xplaint\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"97.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Common Sense Reasoning\\", \\"Dataset\\": \\"Xplaint\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"97.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Common Sense Reasoning\\", \\"Dataset\\": \\"Xplaint\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"77.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Common Sense Reasoning\\", \\"Dataset\\": \\"Xplaint\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"78.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Common Sense Reasoning\\", \\"Dataset\\": \\"Xplaint\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"72.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Common Sense Reasoning\\", \\"Dataset\\": \\"Xplaint\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"88.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Common Sense Reasoning\\", \\"Dataset\\": \\"Xplaint\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"80.7\\"}}, { \'LEADERBO"},{"Context":"Generating Function For Network Delay In this paper correspondence between experimental data for packet delay and two theoretical types of distribution is investigated. Statistical tests have shown that only exponential distribution can be used for the description of packet delays in global network. Precision experimental data to within microseconds are gathered by means of the RIPE Test Box. Statistical verification of hypothesis has shown that distribution parameters remain constants during 500 second intervals at least. In paper cumulative distribution function and generating function for packet delay in network are in an explicit form written down, the algorithm of search of parameters of distribution is resulted.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"You Only Watch Once: A Unified CNN Architecture for Real-Time Spatiotemporal Action Localization Spatiotemporal action localization requires the incorporation of two sources of information into the designed architecture: (1) temporal information from the previous frames and (2) spatial information from the key frame. Current stateof-the-art approaches usually extract these information with separate networks and use an extra mechanism for fusion to get detections. In this work, we present YOWO, a unified CNN architecture for real-time spatiotemporal action localization in video streams. YOWO is a single-stage architecture with two branches to extract temporal and spatial information concurrently and predict bounding boxes and action probabilities directly from video clips in one evaluation. Since the whole architecture is unified, it can be optimized end-to-end. The YOWO architecture is fast providing 34 frames-per-second on 16-frames input clips and 62 frames-per-second on 8-frames input clips, which is currently the fastest stateof-the-art architecture on spatiotemporal action localization task. Remarkably, YOWO outperforms the previous state-of-the art results on J-HMDB-21 and UCF101-24 with an impressive improvement of \u223c3% and \u223c12%, respectively.We make our code and pretrained models publicly available 2 . To evaluate YOWO\'s performance, two popular and challenging action detection datasets, UCF101-24 and J-HMDB-21 are selected We follow the official evaluation metrics strictly to report the results and compare the performance of our method with the state of the art UCF101-24 is a subset of UCF101, which is originally an action recognition dataset of realistic action videos J-HMDB-21 is a subset of the HMDB-51 dataset and consists of 928 short videos with 21 action categories in daily life Evaluation metrics: We employ two popular metrics used by the most researches in the region of spatio-temporal action detection to generate convincing evaluations Table 1: Frame-mAP @ IoU 0.5 results on datasets UCF101-24 and J-HMDB-21 for different UCF101 - 24 J - HMDB - 21 Table 3: Frame-mAP @ IoU 0.5 results on datasets UCF101-24 and J-HMDB-21 for different UCF101 - 24 J - HMDB - 21 Table 4: Performance comparison on datasets for different 3D backbones UCF101-24 and GFLOPs UCF101 - 24 Model J - HMDB - 21 Table 5: Performance on dataset J-HMDB-21 and comparison with SOTA results by frame- - Frame - mAP Video - mAP Table 6: Performance on dataset UCF101-24 and comparison with SOTA results by frame- - Frame - mAP Video - mAP Table 7: Run time and performance comparison on dataset UCF101-24 for F-mAP and V- V - mAP F - mAP","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Temporal Action Localization\\", \\"Dataset\\": \\"UCF101-24\\", \\"Metric\\": \\"Frame-mAP\\", \\"Score\\": \\"87.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Temporal Action Localization\\", \\"Dataset\\": \\"UCF101-24\\", \\"Metric\\": \\"Video-mAP 0.5\\", \\"Score\\": \\"48.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Temporal Action Localization\\", \\"Dataset\\": \\"J-HMDB-21\\", \\"Metric\\": \\"Frame-mAP\\", \\"Score\\": \\"74.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Temporal Action Localization\\", \\"Dataset\\": \\"J-HMDB-21\\", \\"Metric\\": \\"Video-mAP 0.2\\", \\"Score\\": \\"87.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Temporal Action Localization\\", \\"Dataset\\": \\"J-HMDB-21\\", \\"Metric\\": \\"Video-mAP 0.5\\", \\"Score\\": \\"85.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Temporal Action Localization\\", \\"Dataset\\": \\"J-HMDB-21\\", \\"Metric\\": \\"Video-mAP 0.75\\", \\"Score\\": \\"58.1\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Temporal Action Localization\\", \\"Dataset\\": \\"UCF101-24\\", \\"Metric\\": \\"Frame-mAP\\", \\"Score\\": \\"69.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Temporal Action Localization\\", \\"Dataset\\": \\"J-HMDB-21\\", \\"Metric\\": \\"Frame-mAP\\", \\"Score\\": \\"65.7\\"}} ]"},{"Context":"Index Networks We show that existing upsampling operators can be unified using the notion of the index function. This notion is inspired by an observation in the decoding process of deep image matting where indices-guided unpooling can often recover boundary details considerably better than other upsampling operators such as bilinear interpolation. By viewing the indices as a function of the feature map, we introduce the concept of \'learning to index\', and present a novel index-guided encoder-decoder framework where indices are learned adaptively from data and are used to guide downsampling and upsampling stages, without extra training supervision. At the core of this framework is anew learnable module, termed Index Network (IndexNet), which dynamically generates indices conditioned on the feature map. IndexNet can be used as a plug-in applicable to almost all convolutional networks that have coupled downsampling and upsampling stages, enabling the networks to dynamically capture variations of local patterns. In particular, we instantiate, investigate five families of IndexNet, highlight their superiority in delivering spatial information over other upsampling operators with experiments on synthetic data, and demonstrate their effectiveness on four dense prediction tasks, including image matting, image denoising, semantic segmentation, and monocular depth estimation. Code and models are available at: https://git.io/IndexNet. Results on the Composition-1k testing dataset are listed in Other implementation details and evaluations are kept consistent with Compared Only HIN (\'Nonlinear+Context\') is evaluated due to varied feature dimensionality of decoder and multi-level feature fusion Performance of Image Reconstruction on the Fashion - MNIST Dataset MAE PSNR SSIM TABLE 3 MSE Ablation Study of Design Choices SAD Conn TABLE 4 MSE Grad Modelwise O2O DINs M2O DINs Shared Stagewise O2O DINs HINs Unshared Stagewise O2O DINs Results on the Composition - 1k Testing Set GFLOPs \u2206 SAD Conn #Param . MSE TABLE 5 Grad Ablation Study of Different Normalization Choices on Index Maps SAD TABLE 6 Conn MSE Grad Modelwise O2O DINs M2O DINs Shared Stagewise O2O DINs HINs Unshared Stagewise O2O DINs Average PSNR ( dB ) and SSIM Results of Various Noise Levels on the BSD68 and Set12 Image Denoising Benchmarks 31 . 20 / 0 . 9365 31 . 22 / 0 . 9366 GFLOPs 31 . 17 / 0 . 9366 31 . 22 / 0 . 9365 15 \u2206 31 . 25 / 0 . 9368 #Param . 30 . 87","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Monocular Depth Estimation\\", \\"Dataset\\": \\"NYU-Depth V2\\", \\"Metric\\": \\"RMSE\\", \\"Score\\": \\"0.565\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Scene Segmentation\\", \\"Dataset\\": \\"SUN-RGBD\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"33.48\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Grayscale Image Denoising\\", \\"Dataset\\": \\"Set12 sigma15\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"32.82\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Grayscale Image Denoising\\", \\"Dataset\\": \\"BSD68 sigma50\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"26.34\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Grayscale Image Denoising\\", \\"Dataset\\": \\"BSD68 sigma25\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"29.06\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Grayscale Image Denoising\\", \\"Dataset\\": \\"Set12 sigma30\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"30.43\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Grayscale Image Denoising\\", \\"Dataset\\": \\"Set12 sigma50\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"27.29\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Grayscale Image Denoising\\", \\"Dataset\\": \\"BSD68 sigma15\\", \\"Metric\\": \\"PSNR\\", \\"Score\\": \\"31.23\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS Area5\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"61.28\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"S3DIS Area5\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"59.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"73.66%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"93.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"73.82%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"67.39%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"70.93%\\"}}, { "},{"Context":"Simple implementation of deletion from open-address hash table","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Adversarial Autoencoders In this paper, we propose the \\"adversarial autoencoder\\" (AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classification tasks. On the MNIST dataset we use the sigmoid activation function in the last layer of the autoencoder and on the TFD dataset we use the linear activation function On the Toronto Face dataset, data points are subtracted by the mean and divided by the standard deviation along each input dimension across the whole training set to normalize the contrast Table 1: Log-likelihood of test data on MNIST and Toronto Face dataset. Higher values are better. On both datasets we report the Parzen window estimate of the log-likelihood obtained by drawing 10K or 10M samples from the trained model. For MNIST, we compare against other models on the real-valued version of the dataset. MNIST ( 10K ) - 2057 \xb1 26 MNIST ( 10M ) Table 2: Semi-supervised classification performance (error-rate) on MNIST and SVHN. - - MNIST ( All ) SVHN ( 1000 )","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised MNIST\\", \\"Dataset\\": \\"MNIST\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Unsupervised Image Classification\\", \\"Dataset\\": \\"MNIST\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.9\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"MNIST, 250 Labels\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"94.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"MNIST, 1000 Labels\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"91.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semi-Supervised Image Classification\\", \\"Dataset\\": \\"MNIST, 4000 Labels\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.8\\"}} ]"},{"Context":"Distilling Translations with Visual Awareness Previous work on multimodal machine translation has shown that visual information is only needed in very specific cases, for example in the presence of ambiguous words where the textual context is not sufficient. As a consequence, models tend to learn to ignore this information. We propose a translate-and-refine approach to this problem where images are only used by a second stage decoder. This approach is trained jointly to generate a good first draft translation and to improve over this draft by (i) making better use of the target language textual context (both left and right-side contexts) and (ii) making use of visual context. This approach leads to the state of the art results. Additionally, we show that it has the ability to recover from erroneous or missing words in the source language. We build and test our MMT models on the Multi30K dataset The dataset contains 29,000 instances for training, 1,014 for development, and 1,000 for test In addition to the official Multi30K test set (test 2016), we also use the test set from the latest WMT evaluation competition, test 2018 Table 1. We note that RND and PERS are the same for lan- guage pairs as the degradation only depends on the source side, while for AMB the words replaced de- pend on the target language. 2 avg . blanks per sent . Table 1: Statistics of datasets after applying source degradation strategies 2 avg . blanks per sent . Table 2: Results for the test sets 2016 and 2018. M denotes METEOR, B -BLEU; * marks statistically sig- nificant changes for METEOR (p-value \u2264 0.05) as com- pared to base, \u2020 -as compared to del. Bold high- lights statistically significant improvements. We report previous state of the art results for multimodal models from until convergence . test 2018 B and train the model test 2016 M - Table 3: Human ranking results: normalised rank (micro-averaged). Bold highlights best results. base+att del+obj del Table 4: Results for the test sets 2016","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Machine Translation\\", \\"Dataset\\": \\"Multi30K\\", \\"Metric\\": \\"BLEU (EN-DE)\\", \\"Score\\": \\"38\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Machine Translation\\", \\"Dataset\\": \\"Multi30K\\", \\"Metric\\": \\"Meteor (EN-DE)\\", \\"Score\\": \\"55.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Machine Translation\\", \\"Dataset\\": \\"Multi30K\\", \\"Metric\\": \\"BLEU (EN-FR)\\", \\"Score\\": \\"60.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multimodal Machine Translation\\", \\"Dataset\\": \\"Multi30K\\", \\"Metric\\": \\"Meteor (EN-FR)\\", \\"Score\\": \\"74.6\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Multimodal Machine Translation\\", \\"Dataset\\": \\"Multi30K\\", \\"Metric\\": \\"BLEU (EN-DE)\\", \\"Score\\": \\"34.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multimodal Machine Translation\\", \\"Dataset\\": \\"Multi30K\\", \\"Metric\\": \\"Meteor (EN-DE)\\", \\"Score\\": \\"55.1\\"}} ]"},{"Context":"A graph polynomial for independent sets of bipartite graphs We introduce anew graph polynomial that encodes interesting properties of graphs, for example, the number of matchings and the number of perfect matchings. Most importantly, for bipartite graphs the polynomial encodes the number of independent sets (#BIS).We analyze the complexity of exact evaluation of the polynomial at rational points and show that for most points exact evaluation is #P-hard (assuming the generalized Riemann hypothesis) and for the rest of the points exact evaluation is trivial.We conjecture that a natural Markov chain can be used to approximately evaluate the polynomial fora range of parameters. The conjecture, if true, would imply an approximate counting algorithm for #BIS, a problem shown, by [10], to be complete (with respect to, so called, AP-reductions) fora rich logically defined sub-class of #P. We give a mild support for our conjecture by proving that the Markov chain is rapidly mixing on trees. As a by-product we show that the \\"single bond flip\\" Markov chain for the random cluster model is rapidly mixing on constant tree-width graphs. x, y except when The second part of Theorem 2 will be proved by reducing from exact evaluation of the Tutte polynomial Assuming GRH, by Lemma 3 and Theorem 4, we have that exact evaluation of R \u2032 2 at rational point (\u03bb, \xb5) is #P-hard when \u03bb \u2208 {0, 1/2, 1} and \xb5 = 0 To show #P-hardness of exact evaluation of R \u2032 2 (G; 1/2, \xb5) for \xb5 / \u2208 {\u22121, 0}, we prove a connection between R \u2032 2 and the \\"permissive version of #BIS\\" (#PBIS) introduced in; #PBIS is a generalization of #BIS where the weight of a set of vertices is determined by the number of pairs of neighboring vertices that are both in the set (in #BIS the weight is zero raised to the number of such pairs)","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"A Formal Verification Methodology for Checking Data Integrity Formal verification techniques have been playing an important role in pre-silicon validation processes. One of the most important points considered in performing formal verification is to define good verification scopes; we should define clearly what to be verified formally upon designs under tests. We considered the following three practical requirements when we defined the scope of formal verification. They are (a) hard to verify (b) small to handle, and (c) easy to understand.Our novel approach is to breakdown generic properties for system into stereotype properties in block level and to define requirements for Verifiable RTL. Consequently, each designer instead of verification experts can describe properties of the design easily, and formal model checking can be applied systematically and thoroughly to all the leaf modules.During the development of a component chip for server platforms, we focused on RAS (Reliability, Availability, and Serviceability) features and described more than 2000 properties in PSL. As a result of the formal verification, we found several critical logic bugs in a short time with limited resources, and successfully verified all of them. This paper presents a study of the functional verification methodology.  Table 2. Number of verified properties 355 Type of Property P0 0 Sub P1 P2 P3 # of 137 6 Type of Property 150 Table 2 . Number of verified properties Table 3. Classification of logic bugs 355 Type of Property P0 0 Sub P1 P2 P3 # of 137 6 Type of Property 150 Table 2 . Number of verified properties","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"FASTER Recurrent Networks for Efficient Video Classification Typical video classification methods often divide a video into short clips, do inference on each clip independently, then aggregate the clip-level predictions to generate the video-level results. However, processing visually similar clips independently ignores the temporal structure of the video sequence, and increases the computational cost at inference time. In this paper, we propose a novel framework named FASTER, i.e., Feature Aggregation for Spatio-TEmporal Redundancy. FASTER aims to leverage the redundancy between neighboring clips and reduce the computational cost by learning to aggregate the predictions from models of different complexities. The FASTER framework can integrate high quality representations from expensive models to capture subtle motion information and lightweight representations from cheap models to cover scene changes in the video. A new recurrent network (i.e., FAST-GRU) is designed to aggregate the mixture of different representations. Compared with existing approaches, FASTER can reduce the FLOPs by over 10\xd7 while maintaining the state-of-the-art accuracy across popular datasets, such as Kinetics, UCF-101 and HMDB-51. In this section, we describe the experimental setups, i.e., the datasets, training and test protocols for both the cliplevel backbones and FASTER framework.: Accuracy of clip-level backbones on Kinetics Datasets We choose the Kinetics dataset as the major testbed for FASTER Kinetics is among the most popular datasets for video classification To simplify, all reported results on Kinetics are trained from scratch, without pretraining on other datasets (e.g., Sports1M or ImageNet) These datasets are much smaller, thus we use Kinetics for pretraining and report mean accuracy on three testing splits Table 1: Clip-level backbones for extracting the expen- sive and lightweight representations. The FLOPs of R(2+1)D-50 is about 10\xd7 of R2D-26. R2D : L R ( 2+1 ) D : L\xd756\xd756 \uf8f9 1\xd71\xd71 , 1024 1\xd73\xd73 , 1152 pool1 3\xd71\xd71 , 64 R ( 2+1 ) D - 50 3\xd71\xd71 , 64 , stride 1 , 1 , 1 8 \xd7112\xd7112 1\xd73\xd73 , 64 8 \xd756\xd756 conv1 1\xd71\xd71 , 1024 stride 1 , 2 , 2 8\xd77\xd77 , 64 R2D - 26 \uf8ee \uf8ef \uf8f0 stride 8 , 2 , 2 1\xd77\xd77 , 45 , stride 1 , 2 , 2 1\xd73\xd73 max \uf8fa \uf8fb \xd73 \xd74 1\xd71\xd71 , 64 \xd76 Table 3: Comparison of different architectures for ag- gregation on Kinetics. The clip length L is 8. For all the methods, only the first clip is processed by the expen- sive model, and the remaining clips are processed by the","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"75.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"71.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"UCF101\\", \\"Metric\\": \\"3-fold Accuracy\\", \\"Score\\": \\"96.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Action Recognition\\", \\"Dataset\\": \\"HMDB-51\\", \\"Metric\\": \\"Average accuracy of 3 splits\\", \\"Score\\": \\"75.7\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"75.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"81.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"71.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"83.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"77.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vid acc@1\\", \\"Score\\": \\"82.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Action Classification\\", \\"Dataset\\": \\"Kinetics-400\\", \\"Metric\\": \\"Vi"},{"Context":"WiC-TSV: An Evaluation Benchmark for Target Sense Verification of Words in Context We present WiC-TSV, anew multi-domain evaluation benchmark for Word Sense Disambiguation. More specifically, we introduce a framework for Target Sense Verification of Words in Context which grounds its uniqueness in the formulation as binary classification task thus being independent of external sense inventories, and the coverage of various domains. This makes the dataset highly flexible for the evaluation of a diverse set of models and systems in and across domains. WiC-TSV provides three different evaluation settings, depending on the input signals provided to the model. We set baseline performance on the dataset using state-of-the-art language models. Experimental results show that even though these models can perform decently on the task, there remains a gap between machine and human performance, especially in out-ofdomain settings. WiC-TSV data is available at https://competitions.codalab. org/competitions/23683 In this section we detail the construction of the dataset In this section we evaluate the performance of different baseline models on our WiC-TSV benchmark Table 2: Statistics of training, development and testing splits of WiC-TSV, including total number of instances (Total), unique number of target words (N w ) and per- centage of positive instances (R + ). ( WNT / WKT ) ( MSH+CTL+CPS ) R w Total + N Table 3: Average human accuracy for native English annotators, on different subsets of the dataset: general purpose, i.e., WNT/WKT, and the domain specific, i.e., MSH, CTL, and CPS. Human Perf . Table 4: Test set performance of the baseline models on WiC-TSV, in terms of accuracy, precision, recall, and F1, on the three different tasks. Baseline True is a naive baseline that always returns True and the human performance is computed as described in Section 3.4. Task - 3 Task - 2 Task - 1 Acc Rec WiC - TSV Prec F1 Table 6: F1 score for the in-domain few-shot analy- sis (Task-3) using","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: all\\", \\"Score\\": \\"75.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: domain specific\\", \\"Score\\": \\"77.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: general purpose\\", \\"Score\\": \\"73.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: all\\", \\"Score\\": \\"71.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: domain specific\\", \\"Score\\": \\"74.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: general purpose\\", \\"Score\\": \\"68.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: all\\", \\"Score\\": \\"76.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: domain specific\\", \\"Score\\": \\"80.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: general purpose\\", \\"Score\\": \\"73.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: all\\", \\"Score\\": \\"54.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: domain specific\\", \\"Score\\": \\"60.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: general purpose\\", \\"Score\\": \\"49.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: all\\", \\"Score\\": \\"62.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: domain specific\\", \\"Score\\": \\"69.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: general purpose\\", \\"Score\\": \\"57.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: all\\", \\"Score\\": \\"60.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: domain specific\\", \\"Score\\": \\"67.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: general purpose\\", \\"Score\\": \\"54.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: all\\", \\"Score\\": \\"53.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: domain specific\\", \\"Score\\": \\"50.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: general purpose\\", \\"Score\\": \\"56.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: all\\", \\"Score\\": \\"52.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: domain specific\\", \\"Score\\": \\"47.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: general purpose\\", \\"Score\\": \\"56.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: all\\", \\"Score\\": \\"53.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: domain specific\\", \\"Score\\": \\"49.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: general purpose\\", \\"Score\\": \\"57.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: all\\", \\"Score\\": \\"50.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: domain specific\\", \\"Score\\": \\"47.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: general purpose\\", \\"Score\\": \\"53.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: all\\", \\"Score\\": \\"50.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: domain specific\\", \\"Score\\": \\"47.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: general purpose\\", \\"Score\\": \\"53.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: all\\", \\"Score\\": \\"50.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: domain specific\\", \\"Score\\": \\"47.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: general purpose\\", \\"Score\\": \\"53.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: all\\", \\"Score\\": \\"85.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: domain specific\\", \\"Score\\": \\"89.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: general purpose\\", \\"Score\\": \\"82.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: all\\", \\"Score\\": \\"75.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: domain specific\\", \\"Score\\": \\"77.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: general purpose\\", \\"Score\\": \\"73.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: all\\", \\"Score\\": \\"71.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: domain specific\\", \\"Score\\": \\"74.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: general purpose\\", \\"Score\\": \\"68.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: all\\", \\"Score\\": \\"76.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: domain specific\\", \\"Score\\": \\"80.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: general purpose\\", \\"Score\\": \\"73.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: all\\", \\"Score\\": \\"54.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: domain specific\\", \\"Score\\": \\"60.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: general purpose\\", \\"Score\\": \\"49.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: all\\", \\"Score\\": \\"62.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: domain specific\\", \\"Score\\": \\"69.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: general purpose\\", \\"Score\\": \\"57.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: all\\", \\"Score\\": \\"60.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: domain specific\\", \\"Score\\": \\"67.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: general purpose\\", \\"Score\\": \\"54.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: all\\", \\"Score\\": \\"53.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: domain specific\\", \\"Score\\": \\"50.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: general purpose\\", \\"Score\\": \\"56.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: all\\", \\"Score\\": \\"52.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: domain specific\\", \\"Score\\": \\"47.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: general purpose\\", \\"Score\\": \\"56.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: all\\", \\"Score\\": \\"53.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: domain specific\\", \\"Score\\": \\"49.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: general purpose\\", \\"Score\\": \\"57.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: all\\", \\"Score\\": \\"50.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: domain specific\\", \\"Score\\": \\"47.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 1 Accuracy: general purpose\\", \\"Score\\": \\"53.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: all\\", \\"Score\\": \\"50.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: domain specific\\", \\"Score\\": \\"47.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 2 Accuracy: general purpose\\", \\"Score\\": \\"53.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: all\\", \\"Score\\": \\"50.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: domain specific\\", \\"Score\\": \\"47.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: general purpose\\", \\"Score\\": \\"53.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: all\\", \\"Score\\": \\"85.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: domain specific\\", \\"Score\\": \\"89.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Entity Linking\\", \\"Dataset\\": \\"WiC-TSV\\", \\"Metric\\": \\"Task 3 Accuracy: general purpose\\", \\"Score\\": \\"82.1\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WC-TSV\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"77.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WC-TSV\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"77.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WC-TSV\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"77.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WC-TSV\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"77.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WC-TSV\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"87.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WC-TSV\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"83.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Word Sense Disambiguation\\", \\"Dataset\\": \\"WC-TSV\\", \\"Metric\\": \\""},{"Context":"A Novel Model for Optimized GSM Network Design GSM networks are very expensive. The network design process requires too many decisions in a combinatorial explosion. For this reason, the larger is the network, the harder is to achieve a totally human based optimized solution. The BSC (Base Station Control) nodes have to be geographically well allocated to reduce the transmission costs. There are decisions of association between BTS and BSC those impacts in the correct dimensioning of these BSC. The choice of BSC quantity and model capable of carrying the cumulated traffic of its affiliated BTS nodes in turn reflects on the total cost. In addition, the last component of the total cost is due to transmission for linking BSC nodes to MSC. These trunks have a major significance since the number of required E1 lines is larger than BTS to BSC link. This work presents an integer programming model and a computational tool for designing GSM (Global System for Mobile Communications) networks, regarding BSS (Base Station Subsystem) with optimized cost.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Quaternion Knowledge Graph Embeddings In this work, we move beyond the traditional complex-valued representations, introducing more expressive hypercomplex representations to model entities and relations for knowledge graph embeddings. More specifically, quaternion embeddings, hypercomplex-valued embeddings with three imaginary components, are utilized to represent entities. Relations are modelled as rotations in the quaternion space. The advantages of the proposed approach are: (1) Latent inter-dependencies (between all components) are aptly captured with Hamilton product, encouraging a more compact interaction between entities and relations; (2) Quaternions enable expressive rotation in four-dimensional space and have more degree of freedom than rotation in complex plane; (3) The proposed framework is a generalization of ComplEx on hypercomplex space while offering better geometrical interpretations, concurrently satisfying the key desiderata of relational representation learning (i.e., modeling symmetry, anti-symmetry and inversion). Experimental results demonstrate that our method achieves state-of-the-art performance on four wellestablished knowledge graph completion benchmarks.  Table 2: Statistics of the data sets used in this paper. avg . #degree #training #test #validation N Table 3: Link prediction results on WN18 and FB15K. Best results are in bold and second best results are underlined. [ \u2020]: Results are taken from [Nickel et al., 2016]; [ ]: Results are taken from [Kadlec et al., 2017]; [ * ]: Results are taken from [Sun et al., 2019]. a-RotatE denotes RotatE with self-adversarial negative sampling. [QuatE 1 ]: without type constraints; [QuatE 2 ]: with N3 regularization and reciprocal learning; [QuatE 3 ]: with type constraints. 1 2 FB15K MR WN18 Hit@10 MRR Hit@1 - Hit@3 Table 4: Link prediction results on WN18RR and FB15K-237. [ \u2020]: Results are taken from [Nguyen et al., 2017]; [ ]: Results are taken from [Dettmers et al., 2018]; [ * ]: Results are taken from [Sun et al., 2019]. Hit@10 WN18RR FB15K -","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.945\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.959\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.954\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18\\", \\"Metric\\": \\"MR\\", \\"Score\\": \\"162\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.95\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.800\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.900\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.859\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k\\", \\"Metric\\": \\"MR\\", \\"Score\\": \\"17\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.833\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.438\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.582\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.508\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"MR\\", \\"Score\\": \\"2314\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.488\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.248\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.550\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.382\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"MR\\", \\"Score\\": \\"87\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"FB15k-237\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.348\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.957\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.947\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.963\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18\\", \\"Metric\\": \\"MRR\\", \\"Score\\": \\"0.963\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@1\\", \\"Score\\": \\"0.452\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@10\\", \\"Score\\": \\"0.582\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction\\", \\"Dataset\\": \\"WN18RR\\", \\"Metric\\": \\"Hits@3\\", \\"Score\\": \\"0.516\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Link Prediction"},{"Context":"ELECTRAMED: A NEW PRE-TRAINED LANGUAGE REPRESENTATION MODEL FOR BIOMEDICAL NLP The overwhelming amount of biomedical scientific texts calls for the development of effective language models able to tackle a wide range of biomedical natural language processing (NLP) tasks. The most recent dominant approaches are domain-specific models, initialized with general-domain textual data and then trained on a variety of scientific corpora. However, it has been observed that for specialized domains in which large corpora exist, training a model from scratch with just in-domain knowledge may yield better results. Moreover, the increasing focus on the compute costs for pre-training recently led to the design of more efficient architectures, such as ELECTRA. In this paper, we propose a pre-trained domain-specific language model, called ELECTRAMed, suited for the biomedical field. The novel approach inherits the learning framework of the general-domain ELECTRA architecture, as well as its computational advantages. Experiments performed on benchmark datasets for several biomedical NLP tasks support the usefulness of ELECTRAMed, which sets the novel state-of-the-art result on the BC5CDR corpus for named entity recognition, and provides the best outcome in 2 over the 5 runs of the 7th BioASQ-factoid Challange for the question answering task.Keywords Pre-trained language models \xb7 ELECTRA \xb7 Biomedical NLP * Corresponding authors.While ELMo and BERT architectures pre-trained on general-domain corpora are well-established top performers for general NLP tasks, they might yield poor results in case of scientific or specific domains, since the corpora used for pre-training, such as news articles and Wikipedia [3], might not include the same terminology adopted in the indomain tasks. For specialized contexts past studies showed that general-domain language models can largely benefit from the use of in-domain textual data [4]. As a consequence, recent models for biomedical NLP relied on adapted versions of general-domain approaches. Among these, two of the most noteworthy and successful examples are represented by BioBERT [5]  and BlueBERT [4], which are domain-specific language models initialized with the general-domain BERT, and then pre-trained on a wide range of biomedical and scientific corpora. In principle, these last methods rely on the assumption that initializing the pre-training from general-domain models might improve the overall performance for domain-specific purposes. However, it has been recently observed that for domains in which large corpora exist, like the biomedical field, pre-training language models from scratch yields better results than feeding the pre-training phase with general-domain knowledge [6].To obtain contextualized word embeddings, BERT pre-training is based on masked language modelling (MLM) which aims at predicting a small random subset of masked input tokens, considering only the token context. This approach allows the model to learn bidirectional representations. A different input corruption procedure has been recently proposed, in which instead of masking, and therefore losing, some of the input tokens, these are replaced with plausible alternatives produced by a small generator network. By learning from all the input tokens this novel approach, called ELECTRA (Efficiently Learning an Encoder that Classifies Token Replacements Accurately), is computationally much more efficient than BERT, and has been shown to outperform the latter in several tasks [7].  Table 1: Hyperparameters used for ELECTRAMed pre-training 1 / 3 2e - 4 Value 10000 768 1e - 6 Linear Table 1 : Hyperparameters used for ELECTRAMed pre - training 3072 Table 2: Description of the corpora used as benchmarks for biomedical NER 5 , 006 CPR : 4 1 , 212 effect 35 , 336 proteins 4 , 409 chemicals N . relations 10 , 028 TOT 10 , 227 TOT N . val 2 , 937 TOT Table 2 : Description of the corpora used as benchmarks for biomedical NER N . test 1 , 983 CPR : 3 N . entities 59 , 963 TOT Table 3: Description of the corpora used as benchmarks for biomedical RE 5 , 006 CPR : 4 1 , 212 effect 35 , 336 proteins 4 , 409 chemicals N . relations 10 , 028 TOT 10 , 227 TOT N .","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"ChemProt\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"72.94\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Drug\u2013drug Interaction Extraction\\", \\"Dataset\\": \\"DDI extraction 2013 corpus\\", \\"Metric\\": \\"Micro F1\\", \\"Score\\": \\"79.13\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"NCBI-disease\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"87.54\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Named Entity Recognition\\", \\"Dataset\\": \\"BC5CDR\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"90.03\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Natural Language Inference\\", \\"Dataset\\": \\"MultiNLI\\", \\"Metric\\": \\"Matched\\", \\"Score\\": \\"84.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Natural Language Inference\\", \\"Dataset\\": \\"MultiNLI\\", \\"Metric\\": \\"Mismatched\\", \\"Score\\": \\"84.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Natural Language Inference\\", \\"Dataset\\": \\"SNLI\\", \\"Metric\\": \\"% Test Accuracy\\", \\"Score\\": \\"90.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Natural Language Inference\\", \\"Dataset\\": \\"SciTail\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"89.9%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Natural Language Inference\\", \\"Dataset\\": \\"WNLI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"94.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Natural Language Inference\\", \\"Dataset\\": \\"QNLI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"90.5%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Textual Similarity\\", \\"Dataset\\": \\"STS Benchmark\\", \\"Metric\\": \\"Pearson Correlation\\", \\"Score\\": \\"0.9"},{"Context":"Understanding Humans in Crowded Scenes: Deep Nested Adversarial Learning and A New Benchmark for Multi-Human Parsing Despite the noticeable progress in perceptual tasks like detection, instance segmentation and human parsing, computers still perform unsatisfactorily on visually understanding humans in crowded scenes, such as group behavior analysis, person re-identification and autonomous driving, etc. To this end, models need to comprehensively perceive the semantic information and the differences between instances in a multi-human image, which is recently defined as the multi-human parsing task. In this paper, we present anew large-scale database \\"Multi-Human Parsing (MHP)\\" for algorithm development and evaluation, and advances the state-of-the-art in understanding humans in crowded scenes. MHP contains 25,403 elaborately annotated images with 58 fine-grained semantic category labels, involving 2-26 persons per image and captured in real-world scenes from various viewpoints, poses, occlusion, interactions and background. We further propose a novel deep Nested Adversarial Network (NAN) model for multi-human parsing. NAN consists of three Generative Adversarial Network (GAN)-like sub-nets, respectively performing semantic saliency prediction, instance-agnostic parsing and instance-aware clustering. These sub-nets form a nested structure and are carefully designed to learn jointly in an end-to-end way. NAN consistently outperforms existing state-of-the-art solutions on our MHP and several other datasets, and serves as a strong baseline to drive the future research for multi-human parsing. In total, there are 25,403 images in the MHP v2.0 dataset data distribution on 59 semantic categories, the average semantic category number per image and the average instance number per image in the MHP v2.0 dataset are illustrated in (a), (b) and (c), respectively The images in the MHP v2.0 dataset contain diverse instance numbers, viewpoints, poses, occlusion, interactions and background complexities We evaluate NAN qualitatively and quantitatively under various settings and granularities for understanding humans in crowded scenes In particular, we evaluate multihuman parsing performance on the MHP v2.0 dataset proposed in this work, as well as the MHP v1.0 and PASCAL-Person-Part benchmark datasets We also evaluate instance-agnostic parsing and instance-aware clustering results on the Buffy benchmark dataset, which are byproducts of NAN Following, we use the Average Precision based on part (AP p ) and Percentage of Correctly parsed semantic Parts (PCP) metrics for multi-human parsing evaluation We further Table 1: Statistics for publicly available human parsing datasets. 56 13 19 Datasets 10 , 000 # Testing PASCAL - Person - Part [ 4 ] # Training 1 , 000 LIP [ 17 ] 1 , 817 - # Total # Validation Table 2: Component analysis on the MHP v2.0 validation set. Upperbound diction are already small and have only little effect on the flow consistency , the superiority of which is verified by and Finally , we also semantic saliency prediction sub - net from NAN , leading human - centic processing . The superiority of incorporating process can be verified by comparing w / o Di , i \u2208 {1 , 2 , 3} results from the 2 refines \u2208 parses In particular , w / o G1 refers to truncating the results , refinement whereas different MH - Parser results complexity , the superiority of which is","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Multi-Human Parsing\\", \\"Dataset\\": \\"PASCAL-Part\\", \\"Metric\\": \\"AP 0.5\\", \\"Score\\": \\"59.70%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multi-Human Parsing\\", \\"Dataset\\": \\"MHP v2.0\\", \\"Metric\\": \\"AP 0.5\\", \\"Score\\": \\"25.14%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multi-Human Parsing\\", \\"Dataset\\": \\"MHP v1.0\\", \\"Metric\\": \\"AP 0.5\\", \\"Score\\": \\"57.09%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-Human Parsing\\", \\"Dataset\\": \\"MHP v2 test-dev\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"46.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-Human Parsing\\", \\"Dataset\\": \\"MHP v2 test-std\\", \\"Metric\\": \\"overall\\", \\"Score\\": \\"49.4\\"}} ]"},{"Context":"Adaloss: Adaptive Loss Function for Landmark Localization Landmark localization is a challenging problem in computer vision with a multitude of applications. Recent deeplearning based methods have shown improved results by regressing likelihood maps (i.e. heatmaps) instead of regressing the coordinates directly. However, setting the precision of these regression targets during the training has been a cumbersome process since it creates a trade-off between trainability vs. localization accuracy. Using precise targets introduces a significant sampling bias and hence makes the training more difficult, whereas using imprecise targets results in inaccurate landmark detectors. In this paper, we introduce \\"Adaloss\\", an objective function that adapts itself during the training by updating the target precision based on the training statistics. This approach does not require setting problem-specific parameters and shows improved stability in training and better localization accuracy in inference. We demonstrate the effectiveness of our proposed method in three very different applications of landmark localization: 1) the challenging task of precisely detecting catheter tips in medical X-ray images 1 , 2) localizing surgical instruments in endoscopic images 1 , and 3) localizing facial features on in-the-wild images where we show state-of-the-art results on the 300-W benchmark dataset. We evaluated our method on three very different landmark localization problems: catheter tip detection in X-ray images (single instance of a single landmark that needs to be localized very precisely), facial feature localization (single instances of multiple landmarks where the achievable precision is landmark-dependent), and surgical instrument Table 1: Euclidian distance on CathDet testing set for multi- ple values of sigma compared to Adaloss. \u03c3 = 60 Adaloss \u03c3 = 5 \u03c3 = 40 \u03c3 = 25 Table 2. Model trained with Adaloss presents a much smaller NTV (2.80 vs 3.03), indicating a potential impact of using Adaloss on filter smoothness. Adaloss Fixed sigma Table 2: Normalized Total Variation (NTV) score with and without Adaloss. \'all\' represents the aggregate NTV on all the layers, and \'last\' the NTV on the final convolutional layer. Model trained using Adaloss has smoother filters, indicating potential improvement in network stability. Adaloss Fixed sigma Table 3: Normalized mean errors (NME) on the 300-W dataset. Proposed approach shows best results on all testing sets. Challenging Full Common Table 4: Quantitative results of the Adaloss model on dif- ferent testing set of EndoVis: Recall (%) / Precision (%) / Euclidian distance (px). Left Clasper Right","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Facial Landmark Detection\\", \\"Dataset\\": \\"300W\\", \\"Metric\\": \\"NME\\", \\"Score\\": \\"3.31\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Facial Landmark Detection\\", \\"Dataset\\": \\"300W\\", \\"Metric\\": \\"NME\\", \\"Score\\": \\"3.49\\"}} ]"},{"Context":"A Surprisingly Robust Trick for the Winograd Schema Challenge The Winograd Schema Challenge (WSC) dataset WSC273 and its inference counterpart WNLI are popular benchmarks for natural language understanding and commonsense reasoning. In this paper, we show that the performance of three language models on WSC273 consistently and robustly improves when finetuned on a similar pronoun disambiguation problem dataset (denoted WSCR). We additionally generate a large unsupervised WSClike dataset. By fine-tuning the BERT language model both on the introduced and on the WSCR dataset, we achieve overall accuracies of 72.5% and 74.7% on WSC273 and WNLI, improving the previous state-of-theart solutions by 8.8% and 9.6%, respectively. Furthermore, our fine-tuned models are also consistently more accurate on the \\"complex\\" subsets of WSC273, introduced by Trichelair et al. (2018). The model is trained with a single epoch of the MaskedWiki dataset, using batches of size 64 (distributed on 8 GPUs), Adam optimizer, a learning rate of 5.0 \xb7 10 \u22126 , and hyperparameter val-ues \u03b1 = 20 and \u03b2 = 0.2 in the loss function) Both BERT and BERT WIKI are fine-tuned on the WSCR training dataset to create BERT WSCR and BERT WIKI WSCR The model BERT WIKI WSCR pairs is obtained by fine-tuning BERT WIKI on half of the WSCR dataset This time, all examples in the subset come in pairs, just like in the unreduced WSCR dataset We evaluate all models on WSC273 and the WNLI test dataset, as well as the various subsets of WSC273, as described in Section 2 Firstly, we note that models that are fine-tuned on the WSCR dataset consistently outperform their non-fine-tuned counterparts Secondly, the results of BERT WIKI seem to indicate Table 1: Results on WSC273 and its subsets. The comparison between each language model and its WSCR-tuned model is given. For each column, the better result of the two is in bold. The best result in the column overall is underlined. Results for the LM ensemble and Knowledge Hunter are taken from Trichelair et al. (2018). All models consistently improve their accuracy when fine-tuned on the WSCR dataset. - WSC273 assoc . consist . non - assoc . switched WNLI unswitched","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Common Sense Reasoning\\", \\"Dataset\\": \\"Winograd Schema Challenge\\", \\"Metric\\": \\"Score\\", \\"Score\\": \\"72.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Common Sense Reasoning\\", \\"Dataset\\": \\"Winograd Schema Challenge\\", \\"Metric\\": \\"Score\\", \\"Score\\": \\"70.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Natural Language Understanding\\", \\"Dataset\\": \\"WNLI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"71.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Natural Language Understanding\\", \\"Dataset\\": \\"WNLI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"70.5\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"WNLI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"74.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"WNLI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"74.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"WNLI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"74.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"WNLI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"74.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"WNLI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"74.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"WNLI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"81.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Sentiment Analysis\\", \\"Dataset\\": \\"WNLI\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"84.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\":"},{"Context":"Maximum \u2206-edge-colorable subgraphs of class II graphs A graph G is class II, if its chromatic index is at least \u2206 + 1. Let H be a maximum \u2206-edge-colorable subgraph of G. The paper proves best possible lower bounds for |E(H)| |E(G)| , and structural properties of maximum \u2206-edge-colorable subgraphs. It is shown that every set of vertex-disjoint cycles of a class II graph with \u2206 \u2265 3 can be extended to a maximum \u2206-edge-colorable subgraph. Simple graphs have a maximum \u2206-edge-colorable subgraph such that the complement is a matching. Furthermore, a maximum \u2206-edgecolorable subgraph of a simple graph is always class I.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Discriminative Adversarial Domain Adaptation Given labeled instances on a source domain and unlabeled ones on a target domain, unsupervised domain adaptation aims to learn a task classifier that can well classify target instances. Recent advances rely on domain-adversarial training of deep networks to learn domain-invariant features. However, due to an issue of mode collapse induced by the separate design of task and domain classifiers, these methods are limited in aligning the joint distributions of feature and category across domains. To overcome it, we propose a novel adversarial learning method termed Discriminative Adversarial Domain Adaptation (DADA). Based on an integrated category and domain classifier, DADA has a novel adversarial objective that encourages a mutually inhibitory relation between category and domain predictions for any input instance. We show that under practical conditions, it defines a minimax game that can promote the joint distribution alignment. Except for the traditional closed set domain adaptation, we also extend DADA for extremely challenging problem settings of partial and open set domain adaptation. Experiments show the efficacy of our proposed methods and we achieve the new state of the art for all the three settings on benchmark datasets. Datasets and Implementation Details) is a popular benchmark domain adaptation dataset consisting of 4, 110 images of 31 categories collected from three domains: Amazon (A), Webcam (W), and DSLR (D) We evaluate on six settings For open set domain adaptation, we evaluate on Syn2Real-O, which includes two domains Implementation Details We follow standard evaluation protocols for unsupervised domain adaptation: we use all labeled source and all unlabeled target instances as the training data For other tasks of Syn2Real, we evaluate the accuracy of each category based on ResNet-101 and ResNet-152 (for closed and open set domain adaptation respectively) Table 1: Ablation studies using Office-31 based on ResNet-50. Please refer to the main text for how they are defined. Avg Table 2: Results for closed set domain adaptation on Office-31 based on ResNet-50. Note that SimNet is implemented by an unknown framework; MADA and DANN-CA are implemented by Caffe; all the other methods are implemented by PyTorch. Avg Table 3: Results for closed set domain adaptation on Syn2Real-C based on ResNet-101. Note that all compared methods are based on PyTorch implementation. plane bus mcycl truck sktbrd horse bcycl knife car person mean plant train Table 4: Results for open set domain adaptation on Syn2Real-O based on ResNet-152. Known indicates the mean classification result over the known categories whereas Mean also includes the unknown category. The table below shows the results when the Known-to-Unknown Ratio in the target domain is set to 1 : 10. All compared methods are based on","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Synthetic-to-Real Translation\\", \\"Dataset\\": \\"Syn2Real-C\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"79.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Domain Adaptation\\", \\"Dataset\\": \\"Office-31\\", \\"Metric\\": \\"Average Accuracy\\", \\"Score\\": \\"89\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Domain Adaptation\\", \\"Dataset\\": \\"Office-31\\", \\"Metric\\": \\"Average Accuracy\\", \\"Score\\": \\"88.2\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Domain Adaptation\\", \\"Dataset\\": \\"Office-Home\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"72.3\\"}} ]"},{"Context":"Asynchronous Remote Medical Consultation for Ghana Computer-mediated communication systems can be used to bridge the gap between doctors in underserved regions with local shortages of medical expertise and medical specialists worldwide. To this end, we describe the design of a prototype remote consultation system intended to provide the social, institutional and infrastructural context for sustained, self-organizing growth of a globally-distributed Ghanaian medical community. The design is grounded in an iterative design process that included two rounds of extended design fieldwork throughout Ghana and draws on three key design principles (social networks as a framework on which to build incentives within a self-organizing network; optional and incremental integration with existing referral mechanisms; and a weakly-connected, distributed architecture that allows fora highly interactive, responsive system despite failures in connectivity). We discuss initial experiences from an ongoing trial deployment in southern Ghana.  Table 1. Categorization of analyzed conversational threads. 10 Social Professional Total","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":":2) Desharnais, Gupta, Jagadeesan and Panangaden introduced a family of behavioural pseudometrics for probabilistic transition systems. These pseudometrics area quantitative analogue of probabilistic bisimilarity. Distance zero captures probabilistic bisimilarity. Each pseudometric has a discount factor, areal number in the interval (0, 1]. The smaller the discount factor, the more the future is discounted. If the discount factor is one, then the future is not discounted at all. Desharnais et al. showed that the behavioural distances can be calculated up to any desired degree of accuracy if the discount factor is smaller than one. In this paper, we show that the distances can also be approximated if the future is not discounted. A key ingredient of our algorithm is Tarski\'s decision procedure for the first order theory over real closed fields. By exploiting the Kantorovich-Rubinstein duality theorem we can restrict to the existential fragment for which more efficient decision procedures exist.distance is zero if and only if the states are probabilistic bisimilar, a behavioural equivalence introduced by Larsen and Skou [26].The pseudometrics of Desharnais et al. are defined via real-valued interpretations of Larsen and Skou\'s probabilistic modal logic. Formulae assume truth values in the interval [0, 1]. Conjunction and disjunction are interpreted using the lattice structure of the unit interval. The modality a is interpreted arithmetically by integration. The behavioural distance between states s 1 and s 2 is then defined as the supremum overall formulae \u03d5 of the difference in the truth value of \u03d5 in s 1 and in s 2 . 1 The definition of the behavioural pseudometrics of Desharnais et al. is parametrized by a discount factor \u03b4, areal number in the interval (0, 1]. The smaller the discount factor, the more (behavioural differences in) the future are discounted. In the case that \u03b4 equals one, the future is not discounted. All differences in behaviour, whether in the near or far future, contribute alike to the distance. For systems that (in principle) run forever, we maybe interested in all these differences and, hence, in the pseudometric that does not discount the future.In [16], Desharnais et al. presented an algorithm to approximate the behavioural distances for \u03b4 smaller than one. The first and third author [7] presented also an approximation algorithm for \u03b4 smaller than one.There is a fundamental difference between pseudometrics that discount the future and the one that does not. This is, for example, reflected by the fact that all pseudometrics that discount the future give rise to the same topology, whereas the pseudometric that does not discount the future gives rise to a different topology (see, for example, [18, page 350]). As a consequence, it may not be surprising that neither approximation algorithm mentioned in the previous paragraph can be modified in an obvious way to handle the case that \u03b4 equals one.The main contribution of this paper is an algorithm that approximates behavioural distances in case the discount factor \u03b4 equals one. Starting from the logical definition of the pseudometric by Desharnais et al., we first give a characterisation of the pseudometric as the greatest (post-)fixed point of a functional on a complete lattice [0, 1] S , where S is the set of states of the probabilistic transition system in question. This functional is closely related to the Kantorovich metric [24] on probability measures. Next, we dualize this characterization exploiting the Kantorovich-Rubinstein duality theorem [25]. Subsequently, we show, exploiting the dual characterization, that a pseudometric being a post-fixed point can be expressed in the existential fragment of the first order theory over real closed fields. Based on the fact that this first order theory is decidable, a result due to Tarski [31], we show how to approximate the behavioural distances. Finally, we discuss an implementation of our algorithm in Mathematica.Exploiting the techniques put forward in this paper, we have also developed an algorithm to approximate the behavioural pseudometric that is presented in [3]. The other algorithm can be found in [30].","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Quasi-Dense Similarity Learning for Multiple Object Tracking Similarity learning has been recognized as a crucial step for object tracking. However, existing multiple object tracking methods only use sparse ground truth matching as the training objective, while ignoring the majority of the informative regions on the images. In this paper, we present Quasi-Dense Similarity Learning, which densely samples hundreds of region proposals on a pair of images for contrastive learning. We can directly combine this similarity learning with existing detection methods to build Quasi-Dense Tracking (QDTrack) without turning to displacement regression or motion priors. We also find that the resulting distinctive feature space admits a simple nearest neighbor search at the inference time. Despite its simplicity, QDTrack outperforms all existing methods on MOT, BDD100K, Waymo, and TAO tracking benchmarks. It achieves 68.7 MOTA at 20.3 FPS on MOT17 without using external training data. Compared to methods with similar detectors, it boosts almost 10 points of MOTA and significantly decreases the number of ID switches on BDD100K and Waymo datasets. 1 . We also like to test on larger scale and more diverse datasets to study the efficacy of quasi-dense similarity learning The dataset contains 7 videos (5,316 images) for training and 7 videos (5,919 images) for testing Only pedestrians are evaluated in this benchmark BDD100K We use BDD100K annotates 482 classes in total, which are the subset of LVIS dataset MOT17 with public detectors Following the strategy in Tracktor and CenterTrack, we evaluate our method with public detectors on MOT17 TAO presents detailed results on the TAO dataset Although QDTrack does not perform zero-shot and few-shot learning for the long-tail categories, our method is still a stronger baseline method on this dataset and paves the way for future studies Table 1: Results on MOT16 and MOT17 object tracking benchmark test set. Note that we do not use extra data for training. \u2191 means higher is better, \u2193 means lower is better. * means external data besides COCO and ImageNet is used. MOTA \u2191 IDF1 \u2191 MOTP \u2191 292 250 296 498 246 258 316 735 637 759 816 Table 2: Results on BDD100K tracking validation and test set. mMOTA and mIDF1 are averages over 8 categories while MOTA and IDF1 indicates the overall performance without considering categories. Our method outperforms the champion of BDD100K 2020 Tracking Challenge (madamada) only with a simple single model. mMOTA \u2191 mIDF1 \u2191 mAP \u2191 MOTA \u2191 IDF1 \u2191 - 292063 209339 Table 3: Results on Waymo tracking validation set using py-motmetrics library (top) 2 and test set using official evaluation. * indicates methods using undisclosed detectors. Miss / L2 \u2193 Miss / L1 \u2193","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Multi-Object Tracking\\", \\"Dataset\\": \\"MOT17\\", \\"Metric\\": \\"IDF1\\", \\"Score\\": \\"66.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multi-Object Tracking\\", \\"Dataset\\": \\"MOT17\\", \\"Metric\\": \\"MOTA\\", \\"Score\\": \\"68.7\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multi-Object Tracking\\", \\"Dataset\\": \\"MOT16\\", \\"Metric\\": \\"IDF1\\", \\"Score\\": \\"67.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multi-Object Tracking\\", \\"Dataset\\": \\"MOT16\\", \\"Metric\\": \\"MOTA\\", \\"Score\\": \\"69.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multi-Object Tracking\\", \\"Dataset\\": \\"BDD100K val\\", \\"Metric\\": \\"MOTA\\", \\"Score\\": \\"36.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multiple Object Tracking\\", \\"Dataset\\": \\"Waymo Open Dataset\\", \\"Metric\\": \\"MOTA\\", \\"Score\\": \\"51.18\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"One-Shot Object Detection\\", \\"Dataset\\": \\"PASCAL VOC 2012 val\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"22.1\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-Object Tracking\\", \\"Dataset\\": \\"MOT17\\", \\"Metric\\": \\"MOTA\\", \\"Score\\": \\"61.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-Object Tracking\\", \\"Dataset\\": \\"MOT16\\", \\"Metric\\": \\"MOTA\\", \\"Score\\": \\"68.03\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-Object Tracking\\", \\"Dataset\\": \\"nuScenes\\", \\"Metric\\": \\"amota\\", \\"Score\\": \\"0.18\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-Object Tracking\\", \\"Dataset\\": \\"Natural Questions (short)\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"60.42\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-Object Tracking\\", \\"Dataset\\": \\"Natural Questions (long)\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"Open.57\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-Object Tracking\\", \\"Dataset\\": \\"Natural Questions (Easy)\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"57.0\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Multi-Object Tracking\\", \\"Dataset\\": \\"Natural Questions (Easy)\\", \\"Metric\\": \\"F"},{"Context":"A Simple In-Place Algorithm for In-Shuffle","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Neural Machine Translation of Rare Words with Subword Units Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units. This is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via compositional translation), and cognates and loanwords (via phonological and morphological transformations). We discuss the suitability of different word segmentation techniques, including simple character ngram models and a segmentation based on the byte pair encoding compression algorithm, and empirically show that subword models improve over a back-off dictionary baseline for the WMT 15 translation tasks English\u2192German and English\u2192Russian by up to 1.1 and 1.3 BLEU, respectively.  Table 2: English\u2192German translation performance (BLEU, CHRF3 and unigram F 1 ) on newstest2015. Ens-8: ensemble of 8 models. Best NMT system in bold. Unigram F 1 (with ensembles) is computed for all words (n = 44085), rare words (not among top 50 000 in training set; n = 2900), and OOVs (not in training set; n = 1168). single all ens - 8 unigram F1 ( % ) BLEU rare OOV CHRF3 Table 1: Corpus statistics for German training corpus with different word segmentation tech- niques. #UNK: number of unknown tokens in newstest2013. \u25b3: 0 34 \u25b3 59 \u22c4 1079 32 0 # tokens # UNK 3000 # types Table 3: English\u2192Russian translation performance (BLEU, CHRF3 and unigram F 1 ) on newstest2015. Ens-8: ensemble of 8 models. Best NMT system in bold. Unigram F 1 (with ensembles) is computed for all words (n = 55654), rare words (not among","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2015 English-Russian\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"20.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2015 English-German\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"22.8\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-German\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"31.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-German\\", \\"Metric\\": \\"SacreBLEU\\", \\"Score\\": \\"34.8\\"}} ]"},{"Context":"Disentangling Physical Dynamics from Unknown Factors for Unsupervised Video Prediction Leveraging physical knowledge described by partial differential equations (PDEs) is an appealing way to improve unsupervised video prediction methods. Since physics is too restrictive for describing the full visual content of generic videos, we introduce PhyDNet, a two-branch deep architecture, which explicitly disentangles PDE dynamics from unknown complementary information. A second contribution is to propose anew recurrent physical cell (PhyCell), inspired from data assimilation techniques, for performing PDE-constrained prediction in latent space. Extensive experiments conducted on four various datasets show the ability of PhyDNet to outperform state-of-the-art methods. Ablation studies also highlight the important gain brought out by both disentanglement and PDE-constrained prediction. Finally, we show that PhyDNet presents interesting features for dealing with missing data and long-term forecasting. Datasets We evaluate PhyDNet on four datasets from various origins We give details about all datasets in supplementary 2.1 Metrics are scaled to be in a similar range across datasets to ease comparison Network architectures and training PhyDNet shares a common backbone architecture for all datasets where the physical branch contains 49 PhyCells (7 \xd7 7 kernel filters) and the residual branch is composed of a 3-layers ConvL-STM with 128 filters in each layer We follow evaluation metrics commonly used in state-of-the-art video prediction methods: the Mean Squared Error (MSE), Mean Absolute Error (MAE) and the Structural Similarity (SSIM) that computes the perceived image quality with respect to a reference Table 1. Quantitative forecasting results of PhyDNet compared to baselines using various datasets. Numbers are copied from original or citing papers. * corresponds to results obtained by running online code from the authors. The first five baseline are general deep models applicable to all datasets, whereas DDPAE MAE MAE / 100 SSIM MSE \xd710 MSE / 10 MSE \xd7100 - MSE Table 2. An ablation study shows the consistent performance gain on all datasets of our physically-constrained PhyCell vs the general purpose ConvLSTM, and the additional gain brought up by the disentangling architecture PhyDNet. * corresponds to results obtained by running online code from the authors. MAE MAE / 100 SSIM MSE \xd7 100 MSE / 10 MSE \xd7 10 MSE Table 3. Influence of physical regularization for Moving MNIST. MAE SSIM MSE","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Video Prediction\\", \\"Dataset\\": \\"Moving MNIST\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"70.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Video Prediction\\", \\"Dataset\\": \\"Moving MNIST\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"24.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Video Prediction\\", \\"Dataset\\": \\"Moving MNIST\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.947\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Video Prediction\\", \\"Dataset\\": \\"Human3.6M\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"1620\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Video Prediction\\", \\"Dataset\\": \\"Human3.6M\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"369\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Video Prediction\\", \\"Dataset\\": \\"Human3.6M\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.901\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Video Prediction\\", \\"Dataset\\": \\"D&D\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"4.35\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Prediction\\", \\"Dataset\\": \\"D&D\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"5.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Prediction\\", \\"Dataset\\": \\"D&D\\", \\"Metric\\": \\"SSIM\\", \\"Score\\": \\"0.895\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Prediction\\", \\"Dataset\\": \\"D&D\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"5.44\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Prediction\\", \\"Dataset\\": \\"D&D\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"5.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Prediction\\", \\"Dataset\\": \\"D&D\\", \\"Metric\\": \\"MAE\\", \\"Score\\": \\"0.07\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Prediction\\", \\"Dataset\\": \\"D&D\\", \\"Metric\\": \\"MSE\\", \\"Score\\": \\"0.17\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Video Prediction\\", \\"Dataset\\": "},{"Context":"SphereFace: Deep Hypersphere Embedding for Face Recognition This paper addresses deep face recognition (FR) problem under open-set protocol, where ideal face features are expected to have smaller maximal intra-class distance than minimal inter-class distance under a suitably chosen metric space. However, few existing algorithms can effectively achieve this criterion. To this end, we propose the angular softmax (A-Softmax) loss that enables convolutional neural networks (CNNs) to learn angularly discriminative features. Geometrically, A-Softmax loss can be viewed as imposing discriminative constraints on a hypersphere manifold, which intrinsically matches the prior that faces also lie on a manifold. Moreover, the size of angular margin can be quantitatively adjusted by a parameter m. We further derive specific m to approximate the ideal feature criterion. Extensive analysis and experiments on Labeled Face in the Wild (LFW), Youtube Faces (YTF) and MegaFace Challenge show the superiority of A-Softmax loss in FR tasks. The code has also been made publicly available 1 . CNNs with different depths (4, 10, 20, 36, 64) are used to better evaluate our method We use publicly available web-collected training dataset CASIA-WebFace (after excluding the images of identities appearing in testing sets) to train our CNN models Notice that the scale of our training data (0.49M) is relatively small, especially compared to other private datasets used in DeepFace (4M), VGGFace (2M) and FaceNet (200M) We also use class 1 (blue) and class 2 (dark green) to construct positive and negative pairs to evaluate the angle distribution of features from the same class and different classes Besides visual comparison, we also perform face recognition on LFW and YTF to evaluate the effect of m LFW dataset includes 13,233 face images from 5749 different identities, and YTF dataset includes 3,424 videos from 1,595 different individuals Both datasets contains faces with large variations in pose, expression and illuminations We follow the unrestricted Table 2: Our CNN architectures with different convolutional layers. Conv1.x, Conv2.x and Conv3.x denote convolution units that may contain multiple convolution layers and residual units are shown in double-column brackets. E.g., [3\xd73, 64]\xd74 denotes 4 cascaded convolution layers with 64 filters of size 3\xd73, and S2 denotes stride 2. FC1 is the fully connected layer. \xd7 16 [ 3\xd73 , 256 ] \xd71 , S2 64 - layer CNN [ 3\xd73 , 128 ] \xd71 , S2 20 - layer CNN [ 3\xd73 , 64 ] \xd71 , S2 10 - layer CNN [ 3\xd73 , 512 ] \xd71 , S2 36 - layer CNN Table 3. One can observe that while m becomes larger, the accuracy of A-Softmax loss also be- comes better, which shows that larger angular margin can bring stronger discrimination power. m=1 m=3 m=2 m=4 Original Table 3: Accuracy(%) comparison of different m (A-Softmax loss) and original","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"Trillion Pairs Dataset\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"43.76\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"MegaFace\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"89.142%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"MegaFace\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"85.561%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"CK+\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"93.80\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"YouTube Faces DB\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95.0%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"Labeled Faces in the Wild\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"99.42%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Identification\\", \\"Dataset\\": \\"Trillion Pairs Dataset\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"43.89\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Identification\\", \\"Dataset\\": \\"MegaFace\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"75.766%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Face Identification\\", \\"Dataset\\": \\"MegaFace\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"72.729%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"YouTube Faces DB\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"98.12%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Face Verification\\", \\"Dataset\\": \\"Labeled Faces in the Wild\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"99.03%\\"}} ]"},{"Context":"RGBD Salient Object Detection via Deep Fusion Numerous efforts have been made to design different low level saliency cues for the RGBD saliency detection, such as color or depth contrast features, background and color compactness priors. However, how these saliency cues interact with each other and how to incorporate these low level saliency cues effectively to generate a master saliency map remain a challenging problem. In this paper, we design anew convolutional neural network (CNN) to fuse different low level saliency cues into hierarchical features for automatically detecting salient objects in RGBD images. In contrast to the existing works that directly feed raw image pixels to the CNN, the proposed method takes advantage of the knowledge in traditional saliency detection by adopting various meaningful and well-designed saliency feature vectors as input. This can guide the training of CNN towards detecting salient object more effectively due to the reduced learning ambiguity. We then integrate a Laplacian propagation framework with the learned CNN to extract a spatially consistent saliency map by exploiting the intrinsic structure of the input image. Extensive quantitative and qualitative experimental evaluations on three datasets demonstrate that the proposed method consistently outperforms state-of-the-art methods. In this section, we evaluate the proposed method on three datasets, NLPR RGBD salient dataset, NJUDS2000 stereo datast, and LFSD dataset NLPR dataset The NLPR RGBD salient dataset, BSCA, MB+, and LEGS are obtained from RGB image while the saliency maps of LMH, ACSD, GP are from RGBD image We split this dataset into two part randomly: 750 for training and 250 for testing NJUDS2000 dataset The NJUDS2000 dataset contains 2000 stereo images, as well as the corresponding depth maps and manually labeled groundtruth We also split this dataset into two part randomly: 1000 for training and 1000 for testing LFSD dataset The LFSD dataset contains 100 images with depth information and manually labeled groundtruth All the images in this dataset are for testing Evaluation metrics We compute the precision-recall (PR) curve, mean of average precision and recall, and F-measure score to evaluate the performance of different saliency detection methods","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"RGB-D Salient Object Detection\\", \\"Dataset\\": \\"NJU2K\\", \\"Metric\\": \\"Average MAE\\", \\"Score\\": \\"0.205\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"RGB-D Salient Object Detection\\", \\"Dataset\\": \\"NJU2K\\", \\"Metric\\": \\"S-Measure\\", \\"Score\\": \\"51.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"RGB-D Salient Object Detection\\", \\"Dataset\\": \\"NJU2K\\", \\"Metric\\": \\"max E-Measure\\", \\"Score\\": \\"72.4\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"RGB-D Salient Object Detection\\", \\"Dataset\\": \\"NJU2K\\", \\"Metric\\": \\"max F-Measure\\", \\"Score\\": \\"63.2\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"RGB-D Salient Object Detection\\", \\"Dataset\\": \\"NJU2K\\", \\"Metric\\": \\"Average MAE\\", \\"Score\\": \\"0.07\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"RGB-D Salient Object Detection\\", \\"Dataset\\": \\"NJU2K\\", \\"Metric\\": \\"S-Measure\\", \\"Score\\": \\"91.1\\"}} ]"},{"Context":"Learning Geometry-Disentangled Representation for Complementary Understanding of 3D Object Point Cloud In 2D image processing, some attempts decompose images into high and low frequency components for describing edge and smooth parts respectively. Similarly, the contour and flat area of 3D objects, such as the boundary and seat area of a chair, describe different but also complementary geometries. However, such investigation is lost in previous deep networks that understand point clouds by directly treating all points or local patches equally. To solve this problem, we propose Geometry-Disentangled Attention Network (GDANet). GDANet introduces Geometry-Disentangle Module to dynamically disentangle point clouds into the contour and flat part of 3D objects, respectively denoted by sharp and gentle variation components. Then GDANet exploits Sharp-Gentle Complementary Attention Module that regards the features from sharp and gentle variation components as two holistic representations, and pays different attentions to them while fusing them respectively with original point cloud features. In this way, our method captures and refines the holistic and complementary 3D geometric semantics from two distinct disentangled components to supplement the local information. Extensive experiments on 3D object classification and segmentation benchmarks demonstrate that GDANet achieves the state-of-the-arts with fewer parameters. Code is released on https://github.com/mutianxu/GDANet. We evaluate our network on shape classification task and part segmentation task on various datasets Table 1: Segmentation results (%) on ShapeNet Part dataset. motor inst . chair rocket bag lamp pistol aero guitar mIOU knife cap top car phone ear lap skate class mug board table Table 2: Classification accuracy (%) on ModelNet40 dataset. Acc . Table 3: Classification results (%) on ScanObjectNN dataset (noise robustness test). acc drop OBJ ONLY OBJ BG Table 4: Geometry-Disentangled complementary effect to supplement KNN information in GDANet on ModelNet40. \'knn\' indicates KNN aggregation, \'self\' means the input point cloud is fused with itself by self-attention, \'sharp\' and \'gentle\' denote the input point cloud is fused with features of sharp and gentle variation, \'voting\' is the voting strategy during testing, respectively. hancement of random point dropout during training . acc . ( % ) Density robustness test . ( a ) . Point cloud with ran - Table 5: Classification results (%) of using different point selection methods in","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"3D Part Segmentation\\", \\"Dataset\\": \\"ShapeNet-Part\\", \\"Metric\\": \\"Class Average IoU\\", \\"Score\\": \\"85.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Part Segmentation\\", \\"Dataset\\": \\"ShapeNet-Part\\", \\"Metric\\": \\"Instance Average IoU\\", \\"Score\\": \\"86.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"3D Point Cloud Classification\\", \\"Dataset\\": \\"ModelNet40\\", \\"Metric\\": \\"Overall Accuracy\\", \\"Score\\": \\"93.8\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Part Segmentation\\", \\"Dataset\\": \\"ShapeNet-Part\\", \\"Metric\\": \\"Class Average IoU\\", \\"Score\\": \\"84.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Part Segmentation\\", \\"Dataset\\": \\"ShapeNet-Part\\", \\"Metric\\": \\"Instance Average IoU\\", \\"Score\\": \\"86.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Point Cloud Classification\\", \\"Dataset\\": \\"ScanObjectNN\\", \\"Metric\\": \\"Overall Accuracy\\", \\"Score\\": \\"73.7\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Point Cloud Classification\\", \\"Dataset\\": \\"ModelNet40\\", \\"Metric\\": \\"Overall Accuracy\\", \\"Score\\": \\"92.4\\"}} ]"},{"Context":"Cognitive MAC Protocols Using Memory for Distributed Spectrum Sharing Under Limited Spectrum Sensing The main challenges of cognitive radio include spectrum sensing at the physical (PHY) layer to detect the activity of primary users and spectrum sharing at the medium access control (MAC) layer to coordinate access among coexisting secondary users. In this paper, we consider a cognitive radio network in which a primary user shares a channel with secondary users that cannot distinguish the signals of the primary user from those of a secondary user. We propose a class of distributed cognitive MAC protocols to achieve efficient spectrum sharing among the secondary users while protecting the primary user from potential interference by the secondary users. By using a MAC protocol with one-slot memory, we can obtain high channel utilization by the secondary users while limiting interference to the primary user at a low level. The results of this paper suggest the possibility of utilizing MAC design in cognitive radio networks to overcome limitations in spectrum sensing at the PHY layer as well as to achieve spectrum sharing at the MAC layer.Cognitive medium access control, cognitive radio networks, protocols with memory, spectrum sensing, spectrum sharing.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"A-CNN: Annularly Convolutional Neural Networks on Point Clouds Analyzing the geometric and semantic properties of 3D point clouds through the deep networks is still challenging due to the irregularity and sparsity of samplings of their geometric structures. This paper presents anew method to define and compute convolution directly on 3D point clouds by the proposed annular convolution. This new convolution operator can better capture the local neighborhood geometry of each point by specifying the (regular and dilated) ring-shaped structures and directions in the computation. It can adapt to the geometric variability and scalability at the signal processing level. We apply it to the developed hierarchical neural networks for object classification, part segmentation, and semantic segmentation in large-scale scenes. The extensive experiments and comparisons demonstrate that our approach outperforms the state-of-the-art methods on a variety of standard benchmark datasets (e.g., ModelNet10, ModelNet40, ShapeNetpart, S3DIS, and ScanNet). We evaluate our A-CNN model on various tasks such as point cloud classification, part segmentation, and largescale scene segmentation 7 show the quantitative results of part segmentation on ShapeNet-part dataset with two different inputs For ShapeNet-part dataset, we visualize more results (besides the segmentation results shown in the paper) in For S3DIS dataset, we pick rooms from all six areas: area 1 (row 1), area 2: The visualization results on S3DIS dataset Table 1: Classification results on ModelNet10 and ModelNet40 datasets. AAC is accuracy average class, OA is overall accuracy. point cloud based methods with 1024 points different methods with additional input or more points OA AAC ModelNet40 ModelNet10 Table 2: Segmentation results on ShapeNet-part, S3DIS, and Scan- Net. \\"mean\\" is mean IoU (%), OA is overall accuracy. - OA mean without normals S3DIS ShapeNet - part - with normals ScanNet Table 3: Ablation experiments on ModelNet40 dataset. AAC is accuracy average class, OA is overall accuracy. OA AAC Table 4: Experiments on redundancy on ModelNet40 dataset. AAC is accuracy average class, OA is overall accuracy. OA AAC Table 5: Network configurations. inner , Router ] , k is number of neighbors , F is feature map size . For - [ 16 , 48 ] [ [ 64 , 64 , 128 ] , [ 128 , 128 , 256 ] ]","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"3D Point Cloud Classification\\", \\"Dataset\\": \\"ModelNet40\\", \\"Metric\\": \\"Overall Accuracy\\", \\"Score\\": \\"92.6\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"3D Part Segmentation\\", \\"Dataset\\": \\"ShapeNet-Part\\", \\"Metric\\": \\"Instance Average IoU\\", \\"Score\\": \\"84.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Point Cloud Classification\\", \\"Dataset\\": \\"ScanObjectNN\\", \\"Metric\\": \\"Overall Accuracy\\", \\"Score\\": \\"78.5\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Point Cloud Classification\\", \\"Dataset\\": \\"ModelNet40\\", \\"Metric\\": \\"Mean Accuracy\\", \\"Score\\": \\"90.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Point Cloud Classification\\", \\"Dataset\\": \\"ModelNet40\\", \\"Metric\\": \\"Overall Accuracy\\", \\"Score\\": \\"92.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Point Cloud Classification\\", \\"Dataset\\": \\"ModelNet40\\", \\"Metric\\": \\"Overall Accuracy\\", \\"Score\\": \\"92.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Point Cloud Classification\\", \\"Dataset\\": \\"ModelNet40\\", \\"Metric\\": \\"Mean Accuracy\\", \\"Score\\": \\"81.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"3D Point Cloud Classification\\", \\"Dataset\\": \\"ModelNet40\\", \\"Metric\\": \\"Overall Accuracy\\", "},{"Context":"Self-stabilizing Tiny Interaction Protocols In this paper we present the self-stabilizing implementation of a class of token based algorithms. In the current work we only consider interactions between weak nodes. They are uniform, they do not have unique identifiers, are static and their interactions are restricted to a subset of nodes called neighbours. While interacting, a pair of neighbouring nodes may create mobile agents (that materialize in the current work the token abstraction) that perform traversals of the network and accelerate the system stabilization. In this work we only explore the power of oblivious stateless agents. Our work shows that the agent paradigm is an elegant distributed tool for achieving selfstabilization in Tiny Interaction Protocols (TIP). Nevertheless, in order to reach the full power of classical self-stabilizing algorithms more complex classes of agents have to be considered (e.g. agents with memory, identifiers or communication skills). Interestingly, our work proposes for the first time a model that unifies the recent studies in mobile robots(agents) that evolve in a discrete space and the already established population protocols paradigm.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"LT-GAN: Self-Supervised GAN with Latent Transformation Detection Generative Adversarial Networks (GANs) coupled with self-supervised tasks, have shown promising results in unconditional and semi-supervised image generation. We propose a self-supervised approach (LT-GAN) to improve the generation quality and diversity of images by estimating the GAN-induced transformation (i.e. transformation induced in the generated images by perturbing the latent space of generator). Specifically, given two pairs of images where each pair comprises of a generated image and its transformed version, the self-supervision task aims to identify whether the latent transformation applied in the given pair is same to that of the other pair. Hence, this auxiliary loss encourages the generator to produce images that are distinguishable by the auxiliary network, which in turn promotes the synthesis of semantically consistent images with respect to latent transformations. We show the efficacy of this pretext task by improving the image generation quality in terms of FID on state-of-the-art models for both conditional and unconditional settings on CIFAR-10, CelebA-HQ and ImageNet datasets. Moreover, we empirically show that LT-GAN helps in improving controlled image editing for CelebA-HQ and ImageNet over baseline models. We experimentally demonstrate that our proposed LT self-supervision task can be effectively combined with other state-of-the-art training techniques for added benefits. Consequently, we show that our approach achieves the new state-of-the-art FID score of 9.8 on conditional CIFAR-10 image generation. Datasets We validate our proposed self-supervised task on CIFAR-10, STL-10, CelebA-HQ-128 and ImageNet-2012 datasets FID has been shown to be more consistent with human evaluation of image quality and also helps in detecting intra-class mode collapse We calculate FID between test set images and equal number of generated images for all datasets and report the best FID obtained across 3 runs We use this methodology to discover latent space trajectories corresponding to the image transformations: brightness, scale, horizontal shift and vertical shift for BigGAN conditional model trained on ImageNet dataset CelebA-HQ Dataset InterfaceGAN provides a framework to find the interpretable semantic directions encoded in the latent space of face synthesis GAN models Table 1: Comparison of self-supervised LT-GAN training approach with # FID Table 2: Classification accuracy (%) on separation boundaries in latent LT - GAN SS - GAN Baseline Table 3: Correlation matrix of synthesized attribute distributions of Table 4: FID comparison of LT-GAN with SS-GAN on different datasets STL - 10 CIFAR - 10 CelebA - HQ Table 5: Inception Score for SNDCGAN and BigGAN architectures BigGAN","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CelebA-HQ 128x128\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"16.84\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"9.80\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"4.30\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"CIFAR-10\\", \\"Metric\\": \\"Inception score\\", \\"Score\\": \\"8.49\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Generation\\", \\"Dataset\\": \\"ImageNet 32x32\\", \\"Metric\\": \\"FID\\", \\"Score\\": \\"12.3\\"}} ]"},{"Context":"EfficientPose: An efficient, accurate and scalable end-to-end 6D multi object pose estimation approach In this paper we introduce EfficientPose, anew approach for 6D object pose estimation. Our method is highly accurate, efficient and scalable over a wide range of computational resources. Moreover, it can detect the 2D bounding box of multiple objects and instances as well as estimate their full 6D poses in a single shot. This eliminates the significant increase in runtime when dealing with multiple objects other approaches suffer from. These approaches aim to first detect 2D targets, e.g. keypoints, and solve a Perspective-n-Point problem for their 6D pose for each object afterwards. We also propose a novel augmentation method for direct 6D pose estimation approaches to improve performance and generalization, called 6D augmentation. Our approach achieves anew state-of-theart accuracy of 97.35% in terms of the ADD(-S) metric on the widely-used 6D pose estimation benchmark dataset Linemod using RGB input, while still running end-to-end at over 27 FPS. Through the inherent handling of multiple objects and instances and the fused single shot 2D object detection as well as 6D pose estimation, our approach runs even with multiple objects (eight) end-to-end at over 26 FPS, making it highly attractive to many real world scenarios. Code will be made publicly available at In this section we describe the experiments we did, our experimental setup with implementation details as well as the evaluation metrics we use We evaluate our approach on two popular benchmark datasets which are described in this subsection We evaluate our approach with the commonly used ADD(-S) metric Symmetric objects are evaluated using the ADD-S metric which is given by the following equation Method YOLO6D Pix2Pose PVNet DPOD DPOD+ CDPN Hybrid-Pose Ours \u03c6 = 0 Quantitative evaluation and comparison on the Linemod dataset in terms of the ADD(-S) metric Table 1. Quantitative evaluation and comparison on the Linemod dataset in terms of the ADD(-S) metric. Symmetric objects are marked with * and approaches marked with + are using an additional refinement method. \u03c6 = 3 100 Ours Table 2. Quantitative evaluation in terms of the ADD(-S) metric for the task of multi object 6D pose estimation using a single model on the Occlusion dataset. Symmetric objects are marked with * Ours \u03c6 = 0 Ours \u03c6 = 3 Table 3. Runtime analysis and comparison of our method performing single and multiple object pose estimation while using different scales. For single object 6D pose estimation the Linemod dataset is used while for multi object pose estimation the Occlusion dataset is used which contains usually eight annotated objects per image. We further compare our method\'s runtime with the vanilla EfficientDet Single Multi Table 4. Ablation study to evaluate the influence of our","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"6D Pose Estimation using RGB\\", \\"Dataset\\": \\"LineMOD\\", \\"Metric\\": \\"Accuracy (ADD)\\", \\"Score\\": \\"97.35%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"6D Pose Estimation using RGB\\", \\"Dataset\\": \\"LineMOD\\", \\"Metric\\": \\"Mean ADD\\", \\"Score\\": \\"97.35\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"6D Pose Estimation using RGB\\", \\"Dataset\\": \\"LineMOD\\", \\"Metric\\": \\"Mean ADD\\", \\"Score\\": \\"47.4\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"6D Pose Estimation using RGB\\", \\"Dataset\\": \\"LineMOD\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"94.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"6D Pose Estimation using RGB\\", \\"Dataset\\": \\"LineMOD\\", \\"Metric\\": \\"Accuracy (ADD)\\", \\"Score\\": \\"94.3\\"}} ]"},{"Context":"Neural-Guided RANSAC: Learning Where to Sample Model Hypotheses We present Neural-Guided RANSAC (NG-RANSAC), an extension to the classic RANSAC algorithm from robust optimization. NG-RANSAC uses prior information to improve model hypothesis search, increasing the chance of finding outlier-free minimal sets. Previous works use heuristic side information like hand-crafted descriptor distance to guide hypothesis search. In contrast, we learn hypothesis search in a principled fashion that lets us optimize an arbitrary task loss during training, leading to large improvements on classic computer vision tasks. We present two further extensions to NG-RANSAC. Firstly, using the inlier count itself as training signal allows us to train neural guidance in a self-supervised fashion. Secondly, we combine neural guidance with differentiable RANSAC to build neural networks which focus on certain parts of the input data and make the output predictions as good as possible. We evaluate NG-RANSAC on a wide array of computer vision tasks, namely estimation of epipolar geometry, horizon line estimation and camera re-localization. We achieve superior or competitive results compared to state-of-the-art robust estimators, including very recent, learned ones. We evaluate neural guidance on multiple, classic computer vision tasks","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Horizon Line Estimation\\", \\"Dataset\\": \\"Horizon Lines in the Wild\\", \\"Metric\\": \\"AUC (horizon error)\\", \\"Score\\": \\"75.2\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet (finetuned)\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"71.1%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet (finetuned)\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"90.3%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 1 Accuracy\\", \\"Score\\": \\"75.4%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Self-Supervised Image Classification\\", \\"Dataset\\": \\"ImageNet\\", \\"Metric\\": \\"Top 5 Accuracy\\", \\"Score\\": \\"90.0%\\"}} ]"},{"Context":"Aerial Imagery Pixel-level Segmentation Aerial Imagery Pixel-level Segmentation Aerial imagery can be used for important work on a global scale. Nevertheless, the analysis of this data using neural network architectures lags behind the current state-of-the-art on popular datasets such as PASCAL VOC, CityScapes and Camvid. In this paper we bridge the performance-gap between these popular datasets and aerial imagery data. Little work is done on aerial imagery with state-of-the-art neural network architectures in a multiclass setting. Our experiments concerning data augmentation, normalisation, image size and loss functions give insight into a high performance setup for aerial imagery segmentation datasets. Our work, using the state-of-the-art DeepLabv3+ Xception65 architecture, achieves a mean IOU of 70% on the DroneDeploy validation set. With this result, we clearly outperform the current publicly available state-of-the-art validation set mIOU (65%) performance with 5%. Furthermore, to our knowledge, there is no mIOU benchmark for the test set. Hence, we also propose anew benchmark on the DroneDeploy test set using the best performing DeepLabv3+ Xception65 architecture, with a mIOU score of 52.5%. Since we are dealing with a pixel level segmentation problem, it might seem logical to think of pixel accuracy as a valid evaluation metric For aerial datasets such as the DroneDeploy dataset this problem is more important since the ground (37.7%) and vegetation (10.43%) classes are dominantly present, so this cannot be ignored CCE loss is still widely used in the current state-of-the-art, but given the expected class imbalance issues in our dataset, we also inspect a loss function which deals explicitly with class imbalance The need for this is also discussed in where they discuss weighting their loss \\"for each output channel in order to counteract a class imbalance present in the dataset\\" In this section we look into how these design choices affect their performance in detail by experimenting on an aerial imagery dataset Geospatial datasets comes in a large number of different file formats, sizes, and schemes There Table 2: Details of the cluster used for training and experimentation A Precision scores recorded using the Weights and Biases package , for all exploratory S : Table 3: Results of DeepLabv3+ and u-net architecture variants trained on the DroneDe- ploy dataset. val: mean IOU on validation set trained on train set only. test: mean IOU on test set trained on train+validation set. Class IOU scores: 1:Building, 2:Clutter, 3:Vegetation, 4:Water, 5:Ground, 6:Car f1: f1 mean, reported for benchmark architecture comparison against DroneDe- ploy public leaderboard. test set . val test aforementioned for training f1 with 1 2 are obtained by training for 40 epochs on the 3 split 4 5 6 of Table 4: Results of DeepLabv3+ architecture variants trained on the DroneDeploy train and validation images. test: mean IOU on test set. Class IOU scores: 1:Building, 2:Clutter, 3:Vegetation, 4:Water, 5:Ground, 6:Car. 1 2 3 4 test 5","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"DroneDeploy\\", \\"Metric\\": \\"Mean IoU (test)\\", \\"Score\\": \\"52.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"DroneDeploy\\", \\"Metric\\": \\"Mean IoU (val)\\", \\"Score\\": \\"69.9\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"Cityscapes test\\", \\"Metric\\": \\"Mean IoU (class)\\", \\"Score\\": \\"78.4%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL VOC 2012 test\\", \\"Metric\\": \\"Mean IoU\\", \\"Score\\": \\"68.10%\\"}} ]"},{"Context":"FCNs in the Wild: Pixel-level Adversarial and Constraint-based Adaptation Fully convolutional models for dense prediction have proven successful fora wide range of visual tasks. Such models perform well in a supervised setting, but performance can be surprisingly poor under domain shifts that appear mild to a human observer. For example, training on one city and testing on another in a different geographic region and/or weather condition may result in significantly degraded performance due to pixel-level distribution shift. In this paper, we introduce the first domain adaptive semantic segmentation method, proposing an unsupervised adversarial approach to pixel prediction problems. Our method consists of both global and category specific adaptation techniques. Global domain alignment is performed using a novel semantic segmentation network with fully convolutional domain adversarial learning. This initially adapted space then enables category specific adaptation through a generalization of constrained weak learning, with explicit transfer of the spatial layout from the source to the target domains. Our approach outperforms baselines across different settings on multiple large-scale datasets, including adapting across various real city environments, different synthetic sub-domains, from simulated to real environments, and on a novel large-scale dash-cam dataset. In this section, we report our experimental results on three different domain adaptation tasks: cities \u2192 cities, season \u2192 season, and synthetic \u2192 real, studied across four different datasets All code and models are trained and evaluated in the Caffe framework and will be made available before camera-ready For fair comparison, we use the Intersection over Union (IoU) evaluation metric for all experiments For cities \u2192 cities and synthetic \u2192 real tasks, we followed the evaluation protocol of and train our models with 19 semantic labels of Cityscapes The whole dataset is divided into three parts: 2, 975 training samples, 500 validation samples and 1, 525 test samples The split of this dataset is city-level, which covers individual European cities in different geographic and population distribution We take the whole dataset with labels compatible to Cityscapes categories for synthetic \u2192 real adaptation Table 1: Adaptation from synthetic to real. We study the performance using GTA5 and SYNTHIA as source labeled training data adapted and Cityscapes train as an unlabeled target domain, while evaluating our adaptation algorithm on Cityscapes val. Meanwhile, we show an ablation of the components of our method and how each contributes to the overall performance of our approach. Here GA represents global domain alignment and CA indicates category specific adaptation. SYNTHIA \u2192 Cityscapes mIoU bike Table 2: Adaptation across seasons. We study the cross season performance using sub-sequences of SYNTHIA dataset. We report quantitative comparisons of performance before and after adaptation for training on one season and evaluating on another unannotated novel season. (Avg: the average performance of adaptation from one to another.) sky sidewalk bicycle sign vegetation pole building mIoU t road car light pedestrian lanemarking fence Table 3: Adaptation across cities. We study the performance using Cityscapes train","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"SYNTHIA Fall-to-Winter\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"59.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"SYNTHIA-to-Cityscapes\\", \\"Metric\\": \\"mIoU (13 classes)\\", \\"Score\\": \\"20.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Synthetic-to-Real Translation\\", \\"Dataset\\": \\"GTAV-to-Cityscapes Labels\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"27.1\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image-to-Image Translation\\", \\"Dataset\\": \\"GTAV-to-Cityscapes Labels\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"43.2\\"}} ]"},{"Context":"A Trust-Based Cross-Layer Security Protocol for Mobile Ad hoc Networks In this paper, we develop a trust based security protocol based on a cross-layer approach which attains confidentiality and authentication of packets in both routing and link layers of MANETs. In the first phase of the protocol, we design a trust based packet forwarding scheme for detecting and isolating the malicious nodes using the routing layer information. It uses trust values to favor packet forwarding by maintaining a trust counter for each node. A node is punished or rewarded by decreasing or increasing the trust counter. If the trust counter value falls below a trust threshold, the corresponding intermediate node is marked as malicious. In the next phase of the protocol, we provide link-layer security using the CBC-X mode of authentication and encryption. By simulation results, we show that the proposed cross-layer security protocol achieves high packet delivery ratio while attaining low delay and overhead.The neighbor attack and the black hole attack prevent the data from being delivered to the destination. But the neighbor attacker does not catch and capture the data packets from the source node. It leaves the settings as soon as sending the false messages.Two malicious nodes share a private communication link between them. One node captures the traffic information of the network and sends them directly to other node. Warm hole can eavesdrop the traffic, maliciously drop the packets, and perform man-in-the-middle attacks against the network protocols.[6].When the network bandwidth is hacked by a malicious node [5], then it results to the DoS attack. In order to utilize precious network resources like bandwidth, or to utilize node resources like memory or computation power, the attacker inserts packets into the network. The specific instances of the DoS attack are the routing table overflow attack and energy consumption attack.The information disclosure attack aims at the privacy requirements of network. The confidential information\'s like A. Rajaram received the B.E. degree in electronics and communication engineering from the Govt., college of Technology, Coimbatore, Anna University, Chennai, India, in 2006, the M.E. degree in electronics and communication engineering (Applied Electronics) from the Govt., college of Technology, Anna University, Chennai, India, in 2008 and he is currently pursuing the full time Ph.D. degree in electronics and communication engineering from the Anna University Coimbatore, Coimbatore, India. His research interests include communication and networks mobile adhoc networks, wireless communication networks (WiFi, WiMax HighSlot GSM), novel VLSI NOC Design approaches to address issues such as low-power, cross-talk, hardware acceleration, Design issues includes OFDM MIMO and noise Suppression in MAI Systems, ASIC design, Control systems, Fuzzy logic and Networks, AI, Sensor Networks.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Algebraic Linear Orderings An algebraic linear ordering is a component of the initial solution of a first-order recursion scheme over the continuous categorical algebra of countable linear orderings equipped with the sum operation and the constant 1. Due to a general Mezei-Wright type result, algebraic linear orderings are exactly those isomorphic to the linear ordering of the leaves of an algebraic tree. Using Courcelle\'s characterization of algebraic trees, we obtain the fact that a linear ordering is algebraic if and only if it can be represented as the lexicographic ordering of a deterministic contextfree language. When the algebraic linear ordering is a well-ordering, its order type is an algebraic ordinal. We prove that the Hausdorff rank of any scattered algebraic linear ordering is less than \u03c9 \u03c9 . It follows that the algebraic ordinals are exactly those less than \u03c9 \u03c9 \u03c9 .","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"Efficient Image Retrieval via Decoupling Diffusion into Online and Offline Processing Diffusion is commonly used as a ranking or re-ranking method in retrieval tasks to achieve higher retrieval performance, and has attracted lots of attention in recent years. A downside to diffusion is that it performs slowly in comparison to the naive k-NN search, which causes a non-trivial online computational cost on large datasets. To overcome this weakness, we propose a novel diffusion technique in this paper. In our work, instead of applying diffusion to the query, we precompute the diffusion results of each element in the database, making the online search a simple linear combination on top of the k-NN search process. Our proposed method becomes 10\u223c times faster in terms of online search speed. Moreover, we propose to use late truncation instead of early truncation in previous works to achieve better retrieval performance. For the efficiency evaluation, we use a single core of Intel Xeon 2.80GHz CPU Datasets We use the Oxford Buildings ) and Paris) datasets in our experiments The datasets are referred to as Oxford5k and Paris6k respectively in correspondence with the size of each dataset Another set of 100k random images from Flicker) are commonly used as distractors to enlarge the above datasets to Oxford105k and Paris106k We measure the online computational time on the 55 queries of the datasets for Iscen\'s method) and our proposed method For evaluation, we adopt the standard mean average precision (mAP) as a performance measurement We experiment on both global and regional features provided For the Oxford and Paris datasets, there are 21 regional features per image on average We conduct k-NN search by using the efficient FAISS toolkit 1 , containing a CPU version and a faster GPU version, which allows us to deal Table 1: Performance comparison with the state of the art. We used R-MAC features extracted with VGG Figure 6 : Retrieval performance ( mAP ) vs . the size of truncated graph L using early truncation and late truncation . Iscen , late R - MAC ( VGG ) R - MAC ( ResNet ) Oxf5k Par6k Par106k 10 3 size of truncated graph k - NN 10 2 ( c ) Paris6k ( d ) Paris106k Oxf105k ours , early Iscen , early ours , late","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"Par106k\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"96.2%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"Oxf105k\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"95.2%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"Par6k\\", \\"Metric\\": \\"mAP\\", \\"Score\\": \\"97.8%\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"Oxf5k\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"96.2%\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"Par106k\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"90.8%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"Oxf105k\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"87.8%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"Par6k\\", \\"Metric\\":\\"mAP\\", \\"Score\\": \\"93.8%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Image Retrieval\\", \\"Dataset\\": \\"Oxf5k\\", \\"Metric\\": \\"MAP\\", \\"Score\\": \\"89.9%\\"}} ]"},{"Context":"Decoders Matter for Semantic Segmentation: Data-Dependent Decoding Enables Flexible Feature Aggregation Recent semantic segmentation methods exploit encoderdecoder architectures to produce the desired pixel-wise segmentation prediction. The last layer of the decoders is typically a bilinear upsampling procedure to recover the final pixel-wise prediction. We empirically show that this oversimple and data-independent bilinear upsampling may lead to sub-optimal results.In this work, we propose a data-dependent upsampling (DUpsampling) to replace bilinear, which takes advantages of the redundancy in the label space of semantic segmentation and is able to recover the pixel-wise prediction from low-resolution outputs of CNNs. The main advantage of the new upsampling layer lies in that with a relatively lowerresolution feature map such as 1 16 or 1 32 of the input size, we can achieve even better segmentation accuracy, significantly reducing computation complexity. This is made possible by 1) the new upsampling layer\'s much improved reconstruction capability; and more importantly 2) the DUpsampling based decoder\'s flexibility in leveraging almost arbitrary combinations of the CNN encoders\' features. Experiments demonstrate that our proposed decoder outperforms the state-of-the-art decoder, with only \u223c20% of computation. Finally, without any post-processing, the framework equipped with our proposed decoder achieves new state-of-the-art performance on two datasets: 88.1% mIOU on PASCAL VOC with 30% computation of the previously best model; and 52.5% mIOU on PASCAL Context. The proposed models are evaluated on the PASCAL VOC 2012 semantic segmentation benchmark and PAS-CAL Context benchmark PASCAL VOC is the dataset widely used for semantic segmentation Table 1: mIOU over the PASCAL VOC val set of DUpsampling vs. bilinear upsampling. \\"output stride\\" indicates the ratio of in- put image spatial resolution to final output resolution. mIOU* denotes the upper bound. mIOU * ( % ) mIOU ( % ) Table 2: mIOU over PASCAL VOC val set when using differ- ent fusion of features. bxuycz denotes low-level features named block x/unit y/conv z in ResNet. \\"FLOPS\\" denotes the amount of computation of the decoder including feature aggregation, con- volutional decoder and the final upsampling. FLOPS mIOU ( % ) Table 2. The best one is the combination of conv1 3 + b3u6u3, achieving mIOU 74.20% over val set. Additionally, as shown in is the combination of conv1 3 + b3u6u3 , achieving mIOU Table 2 . Table 3: mIOU over the PASCAL VOC val set when using dif- ferent fusion strategies of features. bxuycz denotes low-level fea-","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL Context\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"52.5\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"PASCAL Context\\", \\"Metric\\":\\"mIoU\\", \\"Score\\": \\"51.2\\"}} ]"},{"Context":"OmniNet: Omnidirectional Representations from Transformers This paper proposes Omnidirectional Representations from Transformers (OMNINET). In OmniNet, instead of maintaining a strictly horizontal receptive field, each token is allowed to attend to all tokens in the entire network. This process can also be interpreted as a form of extreme or intensive attention mechanism that has the receptive field of the entire width and depth of the network. To this end, the omnidirectional attention is learned via a meta-learner, which is essentially another self-attention based model. In order to mitigate the computationally expensive costs of full receptive field attention, we leverage efficient self-attention models such as kernel-based (Choromanski et al., 2020), low-rank attention ) and/or Big Bird (Zaheer et al., 2020 as the meta-learner. Extensive experiments are conducted on autoregressive language modeling (LM1B, C4), Machine Translation, Long Range Arena (LRA), and Image Recognition. The experiments show that OmniNet achieves considerable improvements across these tasks, including achieving state-of-the-art performance on LM1B, WMT\'14 En-De/En-Fr, and Long Range Arena. Moreover, using omnidirectional representation in Vision Transformers leads to significant improvements on image recognition tasks on both few-shot learning and fine-tuning setups. Similar to the ViT setup, we pre-train our OmniNet models on the JFT dataset with 18k classes and 303M images, for 7 epochs We evaluate our models in the transfer setup (few-shot and fine-tuning) on several downstream tasks: ImageNet, CIFAR-10, CIFAR-100), Oxford-IIIT Pets, and Oxford Flowers-102 For WMT\'17, we build sentencepiece tokenizers of 32K from the dataset WMT\'17 collections are obtained from Tensorflow datasets (TFDS) For autoregressive language modeling, the C4 corpus is similarly found in TFDS Table 1. Experimental results (quality, i.e., perplexity scores at 30K and 100K respectively) on autoregressive language modeling. All models are approximately 50M parameters. LM1B C4 Table 2. Comparison with existing state-of-the-art and published works on One Billion Word Language modeling (Chelba et al., 2013) benchmark. LM1B C4 Table 3. Results on five collections from the WMT\'17 machine translation task. En - De Ru - En En - Fi Cs - En En - Fr Table 4. Comparisons with the state-of-the-art on WMT\'14 En-De and WMT\'14 En-Fr. OmniNet outperforms ADMIN (Liu et al., 2020), the current state-of-the-art deep transformer model for MT. n / a En - De En - Fr Table 5. Results on Long Range Arena (Tay et al., 2020a). Retrieval Avg ListOps Text Table 6. Transfer performance of pre-trained OmniNet and equivalent ViT models in fine-tuning setup on popular image classification benchmarks. All models are pre-trained on the JFT-300M","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-French\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"42.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2017 Russian-English\\", \\"Metric\\": \\"BLEU\\", \\"Score\\": \\"36.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2017 English-Finnish\\", \\"Metric\\": \\"BLEU\\", \\"Score\\": \\"20.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2017 Chinese-English\\", \\"Metric\\": \\"BLEU\\", \\"Score\\": \\"23.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2017 English-French\\", \\"Metric\\": \\"BLEU\\", \\"Score\\": \\"43.1\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2014 English-German\\", \\"Metric\\": \\"BLEU score\\", \\"Score\\": \\"29.8\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Machine Translation\\", \\"Dataset\\": \\"WMT2017 English-German\\", \\"Metric\\": \\"BLEU\\", \\"Score\\": \\"29.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"One Billion Word\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"100M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"One Billion Word\\", \\"Metric\\": \\"PPL\\", \\"Score\\": \\"21.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"One Billion Word\\", \\"Metric\\": \\"PPL\\", \\"Score\\": \\"21.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"One Billion Word\\", \\"Metric\\": \\"PPL\\", \\"Score\\": \\"22\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Stanford Cars\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"96.2%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"CUB-200-2011\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"98%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Oxford 102 Flowers\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"94.9%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Caltech-101\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"90.8%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"Caltech-101\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"90.8%\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Fine-Grained Image Classification\\", \\"Dataset\\": \\"OMNIGLOT\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"95%\\"}}]"},{"Context":"Capturing Polynomial Time on Interval Graphs We prove a characterization of all polynomial-time computable queries on the class of interval graphs by sentences of fixed-point logic with counting. More precisely, it is shown that on the class of unordered interval graphs, any query is polynomial-time computable if and only if it is definable in fixed-point logic with counting. This result is one of the first establishing the capturing of polynomial time on a graph class which is defined by forbidden induced subgraphs. For this, we define a canonical form of interval graphs using a type of modular decomposition, which is different from the method of tree decomposition that is used inmost known capturing results for other graph classes, specifically those defined by forbidden minors. The method might also be of independent interest for its conceptual simplicity. Furthermore, it is shown that fixed-point logic with counting is not expressive enough to capture polynomial time on the classes of chordal graphs or incomparability graphs.","PWC Annotation":"unanswerable","LLM prediction":"unanswerable"},{"Context":"EFFICIENT LONG-DISTANCE RELATION EXTRACTION WITH DG-SPANBERT In natural language processing, relation extraction seeks to rationally understand unstructured text. Here, we propose a novel SpanBERT-based graph convolutional network (DG-SpanBERT) that extracts semantic features from a raw sentence using the pre-trained language model SpanBERT and a graph convolutional network to pool latent features. Our DG-SpanBERT model inherits the advantage of SpanBERT on learning rich lexical features from large-scale corpus. It also has the ability to capture long-range relations between entities due to the usage of GCN on dependency tree. The experimental results show that our model outperforms other existing dependency-based and sequence-based models and achieves a state-of-the-art performance on the TACRED dataset.Relation extraction aims to discern the semantic relation that exists between two entities within the context of a sentence. For example, in the sentence \\"The key was in a chest\\", \\"key\\" is a subject entity and \\"chest\\" is an object entity. The target for relation extraction is to predict the relation between \\"key\\" and \\"chest\\", which is \\"Content-Container\\". Relation extraction plays a fundamental role in natural language understanding of unstructured text, such as knowledge base population [1], question answering [2] and information extraction [3].The existing solutions for relation extraction can be categorized into dependency-based and sequence-based approaches. Dependency-based models rely on the dependency trees that are able to provide rich structural and syntactic information for classifying relations; see, for example, [4] and [5]. Sequence-based models directly operate on the word sequences and forgo the information of dependency structures. For example, the model described in [6] relies on a multi-level attention mechanism to capture the attentions regarding target entities and relations. Bidirectional Long Short-Term Memory (LSTM) is applied on sentences to capture the semantic features in [7]. Recently, BERT-related models [8,9,10] have shown their ability to improve relation extraction tasks and achieve state-of-the-art results.Although BERT-based models are strong on learning rich semantic features, they may not effectively capture the long-range syntactic relations. For example, in the sentence \\"Arcandor said in documents filed Wednesday with a district court in Essen, where it is based, that the 15 companies include Corporate Service Group GmbH\\", with \\"Arcandor\\" as the subject and \\"Corporate Service Grroup GmbH\\" as the object, it is difficult for sequence-based models to extract features between such long-distance entities. Therefore, we propose DG-SpanBERT model, which is the first to combine BERT-related model with Graph Convolutional Network (GCN) on relation extraction. Specifically, our model groups BERT sentence-embedding in a dependency tree structure and then uses a GCN network to extract features from the tree. The TACRED dataset contains over 106K sentences, and it covers 41 relation types (e.g., per:schools_attended and org:members) and one \\"no relation\\" label to describe the relation between the subject and the object in the sentences To make an appropriate comparison, all evaluated models in this paper are trained with the same setting Table 1: Compare DG-SpanBERT with other models on TACRED dataset. Bold indicates the best performance among all. P R F1 Table 2: Compare average F1 performance for those token distances \u2265 11 tokens between the subject and object. Bold indicates the best performance among all. F1","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"TACRED\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"71.5\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"TACRED\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"60.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"SemEval-2010 Task 8\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"71.3\\"}} ]"},{"Context":"Fast-Slow Recurrent Neural Networks Processing sequential data of variable length is a major challenge in a wide range of applications, such as speech recognition, language modeling, generative image modeling and machine translation. Here, we address this challenge by proposing a novel recurrent neural network (RNN) architecture, the Fast-Slow RNN (FS-RNN). The FS-RNN incorporates the strengths of both multiscale RNNs and deep transition RNNs as it processes sequential data on different timescales and learns complex transition functions from onetime step to the next. We evaluate the FS-RNN on two character level language modeling data sets, Penn Treebank and Hutter Prize Wikipedia, where we improve state of the art results to 1.19 and 1.25 bits-per-character (BPC), respectively. In addition, an ensemble of two FS-RNNs achieves 1.20 BPC on Hutter Prize Wikipedia outperforming the best known compression algorithm with respect to the BPC measure. We also present an empirical investigation of the learning and network dynamics of the FS-RNN, which explains the improved performance compared to other RNN architectures. Our approach is general as any kind of RNN cell is a possible building block for the FS-RNN architecture, and thus can be flexibly applied to different tasks. The FS-LSTM is evaluated on two character level language modeling data sets, namely Penn Treebank and Hutter Prize Wikipedia, which will be referred to as enwik8 in this section Table 1: BPC on Penn Treebank - Param Count Table 1 : BPC on Penn Treebank BPC Table 2: BPC on enwik8 2 \xd7 47M 18M 27M 14M 47M 35M 46M 23M 21M 64M Table 2 : BPC on enwik8 BPC Table 3: Hyperparameters for the character-level language model experiments. 1200 FS - LSTM - 4 1500 enwik8 Penn Treebank FS - LSTM - 4 FS - LSTM - 2","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"enwik8\\", \\"Metric\\": \\"Bit per Character (BPC)\\", \\"Score\\": \\"1.25\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"enwik8\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"47M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"Hutter Prize\\", \\"Metric\\": \\"Bit per Character (BPC)\\", \\"Score\\": \\"1.245\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"Hutter Prize\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"47M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"Hutter Prize\\", \\"Metric\\": \\"Bit per Character (BPC)\\", \\"Score\\": \\"1.277\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"Hutter Prize\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"27M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"Penn Treebank (Character Level)\\", \\"Metric\\": \\"Bit per Character (BPC)\\", \\"Score\\": \\"1.190\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"Penn Treebank (Character Level)\\", \\"Metric\\": \\"Number of params\\", \\"Score\\": \\"27M\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"Penn Treebank (Character Level)\\", \\"Metric\\": \\"Bit per Character (BPC)\\", \\"Score\\": \\"1.193\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Language Modelling\\", \\"Dataset\\": \\"enwik8\\", \\"Metric\\": \\"Bit per Character (BPC)\\", \\"Score\\": \\"1.22\\"}} ]"},{"Context":"ScaleNAS: One-Shot Learning of Scale-Aware Representations for Visual Recognition Scale variance among different sizes of body parts and objects is a challenging problem for visual recognition tasks. Existing works usually design a dedicated backbone or apply Neural architecture Search(NAS) for each task to tackle this challenge. However, existing works impose significant limitations on the design or search space. To solve these problems, we present ScaleNAS, a one-shot learning method for exploring scale-aware representations. Scale-NAS solves multiple tasks at a time by searching multi-scale feature aggregation. ScaleNAS adopts a flexible search space that allows an arbitrary number of blocks and crossscale feature fusions. To cope with the high search cost incurred by the flexible space, ScaleNAS employs one-shot learning for multi-scale supernet driven by grouped sampling and evolutionary search. Without further retraining, ScaleNet can be directly deployed for different visual recognition tasks with superior performance. We use Scale-NAS to create high-resolution models for two different tasks, ScaleNet-P for human pose estimation and ScaleNet-S for semantic segmentation. ScaleNet-P and ScaleNet-S outperform existing manually crafted and NAS-based methods in both tasks. When applying ScaleNet-P to bottom-up human pose estimation, it surpasses the state-of-the-art High-erHRNet. In particular, ScaleNet-P4 achieves 71.6% AP on COCO test-dev, achieving new state-of-the-art result. In this section, we evaluate ScaleNAS by searching neural architectures for semantic segmentation and human pose estimation First we train SuperScaleNet on semantic segmentation with Ctiyscapes dataset and derive ScaleNet-S using ScaleNAS Then we apply the same searching routine on top-down human pose estimation framework with COCO dataset to derive ScaleNet-P In order to evaluate the generalizability of ScaleNet, we apply ScaleNet-P to HigherHRNet framework for bottom-up human pose estimation To stabilize training, we first train the teacher model with full depths and fusions on ImageNet-1k dataset Did you use tabular or surrogate benchmarks for indepth evaluations? -No, existing surrogate benchmarks such as NASBench-101, NAS-Bench-201, NAS-Bench-1Shot1 are not application to our search space Table 1. Semantic segmentation results on Cityscapes val (single scale and no flipping). The GFLOPs is calculated on the input size 1024 \xd7 2048. \'D-X\' equals to \'Dilated-X\'. For existing segmentation NAS works, the total cost grows linear to the number of deployment scenarios N , while the cost of our ScaleNAS remains constant. spectively . Without additional retraining , ScaleNet - S1 out - improves the mIoU to 82 . 0% , surpassing HRNet and Auto - #Params Backbone GFLOPs we use ( GPU hours ) Method Total Cost ( N =40 ) - mIoU 200 300 ( % ) 600 More training details can be found in the sup - After the teacher model is trained , Table 2. Top-down human pose estimation results. 256\xd7192 Comparison on MPII val . The GFLOPs is calculated on the input size 256 \xd7 256 . We reuse the searched ScaleNet - P","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Multi-Person Pose Estimation\\", \\"Dataset\\": \\"CrowdPose\\", \\"Metric\\": \\"mAP @0.5:0.95\\", \\"Score\\": \\"71.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multi-Person Pose Estimation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP\\", \\"Score\\": \\"71.6\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multi-Person Pose Estimation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"90.3\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multi-Person Pose Estimation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"78.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multi-Person Pose Estimation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"77.2\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multi-Person Pose Estimation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"67.5\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multi-Person Pose Estimation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AR\\", \\"Score\\": \\"76.0\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Multi-Person Pose Estimation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AR50\\", \\"Score\\": \\"92.3\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP50\\", \\"Score\\": \\"71.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP75\\", \\"Score\\": \\"41.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APL\\", \\"Score\\": \\"72.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APM\\", \\"Score\\": \\"40.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"APS\\", \\"Score\\": \\"22.1\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"box AP\\", \\"Score\\": \\"41.3\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Semantic Segmentation\\", \\"Dataset\\": \\"COCO test-dev\\", \\"Metric\\": \\"AP50\\", \\"Score\\": "},{"Context":"Satellite Image Time Series Classification with Pixel-Set Encoders and Temporal Self-Attention Satellite image time series, bolstered by their growing availability, are at the forefront of an extensive effort towards automated Earth monitoring by international institutions. In particular, large-scale control of agricultural parcels is an issue of major political and economic importance. In this regard, hybrid convolutional-recurrent neural architectures have shown promising results for the automated classification of satellite image time series.We propose an alternative approach in which the convolutional layers are advantageously replaced with encoders operating on unordered sets of pixels to exploit the typically coarse resolution of publicly available satellite images. We also propose to extract temporal features using a bespoke neural architecture based on self-attention instead of recurrent networks. We demonstrate experimentally that our method not only outperforms previous state-of-the-art approaches in terms of precision, but also significantly decreases processing time and memory requirements. Lastly, we release a large openaccess annotated dataset as a benchmark for future work on satellite image time series. We evaluate our models using Sentinel-2 multi-spectral image sequences in top-of-canopy reflectance Data Preparation: In order to evaluate both ours and convolution-based methods, we organize the parcels into two different formats: patches and pixel sets Note that the geometric features f must be computed and saved before preparing the dataset, as all spatial structure is henceforth lost The dataset is highly imbalanced as is often the casein such real word applications and this motivated the use of the focal loss to train our models Both datasets will be released upon publication To the best of our knowledge, no benchmark dataset currently exists for object-based agricultural parcel classification Our datasets area first step towards more reproducible and comparable methodological work in this field Table 1: Configuration of our model chosen for the numer- ical experiments. The dimension of each successive feature space is given for MLPs and fully connected layers. We show the corresponding number of trainable parameters on the last column. parameters 128 , 32 , 4 Hyperparameters Number of 32 \u2192 32 10 \u2192 32 \u2192 64 64 Table 2: Classification metrics and time benchmark of the different architectures. The inter-fold standard deviation of the OA and mIoU is given in smaller font. Additionally, the total time for one epoch of training, and for inference on the complete dataset are given on the third and fourth columns. 1 disk space required for training and pure inference, 2 time for the entire training Training ( s / epoch ) mIoU OA Disk Size Gb Table 3: Ablation study of our different design choices, sorted by decreasing mIoU. minor drop in precision . mIoU","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Classification\\", \\"Dataset\\": \\"s2-agri\\", \\"Metric\\": \\"mIoU\\", \\"Score\\": \\"50.9\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Time Series Classification\\", \\"Dataset\\": \\"s2-agri\\", \\"Metric\\": \\"oAcc\\", \\"Score\\": \\"94.2\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Satellite Image Classification\\", \\"Dataset\\": \\"Satellite Image Classification Challenge\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"94.9\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Satellite Image Classification\\", \\"Dataset\\": \\"Satellite Image Classification Challenge\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"92.8\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Satellite Image Classification\\", \\"Dataset\\": \\"Satellite Image Classification Challenge\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"80.6\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Satellite Image Classification\\", \\"Dataset\\": \\"Satellite Image Classification Challenge\\", \\"Metric\\": \\"Accuracy\\", \\"Score\\": \\"9Nu\\"}} ]"},{"Context":"Reasoning with Latent Structure Refinement for Document-Level Relation Extraction Document-level relation extraction requires integrating information within and across multiple sentences of a document and capturing complex interactions between inter-sentence entities. However, effective aggregation of relevant information in the document remains a challenging research question. Existing approaches construct static document-level graphs based on syntactic trees, co-references or heuristics from the unstructured text to model the dependencies. Unlike previous methods that may not be able to capture rich non-local interactions for inference, we propose a novel model that empowers the relational reasoning across sentences by automatically inducing the latent document-level graph. We further develop a refinement strategy, which enables the model to incrementally aggregate relevant information for multi-hop reasoning. Specifically, our model achieves an F 1 score of 59.05 on a large-scale documentlevel dataset (DocRED), significantly improving over the previous results, and also yields new state-of-the-art results on the CDR and GDA dataset. Furthermore, extensive analyses show that the model is able to discover more accurate inter-sentence relations.  Table 1: Hyper-parameters of LSR. Adam 2 20 120 Table 2: Main results on the development and the test set of DocRED: Models with p are adapted to DocRED based on their open implementations. Results with * are computed based on re-trained models as we need to evaluate F 1 for both intra-and inter-sentence setting, which are not given in original papers. Ign F 1 Dev Test F 1 Inter - F 1 Intra - F 1 Table 3: Results on the test set of the CDR dataset. The methods below the double line take advantage of addi- tional training data and/or incorporate external tools. - F 1 Inter - F 1 Intra - F 1 - Table 4: Results on the test set of the GDA dataset. F 1 Inter - F 1 Intra - F 1 Table 5: Ablation study of LSR on DocRED. F 1 Inter - F","PWC Annotation":"[{\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"DocRED\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"59.05\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"DocRED\\", \\"Metric\\": \\"Ign F1\\", \\"Score\\": \\"56.97\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"DocRED\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"54.18\\"}}, {\\"LEADERBOARD\\": {\\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"DocRED\\", \\"Metric\\": \\"Ign F1\\", \\"Score\\": \\"52.15\\"}}]","LLM prediction":"[{ \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"DocRED\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"59.82\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"DocRED\\", \\"Metric\\": \\"Ign F1\\", \\"Score\\": \\"57.89\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"DocRED\\", \\"Metric\\": \\"F1\\", \\"Score\\": \\"55.75\\"}}, { \\"LEADERBOARD\\": { \\"Task\\": \\"Relation Extraction\\", \\"Dataset\\": \\"DocRED\\", \\"Metric\\": \\"Ign F1\\", \\"Score\\": \\"53.43\\"}} ]"}]'),va=function(e){d(a,e);var t=p(a);function a(e){var i;n(this,a),(i=t.call(this,e)).onRefresh=function(){for(var e=ba[Math.floor(450*Math.random())+1];!i.checkJson(e["LLM prediction"])||!i.checkJson(e["PWC Annotation"]);)e=ba[Math.floor(450*Math.random())+1];i.setState({title:"",abstract:e.Context,label:e["PWC Annotation"],prediction:e["LLM prediction"]})};for(var o=ba[Math.floor(450*Math.random())+1];!i.checkJson(o["LLM prediction"])||!i.checkJson(o["PWC Annotation"]);)o=ba[Math.floor(450*Math.random())+1];return i.label_heading="PWC Annotation",i.prediction_heading="LLM Prediction",i.state={title:"",abstract:o.Context,label:o["PWC Annotation"],prediction:o["LLM prediction"]},i}return c(a,[{key:"checkJson",value:function(e){try{return JSON.parse(e),!0}catch(t){return!1}}},{key:"render",value:function(){return(0,Ut.jsxs)("div",{children:[(0,Ut.jsx)(ga,{}),(0,Ut.jsx)(sa,{title:this.state.title,abstract:this.state.abstract,onClick:this.onRefresh}),(0,Ut.jsx)(da,{label:this.state.label,prediction:this.state.prediction,label_heading:this.label_heading,prediction_heading:this.prediction_heading})]})}}]),a}(e.Component),ya=["className","cssModule","fluid","tag"];function wa(){return wa=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var a=arguments[t];for(var i in a)Object.prototype.hasOwnProperty.call(a,i)&&(e[i]=a[i])}return e},wa.apply(this,arguments)}function Da(e,t){if(null==e)return{};var a,i,n=function(e,t){if(null==e)return{};var a,i,n={},o=Object.keys(e);for(i=0;i<o.length;i++)a=o[i],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)a=o[i],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var Aa={tag:T,fluid:v().oneOfType([v().bool,v().string]),className:v().string,cssModule:v().object};function Ra(e){var t=e.className,a=e.cssModule,i=e.fluid,n=e.tag,o=void 0===n?"div":n,s=Da(e,ya),r="container";!0===i?r="container-fluid":i&&(r="container-".concat(i));var c=A(w()(t,r),a);return g.createElement(o,wa({},s,{className:c}))}Ra.propTypes=Aa;var Sa=Ra,Ta=function(e){d(a,e);var t=p(a);function a(){return n(this,a),t.apply(this,arguments)}return c(a,[{key:"render",value:function(){return(0,Ut.jsx)("div",{children:(0,Ut.jsxs)(Sa,{children:[(0,Ut.jsx)(Gt,{}),(0,Ut.jsxs)(Tt,{children:[(0,Ut.jsx)(Rt,{path:"/",element:(0,Ut.jsx)(Yt,{})}),(0,Ut.jsx)(Rt,{path:"/r0-estimates",element:(0,Ut.jsx)(pa,{})}),(0,Ut.jsx)(Rt,{path:"/sota",element:(0,Ut.jsx)(va,{})}),(0,Ut.jsx)(Rt,{path:"/:path",element:(0,Ut.jsx)(pa,{})})]}),(0,Ut.jsx)(qt,{})]})})}}]),a}(e.Component),Ca=Ta,Ea=function(e){e&&e instanceof Function&&a.e(787).then(a.bind(a,787)).then((function(t){var a=t.getCLS,i=t.getFID,n=t.getFCP,o=t.getLCP,s=t.getTTFB;a(e),i(e),n(e),o(e),s(e)}))};i.createRoot(document.getElementById("root")).render((0,Ut.jsx)(e.StrictMode,{children:(0,Ut.jsx)(Pt,{children:(0,Ut.jsx)(Ca,{})})})),Ea()}()}();
//# sourceMappingURL=main.126f56b0.js.map